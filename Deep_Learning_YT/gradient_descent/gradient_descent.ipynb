{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e8a743d-67d5-4f70-9be7-04b7168bfece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 10:16:23.561293: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-06 10:16:23.648848: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-06 10:16:23.747678: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736138783.838422  470373 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736138783.863474  470373 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-06 10:16:24.049649: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "891f899c-4418-47f2-bc02-b6c363ec5f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('insurance_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1235d010-4d1c-4f60-959f-eb782f51257a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "      <th>bought_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  affordibility  bought_insurance\n",
       "0   22              1                 0\n",
       "1   25              0                 0\n",
       "2   47              1                 1\n",
       "3   52              0                 0\n",
       "4   46              1                 1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b943b7d-3e0a-4553-92f6-398e87dd53be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9fbc662-53a5-40e8-afe0-b72cd720a33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import X\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['age', 'affordibility']], df['bought_insurance'], test_size=0.2, random_state=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f32e01a-01ca-4372-8ca1-866ca8d56df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "448830df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled['age'] = X_train_scaled['age'] / 100\n",
    "\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled['age'] = X_test_scaled['age'] / 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "265e8385",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  affordibility\n",
       "0   0.22              1\n",
       "13  0.29              0\n",
       "6   0.55              0\n",
       "17  0.58              1\n",
       "24  0.50              1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e4d59aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/muhammed-shafeeh/AI_ML/Ai-and-Ml/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "W0000 00:00:1736142828.597493  470373 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1, input_shape=(2,), activation='sigmoid', kernel_initializer='ones', bias_initializer='zeros')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1b0f743d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e3cb416d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step - accuracy: 0.5000 - loss: 0.7113\n",
      "Epoch 2/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.7110\n",
      "Epoch 3/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.7106\n",
      "Epoch 4/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.7102\n",
      "Epoch 5/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.7098\n",
      "Epoch 6/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.7094\n",
      "Epoch 7/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.7091\n",
      "Epoch 8/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.7087\n",
      "Epoch 9/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.7083\n",
      "Epoch 10/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.7079\n",
      "Epoch 11/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5000 - loss: 0.7076\n",
      "Epoch 12/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.7072\n",
      "Epoch 13/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.7068\n",
      "Epoch 14/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.7065\n",
      "Epoch 15/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.7061\n",
      "Epoch 16/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.5000 - loss: 0.7057\n",
      "Epoch 17/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.7054\n",
      "Epoch 18/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.7050\n",
      "Epoch 19/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.7046\n",
      "Epoch 20/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.7043\n",
      "Epoch 21/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.7039\n",
      "Epoch 22/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.7035\n",
      "Epoch 23/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.7032\n",
      "Epoch 24/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.7028\n",
      "Epoch 25/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.7025\n",
      "Epoch 26/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.7021\n",
      "Epoch 27/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.7017\n",
      "Epoch 28/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.7014\n",
      "Epoch 29/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.7010\n",
      "Epoch 30/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.7007\n",
      "Epoch 31/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.7003\n",
      "Epoch 32/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.7000\n",
      "Epoch 33/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6996\n",
      "Epoch 34/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5000 - loss: 0.6993\n",
      "Epoch 35/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6989\n",
      "Epoch 36/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6986\n",
      "Epoch 37/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5000 - loss: 0.6982\n",
      "Epoch 38/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6979\n",
      "Epoch 39/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6975\n",
      "Epoch 40/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.6972\n",
      "Epoch 41/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6969\n",
      "Epoch 42/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6965\n",
      "Epoch 43/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.6962\n",
      "Epoch 44/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6958\n",
      "Epoch 45/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.6955\n",
      "Epoch 46/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6952\n",
      "Epoch 47/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6948\n",
      "Epoch 48/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.6945\n",
      "Epoch 49/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6942\n",
      "Epoch 50/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6938\n",
      "Epoch 51/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6935\n",
      "Epoch 52/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6932\n",
      "Epoch 53/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6928\n",
      "Epoch 54/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.6925\n",
      "Epoch 55/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6922\n",
      "Epoch 56/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.6918\n",
      "Epoch 57/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.6915\n",
      "Epoch 58/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.6912\n",
      "Epoch 59/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.6909\n",
      "Epoch 60/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6906\n",
      "Epoch 61/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6902\n",
      "Epoch 62/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.6899\n",
      "Epoch 63/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6896\n",
      "Epoch 64/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6893\n",
      "Epoch 65/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6890\n",
      "Epoch 66/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6886\n",
      "Epoch 67/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6883\n",
      "Epoch 68/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6880\n",
      "Epoch 69/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6877\n",
      "Epoch 70/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6874\n",
      "Epoch 71/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6871\n",
      "Epoch 72/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6868\n",
      "Epoch 73/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6865\n",
      "Epoch 74/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6862\n",
      "Epoch 75/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6859\n",
      "Epoch 76/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.6856\n",
      "Epoch 77/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6853\n",
      "Epoch 78/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6849\n",
      "Epoch 79/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6846\n",
      "Epoch 80/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6843\n",
      "Epoch 81/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.6840\n",
      "Epoch 82/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6838\n",
      "Epoch 83/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6835\n",
      "Epoch 84/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6832\n",
      "Epoch 85/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.6829\n",
      "Epoch 86/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.5000 - loss: 0.6826\n",
      "Epoch 87/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.6823\n",
      "Epoch 88/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6820\n",
      "Epoch 89/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6817\n",
      "Epoch 90/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6814\n",
      "Epoch 91/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6811\n",
      "Epoch 92/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5000 - loss: 0.6808\n",
      "Epoch 93/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6805\n",
      "Epoch 94/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6803\n",
      "Epoch 95/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6800\n",
      "Epoch 96/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6797\n",
      "Epoch 97/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6794\n",
      "Epoch 98/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6791\n",
      "Epoch 99/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6788\n",
      "Epoch 100/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6786\n",
      "Epoch 101/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6783\n",
      "Epoch 102/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6780\n",
      "Epoch 103/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6777\n",
      "Epoch 104/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6775\n",
      "Epoch 105/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6772\n",
      "Epoch 106/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6769\n",
      "Epoch 107/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6766\n",
      "Epoch 108/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6764\n",
      "Epoch 109/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6761\n",
      "Epoch 110/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.6758\n",
      "Epoch 111/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6756\n",
      "Epoch 112/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6753\n",
      "Epoch 113/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6750\n",
      "Epoch 114/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6748\n",
      "Epoch 115/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6745\n",
      "Epoch 116/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6742\n",
      "Epoch 117/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.6740\n",
      "Epoch 118/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6737\n",
      "Epoch 119/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6735\n",
      "Epoch 120/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6732\n",
      "Epoch 121/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6730\n",
      "Epoch 122/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6727\n",
      "Epoch 123/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6724\n",
      "Epoch 124/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6722\n",
      "Epoch 125/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6719\n",
      "Epoch 126/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6717\n",
      "Epoch 127/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6714\n",
      "Epoch 128/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6712\n",
      "Epoch 129/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6709\n",
      "Epoch 130/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6707\n",
      "Epoch 131/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6704\n",
      "Epoch 132/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6702\n",
      "Epoch 133/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6699\n",
      "Epoch 134/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6697\n",
      "Epoch 135/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.6695\n",
      "Epoch 136/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5000 - loss: 0.6692\n",
      "Epoch 137/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5000 - loss: 0.6690\n",
      "Epoch 138/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6687\n",
      "Epoch 139/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6685\n",
      "Epoch 140/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6683\n",
      "Epoch 141/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6680\n",
      "Epoch 142/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6678\n",
      "Epoch 143/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6675\n",
      "Epoch 144/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6673\n",
      "Epoch 145/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6671\n",
      "Epoch 146/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5000 - loss: 0.6668\n",
      "Epoch 147/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6666\n",
      "Epoch 148/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6664\n",
      "Epoch 149/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.6661\n",
      "Epoch 150/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6659\n",
      "Epoch 151/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5000 - loss: 0.6657\n",
      "Epoch 152/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6655\n",
      "Epoch 153/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.6652\n",
      "Epoch 154/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6650\n",
      "Epoch 155/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6648\n",
      "Epoch 156/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5000 - loss: 0.6646\n",
      "Epoch 157/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6643\n",
      "Epoch 158/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6641\n",
      "Epoch 159/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6639\n",
      "Epoch 160/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5000 - loss: 0.6637\n",
      "Epoch 161/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5000 - loss: 0.6635\n",
      "Epoch 162/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5000 - loss: 0.6632\n",
      "Epoch 163/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5000 - loss: 0.6630\n",
      "Epoch 164/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5000 - loss: 0.6628\n",
      "Epoch 165/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.6626\n",
      "Epoch 166/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6624\n",
      "Epoch 167/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5000 - loss: 0.6622\n",
      "Epoch 168/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5000 - loss: 0.6620\n",
      "Epoch 169/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.5000 - loss: 0.6617\n",
      "Epoch 170/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5000 - loss: 0.6615\n",
      "Epoch 171/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5000 - loss: 0.6613\n",
      "Epoch 172/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5000 - loss: 0.6611\n",
      "Epoch 173/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5455 - loss: 0.6609\n",
      "Epoch 174/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5455 - loss: 0.6607\n",
      "Epoch 175/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5455 - loss: 0.6605\n",
      "Epoch 176/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5455 - loss: 0.6603\n",
      "Epoch 177/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5455 - loss: 0.6601\n",
      "Epoch 178/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5455 - loss: 0.6599\n",
      "Epoch 179/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5455 - loss: 0.6597\n",
      "Epoch 180/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5455 - loss: 0.6595\n",
      "Epoch 181/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5455 - loss: 0.6593\n",
      "Epoch 182/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5455 - loss: 0.6591\n",
      "Epoch 183/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5455 - loss: 0.6589\n",
      "Epoch 184/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5455 - loss: 0.6587\n",
      "Epoch 185/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5455 - loss: 0.6585\n",
      "Epoch 186/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5455 - loss: 0.6583\n",
      "Epoch 187/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5455 - loss: 0.6581\n",
      "Epoch 188/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5455 - loss: 0.6579\n",
      "Epoch 189/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5455 - loss: 0.6577\n",
      "Epoch 190/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5455 - loss: 0.6575\n",
      "Epoch 191/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5455 - loss: 0.6573\n",
      "Epoch 192/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5455 - loss: 0.6571\n",
      "Epoch 193/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5455 - loss: 0.6569\n",
      "Epoch 194/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5455 - loss: 0.6568\n",
      "Epoch 195/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5455 - loss: 0.6566\n",
      "Epoch 196/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5455 - loss: 0.6564\n",
      "Epoch 197/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5455 - loss: 0.6562\n",
      "Epoch 198/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5455 - loss: 0.6560\n",
      "Epoch 199/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5455 - loss: 0.6558\n",
      "Epoch 200/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5455 - loss: 0.6556\n",
      "Epoch 201/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5455 - loss: 0.6555\n",
      "Epoch 202/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5455 - loss: 0.6553\n",
      "Epoch 203/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5455 - loss: 0.6551\n",
      "Epoch 204/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5455 - loss: 0.6549\n",
      "Epoch 205/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5455 - loss: 0.6547\n",
      "Epoch 206/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5455 - loss: 0.6545\n",
      "Epoch 207/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5455 - loss: 0.6544\n",
      "Epoch 208/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5455 - loss: 0.6542\n",
      "Epoch 209/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5455 - loss: 0.6540\n",
      "Epoch 210/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5455 - loss: 0.6538\n",
      "Epoch 211/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5455 - loss: 0.6537\n",
      "Epoch 212/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5455 - loss: 0.6535\n",
      "Epoch 213/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5455 - loss: 0.6533\n",
      "Epoch 214/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5455 - loss: 0.6531\n",
      "Epoch 215/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5455 - loss: 0.6530\n",
      "Epoch 216/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5455 - loss: 0.6528\n",
      "Epoch 217/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5455 - loss: 0.6526\n",
      "Epoch 218/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5455 - loss: 0.6525\n",
      "Epoch 219/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5455 - loss: 0.6523\n",
      "Epoch 220/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.5455 - loss: 0.6521\n",
      "Epoch 221/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5455 - loss: 0.6519\n",
      "Epoch 222/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5455 - loss: 0.6518\n",
      "Epoch 223/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5455 - loss: 0.6516\n",
      "Epoch 224/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5455 - loss: 0.6515\n",
      "Epoch 225/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5455 - loss: 0.6513\n",
      "Epoch 226/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5455 - loss: 0.6511\n",
      "Epoch 227/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5455 - loss: 0.6510\n",
      "Epoch 228/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5455 - loss: 0.6508\n",
      "Epoch 229/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5455 - loss: 0.6506\n",
      "Epoch 230/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5455 - loss: 0.6505\n",
      "Epoch 231/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5455 - loss: 0.6503\n",
      "Epoch 232/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5455 - loss: 0.6502\n",
      "Epoch 233/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5455 - loss: 0.6500\n",
      "Epoch 234/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5455 - loss: 0.6498\n",
      "Epoch 235/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5455 - loss: 0.6497\n",
      "Epoch 236/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5455 - loss: 0.6495\n",
      "Epoch 237/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5455 - loss: 0.6494\n",
      "Epoch 238/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5455 - loss: 0.6492\n",
      "Epoch 239/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5455 - loss: 0.6491\n",
      "Epoch 240/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.5455 - loss: 0.6489\n",
      "Epoch 241/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5455 - loss: 0.6488\n",
      "Epoch 242/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5909 - loss: 0.6486\n",
      "Epoch 243/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5909 - loss: 0.6485\n",
      "Epoch 244/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5909 - loss: 0.6483\n",
      "Epoch 245/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5909 - loss: 0.6482\n",
      "Epoch 246/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5909 - loss: 0.6480\n",
      "Epoch 247/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5909 - loss: 0.6479\n",
      "Epoch 248/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5909 - loss: 0.6477\n",
      "Epoch 249/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5909 - loss: 0.6476\n",
      "Epoch 250/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5909 - loss: 0.6474\n",
      "Epoch 251/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.5909 - loss: 0.6473\n",
      "Epoch 252/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.5909 - loss: 0.6471\n",
      "Epoch 253/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.5909 - loss: 0.6470\n",
      "Epoch 254/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.5909 - loss: 0.6468\n",
      "Epoch 255/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.5909 - loss: 0.6467\n",
      "Epoch 256/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.5909 - loss: 0.6465\n",
      "Epoch 257/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5909 - loss: 0.6464\n",
      "Epoch 258/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5909 - loss: 0.6463\n",
      "Epoch 259/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6364 - loss: 0.6461\n",
      "Epoch 260/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6364 - loss: 0.6460\n",
      "Epoch 261/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6364 - loss: 0.6458\n",
      "Epoch 262/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6364 - loss: 0.6457\n",
      "Epoch 263/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6364 - loss: 0.6456\n",
      "Epoch 264/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6364 - loss: 0.6454\n",
      "Epoch 265/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6453\n",
      "Epoch 266/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6452\n",
      "Epoch 267/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6450\n",
      "Epoch 268/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6449\n",
      "Epoch 269/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6448\n",
      "Epoch 270/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6446\n",
      "Epoch 271/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6445\n",
      "Epoch 272/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6364 - loss: 0.6444\n",
      "Epoch 273/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6364 - loss: 0.6442\n",
      "Epoch 274/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6364 - loss: 0.6441\n",
      "Epoch 275/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6364 - loss: 0.6440\n",
      "Epoch 276/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6364 - loss: 0.6438\n",
      "Epoch 277/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6364 - loss: 0.6437\n",
      "Epoch 278/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6364 - loss: 0.6436\n",
      "Epoch 279/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6364 - loss: 0.6435\n",
      "Epoch 280/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6364 - loss: 0.6433\n",
      "Epoch 281/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6364 - loss: 0.6432\n",
      "Epoch 282/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6364 - loss: 0.6431\n",
      "Epoch 283/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6364 - loss: 0.6430\n",
      "Epoch 284/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6428\n",
      "Epoch 285/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6364 - loss: 0.6427\n",
      "Epoch 286/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6364 - loss: 0.6426\n",
      "Epoch 287/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6364 - loss: 0.6425\n",
      "Epoch 288/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6364 - loss: 0.6423\n",
      "Epoch 289/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6364 - loss: 0.6422\n",
      "Epoch 290/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6364 - loss: 0.6421\n",
      "Epoch 291/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6364 - loss: 0.6420\n",
      "Epoch 292/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6364 - loss: 0.6419\n",
      "Epoch 293/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6364 - loss: 0.6417\n",
      "Epoch 294/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6364 - loss: 0.6416\n",
      "Epoch 295/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6415\n",
      "Epoch 296/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6364 - loss: 0.6414\n",
      "Epoch 297/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6413\n",
      "Epoch 298/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6411\n",
      "Epoch 299/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6410\n",
      "Epoch 300/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6409\n",
      "Epoch 301/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6364 - loss: 0.6408\n",
      "Epoch 302/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6364 - loss: 0.6407\n",
      "Epoch 303/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6364 - loss: 0.6406\n",
      "Epoch 304/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6364 - loss: 0.6405\n",
      "Epoch 305/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6403\n",
      "Epoch 306/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6402\n",
      "Epoch 307/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6401\n",
      "Epoch 308/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6400\n",
      "Epoch 309/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6364 - loss: 0.6399\n",
      "Epoch 310/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6364 - loss: 0.6398\n",
      "Epoch 311/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6364 - loss: 0.6397\n",
      "Epoch 312/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6396\n",
      "Epoch 313/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6364 - loss: 0.6395\n",
      "Epoch 314/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6364 - loss: 0.6394\n",
      "Epoch 315/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6364 - loss: 0.6392\n",
      "Epoch 316/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6364 - loss: 0.6391\n",
      "Epoch 317/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6390\n",
      "Epoch 318/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6389\n",
      "Epoch 319/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6388\n",
      "Epoch 320/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6387\n",
      "Epoch 321/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6386\n",
      "Epoch 322/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6364 - loss: 0.6385\n",
      "Epoch 323/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6364 - loss: 0.6384\n",
      "Epoch 324/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6383\n",
      "Epoch 325/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6382\n",
      "Epoch 326/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6381\n",
      "Epoch 327/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6380\n",
      "Epoch 328/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6379\n",
      "Epoch 329/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6378\n",
      "Epoch 330/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6364 - loss: 0.6377\n",
      "Epoch 331/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6376\n",
      "Epoch 332/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6364 - loss: 0.6375\n",
      "Epoch 333/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6364 - loss: 0.6374\n",
      "Epoch 334/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6364 - loss: 0.6373\n",
      "Epoch 335/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6364 - loss: 0.6372\n",
      "Epoch 336/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6364 - loss: 0.6371\n",
      "Epoch 337/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6370\n",
      "Epoch 338/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6364 - loss: 0.6369\n",
      "Epoch 339/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6364 - loss: 0.6368\n",
      "Epoch 340/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6364 - loss: 0.6367\n",
      "Epoch 341/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6366\n",
      "Epoch 342/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6365\n",
      "Epoch 343/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6364 - loss: 0.6364\n",
      "Epoch 344/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6363\n",
      "Epoch 345/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6364 - loss: 0.6362\n",
      "Epoch 346/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6364 - loss: 0.6361\n",
      "Epoch 347/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6364 - loss: 0.6361\n",
      "Epoch 348/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6364 - loss: 0.6360\n",
      "Epoch 349/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6364 - loss: 0.6359\n",
      "Epoch 350/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6364 - loss: 0.6358\n",
      "Epoch 351/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6357\n",
      "Epoch 352/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6356\n",
      "Epoch 353/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6355\n",
      "Epoch 354/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6354\n",
      "Epoch 355/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6364 - loss: 0.6353\n",
      "Epoch 356/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6364 - loss: 0.6352\n",
      "Epoch 357/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6352\n",
      "Epoch 358/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6364 - loss: 0.6351\n",
      "Epoch 359/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6350\n",
      "Epoch 360/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6349\n",
      "Epoch 361/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6348\n",
      "Epoch 362/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6347\n",
      "Epoch 363/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6346\n",
      "Epoch 364/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6364 - loss: 0.6345\n",
      "Epoch 365/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6364 - loss: 0.6345\n",
      "Epoch 366/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6364 - loss: 0.6344\n",
      "Epoch 367/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6364 - loss: 0.6343\n",
      "Epoch 368/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6364 - loss: 0.6342\n",
      "Epoch 369/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6364 - loss: 0.6341\n",
      "Epoch 370/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6364 - loss: 0.6340\n",
      "Epoch 371/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6364 - loss: 0.6339\n",
      "Epoch 372/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6364 - loss: 0.6339\n",
      "Epoch 373/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6338\n",
      "Epoch 374/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6337\n",
      "Epoch 375/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6336\n",
      "Epoch 376/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6335\n",
      "Epoch 377/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6364 - loss: 0.6335\n",
      "Epoch 378/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6364 - loss: 0.6334\n",
      "Epoch 379/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6364 - loss: 0.6333\n",
      "Epoch 380/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6364 - loss: 0.6332\n",
      "Epoch 381/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6364 - loss: 0.6331\n",
      "Epoch 382/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6364 - loss: 0.6331\n",
      "Epoch 383/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6330\n",
      "Epoch 384/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6329\n",
      "Epoch 385/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6328\n",
      "Epoch 386/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6364 - loss: 0.6327\n",
      "Epoch 387/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6364 - loss: 0.6327\n",
      "Epoch 388/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6364 - loss: 0.6326\n",
      "Epoch 389/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6364 - loss: 0.6325\n",
      "Epoch 390/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6364 - loss: 0.6324\n",
      "Epoch 391/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6364 - loss: 0.6323\n",
      "Epoch 392/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6364 - loss: 0.6323\n",
      "Epoch 393/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6322\n",
      "Epoch 394/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6364 - loss: 0.6321\n",
      "Epoch 395/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6364 - loss: 0.6320\n",
      "Epoch 396/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6320\n",
      "Epoch 397/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6319\n",
      "Epoch 398/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6318\n",
      "Epoch 399/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6317\n",
      "Epoch 400/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6317\n",
      "Epoch 401/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6316\n",
      "Epoch 402/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6315\n",
      "Epoch 403/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6314\n",
      "Epoch 404/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6314\n",
      "Epoch 405/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6364 - loss: 0.6313\n",
      "Epoch 406/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6312\n",
      "Epoch 407/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6312\n",
      "Epoch 408/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6311\n",
      "Epoch 409/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6310\n",
      "Epoch 410/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6309\n",
      "Epoch 411/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6309\n",
      "Epoch 412/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6308\n",
      "Epoch 413/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6307\n",
      "Epoch 414/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6307\n",
      "Epoch 415/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6306\n",
      "Epoch 416/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6305\n",
      "Epoch 417/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6305\n",
      "Epoch 418/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6304\n",
      "Epoch 419/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6364 - loss: 0.6303\n",
      "Epoch 420/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6364 - loss: 0.6302\n",
      "Epoch 421/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6302\n",
      "Epoch 422/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6301\n",
      "Epoch 423/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6300\n",
      "Epoch 424/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6300\n",
      "Epoch 425/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6299\n",
      "Epoch 426/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6298\n",
      "Epoch 427/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6364 - loss: 0.6298\n",
      "Epoch 428/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6297\n",
      "Epoch 429/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6296\n",
      "Epoch 430/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6296\n",
      "Epoch 431/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6295\n",
      "Epoch 432/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6294\n",
      "Epoch 433/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6294\n",
      "Epoch 434/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6293\n",
      "Epoch 435/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6292\n",
      "Epoch 436/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6292\n",
      "Epoch 437/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6291\n",
      "Epoch 438/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6290\n",
      "Epoch 439/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6290\n",
      "Epoch 440/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6289\n",
      "Epoch 441/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6288\n",
      "Epoch 442/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6364 - loss: 0.6288\n",
      "Epoch 443/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6364 - loss: 0.6287\n",
      "Epoch 444/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6364 - loss: 0.6287\n",
      "Epoch 445/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6286\n",
      "Epoch 446/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6285\n",
      "Epoch 447/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6285\n",
      "Epoch 448/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6284\n",
      "Epoch 449/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6283\n",
      "Epoch 450/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6283\n",
      "Epoch 451/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6282\n",
      "Epoch 452/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6282\n",
      "Epoch 453/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6281\n",
      "Epoch 454/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6364 - loss: 0.6280\n",
      "Epoch 455/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6364 - loss: 0.6280\n",
      "Epoch 456/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6364 - loss: 0.6279\n",
      "Epoch 457/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6364 - loss: 0.6278\n",
      "Epoch 458/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6364 - loss: 0.6278\n",
      "Epoch 459/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6277\n",
      "Epoch 460/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6364 - loss: 0.6277\n",
      "Epoch 461/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6364 - loss: 0.6276\n",
      "Epoch 462/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6275\n",
      "Epoch 463/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6275\n",
      "Epoch 464/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6274\n",
      "Epoch 465/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6274\n",
      "Epoch 466/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6364 - loss: 0.6273\n",
      "Epoch 467/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6364 - loss: 0.6272\n",
      "Epoch 468/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6364 - loss: 0.6272\n",
      "Epoch 469/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6364 - loss: 0.6271\n",
      "Epoch 470/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6364 - loss: 0.6271\n",
      "Epoch 471/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6364 - loss: 0.6270\n",
      "Epoch 472/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6269\n",
      "Epoch 473/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6269\n",
      "Epoch 474/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6364 - loss: 0.6268\n",
      "Epoch 475/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6364 - loss: 0.6268\n",
      "Epoch 476/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6364 - loss: 0.6267\n",
      "Epoch 477/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6364 - loss: 0.6267\n",
      "Epoch 478/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6266\n",
      "Epoch 479/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6265\n",
      "Epoch 480/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6364 - loss: 0.6265\n",
      "Epoch 481/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6364 - loss: 0.6264\n",
      "Epoch 482/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6264\n",
      "Epoch 483/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6263\n",
      "Epoch 484/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6262\n",
      "Epoch 485/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6262\n",
      "Epoch 486/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6261\n",
      "Epoch 487/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6261\n",
      "Epoch 488/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6260\n",
      "Epoch 489/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6260\n",
      "Epoch 490/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6259\n",
      "Epoch 491/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6259\n",
      "Epoch 492/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6258\n",
      "Epoch 493/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6257\n",
      "Epoch 494/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6257\n",
      "Epoch 495/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6364 - loss: 0.6256\n",
      "Epoch 496/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6364 - loss: 0.6256\n",
      "Epoch 497/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6364 - loss: 0.6255\n",
      "Epoch 498/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6364 - loss: 0.6255\n",
      "Epoch 499/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6364 - loss: 0.6254\n",
      "Epoch 500/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6364 - loss: 0.6253\n",
      "Epoch 501/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6364 - loss: 0.6253\n",
      "Epoch 502/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6252\n",
      "Epoch 503/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6252\n",
      "Epoch 504/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6251\n",
      "Epoch 505/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6251\n",
      "Epoch 506/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6250\n",
      "Epoch 507/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6364 - loss: 0.6250\n",
      "Epoch 508/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6249\n",
      "Epoch 509/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6249\n",
      "Epoch 510/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6364 - loss: 0.6248\n",
      "Epoch 511/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6364 - loss: 0.6247\n",
      "Epoch 512/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6364 - loss: 0.6247\n",
      "Epoch 513/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6364 - loss: 0.6246\n",
      "Epoch 514/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6364 - loss: 0.6246\n",
      "Epoch 515/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6364 - loss: 0.6245\n",
      "Epoch 516/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6364 - loss: 0.6245\n",
      "Epoch 517/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6364 - loss: 0.6244\n",
      "Epoch 518/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6364 - loss: 0.6244\n",
      "Epoch 519/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6243\n",
      "Epoch 520/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6243\n",
      "Epoch 521/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6242\n",
      "Epoch 522/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6242\n",
      "Epoch 523/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6818 - loss: 0.6241\n",
      "Epoch 524/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6241\n",
      "Epoch 525/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6240\n",
      "Epoch 526/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6239\n",
      "Epoch 527/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6818 - loss: 0.6239\n",
      "Epoch 528/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6818 - loss: 0.6238\n",
      "Epoch 529/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6238\n",
      "Epoch 530/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6237\n",
      "Epoch 531/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6237\n",
      "Epoch 532/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6236\n",
      "Epoch 533/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6236\n",
      "Epoch 534/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6235\n",
      "Epoch 535/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6235\n",
      "Epoch 536/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6234\n",
      "Epoch 537/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6234\n",
      "Epoch 538/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6233\n",
      "Epoch 539/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6233\n",
      "Epoch 540/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6232\n",
      "Epoch 541/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6232\n",
      "Epoch 542/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6231\n",
      "Epoch 543/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6231\n",
      "Epoch 544/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6230\n",
      "Epoch 545/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6230\n",
      "Epoch 546/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6229\n",
      "Epoch 547/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6229\n",
      "Epoch 548/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6228\n",
      "Epoch 549/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6227\n",
      "Epoch 550/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6227\n",
      "Epoch 551/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6226\n",
      "Epoch 552/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6226\n",
      "Epoch 553/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6225\n",
      "Epoch 554/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6225\n",
      "Epoch 555/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.6224\n",
      "Epoch 556/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6224\n",
      "Epoch 557/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6223\n",
      "Epoch 558/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6223\n",
      "Epoch 559/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6222\n",
      "Epoch 560/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6222\n",
      "Epoch 561/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6221\n",
      "Epoch 562/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6221\n",
      "Epoch 563/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.6220\n",
      "Epoch 564/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6220\n",
      "Epoch 565/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6219\n",
      "Epoch 566/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6219\n",
      "Epoch 567/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6218\n",
      "Epoch 568/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6218\n",
      "Epoch 569/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6217\n",
      "Epoch 570/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6217\n",
      "Epoch 571/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.6216\n",
      "Epoch 572/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6216\n",
      "Epoch 573/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6215\n",
      "Epoch 574/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6215\n",
      "Epoch 575/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6214\n",
      "Epoch 576/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6214\n",
      "Epoch 577/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6213\n",
      "Epoch 578/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6213\n",
      "Epoch 579/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6212\n",
      "Epoch 580/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6212\n",
      "Epoch 581/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6211\n",
      "Epoch 582/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6211\n",
      "Epoch 583/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.6210\n",
      "Epoch 584/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6210\n",
      "Epoch 585/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6209\n",
      "Epoch 586/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6209\n",
      "Epoch 587/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6208\n",
      "Epoch 588/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7273 - loss: 0.6208\n",
      "Epoch 589/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7273 - loss: 0.6207\n",
      "Epoch 590/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6207\n",
      "Epoch 591/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6206\n",
      "Epoch 592/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6206\n",
      "Epoch 593/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6205\n",
      "Epoch 594/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6205\n",
      "Epoch 595/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6204\n",
      "Epoch 596/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6204\n",
      "Epoch 597/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6203\n",
      "Epoch 598/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6203\n",
      "Epoch 599/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7273 - loss: 0.6202\n",
      "Epoch 600/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6202\n",
      "Epoch 601/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6201\n",
      "Epoch 602/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6201\n",
      "Epoch 603/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6200\n",
      "Epoch 604/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6200\n",
      "Epoch 605/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7273 - loss: 0.6200\n",
      "Epoch 606/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.6199\n",
      "Epoch 607/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6199\n",
      "Epoch 608/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6198\n",
      "Epoch 609/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6198\n",
      "Epoch 610/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6197\n",
      "Epoch 611/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6197\n",
      "Epoch 612/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6196\n",
      "Epoch 613/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6196\n",
      "Epoch 614/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6195\n",
      "Epoch 615/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6195\n",
      "Epoch 616/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6194\n",
      "Epoch 617/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7273 - loss: 0.6194\n",
      "Epoch 618/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6193\n",
      "Epoch 619/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6193\n",
      "Epoch 620/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6192\n",
      "Epoch 621/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6192\n",
      "Epoch 622/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6191\n",
      "Epoch 623/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6191\n",
      "Epoch 624/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6190\n",
      "Epoch 625/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.6190\n",
      "Epoch 626/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7273 - loss: 0.6189\n",
      "Epoch 627/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.6189\n",
      "Epoch 628/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7273 - loss: 0.6188\n",
      "Epoch 629/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6188\n",
      "Epoch 630/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6187\n",
      "Epoch 631/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6187\n",
      "Epoch 632/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6186\n",
      "Epoch 633/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6186\n",
      "Epoch 634/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.6185\n",
      "Epoch 635/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.6185\n",
      "Epoch 636/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.6184\n",
      "Epoch 637/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.6184\n",
      "Epoch 638/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7273 - loss: 0.6183\n",
      "Epoch 639/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7273 - loss: 0.6183\n",
      "Epoch 640/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.6182\n",
      "Epoch 641/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.6182\n",
      "Epoch 642/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.6181\n",
      "Epoch 643/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6181\n",
      "Epoch 644/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7273 - loss: 0.6181\n",
      "Epoch 645/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.6180\n",
      "Epoch 646/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.6180\n",
      "Epoch 647/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6179\n",
      "Epoch 648/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.6179\n",
      "Epoch 649/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.6178\n",
      "Epoch 650/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.6178\n",
      "Epoch 651/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.6177\n",
      "Epoch 652/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7273 - loss: 0.6177\n",
      "Epoch 653/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7273 - loss: 0.6176\n",
      "Epoch 654/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7273 - loss: 0.6176\n",
      "Epoch 655/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.6175\n",
      "Epoch 656/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.6175\n",
      "Epoch 657/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.6174\n",
      "Epoch 658/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.6174\n",
      "Epoch 659/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6173\n",
      "Epoch 660/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7273 - loss: 0.6173\n",
      "Epoch 661/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7273 - loss: 0.6172\n",
      "Epoch 662/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7273 - loss: 0.6172\n",
      "Epoch 663/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.6171\n",
      "Epoch 664/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.6171\n",
      "Epoch 665/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.6170\n",
      "Epoch 666/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6170\n",
      "Epoch 667/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6169\n",
      "Epoch 668/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.6169\n",
      "Epoch 669/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.6168\n",
      "Epoch 670/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.6168\n",
      "Epoch 671/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6167\n",
      "Epoch 672/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.6167\n",
      "Epoch 673/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.6166\n",
      "Epoch 674/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7273 - loss: 0.6166\n",
      "Epoch 675/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.6166\n",
      "Epoch 676/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7273 - loss: 0.6165\n",
      "Epoch 677/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.6165\n",
      "Epoch 678/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6164\n",
      "Epoch 679/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.6164\n",
      "Epoch 680/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.6163\n",
      "Epoch 681/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.6163\n",
      "Epoch 682/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6162\n",
      "Epoch 683/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7273 - loss: 0.6162\n",
      "Epoch 684/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.6161\n",
      "Epoch 685/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.6161\n",
      "Epoch 686/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.6160\n",
      "Epoch 687/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.6160\n",
      "Epoch 688/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6159\n",
      "Epoch 689/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6159\n",
      "Epoch 690/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.6158\n",
      "Epoch 691/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7273 - loss: 0.6158\n",
      "Epoch 692/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7273 - loss: 0.6157\n",
      "Epoch 693/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.6157\n",
      "Epoch 694/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6156\n",
      "Epoch 695/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.6156\n",
      "Epoch 696/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7273 - loss: 0.6155\n",
      "Epoch 697/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7273 - loss: 0.6155\n",
      "Epoch 698/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7273 - loss: 0.6154\n",
      "Epoch 699/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.6154\n",
      "Epoch 700/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.6153\n",
      "Epoch 701/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6153\n",
      "Epoch 702/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6153\n",
      "Epoch 703/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6152\n",
      "Epoch 704/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.6152\n",
      "Epoch 705/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.6151\n",
      "Epoch 706/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6151\n",
      "Epoch 707/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.6150\n",
      "Epoch 708/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6150\n",
      "Epoch 709/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.6149\n",
      "Epoch 710/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.6149\n",
      "Epoch 711/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7273 - loss: 0.6148\n",
      "Epoch 712/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.6148\n",
      "Epoch 713/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.6147\n",
      "Epoch 714/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.6147\n",
      "Epoch 715/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7273 - loss: 0.6146\n",
      "Epoch 716/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.6146\n",
      "Epoch 717/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.6145\n",
      "Epoch 718/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7273 - loss: 0.6145\n",
      "Epoch 719/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.6144\n",
      "Epoch 720/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7273 - loss: 0.6144\n",
      "Epoch 721/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7273 - loss: 0.6143\n",
      "Epoch 722/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6143\n",
      "Epoch 723/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6142\n",
      "Epoch 724/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.6142\n",
      "Epoch 725/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6141\n",
      "Epoch 726/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.6141\n",
      "Epoch 727/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.6140\n",
      "Epoch 728/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.6140\n",
      "Epoch 729/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.6139\n",
      "Epoch 730/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.6139\n",
      "Epoch 731/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6138\n",
      "Epoch 732/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.6138\n",
      "Epoch 733/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.6138\n",
      "Epoch 734/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6137\n",
      "Epoch 735/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.6137\n",
      "Epoch 736/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.6136\n",
      "Epoch 737/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.6136\n",
      "Epoch 738/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7273 - loss: 0.6135\n",
      "Epoch 739/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7273 - loss: 0.6135\n",
      "Epoch 740/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6134\n",
      "Epoch 741/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7273 - loss: 0.6134\n",
      "Epoch 742/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.6133\n",
      "Epoch 743/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6133\n",
      "Epoch 744/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.6132\n",
      "Epoch 745/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6132\n",
      "Epoch 746/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.6131\n",
      "Epoch 747/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7273 - loss: 0.6131\n",
      "Epoch 748/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7273 - loss: 0.6130\n",
      "Epoch 749/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7273 - loss: 0.6130\n",
      "Epoch 750/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6129\n",
      "Epoch 751/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6129\n",
      "Epoch 752/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.6128\n",
      "Epoch 753/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7273 - loss: 0.6128\n",
      "Epoch 754/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7273 - loss: 0.6127\n",
      "Epoch 755/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7273 - loss: 0.6127\n",
      "Epoch 756/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7273 - loss: 0.6126\n",
      "Epoch 757/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.6126\n",
      "Epoch 758/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7273 - loss: 0.6125\n",
      "Epoch 759/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6125\n",
      "Epoch 760/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.6124\n",
      "Epoch 761/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6124\n",
      "Epoch 762/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7273 - loss: 0.6123\n",
      "Epoch 763/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7273 - loss: 0.6123\n",
      "Epoch 764/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.6122\n",
      "Epoch 765/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.6122\n",
      "Epoch 766/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7273 - loss: 0.6122\n",
      "Epoch 767/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6121\n",
      "Epoch 768/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6121\n",
      "Epoch 769/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6120\n",
      "Epoch 770/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7273 - loss: 0.6120\n",
      "Epoch 771/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7273 - loss: 0.6119\n",
      "Epoch 772/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7273 - loss: 0.6119\n",
      "Epoch 773/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.6118\n",
      "Epoch 774/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6118\n",
      "Epoch 775/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6117\n",
      "Epoch 776/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7273 - loss: 0.6117\n",
      "Epoch 777/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.6116\n",
      "Epoch 778/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.6116\n",
      "Epoch 779/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.6115\n",
      "Epoch 780/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.6115\n",
      "Epoch 781/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.6114\n",
      "Epoch 782/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.6114\n",
      "Epoch 783/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6113\n",
      "Epoch 784/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.6113\n",
      "Epoch 785/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6112\n",
      "Epoch 786/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6112\n",
      "Epoch 787/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6111\n",
      "Epoch 788/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6111\n",
      "Epoch 789/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.6110\n",
      "Epoch 790/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.6110\n",
      "Epoch 791/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6109\n",
      "Epoch 792/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6109\n",
      "Epoch 793/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.6108\n",
      "Epoch 794/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.6108\n",
      "Epoch 795/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6107\n",
      "Epoch 796/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.6107\n",
      "Epoch 797/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6106\n",
      "Epoch 798/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6106\n",
      "Epoch 799/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6105\n",
      "Epoch 800/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.6105\n",
      "Epoch 801/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6104\n",
      "Epoch 802/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6104\n",
      "Epoch 803/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6104\n",
      "Epoch 804/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.6103\n",
      "Epoch 805/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7273 - loss: 0.6103\n",
      "Epoch 806/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7273 - loss: 0.6102\n",
      "Epoch 807/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7273 - loss: 0.6102\n",
      "Epoch 808/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.6101\n",
      "Epoch 809/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.6101\n",
      "Epoch 810/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6100\n",
      "Epoch 811/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6100\n",
      "Epoch 812/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7273 - loss: 0.6099\n",
      "Epoch 813/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6099\n",
      "Epoch 814/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6098\n",
      "Epoch 815/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6098\n",
      "Epoch 816/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6097\n",
      "Epoch 817/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6097\n",
      "Epoch 818/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6096\n",
      "Epoch 819/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6096\n",
      "Epoch 820/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6095\n",
      "Epoch 821/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6095\n",
      "Epoch 822/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7273 - loss: 0.6094\n",
      "Epoch 823/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6094\n",
      "Epoch 824/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6093\n",
      "Epoch 825/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6093\n",
      "Epoch 826/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6092\n",
      "Epoch 827/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6092\n",
      "Epoch 828/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6091\n",
      "Epoch 829/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.6091\n",
      "Epoch 830/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6090\n",
      "Epoch 831/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6090\n",
      "Epoch 832/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6089\n",
      "Epoch 833/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6089\n",
      "Epoch 834/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6088\n",
      "Epoch 835/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6088\n",
      "Epoch 836/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6087\n",
      "Epoch 837/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6087\n",
      "Epoch 838/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6086\n",
      "Epoch 839/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6086\n",
      "Epoch 840/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6085\n",
      "Epoch 841/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6085\n",
      "Epoch 842/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6084\n",
      "Epoch 843/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6084\n",
      "Epoch 844/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.6083\n",
      "Epoch 845/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7273 - loss: 0.6083\n",
      "Epoch 846/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7273 - loss: 0.6082\n",
      "Epoch 847/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6082\n",
      "Epoch 848/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6081\n",
      "Epoch 849/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6081\n",
      "Epoch 850/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6080\n",
      "Epoch 851/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6080\n",
      "Epoch 852/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6080\n",
      "Epoch 853/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6079\n",
      "Epoch 854/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6079\n",
      "Epoch 855/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6078\n",
      "Epoch 856/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7273 - loss: 0.6078\n",
      "Epoch 857/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6077\n",
      "Epoch 858/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6077\n",
      "Epoch 859/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7273 - loss: 0.6076\n",
      "Epoch 860/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6076\n",
      "Epoch 861/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6075\n",
      "Epoch 862/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7273 - loss: 0.6075\n",
      "Epoch 863/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6074\n",
      "Epoch 864/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6074\n",
      "Epoch 865/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6073\n",
      "Epoch 866/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6073\n",
      "Epoch 867/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6072\n",
      "Epoch 868/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.6072\n",
      "Epoch 869/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6071\n",
      "Epoch 870/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6071\n",
      "Epoch 871/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6070\n",
      "Epoch 872/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6070\n",
      "Epoch 873/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6069\n",
      "Epoch 874/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7273 - loss: 0.6069\n",
      "Epoch 875/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7273 - loss: 0.6068\n",
      "Epoch 876/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6068\n",
      "Epoch 877/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7273 - loss: 0.6067\n",
      "Epoch 878/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7273 - loss: 0.6067\n",
      "Epoch 879/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6066\n",
      "Epoch 880/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.6066\n",
      "Epoch 881/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6065\n",
      "Epoch 882/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7273 - loss: 0.6065\n",
      "Epoch 883/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.6064\n",
      "Epoch 884/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7273 - loss: 0.6064\n",
      "Epoch 885/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.6063\n",
      "Epoch 886/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.6063\n",
      "Epoch 887/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6062\n",
      "Epoch 888/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6062\n",
      "Epoch 889/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.6061\n",
      "Epoch 890/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6061\n",
      "Epoch 891/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.6060\n",
      "Epoch 892/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.6060\n",
      "Epoch 893/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.6059\n",
      "Epoch 894/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.6059\n",
      "Epoch 895/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.6058\n",
      "Epoch 896/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.6058\n",
      "Epoch 897/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.6057\n",
      "Epoch 898/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.6057\n",
      "Epoch 899/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.6056\n",
      "Epoch 900/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6056\n",
      "Epoch 901/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6055\n",
      "Epoch 902/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6055\n",
      "Epoch 903/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6054\n",
      "Epoch 904/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6054\n",
      "Epoch 905/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6053\n",
      "Epoch 906/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.6053\n",
      "Epoch 907/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.6052\n",
      "Epoch 908/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6052\n",
      "Epoch 909/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6051\n",
      "Epoch 910/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.6051\n",
      "Epoch 911/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6050\n",
      "Epoch 912/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6050\n",
      "Epoch 913/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6049\n",
      "Epoch 914/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.6049\n",
      "Epoch 915/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.6048\n",
      "Epoch 916/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6048\n",
      "Epoch 917/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6047\n",
      "Epoch 918/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6047\n",
      "Epoch 919/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6046\n",
      "Epoch 920/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6046\n",
      "Epoch 921/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6045\n",
      "Epoch 922/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6045\n",
      "Epoch 923/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6044\n",
      "Epoch 924/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6044\n",
      "Epoch 925/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6043\n",
      "Epoch 926/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6043\n",
      "Epoch 927/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6042\n",
      "Epoch 928/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6042\n",
      "Epoch 929/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6041\n",
      "Epoch 930/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6041\n",
      "Epoch 931/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6040\n",
      "Epoch 932/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6040\n",
      "Epoch 933/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6040\n",
      "Epoch 934/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.6039\n",
      "Epoch 935/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6039\n",
      "Epoch 936/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6038\n",
      "Epoch 937/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6038\n",
      "Epoch 938/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6037\n",
      "Epoch 939/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6037\n",
      "Epoch 940/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6036\n",
      "Epoch 941/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6036\n",
      "Epoch 942/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6035\n",
      "Epoch 943/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6035\n",
      "Epoch 944/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6034\n",
      "Epoch 945/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.6034\n",
      "Epoch 946/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.6033\n",
      "Epoch 947/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6033\n",
      "Epoch 948/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6032\n",
      "Epoch 949/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6032\n",
      "Epoch 950/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6031\n",
      "Epoch 951/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.6031\n",
      "Epoch 952/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6030\n",
      "Epoch 953/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6030\n",
      "Epoch 954/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6029\n",
      "Epoch 955/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6029\n",
      "Epoch 956/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6028\n",
      "Epoch 957/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6028\n",
      "Epoch 958/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6027\n",
      "Epoch 959/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6027\n",
      "Epoch 960/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6026\n",
      "Epoch 961/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6026\n",
      "Epoch 962/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6025\n",
      "Epoch 963/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6025\n",
      "Epoch 964/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6024\n",
      "Epoch 965/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6024\n",
      "Epoch 966/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6023\n",
      "Epoch 967/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.6023\n",
      "Epoch 968/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.6022\n",
      "Epoch 969/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.6022\n",
      "Epoch 970/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.6021\n",
      "Epoch 971/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6818 - loss: 0.6021\n",
      "Epoch 972/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6020\n",
      "Epoch 973/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6818 - loss: 0.6020\n",
      "Epoch 974/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6019\n",
      "Epoch 975/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.6019\n",
      "Epoch 976/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.6018\n",
      "Epoch 977/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6018\n",
      "Epoch 978/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6017\n",
      "Epoch 979/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6017\n",
      "Epoch 980/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6016\n",
      "Epoch 981/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6016\n",
      "Epoch 982/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6818 - loss: 0.6015\n",
      "Epoch 983/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6015\n",
      "Epoch 984/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6014\n",
      "Epoch 985/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6014\n",
      "Epoch 986/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6818 - loss: 0.6013\n",
      "Epoch 987/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6013\n",
      "Epoch 988/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6012\n",
      "Epoch 989/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6012\n",
      "Epoch 990/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6011\n",
      "Epoch 991/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6011\n",
      "Epoch 992/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6010\n",
      "Epoch 993/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6010\n",
      "Epoch 994/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6009\n",
      "Epoch 995/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6009\n",
      "Epoch 996/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6008\n",
      "Epoch 997/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6008\n",
      "Epoch 998/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.6007\n",
      "Epoch 999/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6007\n",
      "Epoch 1000/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.6006\n",
      "Epoch 1001/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6006\n",
      "Epoch 1002/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.6005\n",
      "Epoch 1003/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6005\n",
      "Epoch 1004/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.6004\n",
      "Epoch 1005/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.6004\n",
      "Epoch 1006/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.6003\n",
      "Epoch 1007/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6003\n",
      "Epoch 1008/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6818 - loss: 0.6002\n",
      "Epoch 1009/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.6002\n",
      "Epoch 1010/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.6001\n",
      "Epoch 1011/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.6001\n",
      "Epoch 1012/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.6000\n",
      "Epoch 1013/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.6000\n",
      "Epoch 1014/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5999\n",
      "Epoch 1015/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5999\n",
      "Epoch 1016/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5998\n",
      "Epoch 1017/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5998\n",
      "Epoch 1018/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5997\n",
      "Epoch 1019/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5997\n",
      "Epoch 1020/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5996\n",
      "Epoch 1021/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5996\n",
      "Epoch 1022/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5995\n",
      "Epoch 1023/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5995\n",
      "Epoch 1024/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5994\n",
      "Epoch 1025/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5994\n",
      "Epoch 1026/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5993\n",
      "Epoch 1027/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5993\n",
      "Epoch 1028/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5992\n",
      "Epoch 1029/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5992\n",
      "Epoch 1030/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6818 - loss: 0.5991\n",
      "Epoch 1031/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6818 - loss: 0.5991\n",
      "Epoch 1032/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5990\n",
      "Epoch 1033/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5990\n",
      "Epoch 1034/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5989\n",
      "Epoch 1035/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5989\n",
      "Epoch 1036/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5988\n",
      "Epoch 1037/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5988\n",
      "Epoch 1038/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5987\n",
      "Epoch 1039/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5987\n",
      "Epoch 1040/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5986\n",
      "Epoch 1041/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5986\n",
      "Epoch 1042/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5985\n",
      "Epoch 1043/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5985\n",
      "Epoch 1044/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5984\n",
      "Epoch 1045/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5984\n",
      "Epoch 1046/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5983\n",
      "Epoch 1047/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5983\n",
      "Epoch 1048/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5982\n",
      "Epoch 1049/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5982\n",
      "Epoch 1050/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5981\n",
      "Epoch 1051/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5981\n",
      "Epoch 1052/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5980\n",
      "Epoch 1053/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5980\n",
      "Epoch 1054/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5979\n",
      "Epoch 1055/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5979\n",
      "Epoch 1056/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5978\n",
      "Epoch 1057/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5978\n",
      "Epoch 1058/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5977\n",
      "Epoch 1059/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5977\n",
      "Epoch 1060/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5976\n",
      "Epoch 1061/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5976\n",
      "Epoch 1062/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5975\n",
      "Epoch 1063/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5975\n",
      "Epoch 1064/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5974\n",
      "Epoch 1065/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5974\n",
      "Epoch 1066/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5973\n",
      "Epoch 1067/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5973\n",
      "Epoch 1068/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5972\n",
      "Epoch 1069/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5972\n",
      "Epoch 1070/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5971\n",
      "Epoch 1071/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5971\n",
      "Epoch 1072/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5970\n",
      "Epoch 1073/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5970\n",
      "Epoch 1074/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5969\n",
      "Epoch 1075/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5969\n",
      "Epoch 1076/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5968\n",
      "Epoch 1077/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5968\n",
      "Epoch 1078/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5967\n",
      "Epoch 1079/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5967\n",
      "Epoch 1080/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5966\n",
      "Epoch 1081/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5966\n",
      "Epoch 1082/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5965\n",
      "Epoch 1083/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5965\n",
      "Epoch 1084/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5964\n",
      "Epoch 1085/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5964\n",
      "Epoch 1086/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5963\n",
      "Epoch 1087/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5963\n",
      "Epoch 1088/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5962\n",
      "Epoch 1089/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5962\n",
      "Epoch 1090/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5961\n",
      "Epoch 1091/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5961\n",
      "Epoch 1092/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5960\n",
      "Epoch 1093/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5960\n",
      "Epoch 1094/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5959\n",
      "Epoch 1095/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5959\n",
      "Epoch 1096/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5958\n",
      "Epoch 1097/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5958\n",
      "Epoch 1098/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5957\n",
      "Epoch 1099/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5957\n",
      "Epoch 1100/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5956\n",
      "Epoch 1101/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5956\n",
      "Epoch 1102/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6818 - loss: 0.5955\n",
      "Epoch 1103/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5955\n",
      "Epoch 1104/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5954\n",
      "Epoch 1105/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5954\n",
      "Epoch 1106/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5953\n",
      "Epoch 1107/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5953\n",
      "Epoch 1108/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5952\n",
      "Epoch 1109/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5952\n",
      "Epoch 1110/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5951\n",
      "Epoch 1111/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5951\n",
      "Epoch 1112/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5950\n",
      "Epoch 1113/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5950\n",
      "Epoch 1114/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5949\n",
      "Epoch 1115/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5949\n",
      "Epoch 1116/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5948\n",
      "Epoch 1117/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5948\n",
      "Epoch 1118/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5947\n",
      "Epoch 1119/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5947\n",
      "Epoch 1120/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5946\n",
      "Epoch 1121/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5946\n",
      "Epoch 1122/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5945\n",
      "Epoch 1123/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5945\n",
      "Epoch 1124/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5944\n",
      "Epoch 1125/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5944\n",
      "Epoch 1126/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5943\n",
      "Epoch 1127/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5943\n",
      "Epoch 1128/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5942\n",
      "Epoch 1129/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5942\n",
      "Epoch 1130/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5941\n",
      "Epoch 1131/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5941\n",
      "Epoch 1132/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5940\n",
      "Epoch 1133/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5940\n",
      "Epoch 1134/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5939\n",
      "Epoch 1135/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5939\n",
      "Epoch 1136/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5938\n",
      "Epoch 1137/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5938\n",
      "Epoch 1138/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5937\n",
      "Epoch 1139/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5937\n",
      "Epoch 1140/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5936\n",
      "Epoch 1141/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5936\n",
      "Epoch 1142/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5935\n",
      "Epoch 1143/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5935\n",
      "Epoch 1144/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5934\n",
      "Epoch 1145/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5934\n",
      "Epoch 1146/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5933\n",
      "Epoch 1147/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5933\n",
      "Epoch 1148/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5932\n",
      "Epoch 1149/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5932\n",
      "Epoch 1150/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5931\n",
      "Epoch 1151/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5931\n",
      "Epoch 1152/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5930\n",
      "Epoch 1153/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5930\n",
      "Epoch 1154/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5929\n",
      "Epoch 1155/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6818 - loss: 0.5929\n",
      "Epoch 1156/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5928\n",
      "Epoch 1157/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5928\n",
      "Epoch 1158/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6818 - loss: 0.5927\n",
      "Epoch 1159/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5927\n",
      "Epoch 1160/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5926\n",
      "Epoch 1161/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5926\n",
      "Epoch 1162/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5925\n",
      "Epoch 1163/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5925\n",
      "Epoch 1164/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5924\n",
      "Epoch 1165/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6818 - loss: 0.5924\n",
      "Epoch 1166/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5923\n",
      "Epoch 1167/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5923\n",
      "Epoch 1168/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5922\n",
      "Epoch 1169/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5922\n",
      "Epoch 1170/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5921\n",
      "Epoch 1171/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5921\n",
      "Epoch 1172/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5920\n",
      "Epoch 1173/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5920\n",
      "Epoch 1174/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5919\n",
      "Epoch 1175/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5919\n",
      "Epoch 1176/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5918\n",
      "Epoch 1177/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5918\n",
      "Epoch 1178/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5917\n",
      "Epoch 1179/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5917\n",
      "Epoch 1180/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5916\n",
      "Epoch 1181/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5916\n",
      "Epoch 1182/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5915\n",
      "Epoch 1183/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5915\n",
      "Epoch 1184/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5914\n",
      "Epoch 1185/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5914\n",
      "Epoch 1186/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5913\n",
      "Epoch 1187/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6818 - loss: 0.5913\n",
      "Epoch 1188/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5912\n",
      "Epoch 1189/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5912\n",
      "Epoch 1190/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5911\n",
      "Epoch 1191/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5911\n",
      "Epoch 1192/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5910\n",
      "Epoch 1193/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5910\n",
      "Epoch 1194/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5909\n",
      "Epoch 1195/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5909\n",
      "Epoch 1196/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5908\n",
      "Epoch 1197/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5908\n",
      "Epoch 1198/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5907\n",
      "Epoch 1199/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5907\n",
      "Epoch 1200/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5906\n",
      "Epoch 1201/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5906\n",
      "Epoch 1202/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5905\n",
      "Epoch 1203/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5905\n",
      "Epoch 1204/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5904\n",
      "Epoch 1205/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5904\n",
      "Epoch 1206/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5903\n",
      "Epoch 1207/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5903\n",
      "Epoch 1208/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5902\n",
      "Epoch 1209/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5902\n",
      "Epoch 1210/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5901\n",
      "Epoch 1211/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5901\n",
      "Epoch 1212/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5900\n",
      "Epoch 1213/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5900\n",
      "Epoch 1214/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5899\n",
      "Epoch 1215/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5899\n",
      "Epoch 1216/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5898\n",
      "Epoch 1217/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5898\n",
      "Epoch 1218/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5897\n",
      "Epoch 1219/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5897\n",
      "Epoch 1220/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5896\n",
      "Epoch 1221/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5896\n",
      "Epoch 1222/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5895\n",
      "Epoch 1223/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5895\n",
      "Epoch 1224/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5894\n",
      "Epoch 1225/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5894\n",
      "Epoch 1226/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5894\n",
      "Epoch 1227/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5893\n",
      "Epoch 1228/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5893\n",
      "Epoch 1229/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5892\n",
      "Epoch 1230/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5892\n",
      "Epoch 1231/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5891\n",
      "Epoch 1232/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5891\n",
      "Epoch 1233/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5890\n",
      "Epoch 1234/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5890\n",
      "Epoch 1235/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5889\n",
      "Epoch 1236/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5889\n",
      "Epoch 1237/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5888\n",
      "Epoch 1238/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5888\n",
      "Epoch 1239/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5887\n",
      "Epoch 1240/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5887\n",
      "Epoch 1241/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5886\n",
      "Epoch 1242/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5886\n",
      "Epoch 1243/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5885\n",
      "Epoch 1244/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5885\n",
      "Epoch 1245/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5884\n",
      "Epoch 1246/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5884\n",
      "Epoch 1247/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5883\n",
      "Epoch 1248/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5883\n",
      "Epoch 1249/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5882\n",
      "Epoch 1250/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5882\n",
      "Epoch 1251/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6818 - loss: 0.5881\n",
      "Epoch 1252/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5881\n",
      "Epoch 1253/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5880\n",
      "Epoch 1254/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5880\n",
      "Epoch 1255/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5879\n",
      "Epoch 1256/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5879\n",
      "Epoch 1257/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5878\n",
      "Epoch 1258/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5878\n",
      "Epoch 1259/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5877\n",
      "Epoch 1260/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5877\n",
      "Epoch 1261/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5876\n",
      "Epoch 1262/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5876\n",
      "Epoch 1263/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5875\n",
      "Epoch 1264/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5875\n",
      "Epoch 1265/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5874\n",
      "Epoch 1266/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6818 - loss: 0.5874\n",
      "Epoch 1267/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5873\n",
      "Epoch 1268/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5873\n",
      "Epoch 1269/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5872\n",
      "Epoch 1270/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5872\n",
      "Epoch 1271/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5871\n",
      "Epoch 1272/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5871\n",
      "Epoch 1273/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5870\n",
      "Epoch 1274/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5870\n",
      "Epoch 1275/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5869\n",
      "Epoch 1276/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5869\n",
      "Epoch 1277/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5868\n",
      "Epoch 1278/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5868\n",
      "Epoch 1279/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5867\n",
      "Epoch 1280/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5867\n",
      "Epoch 1281/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5866\n",
      "Epoch 1282/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5866\n",
      "Epoch 1283/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5865\n",
      "Epoch 1284/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5865\n",
      "Epoch 1285/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5864\n",
      "Epoch 1286/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5864\n",
      "Epoch 1287/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5863\n",
      "Epoch 1288/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5863\n",
      "Epoch 1289/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5862\n",
      "Epoch 1290/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5862\n",
      "Epoch 1291/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5861\n",
      "Epoch 1292/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5861\n",
      "Epoch 1293/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5860\n",
      "Epoch 1294/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5860\n",
      "Epoch 1295/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5859\n",
      "Epoch 1296/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5859\n",
      "Epoch 1297/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5858\n",
      "Epoch 1298/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5858\n",
      "Epoch 1299/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5857\n",
      "Epoch 1300/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5857\n",
      "Epoch 1301/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5856\n",
      "Epoch 1302/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5856\n",
      "Epoch 1303/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5855\n",
      "Epoch 1304/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5855\n",
      "Epoch 1305/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5854\n",
      "Epoch 1306/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5854\n",
      "Epoch 1307/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5853\n",
      "Epoch 1308/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5853\n",
      "Epoch 1309/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5852\n",
      "Epoch 1310/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5852\n",
      "Epoch 1311/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5851\n",
      "Epoch 1312/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5851\n",
      "Epoch 1313/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5850\n",
      "Epoch 1314/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6818 - loss: 0.5850\n",
      "Epoch 1315/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5849\n",
      "Epoch 1316/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5849\n",
      "Epoch 1317/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5848\n",
      "Epoch 1318/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5848\n",
      "Epoch 1319/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5847\n",
      "Epoch 1320/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5847\n",
      "Epoch 1321/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5846\n",
      "Epoch 1322/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5846\n",
      "Epoch 1323/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5845\n",
      "Epoch 1324/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5845\n",
      "Epoch 1325/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5844\n",
      "Epoch 1326/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5844\n",
      "Epoch 1327/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5843\n",
      "Epoch 1328/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5843\n",
      "Epoch 1329/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5842\n",
      "Epoch 1330/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5842\n",
      "Epoch 1331/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5841\n",
      "Epoch 1332/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5841\n",
      "Epoch 1333/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5841\n",
      "Epoch 1334/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5840\n",
      "Epoch 1335/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5840\n",
      "Epoch 1336/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5839\n",
      "Epoch 1337/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5839\n",
      "Epoch 1338/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5838\n",
      "Epoch 1339/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5838\n",
      "Epoch 1340/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5837\n",
      "Epoch 1341/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5837\n",
      "Epoch 1342/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5836\n",
      "Epoch 1343/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5836\n",
      "Epoch 1344/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5835\n",
      "Epoch 1345/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5835\n",
      "Epoch 1346/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5834\n",
      "Epoch 1347/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6818 - loss: 0.5834\n",
      "Epoch 1348/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5833\n",
      "Epoch 1349/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5833\n",
      "Epoch 1350/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5832\n",
      "Epoch 1351/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5832\n",
      "Epoch 1352/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5831\n",
      "Epoch 1353/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5831\n",
      "Epoch 1354/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5830\n",
      "Epoch 1355/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5830\n",
      "Epoch 1356/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5829\n",
      "Epoch 1357/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5829\n",
      "Epoch 1358/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5828\n",
      "Epoch 1359/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5828\n",
      "Epoch 1360/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5827\n",
      "Epoch 1361/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5827\n",
      "Epoch 1362/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5826\n",
      "Epoch 1363/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5826\n",
      "Epoch 1364/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5825\n",
      "Epoch 1365/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5825\n",
      "Epoch 1366/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5824\n",
      "Epoch 1367/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5824\n",
      "Epoch 1368/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5823\n",
      "Epoch 1369/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5823\n",
      "Epoch 1370/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5822\n",
      "Epoch 1371/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6818 - loss: 0.5822\n",
      "Epoch 1372/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5821\n",
      "Epoch 1373/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5821\n",
      "Epoch 1374/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5820\n",
      "Epoch 1375/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5820\n",
      "Epoch 1376/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5819\n",
      "Epoch 1377/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6818 - loss: 0.5819\n",
      "Epoch 1378/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5818\n",
      "Epoch 1379/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5818\n",
      "Epoch 1380/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5817\n",
      "Epoch 1381/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5817\n",
      "Epoch 1382/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5816\n",
      "Epoch 1383/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5816\n",
      "Epoch 1384/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5815\n",
      "Epoch 1385/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5815\n",
      "Epoch 1386/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5814\n",
      "Epoch 1387/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5814\n",
      "Epoch 1388/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5813\n",
      "Epoch 1389/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5813\n",
      "Epoch 1390/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5812\n",
      "Epoch 1391/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5812\n",
      "Epoch 1392/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5812\n",
      "Epoch 1393/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5811\n",
      "Epoch 1394/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6818 - loss: 0.5811\n",
      "Epoch 1395/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5810\n",
      "Epoch 1396/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5810\n",
      "Epoch 1397/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5809\n",
      "Epoch 1398/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5809\n",
      "Epoch 1399/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5808\n",
      "Epoch 1400/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5808\n",
      "Epoch 1401/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5807\n",
      "Epoch 1402/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5807\n",
      "Epoch 1403/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5806\n",
      "Epoch 1404/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5806\n",
      "Epoch 1405/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5805\n",
      "Epoch 1406/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5805\n",
      "Epoch 1407/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5804\n",
      "Epoch 1408/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5804\n",
      "Epoch 1409/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5803\n",
      "Epoch 1410/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5803\n",
      "Epoch 1411/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5802\n",
      "Epoch 1412/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5802\n",
      "Epoch 1413/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5801\n",
      "Epoch 1414/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5801\n",
      "Epoch 1415/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5800\n",
      "Epoch 1416/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5800\n",
      "Epoch 1417/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5799\n",
      "Epoch 1418/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5799\n",
      "Epoch 1419/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6818 - loss: 0.5798\n",
      "Epoch 1420/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5798\n",
      "Epoch 1421/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5797\n",
      "Epoch 1422/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5797\n",
      "Epoch 1423/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5796\n",
      "Epoch 1424/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5796\n",
      "Epoch 1425/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5795\n",
      "Epoch 1426/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5795\n",
      "Epoch 1427/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5794\n",
      "Epoch 1428/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5794\n",
      "Epoch 1429/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5793\n",
      "Epoch 1430/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5793\n",
      "Epoch 1431/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6818 - loss: 0.5792\n",
      "Epoch 1432/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6818 - loss: 0.5792\n",
      "Epoch 1433/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5791\n",
      "Epoch 1434/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5791\n",
      "Epoch 1435/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5791\n",
      "Epoch 1436/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5790\n",
      "Epoch 1437/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5790\n",
      "Epoch 1438/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5789\n",
      "Epoch 1439/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5789\n",
      "Epoch 1440/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5788\n",
      "Epoch 1441/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5788\n",
      "Epoch 1442/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5787\n",
      "Epoch 1443/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5787\n",
      "Epoch 1444/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6818 - loss: 0.5786\n",
      "Epoch 1445/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5786\n",
      "Epoch 1446/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5785\n",
      "Epoch 1447/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5785\n",
      "Epoch 1448/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5784\n",
      "Epoch 1449/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5784\n",
      "Epoch 1450/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6818 - loss: 0.5783\n",
      "Epoch 1451/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5783\n",
      "Epoch 1452/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5782\n",
      "Epoch 1453/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5782\n",
      "Epoch 1454/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5781\n",
      "Epoch 1455/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5781\n",
      "Epoch 1456/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5780\n",
      "Epoch 1457/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5780\n",
      "Epoch 1458/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5779\n",
      "Epoch 1459/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5779\n",
      "Epoch 1460/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.6818 - loss: 0.5778\n",
      "Epoch 1461/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5778\n",
      "Epoch 1462/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5777\n",
      "Epoch 1463/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5777\n",
      "Epoch 1464/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5776\n",
      "Epoch 1465/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5776\n",
      "Epoch 1466/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6818 - loss: 0.5775\n",
      "Epoch 1467/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6818 - loss: 0.5775\n",
      "Epoch 1468/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6818 - loss: 0.5774\n",
      "Epoch 1469/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5774\n",
      "Epoch 1470/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5773\n",
      "Epoch 1471/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5773\n",
      "Epoch 1472/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6818 - loss: 0.5773\n",
      "Epoch 1473/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6818 - loss: 0.5772\n",
      "Epoch 1474/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5772\n",
      "Epoch 1475/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5771\n",
      "Epoch 1476/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5771\n",
      "Epoch 1477/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5770\n",
      "Epoch 1478/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5770\n",
      "Epoch 1479/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5769\n",
      "Epoch 1480/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5769\n",
      "Epoch 1481/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5768\n",
      "Epoch 1482/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5768\n",
      "Epoch 1483/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5767\n",
      "Epoch 1484/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5767\n",
      "Epoch 1485/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5766\n",
      "Epoch 1486/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5766\n",
      "Epoch 1487/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5765\n",
      "Epoch 1488/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5765\n",
      "Epoch 1489/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5764\n",
      "Epoch 1490/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5764\n",
      "Epoch 1491/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5763\n",
      "Epoch 1492/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5763\n",
      "Epoch 1493/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5762\n",
      "Epoch 1494/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5762\n",
      "Epoch 1495/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6818 - loss: 0.5761\n",
      "Epoch 1496/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6818 - loss: 0.5761\n",
      "Epoch 1497/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5760\n",
      "Epoch 1498/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5760\n",
      "Epoch 1499/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5759\n",
      "Epoch 1500/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5759\n",
      "Epoch 1501/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5758\n",
      "Epoch 1502/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5758\n",
      "Epoch 1503/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5758\n",
      "Epoch 1504/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5757\n",
      "Epoch 1505/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5757\n",
      "Epoch 1506/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5756\n",
      "Epoch 1507/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5756\n",
      "Epoch 1508/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6818 - loss: 0.5755\n",
      "Epoch 1509/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6818 - loss: 0.5755\n",
      "Epoch 1510/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5754\n",
      "Epoch 1511/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6818 - loss: 0.5754\n",
      "Epoch 1512/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5753\n",
      "Epoch 1513/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5753\n",
      "Epoch 1514/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5752\n",
      "Epoch 1515/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5752\n",
      "Epoch 1516/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5751\n",
      "Epoch 1517/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5751\n",
      "Epoch 1518/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5750\n",
      "Epoch 1519/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5750\n",
      "Epoch 1520/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5749\n",
      "Epoch 1521/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5749\n",
      "Epoch 1522/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5748\n",
      "Epoch 1523/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5748\n",
      "Epoch 1524/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5747\n",
      "Epoch 1525/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5747\n",
      "Epoch 1526/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5746\n",
      "Epoch 1527/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6818 - loss: 0.5746\n",
      "Epoch 1528/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5745\n",
      "Epoch 1529/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5745\n",
      "Epoch 1530/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5745\n",
      "Epoch 1531/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5744\n",
      "Epoch 1532/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5744\n",
      "Epoch 1533/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5743\n",
      "Epoch 1534/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5743\n",
      "Epoch 1535/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5742\n",
      "Epoch 1536/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5742\n",
      "Epoch 1537/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5741\n",
      "Epoch 1538/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6818 - loss: 0.5741\n",
      "Epoch 1539/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5740\n",
      "Epoch 1540/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5740\n",
      "Epoch 1541/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5739\n",
      "Epoch 1542/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5739\n",
      "Epoch 1543/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5738\n",
      "Epoch 1544/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6818 - loss: 0.5738\n",
      "Epoch 1545/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5737\n",
      "Epoch 1546/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5737\n",
      "Epoch 1547/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5736\n",
      "Epoch 1548/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5736\n",
      "Epoch 1549/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5735\n",
      "Epoch 1550/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5735\n",
      "Epoch 1551/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5734\n",
      "Epoch 1552/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5734\n",
      "Epoch 1553/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5733\n",
      "Epoch 1554/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5733\n",
      "Epoch 1555/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5733\n",
      "Epoch 1556/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5732\n",
      "Epoch 1557/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5732\n",
      "Epoch 1558/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5731\n",
      "Epoch 1559/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5731\n",
      "Epoch 1560/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5730\n",
      "Epoch 1561/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5730\n",
      "Epoch 1562/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5729\n",
      "Epoch 1563/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6818 - loss: 0.5729\n",
      "Epoch 1564/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5728\n",
      "Epoch 1565/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5728\n",
      "Epoch 1566/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5727\n",
      "Epoch 1567/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5727\n",
      "Epoch 1568/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5726\n",
      "Epoch 1569/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5726\n",
      "Epoch 1570/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6818 - loss: 0.5725\n",
      "Epoch 1571/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5725\n",
      "Epoch 1572/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5724\n",
      "Epoch 1573/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5724\n",
      "Epoch 1574/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5723\n",
      "Epoch 1575/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5723\n",
      "Epoch 1576/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5722\n",
      "Epoch 1577/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5722\n",
      "Epoch 1578/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5722\n",
      "Epoch 1579/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5721\n",
      "Epoch 1580/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6818 - loss: 0.5721\n",
      "Epoch 1581/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5720\n",
      "Epoch 1582/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5720\n",
      "Epoch 1583/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5719\n",
      "Epoch 1584/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6818 - loss: 0.5719\n",
      "Epoch 1585/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6818 - loss: 0.5718\n",
      "Epoch 1586/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5718\n",
      "Epoch 1587/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5717\n",
      "Epoch 1588/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5717\n",
      "Epoch 1589/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5716\n",
      "Epoch 1590/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5716\n",
      "Epoch 1591/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5715\n",
      "Epoch 1592/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5715\n",
      "Epoch 1593/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5714\n",
      "Epoch 1594/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5714\n",
      "Epoch 1595/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6818 - loss: 0.5713\n",
      "Epoch 1596/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5713\n",
      "Epoch 1597/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5712\n",
      "Epoch 1598/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5712\n",
      "Epoch 1599/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5712\n",
      "Epoch 1600/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5711\n",
      "Epoch 1601/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5711\n",
      "Epoch 1602/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5710\n",
      "Epoch 1603/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5710\n",
      "Epoch 1604/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5709\n",
      "Epoch 1605/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5709\n",
      "Epoch 1606/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5708\n",
      "Epoch 1607/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5708\n",
      "Epoch 1608/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6818 - loss: 0.5707\n",
      "Epoch 1609/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6818 - loss: 0.5707\n",
      "Epoch 1610/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5706\n",
      "Epoch 1611/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5706\n",
      "Epoch 1612/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5705\n",
      "Epoch 1613/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5705\n",
      "Epoch 1614/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5704\n",
      "Epoch 1615/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5704\n",
      "Epoch 1616/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5703\n",
      "Epoch 1617/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5703\n",
      "Epoch 1618/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5702\n",
      "Epoch 1619/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5702\n",
      "Epoch 1620/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5702\n",
      "Epoch 1621/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6818 - loss: 0.5701\n",
      "Epoch 1622/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6818 - loss: 0.5701\n",
      "Epoch 1623/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5700\n",
      "Epoch 1624/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5700\n",
      "Epoch 1625/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5699\n",
      "Epoch 1626/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5699\n",
      "Epoch 1627/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5698\n",
      "Epoch 1628/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5698\n",
      "Epoch 1629/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5697\n",
      "Epoch 1630/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6818 - loss: 0.5697\n",
      "Epoch 1631/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6818 - loss: 0.5696\n",
      "Epoch 1632/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5696\n",
      "Epoch 1633/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5695\n",
      "Epoch 1634/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5695\n",
      "Epoch 1635/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5694\n",
      "Epoch 1636/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5694\n",
      "Epoch 1637/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5694\n",
      "Epoch 1638/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5693\n",
      "Epoch 1639/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5693\n",
      "Epoch 1640/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5692\n",
      "Epoch 1641/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5692\n",
      "Epoch 1642/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5691\n",
      "Epoch 1643/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5691\n",
      "Epoch 1644/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5690\n",
      "Epoch 1645/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5690\n",
      "Epoch 1646/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5689\n",
      "Epoch 1647/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5689\n",
      "Epoch 1648/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5688\n",
      "Epoch 1649/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5688\n",
      "Epoch 1650/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5687\n",
      "Epoch 1651/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6818 - loss: 0.5687\n",
      "Epoch 1652/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5686\n",
      "Epoch 1653/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5686\n",
      "Epoch 1654/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5685\n",
      "Epoch 1655/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5685\n",
      "Epoch 1656/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5685\n",
      "Epoch 1657/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5684\n",
      "Epoch 1658/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5684\n",
      "Epoch 1659/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5683\n",
      "Epoch 1660/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5683\n",
      "Epoch 1661/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5682\n",
      "Epoch 1662/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5682\n",
      "Epoch 1663/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5681\n",
      "Epoch 1664/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5681\n",
      "Epoch 1665/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5680\n",
      "Epoch 1666/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5680\n",
      "Epoch 1667/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5679\n",
      "Epoch 1668/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5679\n",
      "Epoch 1669/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5678\n",
      "Epoch 1670/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5678\n",
      "Epoch 1671/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5677\n",
      "Epoch 1672/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5677\n",
      "Epoch 1673/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5677\n",
      "Epoch 1674/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5676\n",
      "Epoch 1675/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6818 - loss: 0.5676\n",
      "Epoch 1676/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5675\n",
      "Epoch 1677/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5675\n",
      "Epoch 1678/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5674\n",
      "Epoch 1679/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5674\n",
      "Epoch 1680/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5673\n",
      "Epoch 1681/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6818 - loss: 0.5673\n",
      "Epoch 1682/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5672\n",
      "Epoch 1683/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5672\n",
      "Epoch 1684/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5671\n",
      "Epoch 1685/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5671\n",
      "Epoch 1686/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5670\n",
      "Epoch 1687/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5670\n",
      "Epoch 1688/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5670\n",
      "Epoch 1689/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5669\n",
      "Epoch 1690/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5669\n",
      "Epoch 1691/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5668\n",
      "Epoch 1692/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5668\n",
      "Epoch 1693/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5667\n",
      "Epoch 1694/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5667\n",
      "Epoch 1695/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6818 - loss: 0.5666\n",
      "Epoch 1696/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5666\n",
      "Epoch 1697/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5665\n",
      "Epoch 1698/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5665\n",
      "Epoch 1699/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5664\n",
      "Epoch 1700/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5664\n",
      "Epoch 1701/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5663\n",
      "Epoch 1702/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5663\n",
      "Epoch 1703/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5663\n",
      "Epoch 1704/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5662\n",
      "Epoch 1705/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5662\n",
      "Epoch 1706/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5661\n",
      "Epoch 1707/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5661\n",
      "Epoch 1708/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5660\n",
      "Epoch 1709/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5660\n",
      "Epoch 1710/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6818 - loss: 0.5659\n",
      "Epoch 1711/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6818 - loss: 0.5659\n",
      "Epoch 1712/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5658\n",
      "Epoch 1713/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5658\n",
      "Epoch 1714/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5657\n",
      "Epoch 1715/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5657\n",
      "Epoch 1716/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5656\n",
      "Epoch 1717/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5656\n",
      "Epoch 1718/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5656\n",
      "Epoch 1719/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5655\n",
      "Epoch 1720/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5655\n",
      "Epoch 1721/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5654\n",
      "Epoch 1722/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6818 - loss: 0.5654\n",
      "Epoch 1723/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5653\n",
      "Epoch 1724/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5653\n",
      "Epoch 1725/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6818 - loss: 0.5652\n",
      "Epoch 1726/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5652\n",
      "Epoch 1727/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5651\n",
      "Epoch 1728/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6818 - loss: 0.5651\n",
      "Epoch 1729/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5650\n",
      "Epoch 1730/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6818 - loss: 0.5650\n",
      "Epoch 1731/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6818 - loss: 0.5649\n",
      "Epoch 1732/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5649\n",
      "Epoch 1733/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.6818 - loss: 0.5649\n",
      "Epoch 1734/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6818 - loss: 0.5648\n",
      "Epoch 1735/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5648\n",
      "Epoch 1736/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5647\n",
      "Epoch 1737/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5647\n",
      "Epoch 1738/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5646\n",
      "Epoch 1739/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5646\n",
      "Epoch 1740/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5645\n",
      "Epoch 1741/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5645\n",
      "Epoch 1742/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5644\n",
      "Epoch 1743/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5644\n",
      "Epoch 1744/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5643\n",
      "Epoch 1745/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5643\n",
      "Epoch 1746/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5643\n",
      "Epoch 1747/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5642\n",
      "Epoch 1748/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5642\n",
      "Epoch 1749/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5641\n",
      "Epoch 1750/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5641\n",
      "Epoch 1751/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5640\n",
      "Epoch 1752/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5640\n",
      "Epoch 1753/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5639\n",
      "Epoch 1754/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5639\n",
      "Epoch 1755/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5638\n",
      "Epoch 1756/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6818 - loss: 0.5638\n",
      "Epoch 1757/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5637\n",
      "Epoch 1758/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5637\n",
      "Epoch 1759/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5637\n",
      "Epoch 1760/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5636\n",
      "Epoch 1761/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5636\n",
      "Epoch 1762/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5635\n",
      "Epoch 1763/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5635\n",
      "Epoch 1764/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5634\n",
      "Epoch 1765/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5634\n",
      "Epoch 1766/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5633\n",
      "Epoch 1767/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5633\n",
      "Epoch 1768/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5632\n",
      "Epoch 1769/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5632\n",
      "Epoch 1770/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5631\n",
      "Epoch 1771/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5631\n",
      "Epoch 1772/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5631\n",
      "Epoch 1773/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5630\n",
      "Epoch 1774/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5630\n",
      "Epoch 1775/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5629\n",
      "Epoch 1776/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6818 - loss: 0.5629\n",
      "Epoch 1777/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5628\n",
      "Epoch 1778/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5628\n",
      "Epoch 1779/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6818 - loss: 0.5627\n",
      "Epoch 1780/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6818 - loss: 0.5627\n",
      "Epoch 1781/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6818 - loss: 0.5626\n",
      "Epoch 1782/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6818 - loss: 0.5626\n",
      "Epoch 1783/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5625\n",
      "Epoch 1784/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5625\n",
      "Epoch 1785/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5625\n",
      "Epoch 1786/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5624\n",
      "Epoch 1787/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5624\n",
      "Epoch 1788/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5623\n",
      "Epoch 1789/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5623\n",
      "Epoch 1790/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5622\n",
      "Epoch 1791/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5622\n",
      "Epoch 1792/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5621\n",
      "Epoch 1793/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5621\n",
      "Epoch 1794/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5620\n",
      "Epoch 1795/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5620\n",
      "Epoch 1796/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5619\n",
      "Epoch 1797/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6818 - loss: 0.5619\n",
      "Epoch 1798/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5619\n",
      "Epoch 1799/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5618\n",
      "Epoch 1800/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5618\n",
      "Epoch 1801/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5617\n",
      "Epoch 1802/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5617\n",
      "Epoch 1803/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5616\n",
      "Epoch 1804/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5616\n",
      "Epoch 1805/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5615\n",
      "Epoch 1806/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5615\n",
      "Epoch 1807/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5614\n",
      "Epoch 1808/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5614\n",
      "Epoch 1809/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5614\n",
      "Epoch 1810/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5613\n",
      "Epoch 1811/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5613\n",
      "Epoch 1812/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5612\n",
      "Epoch 1813/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5612\n",
      "Epoch 1814/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5611\n",
      "Epoch 1815/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5611\n",
      "Epoch 1816/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5610\n",
      "Epoch 1817/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5610\n",
      "Epoch 1818/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5609\n",
      "Epoch 1819/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6818 - loss: 0.5609\n",
      "Epoch 1820/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5609\n",
      "Epoch 1821/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5608\n",
      "Epoch 1822/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5608\n",
      "Epoch 1823/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5607\n",
      "Epoch 1824/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5607\n",
      "Epoch 1825/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5606\n",
      "Epoch 1826/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5606\n",
      "Epoch 1827/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5605\n",
      "Epoch 1828/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5605\n",
      "Epoch 1829/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5604\n",
      "Epoch 1830/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5604\n",
      "Epoch 1831/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5604\n",
      "Epoch 1832/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5603\n",
      "Epoch 1833/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5603\n",
      "Epoch 1834/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5602\n",
      "Epoch 1835/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5602\n",
      "Epoch 1836/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5601\n",
      "Epoch 1837/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5601\n",
      "Epoch 1838/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5600\n",
      "Epoch 1839/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5600\n",
      "Epoch 1840/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6818 - loss: 0.5599\n",
      "Epoch 1841/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5599\n",
      "Epoch 1842/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5599\n",
      "Epoch 1843/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5598\n",
      "Epoch 1844/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5598\n",
      "Epoch 1845/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5597\n",
      "Epoch 1846/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5597\n",
      "Epoch 1847/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5596\n",
      "Epoch 1848/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5596\n",
      "Epoch 1849/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5595\n",
      "Epoch 1850/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5595\n",
      "Epoch 1851/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5594\n",
      "Epoch 1852/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5594\n",
      "Epoch 1853/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5594\n",
      "Epoch 1854/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5593\n",
      "Epoch 1855/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5593\n",
      "Epoch 1856/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5592\n",
      "Epoch 1857/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5592\n",
      "Epoch 1858/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5591\n",
      "Epoch 1859/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6818 - loss: 0.5591\n",
      "Epoch 1860/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5590\n",
      "Epoch 1861/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5590\n",
      "Epoch 1862/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5589\n",
      "Epoch 1863/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5589\n",
      "Epoch 1864/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5589\n",
      "Epoch 1865/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5588\n",
      "Epoch 1866/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5588\n",
      "Epoch 1867/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5587\n",
      "Epoch 1868/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6818 - loss: 0.5587\n",
      "Epoch 1869/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5586\n",
      "Epoch 1870/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5586\n",
      "Epoch 1871/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5585\n",
      "Epoch 1872/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5585\n",
      "Epoch 1873/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5584\n",
      "Epoch 1874/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5584\n",
      "Epoch 1875/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5584\n",
      "Epoch 1876/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5583\n",
      "Epoch 1877/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5583\n",
      "Epoch 1878/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5582\n",
      "Epoch 1879/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6818 - loss: 0.5582\n",
      "Epoch 1880/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5581\n",
      "Epoch 1881/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5581\n",
      "Epoch 1882/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5580\n",
      "Epoch 1883/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5580\n",
      "Epoch 1884/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5580\n",
      "Epoch 1885/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5579\n",
      "Epoch 1886/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5579\n",
      "Epoch 1887/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5578\n",
      "Epoch 1888/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5578\n",
      "Epoch 1889/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5577\n",
      "Epoch 1890/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5577\n",
      "Epoch 1891/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5576\n",
      "Epoch 1892/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5576\n",
      "Epoch 1893/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5575\n",
      "Epoch 1894/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5575\n",
      "Epoch 1895/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5575\n",
      "Epoch 1896/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5574\n",
      "Epoch 1897/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5574\n",
      "Epoch 1898/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6818 - loss: 0.5573\n",
      "Epoch 1899/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6818 - loss: 0.5573\n",
      "Epoch 1900/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5572\n",
      "Epoch 1901/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5572\n",
      "Epoch 1902/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5571\n",
      "Epoch 1903/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5571\n",
      "Epoch 1904/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5571\n",
      "Epoch 1905/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5570\n",
      "Epoch 1906/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5570\n",
      "Epoch 1907/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5569\n",
      "Epoch 1908/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5569\n",
      "Epoch 1909/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5568\n",
      "Epoch 1910/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5568\n",
      "Epoch 1911/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5567\n",
      "Epoch 1912/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5567\n",
      "Epoch 1913/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5567\n",
      "Epoch 1914/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5566\n",
      "Epoch 1915/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5566\n",
      "Epoch 1916/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5565\n",
      "Epoch 1917/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5565\n",
      "Epoch 1918/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5564\n",
      "Epoch 1919/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6818 - loss: 0.5564\n",
      "Epoch 1920/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6818 - loss: 0.5563\n",
      "Epoch 1921/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5563\n",
      "Epoch 1922/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5563\n",
      "Epoch 1923/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5562\n",
      "Epoch 1924/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5562\n",
      "Epoch 1925/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5561\n",
      "Epoch 1926/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5561\n",
      "Epoch 1927/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5560\n",
      "Epoch 1928/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5560\n",
      "Epoch 1929/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5559\n",
      "Epoch 1930/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5559\n",
      "Epoch 1931/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5559\n",
      "Epoch 1932/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6818 - loss: 0.5558\n",
      "Epoch 1933/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5558\n",
      "Epoch 1934/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5557\n",
      "Epoch 1935/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5557\n",
      "Epoch 1936/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5556\n",
      "Epoch 1937/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5556\n",
      "Epoch 1938/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5555\n",
      "Epoch 1939/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5555\n",
      "Epoch 1940/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5554\n",
      "Epoch 1941/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.6818 - loss: 0.5554\n",
      "Epoch 1942/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6818 - loss: 0.5554\n",
      "Epoch 1943/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6818 - loss: 0.5553\n",
      "Epoch 1944/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5553\n",
      "Epoch 1945/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5552\n",
      "Epoch 1946/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5552\n",
      "Epoch 1947/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5551\n",
      "Epoch 1948/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5551\n",
      "Epoch 1949/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5551\n",
      "Epoch 1950/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5550\n",
      "Epoch 1951/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5550\n",
      "Epoch 1952/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5549\n",
      "Epoch 1953/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5549\n",
      "Epoch 1954/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5548\n",
      "Epoch 1955/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5548\n",
      "Epoch 1956/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5547\n",
      "Epoch 1957/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5547\n",
      "Epoch 1958/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5547\n",
      "Epoch 1959/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5546\n",
      "Epoch 1960/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5546\n",
      "Epoch 1961/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6818 - loss: 0.5545\n",
      "Epoch 1962/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5545\n",
      "Epoch 1963/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5544\n",
      "Epoch 1964/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5544\n",
      "Epoch 1965/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5543\n",
      "Epoch 1966/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5543\n",
      "Epoch 1967/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5543\n",
      "Epoch 1968/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5542\n",
      "Epoch 1969/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5542\n",
      "Epoch 1970/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5541\n",
      "Epoch 1971/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5541\n",
      "Epoch 1972/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5540\n",
      "Epoch 1973/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5540\n",
      "Epoch 1974/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5539\n",
      "Epoch 1975/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6818 - loss: 0.5539\n",
      "Epoch 1976/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5539\n",
      "Epoch 1977/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5538\n",
      "Epoch 1978/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5538\n",
      "Epoch 1979/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5537\n",
      "Epoch 1980/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5537\n",
      "Epoch 1981/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.6818 - loss: 0.5536\n",
      "Epoch 1982/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5536\n",
      "Epoch 1983/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5535\n",
      "Epoch 1984/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5535\n",
      "Epoch 1985/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5535\n",
      "Epoch 1986/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5534\n",
      "Epoch 1987/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5534\n",
      "Epoch 1988/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5533\n",
      "Epoch 1989/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5533\n",
      "Epoch 1990/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5532\n",
      "Epoch 1991/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5532\n",
      "Epoch 1992/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5532\n",
      "Epoch 1993/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5531\n",
      "Epoch 1994/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5531\n",
      "Epoch 1995/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5530\n",
      "Epoch 1996/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5530\n",
      "Epoch 1997/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5529\n",
      "Epoch 1998/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5529\n",
      "Epoch 1999/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5528\n",
      "Epoch 2000/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6818 - loss: 0.5528\n",
      "Epoch 2001/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5528\n",
      "Epoch 2002/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5527\n",
      "Epoch 2003/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5527\n",
      "Epoch 2004/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5526\n",
      "Epoch 2005/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5526\n",
      "Epoch 2006/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5525\n",
      "Epoch 2007/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5525\n",
      "Epoch 2008/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5525\n",
      "Epoch 2009/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5524\n",
      "Epoch 2010/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5524\n",
      "Epoch 2011/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5523\n",
      "Epoch 2012/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5523\n",
      "Epoch 2013/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5522\n",
      "Epoch 2014/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5522\n",
      "Epoch 2015/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5521\n",
      "Epoch 2016/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5521\n",
      "Epoch 2017/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5521\n",
      "Epoch 2018/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5520\n",
      "Epoch 2019/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5520\n",
      "Epoch 2020/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.6818 - loss: 0.5519\n",
      "Epoch 2021/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5519\n",
      "Epoch 2022/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5518\n",
      "Epoch 2023/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5518\n",
      "Epoch 2024/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5518\n",
      "Epoch 2025/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5517\n",
      "Epoch 2026/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5517\n",
      "Epoch 2027/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5516\n",
      "Epoch 2028/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5516\n",
      "Epoch 2029/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5515\n",
      "Epoch 2030/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5515\n",
      "Epoch 2031/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5514\n",
      "Epoch 2032/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5514\n",
      "Epoch 2033/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5514\n",
      "Epoch 2034/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5513\n",
      "Epoch 2035/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5513\n",
      "Epoch 2036/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5512\n",
      "Epoch 2037/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6818 - loss: 0.5512\n",
      "Epoch 2038/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6818 - loss: 0.5511\n",
      "Epoch 2039/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5511\n",
      "Epoch 2040/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5511\n",
      "Epoch 2041/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5510\n",
      "Epoch 2042/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5510\n",
      "Epoch 2043/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5509\n",
      "Epoch 2044/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5509\n",
      "Epoch 2045/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5508\n",
      "Epoch 2046/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5508\n",
      "Epoch 2047/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5508\n",
      "Epoch 2048/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5507\n",
      "Epoch 2049/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5507\n",
      "Epoch 2050/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5506\n",
      "Epoch 2051/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5506\n",
      "Epoch 2052/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5505\n",
      "Epoch 2053/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5505\n",
      "Epoch 2054/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5505\n",
      "Epoch 2055/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5504\n",
      "Epoch 2056/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5504\n",
      "Epoch 2057/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6818 - loss: 0.5503\n",
      "Epoch 2058/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5503\n",
      "Epoch 2059/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5502\n",
      "Epoch 2060/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5502\n",
      "Epoch 2061/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5501\n",
      "Epoch 2062/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5501\n",
      "Epoch 2063/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5501\n",
      "Epoch 2064/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5500\n",
      "Epoch 2065/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5500\n",
      "Epoch 2066/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5499\n",
      "Epoch 2067/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5499\n",
      "Epoch 2068/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5498\n",
      "Epoch 2069/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5498\n",
      "Epoch 2070/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5498\n",
      "Epoch 2071/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5497\n",
      "Epoch 2072/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5497\n",
      "Epoch 2073/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5496\n",
      "Epoch 2074/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5496\n",
      "Epoch 2075/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5495\n",
      "Epoch 2076/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6818 - loss: 0.5495\n",
      "Epoch 2077/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5495\n",
      "Epoch 2078/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5494\n",
      "Epoch 2079/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5494\n",
      "Epoch 2080/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6818 - loss: 0.5493\n",
      "Epoch 2081/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5493\n",
      "Epoch 2082/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5492\n",
      "Epoch 2083/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5492\n",
      "Epoch 2084/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5492\n",
      "Epoch 2085/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5491\n",
      "Epoch 2086/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6818 - loss: 0.5491\n",
      "Epoch 2087/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5490\n",
      "Epoch 2088/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5490\n",
      "Epoch 2089/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5489\n",
      "Epoch 2090/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5489\n",
      "Epoch 2091/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5489\n",
      "Epoch 2092/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5488\n",
      "Epoch 2093/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6818 - loss: 0.5488\n",
      "Epoch 2094/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5487\n",
      "Epoch 2095/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5487\n",
      "Epoch 2096/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5486\n",
      "Epoch 2097/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5486\n",
      "Epoch 2098/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6818 - loss: 0.5486\n",
      "Epoch 2099/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5485\n",
      "Epoch 2100/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5485\n",
      "Epoch 2101/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.6818 - loss: 0.5484\n",
      "Epoch 2102/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6818 - loss: 0.5484\n",
      "Epoch 2103/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5483\n",
      "Epoch 2104/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5483\n",
      "Epoch 2105/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6818 - loss: 0.5483\n",
      "Epoch 2106/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5482\n",
      "Epoch 2107/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5482\n",
      "Epoch 2108/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5481\n",
      "Epoch 2109/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5481\n",
      "Epoch 2110/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5480\n",
      "Epoch 2111/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5480\n",
      "Epoch 2112/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5480\n",
      "Epoch 2113/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5479\n",
      "Epoch 2114/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5479\n",
      "Epoch 2115/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5478\n",
      "Epoch 2116/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6818 - loss: 0.5478\n",
      "Epoch 2117/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5477\n",
      "Epoch 2118/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5477\n",
      "Epoch 2119/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5477\n",
      "Epoch 2120/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5476\n",
      "Epoch 2121/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6818 - loss: 0.5476\n",
      "Epoch 2122/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6818 - loss: 0.5475\n",
      "Epoch 2123/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5475\n",
      "Epoch 2124/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5474\n",
      "Epoch 2125/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6818 - loss: 0.5474\n",
      "Epoch 2126/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5474\n",
      "Epoch 2127/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5473\n",
      "Epoch 2128/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5473\n",
      "Epoch 2129/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5472\n",
      "Epoch 2130/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5472\n",
      "Epoch 2131/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5471\n",
      "Epoch 2132/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5471\n",
      "Epoch 2133/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5471\n",
      "Epoch 2134/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5470\n",
      "Epoch 2135/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5470\n",
      "Epoch 2136/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5469\n",
      "Epoch 2137/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5469\n",
      "Epoch 2138/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5469\n",
      "Epoch 2139/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5468\n",
      "Epoch 2140/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5468\n",
      "Epoch 2141/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5467\n",
      "Epoch 2142/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6818 - loss: 0.5467\n",
      "Epoch 2143/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5466\n",
      "Epoch 2144/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5466\n",
      "Epoch 2145/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5466\n",
      "Epoch 2146/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6818 - loss: 0.5465\n",
      "Epoch 2147/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5465\n",
      "Epoch 2148/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5464\n",
      "Epoch 2149/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5464\n",
      "Epoch 2150/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5463\n",
      "Epoch 2151/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5463\n",
      "Epoch 2152/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6818 - loss: 0.5463\n",
      "Epoch 2153/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5462\n",
      "Epoch 2154/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5462\n",
      "Epoch 2155/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5461\n",
      "Epoch 2156/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5461\n",
      "Epoch 2157/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5460\n",
      "Epoch 2158/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6818 - loss: 0.5460\n",
      "Epoch 2159/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5460\n",
      "Epoch 2160/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5459\n",
      "Epoch 2161/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5459\n",
      "Epoch 2162/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5458\n",
      "Epoch 2163/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5458\n",
      "Epoch 2164/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5458\n",
      "Epoch 2165/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5457\n",
      "Epoch 2166/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5457\n",
      "Epoch 2167/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5456\n",
      "Epoch 2168/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5456\n",
      "Epoch 2169/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5455\n",
      "Epoch 2170/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5455\n",
      "Epoch 2171/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5455\n",
      "Epoch 2172/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5454\n",
      "Epoch 2173/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6818 - loss: 0.5454\n",
      "Epoch 2174/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6818 - loss: 0.5453\n",
      "Epoch 2175/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5453\n",
      "Epoch 2176/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5452\n",
      "Epoch 2177/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5452\n",
      "Epoch 2178/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5452\n",
      "Epoch 2179/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5451\n",
      "Epoch 2180/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5451\n",
      "Epoch 2181/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5450\n",
      "Epoch 2182/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5450\n",
      "Epoch 2183/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5450\n",
      "Epoch 2184/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5449\n",
      "Epoch 2185/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5449\n",
      "Epoch 2186/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5448\n",
      "Epoch 2187/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5448\n",
      "Epoch 2188/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5447\n",
      "Epoch 2189/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5447\n",
      "Epoch 2190/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5447\n",
      "Epoch 2191/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5446\n",
      "Epoch 2192/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5446\n",
      "Epoch 2193/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6818 - loss: 0.5445\n",
      "Epoch 2194/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5445\n",
      "Epoch 2195/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5445\n",
      "Epoch 2196/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5444\n",
      "Epoch 2197/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5444\n",
      "Epoch 2198/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5443\n",
      "Epoch 2199/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5443\n",
      "Epoch 2200/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5442\n",
      "Epoch 2201/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5442\n",
      "Epoch 2202/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5442\n",
      "Epoch 2203/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5441\n",
      "Epoch 2204/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5441\n",
      "Epoch 2205/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5440\n",
      "Epoch 2206/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5440\n",
      "Epoch 2207/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5440\n",
      "Epoch 2208/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5439\n",
      "Epoch 2209/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6818 - loss: 0.5439\n",
      "Epoch 2210/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6818 - loss: 0.5438\n",
      "Epoch 2211/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5438\n",
      "Epoch 2212/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5437\n",
      "Epoch 2213/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5437\n",
      "Epoch 2214/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5437\n",
      "Epoch 2215/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.5436\n",
      "Epoch 2216/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5436\n",
      "Epoch 2217/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5435\n",
      "Epoch 2218/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5435\n",
      "Epoch 2219/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5435\n",
      "Epoch 2220/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5434\n",
      "Epoch 2221/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5434\n",
      "Epoch 2222/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5433\n",
      "Epoch 2223/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5433\n",
      "Epoch 2224/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5432\n",
      "Epoch 2225/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5432\n",
      "Epoch 2226/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6818 - loss: 0.5432\n",
      "Epoch 2227/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5431\n",
      "Epoch 2228/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5431\n",
      "Epoch 2229/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6818 - loss: 0.5430\n",
      "Epoch 2230/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5430\n",
      "Epoch 2231/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5430\n",
      "Epoch 2232/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5429\n",
      "Epoch 2233/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5429\n",
      "Epoch 2234/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5428\n",
      "Epoch 2235/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6818 - loss: 0.5428\n",
      "Epoch 2236/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6818 - loss: 0.5427\n",
      "Epoch 2237/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5427\n",
      "Epoch 2238/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6818 - loss: 0.5427\n",
      "Epoch 2239/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5426\n",
      "Epoch 2240/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5426\n",
      "Epoch 2241/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5425\n",
      "Epoch 2242/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5425\n",
      "Epoch 2243/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5425\n",
      "Epoch 2244/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5424\n",
      "Epoch 2245/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5424\n",
      "Epoch 2246/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5423\n",
      "Epoch 2247/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6818 - loss: 0.5423\n",
      "Epoch 2248/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6818 - loss: 0.5423\n",
      "Epoch 2249/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5422\n",
      "Epoch 2250/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.6818 - loss: 0.5422\n",
      "Epoch 2251/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6818 - loss: 0.5421\n",
      "Epoch 2252/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5421\n",
      "Epoch 2253/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5420\n",
      "Epoch 2254/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5420\n",
      "Epoch 2255/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5420\n",
      "Epoch 2256/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5419\n",
      "Epoch 2257/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6818 - loss: 0.5419\n",
      "Epoch 2258/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6818 - loss: 0.5418\n",
      "Epoch 2259/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5418\n",
      "Epoch 2260/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5418\n",
      "Epoch 2261/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5417\n",
      "Epoch 2262/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6818 - loss: 0.5417\n",
      "Epoch 2263/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6818 - loss: 0.5416\n",
      "Epoch 2264/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6818 - loss: 0.5416\n",
      "Epoch 2265/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.6818 - loss: 0.5416\n",
      "Epoch 2266/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5415\n",
      "Epoch 2267/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5415\n",
      "Epoch 2268/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6818 - loss: 0.5414\n",
      "Epoch 2269/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5414\n",
      "Epoch 2270/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6818 - loss: 0.5413\n",
      "Epoch 2271/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6818 - loss: 0.5413\n",
      "Epoch 2272/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6818 - loss: 0.5413\n",
      "Epoch 2273/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7273 - loss: 0.5412\n",
      "Epoch 2274/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7273 - loss: 0.5412\n",
      "Epoch 2275/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5411\n",
      "Epoch 2276/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7273 - loss: 0.5411\n",
      "Epoch 2277/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.5411\n",
      "Epoch 2278/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5410\n",
      "Epoch 2279/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5410\n",
      "Epoch 2280/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5409\n",
      "Epoch 2281/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5409\n",
      "Epoch 2282/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5409\n",
      "Epoch 2283/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7273 - loss: 0.5408\n",
      "Epoch 2284/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7273 - loss: 0.5408\n",
      "Epoch 2285/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5407\n",
      "Epoch 2286/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5407\n",
      "Epoch 2287/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5406\n",
      "Epoch 2288/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.5406\n",
      "Epoch 2289/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5406\n",
      "Epoch 2290/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5405\n",
      "Epoch 2291/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5405\n",
      "Epoch 2292/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5404\n",
      "Epoch 2293/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5404\n",
      "Epoch 2294/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5404\n",
      "Epoch 2295/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5403\n",
      "Epoch 2296/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5403\n",
      "Epoch 2297/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5402\n",
      "Epoch 2298/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5402\n",
      "Epoch 2299/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5402\n",
      "Epoch 2300/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5401\n",
      "Epoch 2301/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.5401\n",
      "Epoch 2302/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7273 - loss: 0.5400\n",
      "Epoch 2303/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7273 - loss: 0.5400\n",
      "Epoch 2304/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5400\n",
      "Epoch 2305/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5399\n",
      "Epoch 2306/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5399\n",
      "Epoch 2307/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5398\n",
      "Epoch 2308/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5398\n",
      "Epoch 2309/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5398\n",
      "Epoch 2310/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5397\n",
      "Epoch 2311/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5397\n",
      "Epoch 2312/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5396\n",
      "Epoch 2313/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5396\n",
      "Epoch 2314/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5396\n",
      "Epoch 2315/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5395\n",
      "Epoch 2316/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5395\n",
      "Epoch 2317/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5394\n",
      "Epoch 2318/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5394\n",
      "Epoch 2319/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5393\n",
      "Epoch 2320/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7273 - loss: 0.5393\n",
      "Epoch 2321/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7273 - loss: 0.5393\n",
      "Epoch 2322/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5392\n",
      "Epoch 2323/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.5392\n",
      "Epoch 2324/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5391\n",
      "Epoch 2325/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5391\n",
      "Epoch 2326/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5391\n",
      "Epoch 2327/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5390\n",
      "Epoch 2328/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.5390\n",
      "Epoch 2329/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5389\n",
      "Epoch 2330/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5389\n",
      "Epoch 2331/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5389\n",
      "Epoch 2332/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5388\n",
      "Epoch 2333/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5388\n",
      "Epoch 2334/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5387\n",
      "Epoch 2335/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5387\n",
      "Epoch 2336/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5387\n",
      "Epoch 2337/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5386\n",
      "Epoch 2338/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7273 - loss: 0.5386\n",
      "Epoch 2339/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7273 - loss: 0.5385\n",
      "Epoch 2340/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.5385\n",
      "Epoch 2341/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5385\n",
      "Epoch 2342/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5384\n",
      "Epoch 2343/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.5384\n",
      "Epoch 2344/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5383\n",
      "Epoch 2345/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.5383\n",
      "Epoch 2346/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5383\n",
      "Epoch 2347/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5382\n",
      "Epoch 2348/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5382\n",
      "Epoch 2349/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5381\n",
      "Epoch 2350/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5381\n",
      "Epoch 2351/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5381\n",
      "Epoch 2352/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5380\n",
      "Epoch 2353/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5380\n",
      "Epoch 2354/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5379\n",
      "Epoch 2355/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5379\n",
      "Epoch 2356/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7273 - loss: 0.5379\n",
      "Epoch 2357/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7273 - loss: 0.5378\n",
      "Epoch 2358/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5378\n",
      "Epoch 2359/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5377\n",
      "Epoch 2360/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5377\n",
      "Epoch 2361/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5377\n",
      "Epoch 2362/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5376\n",
      "Epoch 2363/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5376\n",
      "Epoch 2364/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5375\n",
      "Epoch 2365/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5375\n",
      "Epoch 2366/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5375\n",
      "Epoch 2367/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5374\n",
      "Epoch 2368/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5374\n",
      "Epoch 2369/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5373\n",
      "Epoch 2370/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5373\n",
      "Epoch 2371/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5373\n",
      "Epoch 2372/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7273 - loss: 0.5372\n",
      "Epoch 2373/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7273 - loss: 0.5372\n",
      "Epoch 2374/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5371\n",
      "Epoch 2375/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5371\n",
      "Epoch 2376/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5371\n",
      "Epoch 2377/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5370\n",
      "Epoch 2378/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5370\n",
      "Epoch 2379/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5369\n",
      "Epoch 2380/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5369\n",
      "Epoch 2381/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5369\n",
      "Epoch 2382/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5368\n",
      "Epoch 2383/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5368\n",
      "Epoch 2384/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5367\n",
      "Epoch 2385/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5367\n",
      "Epoch 2386/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5367\n",
      "Epoch 2387/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7273 - loss: 0.5366\n",
      "Epoch 2388/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7273 - loss: 0.5366\n",
      "Epoch 2389/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5365\n",
      "Epoch 2390/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5365\n",
      "Epoch 2391/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5365\n",
      "Epoch 2392/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5364\n",
      "Epoch 2393/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5364\n",
      "Epoch 2394/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5363\n",
      "Epoch 2395/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5363\n",
      "Epoch 2396/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.5363\n",
      "Epoch 2397/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5362\n",
      "Epoch 2398/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.5362\n",
      "Epoch 2399/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5361\n",
      "Epoch 2400/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5361\n",
      "Epoch 2401/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5361\n",
      "Epoch 2402/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.5360\n",
      "Epoch 2403/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.5360\n",
      "Epoch 2404/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7273 - loss: 0.5359\n",
      "Epoch 2405/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7273 - loss: 0.5359\n",
      "Epoch 2406/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5359\n",
      "Epoch 2407/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5358\n",
      "Epoch 2408/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5358\n",
      "Epoch 2409/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.5357\n",
      "Epoch 2410/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5357\n",
      "Epoch 2411/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5357\n",
      "Epoch 2412/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5356\n",
      "Epoch 2413/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5356\n",
      "Epoch 2414/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5355\n",
      "Epoch 2415/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5355\n",
      "Epoch 2416/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.5355\n",
      "Epoch 2417/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5354\n",
      "Epoch 2418/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5354\n",
      "Epoch 2419/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7273 - loss: 0.5353\n",
      "Epoch 2420/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7273 - loss: 0.5353\n",
      "Epoch 2421/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5353\n",
      "Epoch 2422/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5352\n",
      "Epoch 2423/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5352\n",
      "Epoch 2424/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5352\n",
      "Epoch 2425/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5351\n",
      "Epoch 2426/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5351\n",
      "Epoch 2427/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5350\n",
      "Epoch 2428/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5350\n",
      "Epoch 2429/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5350\n",
      "Epoch 2430/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5349\n",
      "Epoch 2431/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5349\n",
      "Epoch 2432/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5348\n",
      "Epoch 2433/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5348\n",
      "Epoch 2434/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5348\n",
      "Epoch 2435/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5347\n",
      "Epoch 2436/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7273 - loss: 0.5347\n",
      "Epoch 2437/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5346\n",
      "Epoch 2438/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5346\n",
      "Epoch 2439/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5346\n",
      "Epoch 2440/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5345\n",
      "Epoch 2441/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5345\n",
      "Epoch 2442/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5344\n",
      "Epoch 2443/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5344\n",
      "Epoch 2444/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5344\n",
      "Epoch 2445/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5343\n",
      "Epoch 2446/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5343\n",
      "Epoch 2447/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5342\n",
      "Epoch 2448/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5342\n",
      "Epoch 2449/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.5342\n",
      "Epoch 2450/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5341\n",
      "Epoch 2451/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5341\n",
      "Epoch 2452/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.5341\n",
      "Epoch 2453/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7273 - loss: 0.5340\n",
      "Epoch 2454/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7273 - loss: 0.5340\n",
      "Epoch 2455/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.5339\n",
      "Epoch 2456/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7273 - loss: 0.5339\n",
      "Epoch 2457/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5339\n",
      "Epoch 2458/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5338\n",
      "Epoch 2459/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5338\n",
      "Epoch 2460/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5337\n",
      "Epoch 2461/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5337\n",
      "Epoch 2462/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5337\n",
      "Epoch 2463/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5336\n",
      "Epoch 2464/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5336\n",
      "Epoch 2465/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5335\n",
      "Epoch 2466/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7273 - loss: 0.5335\n",
      "Epoch 2467/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7273 - loss: 0.5335\n",
      "Epoch 2468/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5334\n",
      "Epoch 2469/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.5334\n",
      "Epoch 2470/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.5334\n",
      "Epoch 2471/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.5333\n",
      "Epoch 2472/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.5333\n",
      "Epoch 2473/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5332\n",
      "Epoch 2474/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5332\n",
      "Epoch 2475/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.5332\n",
      "Epoch 2476/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.5331\n",
      "Epoch 2477/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.5331\n",
      "Epoch 2478/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7273 - loss: 0.5330\n",
      "Epoch 2479/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5330\n",
      "Epoch 2480/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5330\n",
      "Epoch 2481/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5329\n",
      "Epoch 2482/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5329\n",
      "Epoch 2483/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7273 - loss: 0.5328\n",
      "Epoch 2484/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.5328\n",
      "Epoch 2485/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5328\n",
      "Epoch 2486/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5327\n",
      "Epoch 2487/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5327\n",
      "Epoch 2488/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5327\n",
      "Epoch 2489/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5326\n",
      "Epoch 2490/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5326\n",
      "Epoch 2491/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5325\n",
      "Epoch 2492/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5325\n",
      "Epoch 2493/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5325\n",
      "Epoch 2494/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5324\n",
      "Epoch 2495/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.5324\n",
      "Epoch 2496/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.5323\n",
      "Epoch 2497/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5323\n",
      "Epoch 2498/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5323\n",
      "Epoch 2499/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7273 - loss: 0.5322\n",
      "Epoch 2500/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7273 - loss: 0.5322\n",
      "Epoch 2501/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5321\n",
      "Epoch 2502/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5321\n",
      "Epoch 2503/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5321\n",
      "Epoch 2504/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5320\n",
      "Epoch 2505/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5320\n",
      "Epoch 2506/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5320\n",
      "Epoch 2507/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5319\n",
      "Epoch 2508/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.5319\n",
      "Epoch 2509/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.5318\n",
      "Epoch 2510/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.5318\n",
      "Epoch 2511/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.5318\n",
      "Epoch 2512/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5317\n",
      "Epoch 2513/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5317\n",
      "Epoch 2514/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5316\n",
      "Epoch 2515/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5316\n",
      "Epoch 2516/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7273 - loss: 0.5316\n",
      "Epoch 2517/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7273 - loss: 0.5315\n",
      "Epoch 2518/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.5315\n",
      "Epoch 2519/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5315\n",
      "Epoch 2520/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5314\n",
      "Epoch 2521/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5314\n",
      "Epoch 2522/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5313\n",
      "Epoch 2523/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5313\n",
      "Epoch 2524/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5313\n",
      "Epoch 2525/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5312\n",
      "Epoch 2526/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5312\n",
      "Epoch 2527/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5311\n",
      "Epoch 2528/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5311\n",
      "Epoch 2529/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5311\n",
      "Epoch 2530/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5310\n",
      "Epoch 2531/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5310\n",
      "Epoch 2532/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5310\n",
      "Epoch 2533/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7273 - loss: 0.5309\n",
      "Epoch 2534/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5309\n",
      "Epoch 2535/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5308\n",
      "Epoch 2536/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5308\n",
      "Epoch 2537/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5308\n",
      "Epoch 2538/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5307\n",
      "Epoch 2539/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5307\n",
      "Epoch 2540/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5307\n",
      "Epoch 2541/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5306\n",
      "Epoch 2542/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5306\n",
      "Epoch 2543/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5305\n",
      "Epoch 2544/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5305\n",
      "Epoch 2545/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5305\n",
      "Epoch 2546/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5304\n",
      "Epoch 2547/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.5304\n",
      "Epoch 2548/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7273 - loss: 0.5303\n",
      "Epoch 2549/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.5303\n",
      "Epoch 2550/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.5303\n",
      "Epoch 2551/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.5302\n",
      "Epoch 2552/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5302\n",
      "Epoch 2553/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.5302\n",
      "Epoch 2554/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5301\n",
      "Epoch 2555/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5301\n",
      "Epoch 2556/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5300\n",
      "Epoch 2557/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5300\n",
      "Epoch 2558/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5300\n",
      "Epoch 2559/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5299\n",
      "Epoch 2560/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5299\n",
      "Epoch 2561/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5299\n",
      "Epoch 2562/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7273 - loss: 0.5298\n",
      "Epoch 2563/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7273 - loss: 0.5298\n",
      "Epoch 2564/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.5297\n",
      "Epoch 2565/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7273 - loss: 0.5297\n",
      "Epoch 2566/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.5297\n",
      "Epoch 2567/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5296\n",
      "Epoch 2568/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5296\n",
      "Epoch 2569/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5295\n",
      "Epoch 2570/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5295\n",
      "Epoch 2571/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5295\n",
      "Epoch 2572/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5294\n",
      "Epoch 2573/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5294\n",
      "Epoch 2574/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5294\n",
      "Epoch 2575/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.5293\n",
      "Epoch 2576/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.5293\n",
      "Epoch 2577/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7273 - loss: 0.5292\n",
      "Epoch 2578/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7273 - loss: 0.5292\n",
      "Epoch 2579/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7273 - loss: 0.5292\n",
      "Epoch 2580/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.5291\n",
      "Epoch 2581/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5291\n",
      "Epoch 2582/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7273 - loss: 0.5291\n",
      "Epoch 2583/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5290\n",
      "Epoch 2584/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5290\n",
      "Epoch 2585/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5289\n",
      "Epoch 2586/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.5289\n",
      "Epoch 2587/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5289\n",
      "Epoch 2588/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.5288\n",
      "Epoch 2589/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.5288\n",
      "Epoch 2590/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.5288\n",
      "Epoch 2591/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.5287\n",
      "Epoch 2592/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.5287\n",
      "Epoch 2593/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.5286\n",
      "Epoch 2594/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7273 - loss: 0.5286\n",
      "Epoch 2595/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7273 - loss: 0.5286\n",
      "Epoch 2596/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7273 - loss: 0.5285\n",
      "Epoch 2597/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.5285\n",
      "Epoch 2598/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.5285\n",
      "Epoch 2599/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.5284\n",
      "Epoch 2600/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.5284\n",
      "Epoch 2601/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7273 - loss: 0.5283\n",
      "Epoch 2602/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5283\n",
      "Epoch 2603/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.5283\n",
      "Epoch 2604/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7273 - loss: 0.5282\n",
      "Epoch 2605/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.5282\n",
      "Epoch 2606/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.5282\n",
      "Epoch 2607/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7273 - loss: 0.5281\n",
      "Epoch 2608/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7273 - loss: 0.5281\n",
      "Epoch 2609/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7273 - loss: 0.5280\n",
      "Epoch 2610/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.5280\n",
      "Epoch 2611/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5280\n",
      "Epoch 2612/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5279\n",
      "Epoch 2613/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7273 - loss: 0.5279\n",
      "Epoch 2614/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5279\n",
      "Epoch 2615/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5278\n",
      "Epoch 2616/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5278\n",
      "Epoch 2617/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5277\n",
      "Epoch 2618/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5277\n",
      "Epoch 2619/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5277\n",
      "Epoch 2620/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5276\n",
      "Epoch 2621/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5276\n",
      "Epoch 2622/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5276\n",
      "Epoch 2623/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5275\n",
      "Epoch 2624/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5275\n",
      "Epoch 2625/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7273 - loss: 0.5274\n",
      "Epoch 2626/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7273 - loss: 0.5274\n",
      "Epoch 2627/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5274\n",
      "Epoch 2628/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5273\n",
      "Epoch 2629/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5273\n",
      "Epoch 2630/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5273\n",
      "Epoch 2631/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7273 - loss: 0.5272\n",
      "Epoch 2632/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7273 - loss: 0.5272\n",
      "Epoch 2633/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5271\n",
      "Epoch 2634/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7273 - loss: 0.5271\n",
      "Epoch 2635/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5271\n",
      "Epoch 2636/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5270\n",
      "Epoch 2637/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7273 - loss: 0.5270\n",
      "Epoch 2638/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7273 - loss: 0.5270\n",
      "Epoch 2639/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7273 - loss: 0.5269\n",
      "Epoch 2640/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7273 - loss: 0.5269\n",
      "Epoch 2641/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7273 - loss: 0.5268\n",
      "Epoch 2642/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5268\n",
      "Epoch 2643/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5268\n",
      "Epoch 2644/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5267\n",
      "Epoch 2645/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5267\n",
      "Epoch 2646/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5267\n",
      "Epoch 2647/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5266\n",
      "Epoch 2648/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5266\n",
      "Epoch 2649/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5265\n",
      "Epoch 2650/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5265\n",
      "Epoch 2651/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5265\n",
      "Epoch 2652/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7727 - loss: 0.5264\n",
      "Epoch 2653/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7727 - loss: 0.5264\n",
      "Epoch 2654/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7727 - loss: 0.5264\n",
      "Epoch 2655/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7727 - loss: 0.5263\n",
      "Epoch 2656/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7727 - loss: 0.5263\n",
      "Epoch 2657/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7727 - loss: 0.5263\n",
      "Epoch 2658/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7727 - loss: 0.5262\n",
      "Epoch 2659/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5262\n",
      "Epoch 2660/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5261\n",
      "Epoch 2661/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5261\n",
      "Epoch 2662/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7727 - loss: 0.5261\n",
      "Epoch 2663/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5260\n",
      "Epoch 2664/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7727 - loss: 0.5260\n",
      "Epoch 2665/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5260\n",
      "Epoch 2666/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7727 - loss: 0.5259\n",
      "Epoch 2667/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7727 - loss: 0.5259\n",
      "Epoch 2668/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5258\n",
      "Epoch 2669/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7727 - loss: 0.5258\n",
      "Epoch 2670/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5258\n",
      "Epoch 2671/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7727 - loss: 0.5257\n",
      "Epoch 2672/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7727 - loss: 0.5257\n",
      "Epoch 2673/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7727 - loss: 0.5257\n",
      "Epoch 2674/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5256\n",
      "Epoch 2675/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7727 - loss: 0.5256\n",
      "Epoch 2676/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5256\n",
      "Epoch 2677/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5255\n",
      "Epoch 2678/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5255\n",
      "Epoch 2679/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5254\n",
      "Epoch 2680/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5254\n",
      "Epoch 2681/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5254\n",
      "Epoch 2682/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5253\n",
      "Epoch 2683/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7727 - loss: 0.5253\n",
      "Epoch 2684/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7727 - loss: 0.5253\n",
      "Epoch 2685/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7727 - loss: 0.5252\n",
      "Epoch 2686/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5252\n",
      "Epoch 2687/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7727 - loss: 0.5251\n",
      "Epoch 2688/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7727 - loss: 0.5251\n",
      "Epoch 2689/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7727 - loss: 0.5251\n",
      "Epoch 2690/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7727 - loss: 0.5250\n",
      "Epoch 2691/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7727 - loss: 0.5250\n",
      "Epoch 2692/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7727 - loss: 0.5250\n",
      "Epoch 2693/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7727 - loss: 0.5249\n",
      "Epoch 2694/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7727 - loss: 0.5249\n",
      "Epoch 2695/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7727 - loss: 0.5249\n",
      "Epoch 2696/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7727 - loss: 0.5248\n",
      "Epoch 2697/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5248\n",
      "Epoch 2698/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5247\n",
      "Epoch 2699/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7727 - loss: 0.5247\n",
      "Epoch 2700/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7727 - loss: 0.5247\n",
      "Epoch 2701/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7727 - loss: 0.5246\n",
      "Epoch 2702/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7727 - loss: 0.5246\n",
      "Epoch 2703/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7727 - loss: 0.5246\n",
      "Epoch 2704/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5245\n",
      "Epoch 2705/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7727 - loss: 0.5245\n",
      "Epoch 2706/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7727 - loss: 0.5245\n",
      "Epoch 2707/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5244\n",
      "Epoch 2708/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5244\n",
      "Epoch 2709/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5243\n",
      "Epoch 2710/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7727 - loss: 0.5243\n",
      "Epoch 2711/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7727 - loss: 0.5243\n",
      "Epoch 2712/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5242\n",
      "Epoch 2713/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5242\n",
      "Epoch 2714/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7727 - loss: 0.5242\n",
      "Epoch 2715/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5241\n",
      "Epoch 2716/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7727 - loss: 0.5241\n",
      "Epoch 2717/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7727 - loss: 0.5241\n",
      "Epoch 2718/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7727 - loss: 0.5240\n",
      "Epoch 2719/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7727 - loss: 0.5240\n",
      "Epoch 2720/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7727 - loss: 0.5239\n",
      "Epoch 2721/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7727 - loss: 0.5239\n",
      "Epoch 2722/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5239\n",
      "Epoch 2723/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7727 - loss: 0.5238\n",
      "Epoch 2724/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7727 - loss: 0.5238\n",
      "Epoch 2725/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7727 - loss: 0.5238\n",
      "Epoch 2726/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7727 - loss: 0.5237\n",
      "Epoch 2727/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7727 - loss: 0.5237\n",
      "Epoch 2728/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7727 - loss: 0.5237\n",
      "Epoch 2729/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7727 - loss: 0.5236\n",
      "Epoch 2730/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7727 - loss: 0.5236\n",
      "Epoch 2731/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7727 - loss: 0.5235\n",
      "Epoch 2732/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7727 - loss: 0.5235\n",
      "Epoch 2733/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7727 - loss: 0.5235\n",
      "Epoch 2734/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5234\n",
      "Epoch 2735/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7727 - loss: 0.5234\n",
      "Epoch 2736/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7727 - loss: 0.5234\n",
      "Epoch 2737/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5233\n",
      "Epoch 2738/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7727 - loss: 0.5233\n",
      "Epoch 2739/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7727 - loss: 0.5233\n",
      "Epoch 2740/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7727 - loss: 0.5232\n",
      "Epoch 2741/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5232\n",
      "Epoch 2742/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7727 - loss: 0.5231\n",
      "Epoch 2743/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5231\n",
      "Epoch 2744/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5231\n",
      "Epoch 2745/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7727 - loss: 0.5230\n",
      "Epoch 2746/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5230\n",
      "Epoch 2747/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7727 - loss: 0.5230\n",
      "Epoch 2748/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7727 - loss: 0.5229\n",
      "Epoch 2749/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7727 - loss: 0.5229\n",
      "Epoch 2750/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7727 - loss: 0.5229\n",
      "Epoch 2751/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7727 - loss: 0.5228\n",
      "Epoch 2752/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5228\n",
      "Epoch 2753/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7727 - loss: 0.5227\n",
      "Epoch 2754/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7727 - loss: 0.5227\n",
      "Epoch 2755/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7727 - loss: 0.5227\n",
      "Epoch 2756/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5226\n",
      "Epoch 2757/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7727 - loss: 0.5226\n",
      "Epoch 2758/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7727 - loss: 0.5226\n",
      "Epoch 2759/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5225\n",
      "Epoch 2760/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7727 - loss: 0.5225\n",
      "Epoch 2761/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7727 - loss: 0.5225\n",
      "Epoch 2762/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7727 - loss: 0.5224\n",
      "Epoch 2763/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7727 - loss: 0.5224\n",
      "Epoch 2764/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7727 - loss: 0.5224\n",
      "Epoch 2765/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.7727 - loss: 0.5223\n",
      "Epoch 2766/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7727 - loss: 0.5223\n",
      "Epoch 2767/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7727 - loss: 0.5222\n",
      "Epoch 2768/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5222\n",
      "Epoch 2769/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5222\n",
      "Epoch 2770/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5221\n",
      "Epoch 2771/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5221\n",
      "Epoch 2772/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5221\n",
      "Epoch 2773/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5220\n",
      "Epoch 2774/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5220\n",
      "Epoch 2775/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5220\n",
      "Epoch 2776/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7727 - loss: 0.5219\n",
      "Epoch 2777/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7727 - loss: 0.5219\n",
      "Epoch 2778/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7727 - loss: 0.5219\n",
      "Epoch 2779/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7727 - loss: 0.5218\n",
      "Epoch 2780/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7727 - loss: 0.5218\n",
      "Epoch 2781/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5217\n",
      "Epoch 2782/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5217\n",
      "Epoch 2783/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5217\n",
      "Epoch 2784/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7727 - loss: 0.5216\n",
      "Epoch 2785/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5216\n",
      "Epoch 2786/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7727 - loss: 0.5216\n",
      "Epoch 2787/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5215\n",
      "Epoch 2788/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7727 - loss: 0.5215\n",
      "Epoch 2789/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7727 - loss: 0.5215\n",
      "Epoch 2790/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.7727 - loss: 0.5214\n",
      "Epoch 2791/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7727 - loss: 0.5214\n",
      "Epoch 2792/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8182 - loss: 0.5214\n",
      "Epoch 2793/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8182 - loss: 0.5213\n",
      "Epoch 2794/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5213\n",
      "Epoch 2795/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8182 - loss: 0.5212\n",
      "Epoch 2796/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5212\n",
      "Epoch 2797/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5212\n",
      "Epoch 2798/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5211\n",
      "Epoch 2799/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8182 - loss: 0.5211\n",
      "Epoch 2800/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8182 - loss: 0.5211\n",
      "Epoch 2801/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8182 - loss: 0.5210\n",
      "Epoch 2802/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8182 - loss: 0.5210\n",
      "Epoch 2803/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5210\n",
      "Epoch 2804/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8182 - loss: 0.5209\n",
      "Epoch 2805/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8182 - loss: 0.5209\n",
      "Epoch 2806/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5209\n",
      "Epoch 2807/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5208\n",
      "Epoch 2808/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5208\n",
      "Epoch 2809/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5207\n",
      "Epoch 2810/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8182 - loss: 0.5207\n",
      "Epoch 2811/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5207\n",
      "Epoch 2812/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5206\n",
      "Epoch 2813/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5206\n",
      "Epoch 2814/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5206\n",
      "Epoch 2815/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5205\n",
      "Epoch 2816/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5205\n",
      "Epoch 2817/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5205\n",
      "Epoch 2818/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8182 - loss: 0.5204\n",
      "Epoch 2819/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8182 - loss: 0.5204\n",
      "Epoch 2820/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8182 - loss: 0.5204\n",
      "Epoch 2821/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5203\n",
      "Epoch 2822/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5203\n",
      "Epoch 2823/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8182 - loss: 0.5203\n",
      "Epoch 2824/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8182 - loss: 0.5202\n",
      "Epoch 2825/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5202\n",
      "Epoch 2826/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8182 - loss: 0.5201\n",
      "Epoch 2827/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5201\n",
      "Epoch 2828/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5201\n",
      "Epoch 2829/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5200\n",
      "Epoch 2830/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5200\n",
      "Epoch 2831/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5200\n",
      "Epoch 2832/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5199\n",
      "Epoch 2833/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8182 - loss: 0.5199\n",
      "Epoch 2834/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8182 - loss: 0.5199\n",
      "Epoch 2835/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8182 - loss: 0.5198\n",
      "Epoch 2836/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5198\n",
      "Epoch 2837/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5198\n",
      "Epoch 2838/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5197\n",
      "Epoch 2839/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5197\n",
      "Epoch 2840/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5197\n",
      "Epoch 2841/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5196\n",
      "Epoch 2842/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5196\n",
      "Epoch 2843/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8182 - loss: 0.5195\n",
      "Epoch 2844/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8182 - loss: 0.5195\n",
      "Epoch 2845/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5195\n",
      "Epoch 2846/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5194\n",
      "Epoch 2847/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5194\n",
      "Epoch 2848/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5194\n",
      "Epoch 2849/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8182 - loss: 0.5193\n",
      "Epoch 2850/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8182 - loss: 0.5193\n",
      "Epoch 2851/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8182 - loss: 0.5193\n",
      "Epoch 2852/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5192\n",
      "Epoch 2853/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5192\n",
      "Epoch 2854/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5192\n",
      "Epoch 2855/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5191\n",
      "Epoch 2856/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5191\n",
      "Epoch 2857/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5191\n",
      "Epoch 2858/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5190\n",
      "Epoch 2859/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5190\n",
      "Epoch 2860/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8182 - loss: 0.5190\n",
      "Epoch 2861/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5189\n",
      "Epoch 2862/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5189\n",
      "Epoch 2863/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5188\n",
      "Epoch 2864/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5188\n",
      "Epoch 2865/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8182 - loss: 0.5188\n",
      "Epoch 2866/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8182 - loss: 0.5187\n",
      "Epoch 2867/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8182 - loss: 0.5187\n",
      "Epoch 2868/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5187\n",
      "Epoch 2869/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5186\n",
      "Epoch 2870/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5186\n",
      "Epoch 2871/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5186\n",
      "Epoch 2872/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5185\n",
      "Epoch 2873/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5185\n",
      "Epoch 2874/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5185\n",
      "Epoch 2875/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8182 - loss: 0.5184\n",
      "Epoch 2876/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5184\n",
      "Epoch 2877/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8182 - loss: 0.5184\n",
      "Epoch 2878/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8182 - loss: 0.5183\n",
      "Epoch 2879/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5183\n",
      "Epoch 2880/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8182 - loss: 0.5183\n",
      "Epoch 2881/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8182 - loss: 0.5182\n",
      "Epoch 2882/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5182\n",
      "Epoch 2883/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5181\n",
      "Epoch 2884/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5181\n",
      "Epoch 2885/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8182 - loss: 0.5181\n",
      "Epoch 2886/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8182 - loss: 0.5180\n",
      "Epoch 2887/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8182 - loss: 0.5180\n",
      "Epoch 2888/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5180\n",
      "Epoch 2889/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5179\n",
      "Epoch 2890/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5179\n",
      "Epoch 2891/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8182 - loss: 0.5179\n",
      "Epoch 2892/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8182 - loss: 0.5178\n",
      "Epoch 2893/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8182 - loss: 0.5178\n",
      "Epoch 2894/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8182 - loss: 0.5178\n",
      "Epoch 2895/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8182 - loss: 0.5177\n",
      "Epoch 2896/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8182 - loss: 0.5177\n",
      "Epoch 2897/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8182 - loss: 0.5177\n",
      "Epoch 2898/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5176\n",
      "Epoch 2899/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5176\n",
      "Epoch 2900/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5176\n",
      "Epoch 2901/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8182 - loss: 0.5175\n",
      "Epoch 2902/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8182 - loss: 0.5175\n",
      "Epoch 2903/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5175\n",
      "Epoch 2904/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8182 - loss: 0.5174\n",
      "Epoch 2905/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5174\n",
      "Epoch 2906/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5174\n",
      "Epoch 2907/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5173\n",
      "Epoch 2908/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5173\n",
      "Epoch 2909/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8182 - loss: 0.5172\n",
      "Epoch 2910/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8182 - loss: 0.5172\n",
      "Epoch 2911/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8182 - loss: 0.5172\n",
      "Epoch 2912/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8182 - loss: 0.5171\n",
      "Epoch 2913/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8182 - loss: 0.5171\n",
      "Epoch 2914/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8182 - loss: 0.5171\n",
      "Epoch 2915/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8182 - loss: 0.5170\n",
      "Epoch 2916/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8182 - loss: 0.5170\n",
      "Epoch 2917/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5170\n",
      "Epoch 2918/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8182 - loss: 0.5169\n",
      "Epoch 2919/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5169\n",
      "Epoch 2920/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5169\n",
      "Epoch 2921/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5168\n",
      "Epoch 2922/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8182 - loss: 0.5168\n",
      "Epoch 2923/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8182 - loss: 0.5168\n",
      "Epoch 2924/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8182 - loss: 0.5167\n",
      "Epoch 2925/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8182 - loss: 0.5167\n",
      "Epoch 2926/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5167\n",
      "Epoch 2927/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5166\n",
      "Epoch 2928/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5166\n",
      "Epoch 2929/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5166\n",
      "Epoch 2930/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5165\n",
      "Epoch 2931/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5165\n",
      "Epoch 2932/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8182 - loss: 0.5165\n",
      "Epoch 2933/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8182 - loss: 0.5164\n",
      "Epoch 2934/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8182 - loss: 0.5164\n",
      "Epoch 2935/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5164\n",
      "Epoch 2936/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8182 - loss: 0.5163\n",
      "Epoch 2937/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5163\n",
      "Epoch 2938/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5163\n",
      "Epoch 2939/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8182 - loss: 0.5162\n",
      "Epoch 2940/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5162\n",
      "Epoch 2941/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8182 - loss: 0.5162\n",
      "Epoch 2942/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5161\n",
      "Epoch 2943/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8182 - loss: 0.5161\n",
      "Epoch 2944/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8182 - loss: 0.5160\n",
      "Epoch 2945/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5160\n",
      "Epoch 2946/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5160\n",
      "Epoch 2947/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5159\n",
      "Epoch 2948/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5159\n",
      "Epoch 2949/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5159\n",
      "Epoch 2950/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8182 - loss: 0.5158\n",
      "Epoch 2951/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5158\n",
      "Epoch 2952/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5158\n",
      "Epoch 2953/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8182 - loss: 0.5157\n",
      "Epoch 2954/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8182 - loss: 0.5157\n",
      "Epoch 2955/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8182 - loss: 0.5157\n",
      "Epoch 2956/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5156\n",
      "Epoch 2957/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5156\n",
      "Epoch 2958/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8182 - loss: 0.5156\n",
      "Epoch 2959/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8182 - loss: 0.5155\n",
      "Epoch 2960/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5155\n",
      "Epoch 2961/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5155\n",
      "Epoch 2962/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5154\n",
      "Epoch 2963/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5154\n",
      "Epoch 2964/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5154\n",
      "Epoch 2965/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5153\n",
      "Epoch 2966/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5153\n",
      "Epoch 2967/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8636 - loss: 0.5153\n",
      "Epoch 2968/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8636 - loss: 0.5152\n",
      "Epoch 2969/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5152\n",
      "Epoch 2970/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5152\n",
      "Epoch 2971/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5151\n",
      "Epoch 2972/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5151\n",
      "Epoch 2973/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5151\n",
      "Epoch 2974/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5150\n",
      "Epoch 2975/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5150\n",
      "Epoch 2976/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5150\n",
      "Epoch 2977/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5149\n",
      "Epoch 2978/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5149\n",
      "Epoch 2979/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5149\n",
      "Epoch 2980/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5148\n",
      "Epoch 2981/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5148\n",
      "Epoch 2982/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8636 - loss: 0.5148\n",
      "Epoch 2983/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8636 - loss: 0.5147\n",
      "Epoch 2984/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5147\n",
      "Epoch 2985/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5147\n",
      "Epoch 2986/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5146\n",
      "Epoch 2987/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5146\n",
      "Epoch 2988/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5146\n",
      "Epoch 2989/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5145\n",
      "Epoch 2990/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5145\n",
      "Epoch 2991/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5145\n",
      "Epoch 2992/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5144\n",
      "Epoch 2993/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5144\n",
      "Epoch 2994/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5144\n",
      "Epoch 2995/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5143\n",
      "Epoch 2996/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5143\n",
      "Epoch 2997/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8636 - loss: 0.5143\n",
      "Epoch 2998/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8636 - loss: 0.5142\n",
      "Epoch 2999/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5142\n",
      "Epoch 3000/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8636 - loss: 0.5142\n",
      "Epoch 3001/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5141\n",
      "Epoch 3002/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8636 - loss: 0.5141\n",
      "Epoch 3003/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5141\n",
      "Epoch 3004/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5140\n",
      "Epoch 3005/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5140\n",
      "Epoch 3006/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8636 - loss: 0.5140\n",
      "Epoch 3007/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8636 - loss: 0.5139\n",
      "Epoch 3008/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8636 - loss: 0.5139\n",
      "Epoch 3009/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8636 - loss: 0.5139\n",
      "Epoch 3010/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5138\n",
      "Epoch 3011/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5138\n",
      "Epoch 3012/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8636 - loss: 0.5137\n",
      "Epoch 3013/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8636 - loss: 0.5137\n",
      "Epoch 3014/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5137\n",
      "Epoch 3015/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5136\n",
      "Epoch 3016/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5136\n",
      "Epoch 3017/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5136\n",
      "Epoch 3018/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8636 - loss: 0.5135\n",
      "Epoch 3019/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5135\n",
      "Epoch 3020/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5135\n",
      "Epoch 3021/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8636 - loss: 0.5134\n",
      "Epoch 3022/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5134\n",
      "Epoch 3023/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8636 - loss: 0.5134\n",
      "Epoch 3024/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8636 - loss: 0.5133\n",
      "Epoch 3025/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8636 - loss: 0.5133\n",
      "Epoch 3026/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5133\n",
      "Epoch 3027/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5132\n",
      "Epoch 3028/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5132\n",
      "Epoch 3029/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5132\n",
      "Epoch 3030/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5131\n",
      "Epoch 3031/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5131\n",
      "Epoch 3032/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5131\n",
      "Epoch 3033/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5130\n",
      "Epoch 3034/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5130\n",
      "Epoch 3035/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5130\n",
      "Epoch 3036/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5129\n",
      "Epoch 3037/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.8636 - loss: 0.5129\n",
      "Epoch 3038/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5129\n",
      "Epoch 3039/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5128\n",
      "Epoch 3040/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5128\n",
      "Epoch 3041/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5128\n",
      "Epoch 3042/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5127\n",
      "Epoch 3043/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5127\n",
      "Epoch 3044/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5127\n",
      "Epoch 3045/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5126\n",
      "Epoch 3046/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5126\n",
      "Epoch 3047/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5126\n",
      "Epoch 3048/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5126\n",
      "Epoch 3049/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5125\n",
      "Epoch 3050/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5125\n",
      "Epoch 3051/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8636 - loss: 0.5125\n",
      "Epoch 3052/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8636 - loss: 0.5124\n",
      "Epoch 3053/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8636 - loss: 0.5124\n",
      "Epoch 3054/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5124\n",
      "Epoch 3055/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8636 - loss: 0.5123\n",
      "Epoch 3056/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5123\n",
      "Epoch 3057/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5123\n",
      "Epoch 3058/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5122\n",
      "Epoch 3059/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5122\n",
      "Epoch 3060/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8636 - loss: 0.5122\n",
      "Epoch 3061/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8636 - loss: 0.5121\n",
      "Epoch 3062/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5121\n",
      "Epoch 3063/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5121\n",
      "Epoch 3064/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8636 - loss: 0.5120\n",
      "Epoch 3065/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8636 - loss: 0.5120\n",
      "Epoch 3066/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8636 - loss: 0.5120\n",
      "Epoch 3067/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8636 - loss: 0.5119\n",
      "Epoch 3068/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5119\n",
      "Epoch 3069/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8636 - loss: 0.5119\n",
      "Epoch 3070/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5118\n",
      "Epoch 3071/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5118\n",
      "Epoch 3072/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5118\n",
      "Epoch 3073/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5117\n",
      "Epoch 3074/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5117\n",
      "Epoch 3075/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5117\n",
      "Epoch 3076/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5116\n",
      "Epoch 3077/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5116\n",
      "Epoch 3078/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5116\n",
      "Epoch 3079/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8636 - loss: 0.5115\n",
      "Epoch 3080/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8636 - loss: 0.5115\n",
      "Epoch 3081/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8636 - loss: 0.5115\n",
      "Epoch 3082/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5114\n",
      "Epoch 3083/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8636 - loss: 0.5114\n",
      "Epoch 3084/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5114\n",
      "Epoch 3085/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5113\n",
      "Epoch 3086/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5113\n",
      "Epoch 3087/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5113\n",
      "Epoch 3088/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5112\n",
      "Epoch 3089/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5112\n",
      "Epoch 3090/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5112\n",
      "Epoch 3091/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5111\n",
      "Epoch 3092/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5111\n",
      "Epoch 3093/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5111\n",
      "Epoch 3094/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8636 - loss: 0.5110\n",
      "Epoch 3095/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8636 - loss: 0.5110\n",
      "Epoch 3096/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8636 - loss: 0.5110\n",
      "Epoch 3097/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5109\n",
      "Epoch 3098/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5109\n",
      "Epoch 3099/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8636 - loss: 0.5109\n",
      "Epoch 3100/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5108\n",
      "Epoch 3101/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8636 - loss: 0.5108\n",
      "Epoch 3102/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8636 - loss: 0.5108\n",
      "Epoch 3103/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5107\n",
      "Epoch 3104/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5107\n",
      "Epoch 3105/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5107\n",
      "Epoch 3106/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5106\n",
      "Epoch 3107/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8636 - loss: 0.5106\n",
      "Epoch 3108/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8636 - loss: 0.5106\n",
      "Epoch 3109/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5105\n",
      "Epoch 3110/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5105\n",
      "Epoch 3111/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5105\n",
      "Epoch 3112/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5104\n",
      "Epoch 3113/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8636 - loss: 0.5104\n",
      "Epoch 3114/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5104\n",
      "Epoch 3115/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5104\n",
      "Epoch 3116/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5103\n",
      "Epoch 3117/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5103\n",
      "Epoch 3118/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5103\n",
      "Epoch 3119/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5102\n",
      "Epoch 3120/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5102\n",
      "Epoch 3121/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5102\n",
      "Epoch 3122/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8636 - loss: 0.5101\n",
      "Epoch 3123/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5101\n",
      "Epoch 3124/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5101\n",
      "Epoch 3125/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5100\n",
      "Epoch 3126/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8636 - loss: 0.5100\n",
      "Epoch 3127/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5100\n",
      "Epoch 3128/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5099\n",
      "Epoch 3129/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5099\n",
      "Epoch 3130/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5099\n",
      "Epoch 3131/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5098\n",
      "Epoch 3132/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5098\n",
      "Epoch 3133/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5098\n",
      "Epoch 3134/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8636 - loss: 0.5097\n",
      "Epoch 3135/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8636 - loss: 0.5097\n",
      "Epoch 3136/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5097\n",
      "Epoch 3137/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5096\n",
      "Epoch 3138/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8636 - loss: 0.5096\n",
      "Epoch 3139/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5096\n",
      "Epoch 3140/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5095\n",
      "Epoch 3141/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8636 - loss: 0.5095\n",
      "Epoch 3142/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5095\n",
      "Epoch 3143/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5094\n",
      "Epoch 3144/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5094\n",
      "Epoch 3145/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5094\n",
      "Epoch 3146/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5093\n",
      "Epoch 3147/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5093\n",
      "Epoch 3148/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8636 - loss: 0.5093\n",
      "Epoch 3149/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8636 - loss: 0.5093\n",
      "Epoch 3150/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5092\n",
      "Epoch 3151/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5092\n",
      "Epoch 3152/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5092\n",
      "Epoch 3153/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8636 - loss: 0.5091\n",
      "Epoch 3154/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8636 - loss: 0.5091\n",
      "Epoch 3155/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5091\n",
      "Epoch 3156/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5090\n",
      "Epoch 3157/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8636 - loss: 0.5090\n",
      "Epoch 3158/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5090\n",
      "Epoch 3159/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5089\n",
      "Epoch 3160/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8636 - loss: 0.5089\n",
      "Epoch 3161/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5089\n",
      "Epoch 3162/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8636 - loss: 0.5088\n",
      "Epoch 3163/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8636 - loss: 0.5088\n",
      "Epoch 3164/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8636 - loss: 0.5088\n",
      "Epoch 3165/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5087\n",
      "Epoch 3166/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5087\n",
      "Epoch 3167/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5087\n",
      "Epoch 3168/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5086\n",
      "Epoch 3169/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5086\n",
      "Epoch 3170/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5086\n",
      "Epoch 3171/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5085\n",
      "Epoch 3172/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5085\n",
      "Epoch 3173/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5085\n",
      "Epoch 3174/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5084\n",
      "Epoch 3175/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8636 - loss: 0.5084\n",
      "Epoch 3176/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8636 - loss: 0.5084\n",
      "Epoch 3177/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8636 - loss: 0.5084\n",
      "Epoch 3178/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8636 - loss: 0.5083\n",
      "Epoch 3179/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5083\n",
      "Epoch 3180/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5083\n",
      "Epoch 3181/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5082\n",
      "Epoch 3182/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5082\n",
      "Epoch 3183/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5082\n",
      "Epoch 3184/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5081\n",
      "Epoch 3185/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5081\n",
      "Epoch 3186/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5081\n",
      "Epoch 3187/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5080\n",
      "Epoch 3188/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5080\n",
      "Epoch 3189/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8636 - loss: 0.5080\n",
      "Epoch 3190/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8636 - loss: 0.5079\n",
      "Epoch 3191/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8636 - loss: 0.5079\n",
      "Epoch 3192/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8636 - loss: 0.5079\n",
      "Epoch 3193/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5078\n",
      "Epoch 3194/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5078\n",
      "Epoch 3195/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5078\n",
      "Epoch 3196/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5077\n",
      "Epoch 3197/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5077\n",
      "Epoch 3198/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5077\n",
      "Epoch 3199/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5077\n",
      "Epoch 3200/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8636 - loss: 0.5076\n",
      "Epoch 3201/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5076\n",
      "Epoch 3202/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5076\n",
      "Epoch 3203/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5075\n",
      "Epoch 3204/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8636 - loss: 0.5075\n",
      "Epoch 3205/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8636 - loss: 0.5075\n",
      "Epoch 3206/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8636 - loss: 0.5074\n",
      "Epoch 3207/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5074\n",
      "Epoch 3208/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5074\n",
      "Epoch 3209/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8636 - loss: 0.5073\n",
      "Epoch 3210/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8636 - loss: 0.5073\n",
      "Epoch 3211/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8636 - loss: 0.5073\n",
      "Epoch 3212/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8636 - loss: 0.5072\n",
      "Epoch 3213/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8636 - loss: 0.5072\n",
      "Epoch 3214/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8636 - loss: 0.5072\n",
      "Epoch 3215/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5071\n",
      "Epoch 3216/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5071\n",
      "Epoch 3217/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8636 - loss: 0.5071\n",
      "Epoch 3218/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5071\n",
      "Epoch 3219/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8636 - loss: 0.5070\n",
      "Epoch 3220/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5070\n",
      "Epoch 3221/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5070\n",
      "Epoch 3222/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8636 - loss: 0.5069\n",
      "Epoch 3223/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8636 - loss: 0.5069\n",
      "Epoch 3224/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5069\n",
      "Epoch 3225/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8636 - loss: 0.5068\n",
      "Epoch 3226/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5068\n",
      "Epoch 3227/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8636 - loss: 0.5068\n",
      "Epoch 3228/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5067\n",
      "Epoch 3229/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5067\n",
      "Epoch 3230/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5067\n",
      "Epoch 3231/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8636 - loss: 0.5066\n",
      "Epoch 3232/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5066\n",
      "Epoch 3233/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8636 - loss: 0.5066\n",
      "Epoch 3234/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5065\n",
      "Epoch 3235/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5065\n",
      "Epoch 3236/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5065\n",
      "Epoch 3237/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5065\n",
      "Epoch 3238/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5064\n",
      "Epoch 3239/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8636 - loss: 0.5064\n",
      "Epoch 3240/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8636 - loss: 0.5064\n",
      "Epoch 3241/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8636 - loss: 0.5063\n",
      "Epoch 3242/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8636 - loss: 0.5063\n",
      "Epoch 3243/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8636 - loss: 0.5063\n",
      "Epoch 3244/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8636 - loss: 0.5062\n",
      "Epoch 3245/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8636 - loss: 0.5062\n",
      "Epoch 3246/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8636 - loss: 0.5062\n",
      "Epoch 3247/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8636 - loss: 0.5061\n",
      "Epoch 3248/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8636 - loss: 0.5061\n",
      "Epoch 3249/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5061\n",
      "Epoch 3250/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5060\n",
      "Epoch 3251/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5060\n",
      "Epoch 3252/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5060\n",
      "Epoch 3253/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5060\n",
      "Epoch 3254/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5059\n",
      "Epoch 3255/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9091 - loss: 0.5059\n",
      "Epoch 3256/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5059\n",
      "Epoch 3257/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9091 - loss: 0.5058\n",
      "Epoch 3258/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5058\n",
      "Epoch 3259/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5058\n",
      "Epoch 3260/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5057\n",
      "Epoch 3261/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9091 - loss: 0.5057\n",
      "Epoch 3262/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.5057\n",
      "Epoch 3263/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5056\n",
      "Epoch 3264/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5056\n",
      "Epoch 3265/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5056\n",
      "Epoch 3266/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.5055\n",
      "Epoch 3267/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9091 - loss: 0.5055\n",
      "Epoch 3268/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.5055\n",
      "Epoch 3269/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.5055\n",
      "Epoch 3270/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5054\n",
      "Epoch 3271/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5054\n",
      "Epoch 3272/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.5054\n",
      "Epoch 3273/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.5053\n",
      "Epoch 3274/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5053\n",
      "Epoch 3275/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.5053\n",
      "Epoch 3276/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.5052\n",
      "Epoch 3277/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.5052\n",
      "Epoch 3278/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5052\n",
      "Epoch 3279/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5051\n",
      "Epoch 3280/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5051\n",
      "Epoch 3281/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5051\n",
      "Epoch 3282/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5050\n",
      "Epoch 3283/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5050\n",
      "Epoch 3284/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5050\n",
      "Epoch 3285/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5050\n",
      "Epoch 3286/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5049\n",
      "Epoch 3287/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.5049\n",
      "Epoch 3288/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5049\n",
      "Epoch 3289/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.5048\n",
      "Epoch 3290/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.5048\n",
      "Epoch 3291/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.5048\n",
      "Epoch 3292/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.5047\n",
      "Epoch 3293/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.5047\n",
      "Epoch 3294/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.5047\n",
      "Epoch 3295/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.5046\n",
      "Epoch 3296/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9091 - loss: 0.5046\n",
      "Epoch 3297/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9091 - loss: 0.5046\n",
      "Epoch 3298/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.5046\n",
      "Epoch 3299/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5045\n",
      "Epoch 3300/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5045\n",
      "Epoch 3301/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.5045\n",
      "Epoch 3302/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.5044\n",
      "Epoch 3303/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.5044\n",
      "Epoch 3304/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5044\n",
      "Epoch 3305/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5043\n",
      "Epoch 3306/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5043\n",
      "Epoch 3307/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5043\n",
      "Epoch 3308/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5042\n",
      "Epoch 3309/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.5042\n",
      "Epoch 3310/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9091 - loss: 0.5042\n",
      "Epoch 3311/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.5042\n",
      "Epoch 3312/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5041\n",
      "Epoch 3313/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5041\n",
      "Epoch 3314/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5041\n",
      "Epoch 3315/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.5040\n",
      "Epoch 3316/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.5040\n",
      "Epoch 3317/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5040\n",
      "Epoch 3318/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5039\n",
      "Epoch 3319/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.5039\n",
      "Epoch 3320/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5039\n",
      "Epoch 3321/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5038\n",
      "Epoch 3322/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5038\n",
      "Epoch 3323/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.5038\n",
      "Epoch 3324/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9091 - loss: 0.5038\n",
      "Epoch 3325/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9091 - loss: 0.5037\n",
      "Epoch 3326/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5037\n",
      "Epoch 3327/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5037\n",
      "Epoch 3328/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.5036\n",
      "Epoch 3329/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.5036\n",
      "Epoch 3330/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.5036\n",
      "Epoch 3331/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.5035\n",
      "Epoch 3332/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.5035\n",
      "Epoch 3333/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.5035\n",
      "Epoch 3334/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.5035\n",
      "Epoch 3335/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.5034\n",
      "Epoch 3336/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.5034\n",
      "Epoch 3337/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9091 - loss: 0.5034\n",
      "Epoch 3338/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.5033\n",
      "Epoch 3339/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5033\n",
      "Epoch 3340/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.5033\n",
      "Epoch 3341/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.5032\n",
      "Epoch 3342/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5032\n",
      "Epoch 3343/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.5032\n",
      "Epoch 3344/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.5031\n",
      "Epoch 3345/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.5031\n",
      "Epoch 3346/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5031\n",
      "Epoch 3347/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5031\n",
      "Epoch 3348/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5030\n",
      "Epoch 3349/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.5030\n",
      "Epoch 3350/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9091 - loss: 0.5030\n",
      "Epoch 3351/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.5029\n",
      "Epoch 3352/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5029\n",
      "Epoch 3353/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5029\n",
      "Epoch 3354/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5028\n",
      "Epoch 3355/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5028\n",
      "Epoch 3356/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5028\n",
      "Epoch 3357/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5028\n",
      "Epoch 3358/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.5027\n",
      "Epoch 3359/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5027\n",
      "Epoch 3360/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5027\n",
      "Epoch 3361/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.5026\n",
      "Epoch 3362/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9091 - loss: 0.5026\n",
      "Epoch 3363/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.5026\n",
      "Epoch 3364/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.5025\n",
      "Epoch 3365/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.5025\n",
      "Epoch 3366/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.5025\n",
      "Epoch 3367/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.5024\n",
      "Epoch 3368/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.5024\n",
      "Epoch 3369/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.5024\n",
      "Epoch 3370/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.5024\n",
      "Epoch 3371/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.5023\n",
      "Epoch 3372/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.5023\n",
      "Epoch 3373/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.5023\n",
      "Epoch 3374/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.5022\n",
      "Epoch 3375/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.5022\n",
      "Epoch 3376/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.5022\n",
      "Epoch 3377/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.5021\n",
      "Epoch 3378/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5021\n",
      "Epoch 3379/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.5021\n",
      "Epoch 3380/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5021\n",
      "Epoch 3381/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5020\n",
      "Epoch 3382/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5020\n",
      "Epoch 3383/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5020\n",
      "Epoch 3384/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5019\n",
      "Epoch 3385/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5019\n",
      "Epoch 3386/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5019\n",
      "Epoch 3387/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.5018\n",
      "Epoch 3388/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.5018\n",
      "Epoch 3389/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9091 - loss: 0.5018\n",
      "Epoch 3390/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.5018\n",
      "Epoch 3391/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9091 - loss: 0.5017\n",
      "Epoch 3392/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5017\n",
      "Epoch 3393/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5017\n",
      "Epoch 3394/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5016\n",
      "Epoch 3395/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5016\n",
      "Epoch 3396/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5016\n",
      "Epoch 3397/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5015\n",
      "Epoch 3398/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5015\n",
      "Epoch 3399/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5015\n",
      "Epoch 3400/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5015\n",
      "Epoch 3401/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5014\n",
      "Epoch 3402/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5014\n",
      "Epoch 3403/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.5014\n",
      "Epoch 3404/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.5013\n",
      "Epoch 3405/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.5013\n",
      "Epoch 3406/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5013\n",
      "Epoch 3407/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.5012\n",
      "Epoch 3408/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.5012\n",
      "Epoch 3409/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.5012\n",
      "Epoch 3410/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.5012\n",
      "Epoch 3411/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.5011\n",
      "Epoch 3412/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.5011\n",
      "Epoch 3413/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.5011\n",
      "Epoch 3414/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.5010\n",
      "Epoch 3415/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5010\n",
      "Epoch 3416/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5010\n",
      "Epoch 3417/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5009\n",
      "Epoch 3418/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.5009\n",
      "Epoch 3419/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.5009\n",
      "Epoch 3420/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.5009\n",
      "Epoch 3421/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5008\n",
      "Epoch 3422/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5008\n",
      "Epoch 3423/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5008\n",
      "Epoch 3424/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.5007\n",
      "Epoch 3425/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.5007\n",
      "Epoch 3426/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.5007\n",
      "Epoch 3427/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.5006\n",
      "Epoch 3428/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.5006\n",
      "Epoch 3429/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5006\n",
      "Epoch 3430/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.5006\n",
      "Epoch 3431/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.5005\n",
      "Epoch 3432/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.5005\n",
      "Epoch 3433/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5005\n",
      "Epoch 3434/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5004\n",
      "Epoch 3435/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5004\n",
      "Epoch 3436/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5004\n",
      "Epoch 3437/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5004\n",
      "Epoch 3438/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5003\n",
      "Epoch 3439/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5003\n",
      "Epoch 3440/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5003\n",
      "Epoch 3441/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.5002\n",
      "Epoch 3442/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5002\n",
      "Epoch 3443/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.5002\n",
      "Epoch 3444/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.5001\n",
      "Epoch 3445/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.5001\n",
      "Epoch 3446/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.5001\n",
      "Epoch 3447/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.5001\n",
      "Epoch 3448/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5000\n",
      "Epoch 3449/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5000\n",
      "Epoch 3450/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.5000\n",
      "Epoch 3451/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4999\n",
      "Epoch 3452/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4999\n",
      "Epoch 3453/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4999\n",
      "Epoch 3454/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4998\n",
      "Epoch 3455/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4998\n",
      "Epoch 3456/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4998\n",
      "Epoch 3457/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4998\n",
      "Epoch 3458/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4997\n",
      "Epoch 3459/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4997\n",
      "Epoch 3460/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4997\n",
      "Epoch 3461/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4996\n",
      "Epoch 3462/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4996\n",
      "Epoch 3463/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4996\n",
      "Epoch 3464/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.4996\n",
      "Epoch 3465/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4995\n",
      "Epoch 3466/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4995\n",
      "Epoch 3467/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4995\n",
      "Epoch 3468/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4994\n",
      "Epoch 3469/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9091 - loss: 0.4994\n",
      "Epoch 3470/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4994\n",
      "Epoch 3471/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4993\n",
      "Epoch 3472/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4993\n",
      "Epoch 3473/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4993\n",
      "Epoch 3474/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4993\n",
      "Epoch 3475/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4992\n",
      "Epoch 3476/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4992\n",
      "Epoch 3477/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4992\n",
      "Epoch 3478/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4991\n",
      "Epoch 3479/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4991\n",
      "Epoch 3480/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4991\n",
      "Epoch 3481/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4991\n",
      "Epoch 3482/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4990\n",
      "Epoch 3483/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4990\n",
      "Epoch 3484/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4990\n",
      "Epoch 3485/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4989\n",
      "Epoch 3486/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4989\n",
      "Epoch 3487/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4989\n",
      "Epoch 3488/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.4989\n",
      "Epoch 3489/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4988\n",
      "Epoch 3490/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4988\n",
      "Epoch 3491/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4988\n",
      "Epoch 3492/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4987\n",
      "Epoch 3493/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4987\n",
      "Epoch 3494/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4987\n",
      "Epoch 3495/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4986\n",
      "Epoch 3496/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4986\n",
      "Epoch 3497/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4986\n",
      "Epoch 3498/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4986\n",
      "Epoch 3499/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4985\n",
      "Epoch 3500/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4985\n",
      "Epoch 3501/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4985\n",
      "Epoch 3502/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4984\n",
      "Epoch 3503/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4984\n",
      "Epoch 3504/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4984\n",
      "Epoch 3505/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4984\n",
      "Epoch 3506/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4983\n",
      "Epoch 3507/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4983\n",
      "Epoch 3508/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4983\n",
      "Epoch 3509/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4982\n",
      "Epoch 3510/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4982\n",
      "Epoch 3511/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4982\n",
      "Epoch 3512/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4982\n",
      "Epoch 3513/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4981\n",
      "Epoch 3514/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4981\n",
      "Epoch 3515/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4981\n",
      "Epoch 3516/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4980\n",
      "Epoch 3517/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4980\n",
      "Epoch 3518/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4980\n",
      "Epoch 3519/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4980\n",
      "Epoch 3520/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4979\n",
      "Epoch 3521/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4979\n",
      "Epoch 3522/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4979\n",
      "Epoch 3523/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4978\n",
      "Epoch 3524/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4978\n",
      "Epoch 3525/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4978\n",
      "Epoch 3526/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9091 - loss: 0.4977\n",
      "Epoch 3527/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4977\n",
      "Epoch 3528/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4977\n",
      "Epoch 3529/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4977\n",
      "Epoch 3530/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4976\n",
      "Epoch 3531/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4976\n",
      "Epoch 3532/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4976\n",
      "Epoch 3533/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4975\n",
      "Epoch 3534/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4975\n",
      "Epoch 3535/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4975\n",
      "Epoch 3536/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4975\n",
      "Epoch 3537/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4974\n",
      "Epoch 3538/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4974\n",
      "Epoch 3539/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4974\n",
      "Epoch 3540/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4973\n",
      "Epoch 3541/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4973\n",
      "Epoch 3542/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4973\n",
      "Epoch 3543/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4973\n",
      "Epoch 3544/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4972\n",
      "Epoch 3545/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4972\n",
      "Epoch 3546/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4972\n",
      "Epoch 3547/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4971\n",
      "Epoch 3548/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4971\n",
      "Epoch 3549/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4971\n",
      "Epoch 3550/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4971\n",
      "Epoch 3551/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4970\n",
      "Epoch 3552/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4970\n",
      "Epoch 3553/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4970\n",
      "Epoch 3554/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4969\n",
      "Epoch 3555/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4969\n",
      "Epoch 3556/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4969\n",
      "Epoch 3557/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4969\n",
      "Epoch 3558/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4968\n",
      "Epoch 3559/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4968\n",
      "Epoch 3560/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4968\n",
      "Epoch 3561/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4967\n",
      "Epoch 3562/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4967\n",
      "Epoch 3563/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4967\n",
      "Epoch 3564/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4967\n",
      "Epoch 3565/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4966\n",
      "Epoch 3566/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4966\n",
      "Epoch 3567/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4966\n",
      "Epoch 3568/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4965\n",
      "Epoch 3569/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4965\n",
      "Epoch 3570/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4965\n",
      "Epoch 3571/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4965\n",
      "Epoch 3572/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4964\n",
      "Epoch 3573/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4964\n",
      "Epoch 3574/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9091 - loss: 0.4964\n",
      "Epoch 3575/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4963\n",
      "Epoch 3576/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4963\n",
      "Epoch 3577/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4963\n",
      "Epoch 3578/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4963\n",
      "Epoch 3579/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4962\n",
      "Epoch 3580/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4962\n",
      "Epoch 3581/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4962\n",
      "Epoch 3582/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4961\n",
      "Epoch 3583/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4961\n",
      "Epoch 3584/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4961\n",
      "Epoch 3585/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4961\n",
      "Epoch 3586/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4960\n",
      "Epoch 3587/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4960\n",
      "Epoch 3588/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4960\n",
      "Epoch 3589/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4959\n",
      "Epoch 3590/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4959\n",
      "Epoch 3591/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4959\n",
      "Epoch 3592/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4959\n",
      "Epoch 3593/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4958\n",
      "Epoch 3594/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4958\n",
      "Epoch 3595/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4958\n",
      "Epoch 3596/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4957\n",
      "Epoch 3597/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4957\n",
      "Epoch 3598/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4957\n",
      "Epoch 3599/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4957\n",
      "Epoch 3600/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4956\n",
      "Epoch 3601/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4956\n",
      "Epoch 3602/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4956\n",
      "Epoch 3603/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4955\n",
      "Epoch 3604/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4955\n",
      "Epoch 3605/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4955\n",
      "Epoch 3606/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4955\n",
      "Epoch 3607/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4954\n",
      "Epoch 3608/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4954\n",
      "Epoch 3609/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4954\n",
      "Epoch 3610/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4954\n",
      "Epoch 3611/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4953\n",
      "Epoch 3612/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4953\n",
      "Epoch 3613/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4953\n",
      "Epoch 3614/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4952\n",
      "Epoch 3615/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4952\n",
      "Epoch 3616/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4952\n",
      "Epoch 3617/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4952\n",
      "Epoch 3618/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4951\n",
      "Epoch 3619/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4951\n",
      "Epoch 3620/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4951\n",
      "Epoch 3621/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4950\n",
      "Epoch 3622/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4950\n",
      "Epoch 3623/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4950\n",
      "Epoch 3624/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4950\n",
      "Epoch 3625/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4949\n",
      "Epoch 3626/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4949\n",
      "Epoch 3627/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4949\n",
      "Epoch 3628/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9091 - loss: 0.4948\n",
      "Epoch 3629/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4948\n",
      "Epoch 3630/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4948\n",
      "Epoch 3631/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4948\n",
      "Epoch 3632/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4947\n",
      "Epoch 3633/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4947\n",
      "Epoch 3634/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4947\n",
      "Epoch 3635/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4946\n",
      "Epoch 3636/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4946\n",
      "Epoch 3637/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9091 - loss: 0.4946\n",
      "Epoch 3638/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4946\n",
      "Epoch 3639/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4945\n",
      "Epoch 3640/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4945\n",
      "Epoch 3641/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4945\n",
      "Epoch 3642/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4945\n",
      "Epoch 3643/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4944\n",
      "Epoch 3644/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4944\n",
      "Epoch 3645/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4944\n",
      "Epoch 3646/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4943\n",
      "Epoch 3647/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4943\n",
      "Epoch 3648/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4943\n",
      "Epoch 3649/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9091 - loss: 0.4943\n",
      "Epoch 3650/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4942\n",
      "Epoch 3651/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4942\n",
      "Epoch 3652/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4942\n",
      "Epoch 3653/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4941\n",
      "Epoch 3654/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4941\n",
      "Epoch 3655/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4941\n",
      "Epoch 3656/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4941\n",
      "Epoch 3657/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4940\n",
      "Epoch 3658/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4940\n",
      "Epoch 3659/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4940\n",
      "Epoch 3660/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4940\n",
      "Epoch 3661/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9091 - loss: 0.4939\n",
      "Epoch 3662/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4939\n",
      "Epoch 3663/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4939\n",
      "Epoch 3664/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4938\n",
      "Epoch 3665/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4938\n",
      "Epoch 3666/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4938\n",
      "Epoch 3667/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4938\n",
      "Epoch 3668/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4937\n",
      "Epoch 3669/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4937\n",
      "Epoch 3670/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4937\n",
      "Epoch 3671/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4936\n",
      "Epoch 3672/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4936\n",
      "Epoch 3673/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4936\n",
      "Epoch 3674/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9091 - loss: 0.4936\n",
      "Epoch 3675/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4935\n",
      "Epoch 3676/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4935\n",
      "Epoch 3677/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4935\n",
      "Epoch 3678/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4935\n",
      "Epoch 3679/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4934\n",
      "Epoch 3680/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4934\n",
      "Epoch 3681/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4934\n",
      "Epoch 3682/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4933\n",
      "Epoch 3683/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4933\n",
      "Epoch 3684/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4933\n",
      "Epoch 3685/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4933\n",
      "Epoch 3686/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4932\n",
      "Epoch 3687/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4932\n",
      "Epoch 3688/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4932\n",
      "Epoch 3689/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4932\n",
      "Epoch 3690/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4931\n",
      "Epoch 3691/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4931\n",
      "Epoch 3692/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4931\n",
      "Epoch 3693/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4930\n",
      "Epoch 3694/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4930\n",
      "Epoch 3695/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4930\n",
      "Epoch 3696/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4930\n",
      "Epoch 3697/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4929\n",
      "Epoch 3698/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.4929\n",
      "Epoch 3699/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4929\n",
      "Epoch 3700/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4928\n",
      "Epoch 3701/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9091 - loss: 0.4928\n",
      "Epoch 3702/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4928\n",
      "Epoch 3703/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4928\n",
      "Epoch 3704/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4927\n",
      "Epoch 3705/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4927\n",
      "Epoch 3706/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4927\n",
      "Epoch 3707/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4927\n",
      "Epoch 3708/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4926\n",
      "Epoch 3709/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4926\n",
      "Epoch 3710/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4926\n",
      "Epoch 3711/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4925\n",
      "Epoch 3712/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4925\n",
      "Epoch 3713/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9091 - loss: 0.4925\n",
      "Epoch 3714/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9091 - loss: 0.4925\n",
      "Epoch 3715/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4924\n",
      "Epoch 3716/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4924\n",
      "Epoch 3717/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4924\n",
      "Epoch 3718/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4924\n",
      "Epoch 3719/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4923\n",
      "Epoch 3720/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4923\n",
      "Epoch 3721/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4923\n",
      "Epoch 3722/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4922\n",
      "Epoch 3723/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9091 - loss: 0.4922\n",
      "Epoch 3724/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4922\n",
      "Epoch 3725/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4922\n",
      "Epoch 3726/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4921\n",
      "Epoch 3727/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4921\n",
      "Epoch 3728/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4921\n",
      "Epoch 3729/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4921\n",
      "Epoch 3730/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9091 - loss: 0.4920\n",
      "Epoch 3731/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4920\n",
      "Epoch 3732/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4920\n",
      "Epoch 3733/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4919\n",
      "Epoch 3734/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4919\n",
      "Epoch 3735/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4919\n",
      "Epoch 3736/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4919\n",
      "Epoch 3737/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4918\n",
      "Epoch 3738/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4918\n",
      "Epoch 3739/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4918\n",
      "Epoch 3740/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4918\n",
      "Epoch 3741/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4917\n",
      "Epoch 3742/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9091 - loss: 0.4917\n",
      "Epoch 3743/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4917\n",
      "Epoch 3744/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4916\n",
      "Epoch 3745/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4916\n",
      "Epoch 3746/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4916\n",
      "Epoch 3747/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4916\n",
      "Epoch 3748/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4915\n",
      "Epoch 3749/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.4915\n",
      "Epoch 3750/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4915\n",
      "Epoch 3751/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4915\n",
      "Epoch 3752/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4914\n",
      "Epoch 3753/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4914\n",
      "Epoch 3754/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4914\n",
      "Epoch 3755/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9091 - loss: 0.4913\n",
      "Epoch 3756/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4913\n",
      "Epoch 3757/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4913\n",
      "Epoch 3758/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4913\n",
      "Epoch 3759/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4912\n",
      "Epoch 3760/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4912\n",
      "Epoch 3761/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4912\n",
      "Epoch 3762/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4912\n",
      "Epoch 3763/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4911\n",
      "Epoch 3764/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4911\n",
      "Epoch 3765/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4911\n",
      "Epoch 3766/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4911\n",
      "Epoch 3767/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9091 - loss: 0.4910\n",
      "Epoch 3768/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4910\n",
      "Epoch 3769/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4910\n",
      "Epoch 3770/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4909\n",
      "Epoch 3771/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4909\n",
      "Epoch 3772/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4909\n",
      "Epoch 3773/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4909\n",
      "Epoch 3774/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4908\n",
      "Epoch 3775/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4908\n",
      "Epoch 3776/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4908\n",
      "Epoch 3777/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4908\n",
      "Epoch 3778/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4907\n",
      "Epoch 3779/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4907\n",
      "Epoch 3780/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4907\n",
      "Epoch 3781/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4906\n",
      "Epoch 3782/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4906\n",
      "Epoch 3783/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4906\n",
      "Epoch 3784/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4906\n",
      "Epoch 3785/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4905\n",
      "Epoch 3786/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4905\n",
      "Epoch 3787/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4905\n",
      "Epoch 3788/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4905\n",
      "Epoch 3789/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4904\n",
      "Epoch 3790/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4904\n",
      "Epoch 3791/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4904\n",
      "Epoch 3792/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9091 - loss: 0.4904\n",
      "Epoch 3793/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4903\n",
      "Epoch 3794/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4903\n",
      "Epoch 3795/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4903\n",
      "Epoch 3796/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4902\n",
      "Epoch 3797/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4902\n",
      "Epoch 3798/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4902\n",
      "Epoch 3799/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4902\n",
      "Epoch 3800/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4901\n",
      "Epoch 3801/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4901\n",
      "Epoch 3802/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4901\n",
      "Epoch 3803/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9091 - loss: 0.4901\n",
      "Epoch 3804/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4900\n",
      "Epoch 3805/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4900\n",
      "Epoch 3806/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4900\n",
      "Epoch 3807/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4900\n",
      "Epoch 3808/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4899\n",
      "Epoch 3809/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4899\n",
      "Epoch 3810/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4899\n",
      "Epoch 3811/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4898\n",
      "Epoch 3812/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9091 - loss: 0.4898\n",
      "Epoch 3813/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4898\n",
      "Epoch 3814/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4898\n",
      "Epoch 3815/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9091 - loss: 0.4897\n",
      "Epoch 3816/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4897\n",
      "Epoch 3817/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4897\n",
      "Epoch 3818/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4897\n",
      "Epoch 3819/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4896\n",
      "Epoch 3820/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4896\n",
      "Epoch 3821/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4896\n",
      "Epoch 3822/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4896\n",
      "Epoch 3823/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4895\n",
      "Epoch 3824/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4895\n",
      "Epoch 3825/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4895\n",
      "Epoch 3826/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9091 - loss: 0.4894\n",
      "Epoch 3827/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4894\n",
      "Epoch 3828/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4894\n",
      "Epoch 3829/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4894\n",
      "Epoch 3830/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4893\n",
      "Epoch 3831/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4893\n",
      "Epoch 3832/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4893\n",
      "Epoch 3833/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4893\n",
      "Epoch 3834/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4892\n",
      "Epoch 3835/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4892\n",
      "Epoch 3836/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9091 - loss: 0.4892\n",
      "Epoch 3837/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9091 - loss: 0.4892\n",
      "Epoch 3838/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9091 - loss: 0.4891\n",
      "Epoch 3839/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4891\n",
      "Epoch 3840/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4891\n",
      "Epoch 3841/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4891\n",
      "Epoch 3842/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4890\n",
      "Epoch 3843/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4890\n",
      "Epoch 3844/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4890\n",
      "Epoch 3845/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4889\n",
      "Epoch 3846/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4889\n",
      "Epoch 3847/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4889\n",
      "Epoch 3848/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4889\n",
      "Epoch 3849/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9091 - loss: 0.4888\n",
      "Epoch 3850/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4888\n",
      "Epoch 3851/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4888\n",
      "Epoch 3852/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4888\n",
      "Epoch 3853/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4887\n",
      "Epoch 3854/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4887\n",
      "Epoch 3855/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9091 - loss: 0.4887\n",
      "Epoch 3856/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4887\n",
      "Epoch 3857/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9091 - loss: 0.4886\n",
      "Epoch 3858/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4886\n",
      "Epoch 3859/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4886\n",
      "Epoch 3860/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4886\n",
      "Epoch 3861/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9091 - loss: 0.4885\n",
      "Epoch 3862/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4885\n",
      "Epoch 3863/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4885\n",
      "Epoch 3864/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4884\n",
      "Epoch 3865/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4884\n",
      "Epoch 3866/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4884\n",
      "Epoch 3867/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4884\n",
      "Epoch 3868/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4883\n",
      "Epoch 3869/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4883\n",
      "Epoch 3870/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4883\n",
      "Epoch 3871/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4883\n",
      "Epoch 3872/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9091 - loss: 0.4882\n",
      "Epoch 3873/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4882\n",
      "Epoch 3874/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4882\n",
      "Epoch 3875/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4882\n",
      "Epoch 3876/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4881\n",
      "Epoch 3877/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4881\n",
      "Epoch 3878/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4881\n",
      "Epoch 3879/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4881\n",
      "Epoch 3880/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4880\n",
      "Epoch 3881/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4880\n",
      "Epoch 3882/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4880\n",
      "Epoch 3883/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4880\n",
      "Epoch 3884/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4879\n",
      "Epoch 3885/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4879\n",
      "Epoch 3886/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4879\n",
      "Epoch 3887/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4878\n",
      "Epoch 3888/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4878\n",
      "Epoch 3889/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4878\n",
      "Epoch 3890/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4878\n",
      "Epoch 3891/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4877\n",
      "Epoch 3892/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4877\n",
      "Epoch 3893/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4877\n",
      "Epoch 3894/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4877\n",
      "Epoch 3895/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9091 - loss: 0.4876\n",
      "Epoch 3896/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4876\n",
      "Epoch 3897/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4876\n",
      "Epoch 3898/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4876\n",
      "Epoch 3899/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4875\n",
      "Epoch 3900/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4875\n",
      "Epoch 3901/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4875\n",
      "Epoch 3902/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4875\n",
      "Epoch 3903/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4874\n",
      "Epoch 3904/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4874\n",
      "Epoch 3905/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4874\n",
      "Epoch 3906/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4874\n",
      "Epoch 3907/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4873\n",
      "Epoch 3908/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4873\n",
      "Epoch 3909/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4873\n",
      "Epoch 3910/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4873\n",
      "Epoch 3911/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4872\n",
      "Epoch 3912/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4872\n",
      "Epoch 3913/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4872\n",
      "Epoch 3914/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4871\n",
      "Epoch 3915/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4871\n",
      "Epoch 3916/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4871\n",
      "Epoch 3917/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4871\n",
      "Epoch 3918/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9091 - loss: 0.4870\n",
      "Epoch 3919/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4870\n",
      "Epoch 3920/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4870\n",
      "Epoch 3921/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4870\n",
      "Epoch 3922/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4869\n",
      "Epoch 3923/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4869\n",
      "Epoch 3924/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4869\n",
      "Epoch 3925/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4869\n",
      "Epoch 3926/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4868\n",
      "Epoch 3927/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4868\n",
      "Epoch 3928/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4868\n",
      "Epoch 3929/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9091 - loss: 0.4868\n",
      "Epoch 3930/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4867\n",
      "Epoch 3931/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4867\n",
      "Epoch 3932/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9091 - loss: 0.4867\n",
      "Epoch 3933/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4867\n",
      "Epoch 3934/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4866\n",
      "Epoch 3935/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9091 - loss: 0.4866\n",
      "Epoch 3936/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4866\n",
      "Epoch 3937/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4866\n",
      "Epoch 3938/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4865\n",
      "Epoch 3939/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4865\n",
      "Epoch 3940/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9091 - loss: 0.4865\n",
      "Epoch 3941/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4865\n",
      "Epoch 3942/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4864\n",
      "Epoch 3943/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4864\n",
      "Epoch 3944/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4864\n",
      "Epoch 3945/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4864\n",
      "Epoch 3946/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4863\n",
      "Epoch 3947/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4863\n",
      "Epoch 3948/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4863\n",
      "Epoch 3949/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4862\n",
      "Epoch 3950/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4862\n",
      "Epoch 3951/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4862\n",
      "Epoch 3952/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9091 - loss: 0.4862\n",
      "Epoch 3953/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4861\n",
      "Epoch 3954/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4861\n",
      "Epoch 3955/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4861\n",
      "Epoch 3956/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4861\n",
      "Epoch 3957/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4860\n",
      "Epoch 3958/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4860\n",
      "Epoch 3959/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4860\n",
      "Epoch 3960/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4860\n",
      "Epoch 3961/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4859\n",
      "Epoch 3962/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4859\n",
      "Epoch 3963/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9091 - loss: 0.4859\n",
      "Epoch 3964/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4859\n",
      "Epoch 3965/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4858\n",
      "Epoch 3966/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4858\n",
      "Epoch 3967/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4858\n",
      "Epoch 3968/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4858\n",
      "Epoch 3969/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4857\n",
      "Epoch 3970/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4857\n",
      "Epoch 3971/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4857\n",
      "Epoch 3972/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4857\n",
      "Epoch 3973/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9091 - loss: 0.4856\n",
      "Epoch 3974/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4856\n",
      "Epoch 3975/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4856\n",
      "Epoch 3976/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4856\n",
      "Epoch 3977/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4855\n",
      "Epoch 3978/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4855\n",
      "Epoch 3979/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4855\n",
      "Epoch 3980/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4855\n",
      "Epoch 3981/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4854\n",
      "Epoch 3982/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4854\n",
      "Epoch 3983/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9091 - loss: 0.4854\n",
      "Epoch 3984/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4854\n",
      "Epoch 3985/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4853\n",
      "Epoch 3986/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4853\n",
      "Epoch 3987/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4853\n",
      "Epoch 3988/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4853\n",
      "Epoch 3989/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4852\n",
      "Epoch 3990/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4852\n",
      "Epoch 3991/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4852\n",
      "Epoch 3992/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4852\n",
      "Epoch 3993/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4851\n",
      "Epoch 3994/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.4851\n",
      "Epoch 3995/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4851\n",
      "Epoch 3996/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4851\n",
      "Epoch 3997/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4850\n",
      "Epoch 3998/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4850\n",
      "Epoch 3999/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4850\n",
      "Epoch 4000/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4850\n",
      "Epoch 4001/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4849\n",
      "Epoch 4002/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4849\n",
      "Epoch 4003/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4849\n",
      "Epoch 4004/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9091 - loss: 0.4849\n",
      "Epoch 4005/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9091 - loss: 0.4848\n",
      "Epoch 4006/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4848\n",
      "Epoch 4007/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4848\n",
      "Epoch 4008/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4848\n",
      "Epoch 4009/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4847\n",
      "Epoch 4010/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4847\n",
      "Epoch 4011/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4847\n",
      "Epoch 4012/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4847\n",
      "Epoch 4013/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4846\n",
      "Epoch 4014/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4846\n",
      "Epoch 4015/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4846\n",
      "Epoch 4016/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4846\n",
      "Epoch 4017/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4845\n",
      "Epoch 4018/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4845\n",
      "Epoch 4019/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4845\n",
      "Epoch 4020/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4845\n",
      "Epoch 4021/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4844\n",
      "Epoch 4022/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9091 - loss: 0.4844\n",
      "Epoch 4023/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9091 - loss: 0.4844\n",
      "Epoch 4024/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4844\n",
      "Epoch 4025/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4843\n",
      "Epoch 4026/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4843\n",
      "Epoch 4027/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4843\n",
      "Epoch 4028/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4843\n",
      "Epoch 4029/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4842\n",
      "Epoch 4030/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4842\n",
      "Epoch 4031/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4842\n",
      "Epoch 4032/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4842\n",
      "Epoch 4033/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4841\n",
      "Epoch 4034/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4841\n",
      "Epoch 4035/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4841\n",
      "Epoch 4036/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4841\n",
      "Epoch 4037/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4840\n",
      "Epoch 4038/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4840\n",
      "Epoch 4039/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9091 - loss: 0.4840\n",
      "Epoch 4040/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4840\n",
      "Epoch 4041/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4839\n",
      "Epoch 4042/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4839\n",
      "Epoch 4043/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4839\n",
      "Epoch 4044/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4839\n",
      "Epoch 4045/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4838\n",
      "Epoch 4046/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4838\n",
      "Epoch 4047/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4838\n",
      "Epoch 4048/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4838\n",
      "Epoch 4049/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.4837\n",
      "Epoch 4050/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4837\n",
      "Epoch 4051/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4837\n",
      "Epoch 4052/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4837\n",
      "Epoch 4053/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4836\n",
      "Epoch 4054/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4836\n",
      "Epoch 4055/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4836\n",
      "Epoch 4056/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4836\n",
      "Epoch 4057/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4835\n",
      "Epoch 4058/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4835\n",
      "Epoch 4059/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4835\n",
      "Epoch 4060/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4835\n",
      "Epoch 4061/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9091 - loss: 0.4834\n",
      "Epoch 4062/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4834\n",
      "Epoch 4063/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4834\n",
      "Epoch 4064/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4834\n",
      "Epoch 4065/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4833\n",
      "Epoch 4066/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4833\n",
      "Epoch 4067/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4833\n",
      "Epoch 4068/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4833\n",
      "Epoch 4069/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4832\n",
      "Epoch 4070/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4832\n",
      "Epoch 4071/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9091 - loss: 0.4832\n",
      "Epoch 4072/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4832\n",
      "Epoch 4073/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4831\n",
      "Epoch 4074/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4831\n",
      "Epoch 4075/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4831\n",
      "Epoch 4076/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4831\n",
      "Epoch 4077/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4830\n",
      "Epoch 4078/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4830\n",
      "Epoch 4079/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4830\n",
      "Epoch 4080/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4830\n",
      "Epoch 4081/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4829\n",
      "Epoch 4082/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4829\n",
      "Epoch 4083/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4829\n",
      "Epoch 4084/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.4829\n",
      "Epoch 4085/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4828\n",
      "Epoch 4086/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4828\n",
      "Epoch 4087/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4828\n",
      "Epoch 4088/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4828\n",
      "Epoch 4089/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4827\n",
      "Epoch 4090/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4827\n",
      "Epoch 4091/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4827\n",
      "Epoch 4092/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4827\n",
      "Epoch 4093/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4826\n",
      "Epoch 4094/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9091 - loss: 0.4826\n",
      "Epoch 4095/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4826\n",
      "Epoch 4096/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4826\n",
      "Epoch 4097/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4825\n",
      "Epoch 4098/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4825\n",
      "Epoch 4099/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4825\n",
      "Epoch 4100/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4825\n",
      "Epoch 4101/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4824\n",
      "Epoch 4102/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4824\n",
      "Epoch 4103/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4824\n",
      "Epoch 4104/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4824\n",
      "Epoch 4105/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4824\n",
      "Epoch 4106/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4823\n",
      "Epoch 4107/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4823\n",
      "Epoch 4108/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4823\n",
      "Epoch 4109/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4823\n",
      "Epoch 4110/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4822\n",
      "Epoch 4111/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4822\n",
      "Epoch 4112/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4822\n",
      "Epoch 4113/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4822\n",
      "Epoch 4114/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4821\n",
      "Epoch 4115/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4821\n",
      "Epoch 4116/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4821\n",
      "Epoch 4117/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4821\n",
      "Epoch 4118/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4820\n",
      "Epoch 4119/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4820\n",
      "Epoch 4120/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4820\n",
      "Epoch 4121/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4820\n",
      "Epoch 4122/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4819\n",
      "Epoch 4123/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4819\n",
      "Epoch 4124/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9091 - loss: 0.4819\n",
      "Epoch 4125/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4819\n",
      "Epoch 4126/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4818\n",
      "Epoch 4127/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4818\n",
      "Epoch 4128/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4818\n",
      "Epoch 4129/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4818\n",
      "Epoch 4130/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4817\n",
      "Epoch 4131/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4817\n",
      "Epoch 4132/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4817\n",
      "Epoch 4133/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4817\n",
      "Epoch 4134/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4816\n",
      "Epoch 4135/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4816\n",
      "Epoch 4136/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4816\n",
      "Epoch 4137/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4816\n",
      "Epoch 4138/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4815\n",
      "Epoch 4139/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4815\n",
      "Epoch 4140/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4815\n",
      "Epoch 4141/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4815\n",
      "Epoch 4142/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4815\n",
      "Epoch 4143/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4814\n",
      "Epoch 4144/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4814\n",
      "Epoch 4145/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4814\n",
      "Epoch 4146/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4814\n",
      "Epoch 4147/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4813\n",
      "Epoch 4148/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4813\n",
      "Epoch 4149/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9091 - loss: 0.4813\n",
      "Epoch 4150/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4813\n",
      "Epoch 4151/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4812\n",
      "Epoch 4152/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4812\n",
      "Epoch 4153/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4812\n",
      "Epoch 4154/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4812\n",
      "Epoch 4155/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4811\n",
      "Epoch 4156/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9091 - loss: 0.4811\n",
      "Epoch 4157/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4811\n",
      "Epoch 4158/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4811\n",
      "Epoch 4159/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9091 - loss: 0.4810\n",
      "Epoch 4160/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4810\n",
      "Epoch 4161/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4810\n",
      "Epoch 4162/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4810\n",
      "Epoch 4163/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4809\n",
      "Epoch 4164/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4809\n",
      "Epoch 4165/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4809\n",
      "Epoch 4166/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4809\n",
      "Epoch 4167/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4809\n",
      "Epoch 4168/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4808\n",
      "Epoch 4169/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4808\n",
      "Epoch 4170/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9091 - loss: 0.4808\n",
      "Epoch 4171/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9091 - loss: 0.4808\n",
      "Epoch 4172/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4807\n",
      "Epoch 4173/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4807\n",
      "Epoch 4174/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4807\n",
      "Epoch 4175/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4807\n",
      "Epoch 4176/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4806\n",
      "Epoch 4177/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4806\n",
      "Epoch 4178/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4806\n",
      "Epoch 4179/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4806\n",
      "Epoch 4180/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4805\n",
      "Epoch 4181/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4805\n",
      "Epoch 4182/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4805\n",
      "Epoch 4183/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4805\n",
      "Epoch 4184/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4804\n",
      "Epoch 4185/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4804\n",
      "Epoch 4186/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4804\n",
      "Epoch 4187/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4804\n",
      "Epoch 4188/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4803\n",
      "Epoch 4189/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4803\n",
      "Epoch 4190/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4803\n",
      "Epoch 4191/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9091 - loss: 0.4803\n",
      "Epoch 4192/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4803\n",
      "Epoch 4193/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4802\n",
      "Epoch 4194/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4802\n",
      "Epoch 4195/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4802\n",
      "Epoch 4196/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4802\n",
      "Epoch 4197/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4801\n",
      "Epoch 4198/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4801\n",
      "Epoch 4199/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4801\n",
      "Epoch 4200/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4801\n",
      "Epoch 4201/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4800\n",
      "Epoch 4202/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4800\n",
      "Epoch 4203/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4800\n",
      "Epoch 4204/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4800\n",
      "Epoch 4205/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4799\n",
      "Epoch 4206/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4799\n",
      "Epoch 4207/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4799\n",
      "Epoch 4208/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4799\n",
      "Epoch 4209/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4798\n",
      "Epoch 4210/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4798\n",
      "Epoch 4211/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4798\n",
      "Epoch 4212/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4798\n",
      "Epoch 4213/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4798\n",
      "Epoch 4214/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9091 - loss: 0.4797\n",
      "Epoch 4215/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4797\n",
      "Epoch 4216/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4797\n",
      "Epoch 4217/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4797\n",
      "Epoch 4218/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4796\n",
      "Epoch 4219/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4796\n",
      "Epoch 4220/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4796\n",
      "Epoch 4221/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4796\n",
      "Epoch 4222/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4795\n",
      "Epoch 4223/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4795\n",
      "Epoch 4224/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4795\n",
      "Epoch 4225/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9091 - loss: 0.4795\n",
      "Epoch 4226/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4794\n",
      "Epoch 4227/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4794\n",
      "Epoch 4228/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4794\n",
      "Epoch 4229/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4794\n",
      "Epoch 4230/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4794\n",
      "Epoch 4231/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4793\n",
      "Epoch 4232/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4793\n",
      "Epoch 4233/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4793\n",
      "Epoch 4234/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4793\n",
      "Epoch 4235/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4792\n",
      "Epoch 4236/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4792\n",
      "Epoch 4237/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4792\n",
      "Epoch 4238/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4792\n",
      "Epoch 4239/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4791\n",
      "Epoch 4240/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4791\n",
      "Epoch 4241/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4791\n",
      "Epoch 4242/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4791\n",
      "Epoch 4243/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4790\n",
      "Epoch 4244/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4790\n",
      "Epoch 4245/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4790\n",
      "Epoch 4246/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4790\n",
      "Epoch 4247/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4790\n",
      "Epoch 4248/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4789\n",
      "Epoch 4249/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4789\n",
      "Epoch 4250/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4789\n",
      "Epoch 4251/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4789\n",
      "Epoch 4252/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4788\n",
      "Epoch 4253/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4788\n",
      "Epoch 4254/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4788\n",
      "Epoch 4255/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4788\n",
      "Epoch 4256/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4787\n",
      "Epoch 4257/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4787\n",
      "Epoch 4258/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4787\n",
      "Epoch 4259/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4787\n",
      "Epoch 4260/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4786\n",
      "Epoch 4261/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4786\n",
      "Epoch 4262/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4786\n",
      "Epoch 4263/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4786\n",
      "Epoch 4264/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4786\n",
      "Epoch 4265/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4785\n",
      "Epoch 4266/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4785\n",
      "Epoch 4267/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4785\n",
      "Epoch 4268/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4785\n",
      "Epoch 4269/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4784\n",
      "Epoch 4270/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4784\n",
      "Epoch 4271/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4784\n",
      "Epoch 4272/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4784\n",
      "Epoch 4273/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4783\n",
      "Epoch 4274/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4783\n",
      "Epoch 4275/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.4783\n",
      "Epoch 4276/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4783\n",
      "Epoch 4277/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4783\n",
      "Epoch 4278/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4782\n",
      "Epoch 4279/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4782\n",
      "Epoch 4280/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4782\n",
      "Epoch 4281/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4782\n",
      "Epoch 4282/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4781\n",
      "Epoch 4283/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4781\n",
      "Epoch 4284/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4781\n",
      "Epoch 4285/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4781\n",
      "Epoch 4286/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4780\n",
      "Epoch 4287/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4780\n",
      "Epoch 4288/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4780\n",
      "Epoch 4289/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4780\n",
      "Epoch 4290/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4780\n",
      "Epoch 4291/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4779\n",
      "Epoch 4292/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4779\n",
      "Epoch 4293/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4779\n",
      "Epoch 4294/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4779\n",
      "Epoch 4295/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4778\n",
      "Epoch 4296/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4778\n",
      "Epoch 4297/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4778\n",
      "Epoch 4298/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4778\n",
      "Epoch 4299/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4777\n",
      "Epoch 4300/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4777\n",
      "Epoch 4301/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4777\n",
      "Epoch 4302/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4777\n",
      "Epoch 4303/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4776\n",
      "Epoch 4304/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4776\n",
      "Epoch 4305/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4776\n",
      "Epoch 4306/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4776\n",
      "Epoch 4307/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4776\n",
      "Epoch 4308/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4775\n",
      "Epoch 4309/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4775\n",
      "Epoch 4310/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4775\n",
      "Epoch 4311/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4775\n",
      "Epoch 4312/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4774\n",
      "Epoch 4313/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4774\n",
      "Epoch 4314/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4774\n",
      "Epoch 4315/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4774\n",
      "Epoch 4316/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4774\n",
      "Epoch 4317/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4773\n",
      "Epoch 4318/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4773\n",
      "Epoch 4319/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4773\n",
      "Epoch 4320/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4773\n",
      "Epoch 4321/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4772\n",
      "Epoch 4322/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4772\n",
      "Epoch 4323/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4772\n",
      "Epoch 4324/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4772\n",
      "Epoch 4325/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4771\n",
      "Epoch 4326/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4771\n",
      "Epoch 4327/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4771\n",
      "Epoch 4328/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4771\n",
      "Epoch 4329/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4771\n",
      "Epoch 4330/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4770\n",
      "Epoch 4331/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4770\n",
      "Epoch 4332/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4770\n",
      "Epoch 4333/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4770\n",
      "Epoch 4334/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4769\n",
      "Epoch 4335/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4769\n",
      "Epoch 4336/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4769\n",
      "Epoch 4337/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4769\n",
      "Epoch 4338/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4768\n",
      "Epoch 4339/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4768\n",
      "Epoch 4340/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4768\n",
      "Epoch 4341/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4768\n",
      "Epoch 4342/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4768\n",
      "Epoch 4343/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4767\n",
      "Epoch 4344/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4767\n",
      "Epoch 4345/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4767\n",
      "Epoch 4346/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4767\n",
      "Epoch 4347/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4766\n",
      "Epoch 4348/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4766\n",
      "Epoch 4349/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4766\n",
      "Epoch 4350/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4766\n",
      "Epoch 4351/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4765\n",
      "Epoch 4352/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9091 - loss: 0.4765\n",
      "Epoch 4353/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4765\n",
      "Epoch 4354/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4765\n",
      "Epoch 4355/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4765\n",
      "Epoch 4356/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4764\n",
      "Epoch 4357/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9091 - loss: 0.4764\n",
      "Epoch 4358/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4764\n",
      "Epoch 4359/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4764\n",
      "Epoch 4360/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9091 - loss: 0.4763\n",
      "Epoch 4361/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4763\n",
      "Epoch 4362/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4763\n",
      "Epoch 4363/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4763\n",
      "Epoch 4364/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4763\n",
      "Epoch 4365/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4762\n",
      "Epoch 4366/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4762\n",
      "Epoch 4367/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4762\n",
      "Epoch 4368/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4762\n",
      "Epoch 4369/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4761\n",
      "Epoch 4370/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4761\n",
      "Epoch 4371/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9091 - loss: 0.4761\n",
      "Epoch 4372/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4761\n",
      "Epoch 4373/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4761\n",
      "Epoch 4374/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4760\n",
      "Epoch 4375/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4760\n",
      "Epoch 4376/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4760\n",
      "Epoch 4377/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4760\n",
      "Epoch 4378/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4759\n",
      "Epoch 4379/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4759\n",
      "Epoch 4380/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4759\n",
      "Epoch 4381/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4759\n",
      "Epoch 4382/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4758\n",
      "Epoch 4383/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4758\n",
      "Epoch 4384/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4758\n",
      "Epoch 4385/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.4758\n",
      "Epoch 4386/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4758\n",
      "Epoch 4387/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4757\n",
      "Epoch 4388/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4757\n",
      "Epoch 4389/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4757\n",
      "Epoch 4390/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4757\n",
      "Epoch 4391/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4756\n",
      "Epoch 4392/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4756\n",
      "Epoch 4393/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4756\n",
      "Epoch 4394/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4756\n",
      "Epoch 4395/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4756\n",
      "Epoch 4396/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4755\n",
      "Epoch 4397/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4755\n",
      "Epoch 4398/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4755\n",
      "Epoch 4399/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4755\n",
      "Epoch 4400/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4754\n",
      "Epoch 4401/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4754\n",
      "Epoch 4402/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4754\n",
      "Epoch 4403/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4754\n",
      "Epoch 4404/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9091 - loss: 0.4754\n",
      "Epoch 4405/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4753\n",
      "Epoch 4406/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4753\n",
      "Epoch 4407/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4753\n",
      "Epoch 4408/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4753\n",
      "Epoch 4409/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4752\n",
      "Epoch 4410/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4752\n",
      "Epoch 4411/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4752\n",
      "Epoch 4412/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4752\n",
      "Epoch 4413/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4752\n",
      "Epoch 4414/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4751\n",
      "Epoch 4415/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4751\n",
      "Epoch 4416/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4751\n",
      "Epoch 4417/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4751\n",
      "Epoch 4418/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4750\n",
      "Epoch 4419/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4750\n",
      "Epoch 4420/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4750\n",
      "Epoch 4421/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4750\n",
      "Epoch 4422/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4750\n",
      "Epoch 4423/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4749\n",
      "Epoch 4424/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4749\n",
      "Epoch 4425/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9091 - loss: 0.4749\n",
      "Epoch 4426/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9091 - loss: 0.4749\n",
      "Epoch 4427/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4748\n",
      "Epoch 4428/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4748\n",
      "Epoch 4429/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4748\n",
      "Epoch 4430/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4748\n",
      "Epoch 4431/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4747\n",
      "Epoch 4432/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4747\n",
      "Epoch 4433/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4747\n",
      "Epoch 4434/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4747\n",
      "Epoch 4435/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4747\n",
      "Epoch 4436/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9091 - loss: 0.4746\n",
      "Epoch 4437/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4746\n",
      "Epoch 4438/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4746\n",
      "Epoch 4439/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4746\n",
      "Epoch 4440/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4745\n",
      "Epoch 4441/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4745\n",
      "Epoch 4442/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4745\n",
      "Epoch 4443/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4745\n",
      "Epoch 4444/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4745\n",
      "Epoch 4445/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4744\n",
      "Epoch 4446/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4744\n",
      "Epoch 4447/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9091 - loss: 0.4744\n",
      "Epoch 4448/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4744\n",
      "Epoch 4449/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4744\n",
      "Epoch 4450/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4743\n",
      "Epoch 4451/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4743\n",
      "Epoch 4452/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4743\n",
      "Epoch 4453/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4743\n",
      "Epoch 4454/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4742\n",
      "Epoch 4455/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4742\n",
      "Epoch 4456/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9091 - loss: 0.4742\n",
      "Epoch 4457/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4742\n",
      "Epoch 4458/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.4742\n",
      "Epoch 4459/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4741\n",
      "Epoch 4460/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4741\n",
      "Epoch 4461/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4741\n",
      "Epoch 4462/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4741\n",
      "Epoch 4463/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4740\n",
      "Epoch 4464/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4740\n",
      "Epoch 4465/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4740\n",
      "Epoch 4466/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4740\n",
      "Epoch 4467/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4740\n",
      "Epoch 4468/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4739\n",
      "Epoch 4469/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4739\n",
      "Epoch 4470/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4739\n",
      "Epoch 4471/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4739\n",
      "Epoch 4472/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4738\n",
      "Epoch 4473/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4738\n",
      "Epoch 4474/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4738\n",
      "Epoch 4475/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4738\n",
      "Epoch 4476/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4738\n",
      "Epoch 4477/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4737\n",
      "Epoch 4478/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4737\n",
      "Epoch 4479/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4737\n",
      "Epoch 4480/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4737\n",
      "Epoch 4481/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4736\n",
      "Epoch 4482/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9091 - loss: 0.4736\n",
      "Epoch 4483/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4736\n",
      "Epoch 4484/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9091 - loss: 0.4736\n",
      "Epoch 4485/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9091 - loss: 0.4736\n",
      "Epoch 4486/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4735\n",
      "Epoch 4487/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4735\n",
      "Epoch 4488/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4735\n",
      "Epoch 4489/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9091 - loss: 0.4735\n",
      "Epoch 4490/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.4734\n",
      "Epoch 4491/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4734\n",
      "Epoch 4492/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4734\n",
      "Epoch 4493/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4734\n",
      "Epoch 4494/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9091 - loss: 0.4734\n",
      "Epoch 4495/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4733\n",
      "Epoch 4496/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4733\n",
      "Epoch 4497/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4733\n",
      "Epoch 4498/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4733\n",
      "Epoch 4499/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4733\n",
      "Epoch 4500/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4732\n",
      "Epoch 4501/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9091 - loss: 0.4732\n",
      "Epoch 4502/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9091 - loss: 0.4732\n",
      "Epoch 4503/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9091 - loss: 0.4732\n",
      "Epoch 4504/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9091 - loss: 0.4731\n",
      "Epoch 4505/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9091 - loss: 0.4731\n",
      "Epoch 4506/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9091 - loss: 0.4731\n",
      "Epoch 4507/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9091 - loss: 0.4731\n",
      "Epoch 4508/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9091 - loss: 0.4731\n",
      "Epoch 4509/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9091 - loss: 0.4730\n",
      "Epoch 4510/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.4730\n",
      "Epoch 4511/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9091 - loss: 0.4730\n",
      "Epoch 4512/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9091 - loss: 0.4730\n",
      "Epoch 4513/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4729\n",
      "Epoch 4514/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9091 - loss: 0.4729\n",
      "Epoch 4515/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4729\n",
      "Epoch 4516/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4729\n",
      "Epoch 4517/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9091 - loss: 0.4729\n",
      "Epoch 4518/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4728\n",
      "Epoch 4519/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4728\n",
      "Epoch 4520/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4728\n",
      "Epoch 4521/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9091 - loss: 0.4728\n",
      "Epoch 4522/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4728\n",
      "Epoch 4523/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9091 - loss: 0.4727\n",
      "Epoch 4524/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4727\n",
      "Epoch 4525/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9091 - loss: 0.4727\n",
      "Epoch 4526/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4727\n",
      "Epoch 4527/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9091 - loss: 0.4726\n",
      "Epoch 4528/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4726\n",
      "Epoch 4529/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4726\n",
      "Epoch 4530/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4726\n",
      "Epoch 4531/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4726\n",
      "Epoch 4532/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4725\n",
      "Epoch 4533/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4725\n",
      "Epoch 4534/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4725\n",
      "Epoch 4535/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4725\n",
      "Epoch 4536/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4724\n",
      "Epoch 4537/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4724\n",
      "Epoch 4538/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4724\n",
      "Epoch 4539/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4724\n",
      "Epoch 4540/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4724\n",
      "Epoch 4541/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4723\n",
      "Epoch 4542/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9091 - loss: 0.4723\n",
      "Epoch 4543/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4723\n",
      "Epoch 4544/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4723\n",
      "Epoch 4545/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4723\n",
      "Epoch 4546/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4722\n",
      "Epoch 4547/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4722\n",
      "Epoch 4548/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4722\n",
      "Epoch 4549/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9091 - loss: 0.4722\n",
      "Epoch 4550/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4721\n",
      "Epoch 4551/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4721\n",
      "Epoch 4552/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4721\n",
      "Epoch 4553/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.4721\n",
      "Epoch 4554/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4721\n",
      "Epoch 4555/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4720\n",
      "Epoch 4556/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4720\n",
      "Epoch 4557/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4720\n",
      "Epoch 4558/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9091 - loss: 0.4720\n",
      "Epoch 4559/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4720\n",
      "Epoch 4560/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4719\n",
      "Epoch 4561/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4719\n",
      "Epoch 4562/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4719\n",
      "Epoch 4563/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4719\n",
      "Epoch 4564/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4718\n",
      "Epoch 4565/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4718\n",
      "Epoch 4566/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4718\n",
      "Epoch 4567/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.4718\n",
      "Epoch 4568/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9091 - loss: 0.4718\n",
      "Epoch 4569/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4717\n",
      "Epoch 4570/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4717\n",
      "Epoch 4571/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4717\n",
      "Epoch 4572/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4717\n",
      "Epoch 4573/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4717\n",
      "Epoch 4574/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4716\n",
      "Epoch 4575/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4716\n",
      "Epoch 4576/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4716\n",
      "Epoch 4577/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4716\n",
      "Epoch 4578/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4715\n",
      "Epoch 4579/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4715\n",
      "Epoch 4580/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4715\n",
      "Epoch 4581/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4715\n",
      "Epoch 4582/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4715\n",
      "Epoch 4583/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4714\n",
      "Epoch 4584/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4714\n",
      "Epoch 4585/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4714\n",
      "Epoch 4586/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4714\n",
      "Epoch 4587/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9091 - loss: 0.4714\n",
      "Epoch 4588/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4713\n",
      "Epoch 4589/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4713\n",
      "Epoch 4590/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4713\n",
      "Epoch 4591/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4713\n",
      "Epoch 4592/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4713\n",
      "Epoch 4593/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4712\n",
      "Epoch 4594/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4712\n",
      "Epoch 4595/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4712\n",
      "Epoch 4596/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4712\n",
      "Epoch 4597/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4711\n",
      "Epoch 4598/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4711\n",
      "Epoch 4599/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4711\n",
      "Epoch 4600/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4711\n",
      "Epoch 4601/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4711\n",
      "Epoch 4602/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4710\n",
      "Epoch 4603/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4710\n",
      "Epoch 4604/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.4710\n",
      "Epoch 4605/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4710\n",
      "Epoch 4606/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4710\n",
      "Epoch 4607/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4709\n",
      "Epoch 4608/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4709\n",
      "Epoch 4609/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4709\n",
      "Epoch 4610/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4709\n",
      "Epoch 4611/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4708\n",
      "Epoch 4612/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4708\n",
      "Epoch 4613/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4708\n",
      "Epoch 4614/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4708\n",
      "Epoch 4615/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4708\n",
      "Epoch 4616/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4707\n",
      "Epoch 4617/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4707\n",
      "Epoch 4618/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4707\n",
      "Epoch 4619/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4707\n",
      "Epoch 4620/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4707\n",
      "Epoch 4621/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4706\n",
      "Epoch 4622/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4706\n",
      "Epoch 4623/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9091 - loss: 0.4706\n",
      "Epoch 4624/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4706\n",
      "Epoch 4625/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4706\n",
      "Epoch 4626/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4705\n",
      "Epoch 4627/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4705\n",
      "Epoch 4628/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4705\n",
      "Epoch 4629/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4705\n",
      "Epoch 4630/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9091 - loss: 0.4704\n",
      "Epoch 4631/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4704\n",
      "Epoch 4632/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4704\n",
      "Epoch 4633/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4704\n",
      "Epoch 4634/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4704\n",
      "Epoch 4635/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4703\n",
      "Epoch 4636/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4703\n",
      "Epoch 4637/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4703\n",
      "Epoch 4638/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9091 - loss: 0.4703\n",
      "Epoch 4639/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4703\n",
      "Epoch 4640/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4702\n",
      "Epoch 4641/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4702\n",
      "Epoch 4642/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4702\n",
      "Epoch 4643/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4702\n",
      "Epoch 4644/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4702\n",
      "Epoch 4645/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4701\n",
      "Epoch 4646/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9091 - loss: 0.4701\n",
      "Epoch 4647/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4701\n",
      "Epoch 4648/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4701\n",
      "Epoch 4649/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4700\n",
      "Epoch 4650/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4700\n",
      "Epoch 4651/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4700\n",
      "Epoch 4652/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4700\n",
      "Epoch 4653/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4700\n",
      "Epoch 4654/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4699\n",
      "Epoch 4655/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4699\n",
      "Epoch 4656/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4699\n",
      "Epoch 4657/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4699\n",
      "Epoch 4658/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4699\n",
      "Epoch 4659/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4698\n",
      "Epoch 4660/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4698\n",
      "Epoch 4661/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4698\n",
      "Epoch 4662/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4698\n",
      "Epoch 4663/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4698\n",
      "Epoch 4664/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4697\n",
      "Epoch 4665/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4697\n",
      "Epoch 4666/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4697\n",
      "Epoch 4667/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4697\n",
      "Epoch 4668/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4697\n",
      "Epoch 4669/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4696\n",
      "Epoch 4670/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4696\n",
      "Epoch 4671/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4696\n",
      "Epoch 4672/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4696\n",
      "Epoch 4673/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4695\n",
      "Epoch 4674/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4695\n",
      "Epoch 4675/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4695\n",
      "Epoch 4676/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4695\n",
      "Epoch 4677/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4695\n",
      "Epoch 4678/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4694\n",
      "Epoch 4679/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4694\n",
      "Epoch 4680/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4694\n",
      "Epoch 4681/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4694\n",
      "Epoch 4682/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4694\n",
      "Epoch 4683/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4693\n",
      "Epoch 4684/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4693\n",
      "Epoch 4685/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4693\n",
      "Epoch 4686/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4693\n",
      "Epoch 4687/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4693\n",
      "Epoch 4688/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4692\n",
      "Epoch 4689/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4692\n",
      "Epoch 4690/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4692\n",
      "Epoch 4691/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9091 - loss: 0.4692\n",
      "Epoch 4692/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4692\n",
      "Epoch 4693/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4691\n",
      "Epoch 4694/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4691\n",
      "Epoch 4695/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4691\n",
      "Epoch 4696/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4691\n",
      "Epoch 4697/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4691\n",
      "Epoch 4698/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4690\n",
      "Epoch 4699/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4690\n",
      "Epoch 4700/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4690\n",
      "Epoch 4701/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4690\n",
      "Epoch 4702/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4690\n",
      "Epoch 4703/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4689\n",
      "Epoch 4704/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4689\n",
      "Epoch 4705/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4689\n",
      "Epoch 4706/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4689\n",
      "Epoch 4707/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4688\n",
      "Epoch 4708/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4688\n",
      "Epoch 4709/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9091 - loss: 0.4688\n",
      "Epoch 4710/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4688\n",
      "Epoch 4711/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4688\n",
      "Epoch 4712/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4687\n",
      "Epoch 4713/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4687\n",
      "Epoch 4714/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4687\n",
      "Epoch 4715/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4687\n",
      "Epoch 4716/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4687\n",
      "Epoch 4717/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4686\n",
      "Epoch 4718/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4686\n",
      "Epoch 4719/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4686\n",
      "Epoch 4720/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4686\n",
      "Epoch 4721/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4686\n",
      "Epoch 4722/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4685\n",
      "Epoch 4723/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4685\n",
      "Epoch 4724/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4685\n",
      "Epoch 4725/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4685\n",
      "Epoch 4726/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9091 - loss: 0.4685\n",
      "Epoch 4727/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4684\n",
      "Epoch 4728/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4684\n",
      "Epoch 4729/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4684\n",
      "Epoch 4730/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4684\n",
      "Epoch 4731/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4684\n",
      "Epoch 4732/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4683\n",
      "Epoch 4733/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4683\n",
      "Epoch 4734/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4683\n",
      "Epoch 4735/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4683\n",
      "Epoch 4736/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4683\n",
      "Epoch 4737/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4682\n",
      "Epoch 4738/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4682\n",
      "Epoch 4739/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4682\n",
      "Epoch 4740/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4682\n",
      "Epoch 4741/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4682\n",
      "Epoch 4742/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4681\n",
      "Epoch 4743/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4681\n",
      "Epoch 4744/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4681\n",
      "Epoch 4745/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4681\n",
      "Epoch 4746/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4681\n",
      "Epoch 4747/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4680\n",
      "Epoch 4748/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4680\n",
      "Epoch 4749/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4680\n",
      "Epoch 4750/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4680\n",
      "Epoch 4751/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4679\n",
      "Epoch 4752/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4679\n",
      "Epoch 4753/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4679\n",
      "Epoch 4754/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4679\n",
      "Epoch 4755/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4679\n",
      "Epoch 4756/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9091 - loss: 0.4678\n",
      "Epoch 4757/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4678\n",
      "Epoch 4758/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4678\n",
      "Epoch 4759/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4678\n",
      "Epoch 4760/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4678\n",
      "Epoch 4761/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4677\n",
      "Epoch 4762/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4677\n",
      "Epoch 4763/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4677\n",
      "Epoch 4764/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4677\n",
      "Epoch 4765/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4677\n",
      "Epoch 4766/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4676\n",
      "Epoch 4767/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4676\n",
      "Epoch 4768/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4676\n",
      "Epoch 4769/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4676\n",
      "Epoch 4770/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4676\n",
      "Epoch 4771/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4675\n",
      "Epoch 4772/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4675\n",
      "Epoch 4773/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9091 - loss: 0.4675\n",
      "Epoch 4774/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4675\n",
      "Epoch 4775/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4675\n",
      "Epoch 4776/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4674\n",
      "Epoch 4777/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4674\n",
      "Epoch 4778/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4674\n",
      "Epoch 4779/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4674\n",
      "Epoch 4780/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4674\n",
      "Epoch 4781/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4673\n",
      "Epoch 4782/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4673\n",
      "Epoch 4783/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9091 - loss: 0.4673\n",
      "Epoch 4784/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4673\n",
      "Epoch 4785/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4673\n",
      "Epoch 4786/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4672\n",
      "Epoch 4787/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4672\n",
      "Epoch 4788/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4672\n",
      "Epoch 4789/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4672\n",
      "Epoch 4790/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4672\n",
      "Epoch 4791/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4671\n",
      "Epoch 4792/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4671\n",
      "Epoch 4793/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4671\n",
      "Epoch 4794/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9091 - loss: 0.4671\n",
      "Epoch 4795/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4671\n",
      "Epoch 4796/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4670\n",
      "Epoch 4797/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4670\n",
      "Epoch 4798/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4670\n",
      "Epoch 4799/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4670\n",
      "Epoch 4800/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4670\n",
      "Epoch 4801/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4669\n",
      "Epoch 4802/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9091 - loss: 0.4669\n",
      "Epoch 4803/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4669\n",
      "Epoch 4804/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4669\n",
      "Epoch 4805/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4669\n",
      "Epoch 4806/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4668\n",
      "Epoch 4807/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4668\n",
      "Epoch 4808/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4668\n",
      "Epoch 4809/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4668\n",
      "Epoch 4810/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4668\n",
      "Epoch 4811/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4667\n",
      "Epoch 4812/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4667\n",
      "Epoch 4813/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4667\n",
      "Epoch 4814/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4667\n",
      "Epoch 4815/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4667\n",
      "Epoch 4816/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4666\n",
      "Epoch 4817/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4666\n",
      "Epoch 4818/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4666\n",
      "Epoch 4819/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9091 - loss: 0.4666\n",
      "Epoch 4820/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9091 - loss: 0.4666\n",
      "Epoch 4821/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4665\n",
      "Epoch 4822/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4665\n",
      "Epoch 4823/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4665\n",
      "Epoch 4824/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4665\n",
      "Epoch 4825/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4665\n",
      "Epoch 4826/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4664\n",
      "Epoch 4827/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4664\n",
      "Epoch 4828/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4664\n",
      "Epoch 4829/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4664\n",
      "Epoch 4830/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4664\n",
      "Epoch 4831/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4663\n",
      "Epoch 4832/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4663\n",
      "Epoch 4833/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4663\n",
      "Epoch 4834/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4663\n",
      "Epoch 4835/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4663\n",
      "Epoch 4836/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4662\n",
      "Epoch 4837/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4662\n",
      "Epoch 4838/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4662\n",
      "Epoch 4839/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4662\n",
      "Epoch 4840/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4662\n",
      "Epoch 4841/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4661\n",
      "Epoch 4842/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4661\n",
      "Epoch 4843/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4661\n",
      "Epoch 4844/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4661\n",
      "Epoch 4845/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4661\n",
      "Epoch 4846/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9091 - loss: 0.4660\n",
      "Epoch 4847/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9091 - loss: 0.4660\n",
      "Epoch 4848/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4660\n",
      "Epoch 4849/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4660\n",
      "Epoch 4850/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4660\n",
      "Epoch 4851/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4659\n",
      "Epoch 4852/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4659\n",
      "Epoch 4853/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4659\n",
      "Epoch 4854/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4659\n",
      "Epoch 4855/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4659\n",
      "Epoch 4856/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4659\n",
      "Epoch 4857/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4658\n",
      "Epoch 4858/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4658\n",
      "Epoch 4859/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4658\n",
      "Epoch 4860/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4658\n",
      "Epoch 4861/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4658\n",
      "Epoch 4862/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4657\n",
      "Epoch 4863/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4657\n",
      "Epoch 4864/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4657\n",
      "Epoch 4865/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4657\n",
      "Epoch 4866/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9091 - loss: 0.4657\n",
      "Epoch 4867/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4656\n",
      "Epoch 4868/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4656\n",
      "Epoch 4869/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4656\n",
      "Epoch 4870/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4656\n",
      "Epoch 4871/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4656\n",
      "Epoch 4872/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4655\n",
      "Epoch 4873/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4655\n",
      "Epoch 4874/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4655\n",
      "Epoch 4875/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4655\n",
      "Epoch 4876/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4655\n",
      "Epoch 4877/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4654\n",
      "Epoch 4878/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4654\n",
      "Epoch 4879/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4654\n",
      "Epoch 4880/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4654\n",
      "Epoch 4881/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4654\n",
      "Epoch 4882/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.4653\n",
      "Epoch 4883/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4653\n",
      "Epoch 4884/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4653\n",
      "Epoch 4885/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4653\n",
      "Epoch 4886/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4653\n",
      "Epoch 4887/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4652\n",
      "Epoch 4888/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4652\n",
      "Epoch 4889/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4652\n",
      "Epoch 4890/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4652\n",
      "Epoch 4891/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4652\n",
      "Epoch 4892/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4651\n",
      "Epoch 4893/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4651\n",
      "Epoch 4894/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4651\n",
      "Epoch 4895/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4651\n",
      "Epoch 4896/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4651\n",
      "Epoch 4897/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4650\n",
      "Epoch 4898/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4650\n",
      "Epoch 4899/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4650\n",
      "Epoch 4900/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4650\n",
      "Epoch 4901/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9091 - loss: 0.4650\n",
      "Epoch 4902/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4650\n",
      "Epoch 4903/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4649\n",
      "Epoch 4904/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4649\n",
      "Epoch 4905/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4649\n",
      "Epoch 4906/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4649\n",
      "Epoch 4907/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4649\n",
      "Epoch 4908/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4648\n",
      "Epoch 4909/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4648\n",
      "Epoch 4910/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4648\n",
      "Epoch 4911/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4648\n",
      "Epoch 4912/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4648\n",
      "Epoch 4913/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4647\n",
      "Epoch 4914/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4647\n",
      "Epoch 4915/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4647\n",
      "Epoch 4916/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4647\n",
      "Epoch 4917/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4647\n",
      "Epoch 4918/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4646\n",
      "Epoch 4919/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4646\n",
      "Epoch 4920/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9091 - loss: 0.4646\n",
      "Epoch 4921/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4646\n",
      "Epoch 4922/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9091 - loss: 0.4646\n",
      "Epoch 4923/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4645\n",
      "Epoch 4924/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4645\n",
      "Epoch 4925/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4645\n",
      "Epoch 4926/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4645\n",
      "Epoch 4927/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4645\n",
      "Epoch 4928/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4644\n",
      "Epoch 4929/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4644\n",
      "Epoch 4930/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9091 - loss: 0.4644\n",
      "Epoch 4931/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4644\n",
      "Epoch 4932/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4644\n",
      "Epoch 4933/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4644\n",
      "Epoch 4934/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4643\n",
      "Epoch 4935/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4643\n",
      "Epoch 4936/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4643\n",
      "Epoch 4937/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4643\n",
      "Epoch 4938/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4643\n",
      "Epoch 4939/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4642\n",
      "Epoch 4940/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9091 - loss: 0.4642\n",
      "Epoch 4941/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4642\n",
      "Epoch 4942/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4642\n",
      "Epoch 4943/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9091 - loss: 0.4642\n",
      "Epoch 4944/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4641\n",
      "Epoch 4945/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4641\n",
      "Epoch 4946/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4641\n",
      "Epoch 4947/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4641\n",
      "Epoch 4948/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9091 - loss: 0.4641\n",
      "Epoch 4949/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4640\n",
      "Epoch 4950/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9091 - loss: 0.4640\n",
      "Epoch 4951/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9091 - loss: 0.4640\n",
      "Epoch 4952/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9091 - loss: 0.4640\n",
      "Epoch 4953/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4640\n",
      "Epoch 4954/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9091 - loss: 0.4639\n",
      "Epoch 4955/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4639\n",
      "Epoch 4956/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4639\n",
      "Epoch 4957/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9091 - loss: 0.4639\n",
      "Epoch 4958/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4639\n",
      "Epoch 4959/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9091 - loss: 0.4639\n",
      "Epoch 4960/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9091 - loss: 0.4638\n",
      "Epoch 4961/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.4638\n",
      "Epoch 4962/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9091 - loss: 0.4638\n",
      "Epoch 4963/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4638\n",
      "Epoch 4964/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9091 - loss: 0.4638\n",
      "Epoch 4965/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9091 - loss: 0.4637\n",
      "Epoch 4966/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9091 - loss: 0.4637\n",
      "Epoch 4967/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4637\n",
      "Epoch 4968/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4637\n",
      "Epoch 4969/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4637\n",
      "Epoch 4970/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4636\n",
      "Epoch 4971/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9091 - loss: 0.4636\n",
      "Epoch 4972/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4636\n",
      "Epoch 4973/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.4636\n",
      "Epoch 4974/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9091 - loss: 0.4636\n",
      "Epoch 4975/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4635\n",
      "Epoch 4976/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4635\n",
      "Epoch 4977/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9091 - loss: 0.4635\n",
      "Epoch 4978/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4635\n",
      "Epoch 4979/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4635\n",
      "Epoch 4980/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4635\n",
      "Epoch 4981/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9091 - loss: 0.4634\n",
      "Epoch 4982/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4634\n",
      "Epoch 4983/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9091 - loss: 0.4634\n",
      "Epoch 4984/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4634\n",
      "Epoch 4985/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4634\n",
      "Epoch 4986/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4633\n",
      "Epoch 4987/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9091 - loss: 0.4633\n",
      "Epoch 4988/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4633\n",
      "Epoch 4989/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9091 - loss: 0.4633\n",
      "Epoch 4990/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9091 - loss: 0.4633\n",
      "Epoch 4991/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9091 - loss: 0.4632\n",
      "Epoch 4992/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9091 - loss: 0.4632\n",
      "Epoch 4993/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9091 - loss: 0.4632\n",
      "Epoch 4994/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9091 - loss: 0.4632\n",
      "Epoch 4995/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9091 - loss: 0.4632\n",
      "Epoch 4996/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4631\n",
      "Epoch 4997/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9091 - loss: 0.4631\n",
      "Epoch 4998/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9091 - loss: 0.4631\n",
      "Epoch 4999/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9091 - loss: 0.4631\n",
      "Epoch 5000/5000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9091 - loss: 0.4631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x79e645b169f0>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ec0e006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.7621956 ],\n",
       "       [0.18184492],\n",
       "       [0.0742349 ],\n",
       "       [0.3580879 ],\n",
       "       [0.7939333 ],\n",
       "       [0.92078567]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73793844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     1\n",
       "10    0\n",
       "21    0\n",
       "11    0\n",
       "14    1\n",
       "9     1\n",
       "Name: bought_insurance, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8d977a4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m coef, intercept \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mget_weights()\n\u001b[1;32m      2\u001b[0m coef, intercept\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "coef, intercept = model.get_weights()\n",
    "coef, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a03991cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  affordibility\n",
       "0   0.22              1\n",
       "13  0.29              0\n",
       "6   0.55              0\n",
       "17  0.58              1\n",
       "24  0.50              1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7acc1bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9525741268224334"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nural network from scratch\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    import math\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "sigmoid(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33257636",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_170309/1926367944.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return 1 / (1 + math.exp(-x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7621955387518495"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prediction_function(age, affordability):\n",
    "    weighted_sum = coef[0]*age + coef[1]*affordability + intercept\n",
    "    return sigmoid(weighted_sum)\n",
    "\n",
    "prediction_function(.47, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50bf9e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_170309/1926367944.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return 1 / (1 + math.exp(-x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18184492001835625"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_function(.18, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e50bb4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_loss(y_true, y_predicted):\n",
    "    epsilon = 1e-15\n",
    "    y_predicted_new = [max(epsilon,i)for i in y_predicted]\n",
    "    y_predicted_new = [min(i,1-epsilon)for i in y_predicted_new]\n",
    "    y_predicted_new = np.array(y_predicted_new)\n",
    "    return -np.mean(y_true*np.log(y_predicted_new)+(1-y_true)*np.log(1-np.array(y_predicted_new)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e19cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e884197a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999386, 0.5       , 0.73105858])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sigmoid function for array\n",
    "def sigmoid_numpy(X):\n",
    "    return 1/(1+np.exp(-X))\n",
    "\n",
    "sigmoid_numpy(np.array([12,0,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "10d8b53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(age, affordability,y_true, epochs, loss_threshold):\n",
    "    # w1 w2 biaq\n",
    "    w1 = w2 = 1\n",
    "    bias = 0\n",
    "    rate = 0.5\n",
    "    n = len(age)\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        wieghted_sum = w1 * age + w2 * affordability + bias\n",
    "        y_predicted = sigmoid_numpy(wieghted_sum)\n",
    "        loss = log_loss(y_true, y_predicted)\n",
    "        \n",
    "        w1d = (1/n)*np.dot(np.transpose(age),(y_predicted - y_true))\n",
    "        w2d = (1/n)*np.dot(np.transpose(affordability),(y_predicted - y_true))\n",
    "        bias_d= np.mean(y_predicted-y_true)\n",
    "        \n",
    "        w1 = w1 - rate * w1d\n",
    "        w2 = w2 - rate * w2d\n",
    "        bias = bias - rate * bias_d\n",
    "        \n",
    "        \n",
    "        print(f'Epoch:{i}, w1:{w1}, w2:{w2}, bias:{bias}, loss:{loss}')\n",
    "        \n",
    "        if loss <= loss_threshold:\n",
    "            break\n",
    "        \n",
    "    return w1, w2, bias\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8cdea0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0, w1:0.974907633470177, w2:0.948348125394529, bias:-0.11341867736368583, loss:0.7113403233723417\n",
      "Epoch:1, w1:0.9556229728273669, w2:0.9058873696677865, bias:-0.2122349122718517, loss:0.681264778737757\n",
      "Epoch:2, w1:0.9416488476693794, w2:0.8719790823960313, bias:-0.2977578997796538, loss:0.6591474252715025\n",
      "Epoch:3, w1:0.9323916996249162, w2:0.8457541517722915, bias:-0.3715094724003511, loss:0.6431523291301917\n",
      "Epoch:4, w1:0.9272267472726993, w2:0.8262362885332687, bias:-0.43506643026891584, loss:0.6316873063379158\n",
      "Epoch:5, w1:0.9255469396815343, w2:0.8124402814952774, bias:-0.48994490058938817, loss:0.623471707997592\n",
      "Epoch:6, w1:0.9267936114129968, w2:0.8034375029757677, bias:-0.5375299543522853, loss:0.6175321183044205\n",
      "Epoch:7, w1:0.93047170420295, w2:0.7983920007454487, bias:-0.5790424270894963, loss:0.6131591858705934\n",
      "Epoch:8, w1:0.9361540784567942, w2:0.7965748796787705, bias:-0.6155315088627655, loss:0.6098518179750948\n",
      "Epoch:9, w1:0.9434791243557357, w2:0.7973647616854131, bias:-0.6478828179413606, loss:0.6072639970231438\n",
      "Epoch:10, w1:0.9521448361628082, w2:0.8002404280558159, bias:-0.6768343869109611, loss:0.6051606942838051\n",
      "Epoch:11, w1:0.9619014360798376, w2:0.8047697991276092, bias:-0.7029956527236098, loss:0.6033841405177724\n",
      "Epoch:12, w1:0.9725437902239876, w2:0.8105978078160995, bias:-0.7268665798879941, loss:0.6018292976282692\n",
      "Epoch:13, w1:0.9839042828641819, w2:0.8174345999952901, bias:-0.7488554155033402, loss:0.6004266142491015\n",
      "Epoch:14, w1:0.9958464546516588, w2:0.8250447751055391, bias:-0.769294418817745, loss:0.5991301804031037\n",
      "Epoch:15, w1:1.0082595007242081, w2:0.8332379503132499, bias:-0.7884533918133878, loss:0.5979097221992564\n",
      "Epoch:16, w1:1.0210536111133566, w2:0.8418606908070436, bias:-0.8065510935633605, loss:0.5967452540340851\n",
      "Epoch:17, w1:1.034156080666481, w2:0.8507897246509063, bias:-0.8237647415878959, loss:0.5956235357679642\n",
      "Epoch:18, w1:1.0475080939682688, w2:0.8599263049589658, bias:-0.8402378469114854, loss:0.5945357398126384\n",
      "Epoch:19, w1:1.0610620872868053, w2:0.8691915649552581, bias:-0.8560866317233403, loss:0.5934759216594547\n",
      "Epoch:20, w1:1.0747795953648005, w2:0.8785227146485403, bias:-0.8714052604012273, loss:0.5924400203169505\n",
      "Epoch:21, w1:1.0886295007650375, w2:0.8878699408379153, bias:-0.8862700880092956, loss:0.5914252065214394\n",
      "Epoch:22, w1:1.1025866146156011, w2:0.8971938890119441, bias:-0.9007431016492755, loss:0.5904294583596238\n",
      "Epoch:23, w1:1.1166305284975315, w2:0.9064636231844676, bias:-0.9148747025148294, loss:0.5894512852039241\n",
      "Epoch:24, w1:1.130744687166233, w2:0.9156549761872753, bias:-0.9287059516737735, loss:0.5884895481881011\n",
      "Epoch:25, w1:1.1449156405234902, w2:0.9247492176815199, bias:-0.9422703810055986, loss:0.5875433434377384\n",
      "Epoch:26, w1:1.1591324407175467, w2:0.9337319799254573, bias:-0.9555954523596437, loss:0.5866119260562087\n",
      "Epoch:27, w1:1.1733861565198167, w2:0.9425923921787205, bias:-0.9687037326284236, loss:0.5856946605640079\n",
      "Epoch:28, w1:1.1876694823356402, w2:0.9513223836938425, bias:-0.9816138397030203, loss:0.5847909885040025\n",
      "Epoch:29, w1:1.2019764234961199, w2:0.9599161227563919, bias:-0.994341203820797, loss:0.5839004071862915\n",
      "Epoch:30, w1:1.2163020429886013, w2:0.9683695654077998, bias:-1.006898680274023, loss:0.5830224556644095\n",
      "Epoch:31, w1:1.2306422576428844, w2:0.9766800925300213, bias:-1.0192970425003876, loss:0.5821567054089575\n",
      "Epoch:32, w1:1.244993674111329, w2:0.9848462180774323, bias:-1.0315453789434794, loss:0.5813027540359855\n",
      "Epoch:33, w1:1.2593534568600255, w2:0.9928673545729692, bias:-1.0436514125153917, loss:0.5804602210251408\n",
      "Epoch:34, w1:1.2737192219062514, w2:1.0007436246821175, bias:-1.0556217578155669, loss:0.5796287447370064\n",
      "Epoch:35, w1:1.2880889512619975, w2:1.0084757098569885, bias:-1.067462128294764, loss:0.57880798028165\n",
      "Epoch:36, w1:1.3024609240300042, w2:1.0160647288004139, bias:-1.079177503164993, loss:0.5779975979476322\n",
      "Epoch:37, w1:1.3168336608930384, w2:1.0235121399165894, bias:-1.0907722619345364, loss:0.5771972820026156\n",
      "Epoch:38, w1:1.3312058793761508, w2:1.0308196630555955, bias:-1.1022502929016078, loss:0.5764067297427645\n",
      "Epoch:39, w1:1.3455764577755067, w2:1.03798921677727, bias:-1.1136150806976406, loss:0.5756256507109632\n",
      "Epoch:40, w1:1.3599444060604624, w2:1.0450228680985851, bias:-1.124869776972519, loss:0.5748537660316542\n",
      "Epoch:41, w1:1.3743088423875545, w2:1.0519227922827652, bias:-1.1360172575115421, loss:0.5740908078281305\n",
      "Epoch:42, w1:1.3886689741318716, w2:1.0586912407061275, bias:-1.1470601684290498, loss:0.5733365186998219\n",
      "Epoch:43, w1:1.4030240825556768, w2:1.065330515222758, bias:-1.1580009635655026, loss:0.5725906512447178\n",
      "Epoch:44, w1:1.4173735104064382, w2:1.0718429477560005, bias:-1.1688419347984433, loss:0.5718529676170188\n",
      "Epoch:45, w1:1.4317166518748927, w2:1.0782308840940895, bias:-1.1795852366431911, loss:0.5711232391133308\n",
      "Epoch:46, w1:1.4460529444550507, w2:1.0844966710669584, bias:-1.1902329062502135, loss:0.5704012457828124\n",
      "Epoch:47, w1:1.4603818623375084, w2:1.0906426464418717, bias:-1.2007868796899672, loss:0.5696867760580651\n",
      "Epoch:48, w1:1.474702911039356, w2:1.0966711310047097, bias:-1.2112490052422353, loss:0.5689796264044564\n",
      "Epoch:49, w1:1.4890156230318012, w2:1.1025844223976542, bias:-1.2216210542672539, loss:0.5682796009861607\n",
      "Epoch:50, w1:1.503319554173139, w2:1.108384790367645, bias:-1.2319047301235464, loss:0.5675865113475955\n",
      "Epoch:51, w1:1.5176142807921111, w2:1.1140744731472638, bias:-1.2421016755069894, loss:0.5669001761092021\n",
      "Epoch:52, w1:1.5318993972968091, w2:1.1196556747438646, bias:-1.2522134785128962, loss:0.566220420676692\n",
      "Epoch:53, w1:1.546174514208496, w2:1.1251305629563741, bias:-1.2622416776643735, loss:0.5655470769630154\n",
      "Epoch:54, w1:1.5604392565392238, w2:1.1305012679742994, bias:-1.2721877661030871, loss:0.5648799831223866\n",
      "Epoch:55, w1:1.5746932624478314, w2:1.1357698814417572, bias:-1.2820531951006382, loss:0.5642189832957764\n",
      "Epoch:56, w1:1.5889361821215457, w2:1.1409384558921223, bias:-1.2918393770181935, loss:0.5635639273673236\n",
      "Epoch:57, w1:1.6031676768405996, w2:1.1460090044772484, bias:-1.3015476878174077, loss:0.562914670731162\n",
      "Epoch:58, w1:1.6173874181914885, w2:1.150983500930006, bias:-1.3111794692058374, loss:0.5622710740681858\n",
      "Epoch:59, w1:1.6315950874010996, w2:1.155863879710811, bias:-1.320736030484068, loss:0.5616330031323111\n",
      "Epoch:60, w1:1.6457903747692835, w2:1.1606520362984267, bias:-1.3302186501488862, loss:0.5610003285458062\n",
      "Epoch:61, w1:1.6599729791817353, w2:1.1653498275930778, bias:-1.3396285772964385, loss:0.5603729256032908\n",
      "Epoch:62, w1:1.6741426076885264, w2:1.1699590724061661, bias:-1.348967032860937, loss:0.5597506740840237\n",
      "Epoch:63, w1:1.6882989751364197, w2:1.1744815520159209, bias:-1.3582352107177078, loss:0.5591334580721091\n",
      "Epoch:64, w1:1.7024418038453646, w2:1.1789190107723873, bias:-1.3674342786739169, loss:0.5585211657842806\n",
      "Epoch:65, w1:1.7165708233213919, w2:1.1832731567384374, bias:-1.3765653793659074, loss:0.5579136894049259\n",
      "Epoch:66, w1:1.7306857699995972, w2:1.1875456623561378, bias:-1.385629631078514, loss:0.5573109249280388\n",
      "Epoch:67, w1:1.744786387012096, w2:1.1917381651299463, bias:-1.3946281284988502, loss:0.556712772005794\n",
      "Epoch:68, w1:1.7588724239767908, w2:1.1958522683199346, bias:-1.4035619434147377, loss:0.5561191338034575\n",
      "Epoch:69, w1:1.7729436368035707, w2:1.199889541639625, bias:-1.412432125366066, loss:0.5555299168603557\n",
      "Epoch:70, w1:1.786999787515191, w2:1.2038515219541523, bias:-1.4212397022558536, loss:0.55494503095664\n",
      "Epoch:71, w1:1.8010406440805895, w2:1.2077397139753707, bias:-1.4299856809265468, loss:0.5543643889855958\n",
      "Epoch:72, w1:1.815065980258806, w2:1.21155559095125, bias:-1.4386710477060998, loss:0.5537879068312537\n",
      "Epoch:73, w1:1.8290755754520085, w2:1.2153005953475013, bias:-1.4472967689275704, loss:0.5532155032510755\n",
      "Epoch:74, w1:1.8430692145663952, w2:1.2189761395198406, bias:-1.4558637914253105, loss:0.5526470997634942\n",
      "Epoch:75, w1:1.857046687879965, w2:1.2225836063756854, bias:-1.4643730430103006, loss:0.5520826205400979\n",
      "Epoch:76, w1:1.8710077909163219, w2:1.2261243500243837, bias:-1.472825432926746, loss:0.5515219923022593\n",
      "Epoch:77, w1:1.8849523243238275, w2:1.2295996964153224, bias:-1.4812218522917016, loss:0.5509651442220168\n",
      "Epoch:78, w1:1.898880093759531, w2:1.2330109439634602, bias:-1.4895631745192046, loss:0.5504120078270269\n",
      "Epoch:79, w1:1.9127909097773987, w2:1.2363593641619885, bias:-1.4978502557301687, loss:0.5498625169094129\n",
      "Epoch:80, w1:1.9266845877204517, w2:1.2396462021819508, bias:-1.5060839351490927, loss:0.5493166074383391\n",
      "Epoch:81, w1:1.9405609476164691, w2:1.2428726774587495, bias:-1.5142650354884937, loss:0.5487742174761587\n",
      "Epoch:82, w1:1.9544198140769822, w2:1.2460399842655545, bias:-1.5223943633218389, loss:0.5482352870979753\n",
      "Epoch:83, w1:1.968261016199314, w2:1.2491492922736824, bias:-1.5304727094456483, loss:0.5476997583144769\n",
      "Epoch:84, w1:1.9820843874714607, w2:1.252201747100074, bias:-1.538500849231359, loss:0.5471675749979029\n",
      "Epoch:85, w1:1.995889765679638, w2:1.2551984708420285, bias:-1.5464795429674643, loss:0.5466386828110088\n",
      "Epoch:86, w1:2.0096769928183367, w2:1.2581405625993878, bias:-1.554409536192387, loss:0.5461130291389041\n",
      "Epoch:87, w1:2.023445915002755, w2:1.2610290989843815, bias:-1.5622915600184968, loss:0.545590563023641\n",
      "Epoch:88, w1:2.037196382383489, w2:1.2638651346193672, bias:-1.5701263314476384, loss:0.5450712351014357\n",
      "Epoch:89, w1:2.0509282490633733, w2:1.2666497026227028, bias:-1.577914553678509, loss:0.5445549975424178\n",
      "Epoch:90, w1:2.0646413730163813, w2:1.2693838150830055, bias:-1.585656916406187, loss:0.5440418039927909\n",
      "Epoch:91, w1:2.0783356160084976, w2:1.2720684635220503, bias:-1.5933540961140944, loss:0.5435316095193146\n",
      "Epoch:92, w1:2.092010843520487, w2:1.2747046193465692, bias:-1.6010067563586592, loss:0.5430243705560023\n",
      "Epoch:93, w1:2.1056669246724873, w2:1.2772932342892063, bias:-1.6086155480469115, loss:0.5425200448529465\n",
      "Epoch:94, w1:2.1193037321503643, w2:1.2798352408388918, bias:-1.6161811097072503, loss:0.5420185914271816\n",
      "Epoch:95, w1:2.1329211421337653, w2:1.282331552660889, bias:-1.62370406775359, loss:0.5415199705154982\n",
      "Epoch:96, w1:2.1465190342258187, w2:1.2847830650067702, bias:-1.6311850367430925, loss:0.5410241435291299\n",
      "Epoch:97, w1:2.1600972913844236, w2:1.2871906551145709, bias:-1.638624619627673, loss:0.5405310730102341\n",
      "Epoch:98, w1:2.173655799855084, w2:1.2895551825993699, bias:-1.6460234079994696, loss:0.5400407225900913\n",
      "Epoch:99, w1:2.1871944491052364, w2:1.2918774898345378, bias:-1.6533819823304428, loss:0.5395530569489538\n",
      "Epoch:100, w1:2.200713131760032, w2:1.2941584023238903, bias:-1.6607009122062801, loss:0.5390680417774752\n",
      "Epoch:101, w1:2.2142117435395288, w2:1.2963987290649803, bias:-1.667980756554761, loss:0.5385856437396539\n",
      "Epoch:102, w1:2.227690183197251, w2:1.298599262903754, bias:-1.675222063868738, loss:0.5381058304372313\n",
      "Epoch:103, w1:2.241148352460086, w2:1.300760780880796, bias:-1.6824253724238831, loss:0.5376285703754836\n",
      "Epoch:104, w1:2.2545861559694704, w2:1.302884044569378, bias:-1.68959121049134, loss:0.5371538329303491\n",
      "Epoch:105, w1:2.268003501223843, w2:1.3049698004055226, bias:-1.696720096545423, loss:0.5366815883168389\n",
      "Epoch:106, w1:2.281400298522321, w2:1.30701878001029, bias:-1.7038125394664934, loss:0.5362118075586769\n",
      "Epoch:107, w1:2.294776460909571, w2:1.3090317005044871, bias:-1.7108690387391425, loss:0.5357444624591193\n",
      "Epoch:108, w1:2.308131904121845, w2:1.3110092648159952, bias:-1.717890084645807, loss:0.5352795255729065\n",
      "Epoch:109, w1:2.3214665465341486, w2:1.3129521619799067, bias:-1.7248761584559342, loss:0.5348169701793002\n",
      "Epoch:110, w1:2.334780309108516, w2:1.3148610674316565, bias:-1.7318277326108187, loss:0.5343567702561651\n",
      "Epoch:111, w1:2.3480731153433556, w2:1.3167366432933292, bias:-1.7387452709042173, loss:0.5338989004550466\n",
      "Epoch:112, w1:2.361344891223853, w2:1.318579538653317, bias:-1.7456292286588566, loss:0.5334433360772121\n",
      "Epoch:113, w1:2.3745955651733888, w2:1.3203903898394993, bias:-1.752480052898938, loss:0.5329900530506113\n",
      "Epoch:114, w1:2.387825068005961, w2:1.3221698206861112, bias:-1.759298182518741, loss:0.532539027907722\n",
      "Epoch:115, w1:2.4010333328795768, w2:1.3239184427944621, bias:-1.7660840484474298, loss:0.5320902377642434\n",
      "Epoch:116, w1:2.4142202952505927, w2:1.3256368557876617, bias:-1.772838073810153, loss:0.5316436602986057\n",
      "Epoch:117, w1:2.427385892828985, w2:1.3273256475595065, bias:-1.7795606740855376, loss:0.5311992737322607\n",
      "Epoch:118, w1:2.440530065534521, w2:1.328985394517677, bias:-1.7862522572596642, loss:0.5307570568107249\n",
      "Epoch:119, w1:2.4536527554538115, w2:1.3306166618213877, bias:-1.7929132239766132, loss:0.5303169887853427\n",
      "Epoch:120, w1:2.46675390679823, w2:1.332220003613633, bias:-1.7995439676856702, loss:0.5298790493957434\n",
      "Epoch:121, w1:2.479833465862666, w2:1.3337959632481655, bias:-1.8061448747852695, loss:0.5294432188529623\n",
      "Epoch:122, w1:2.4928913809851023, w2:1.3353450735113397, bias:-1.8127163247637639, loss:0.5290094778232023\n",
      "Epoch:123, w1:2.505927602506996, w2:1.336867856838949, bias:-1.8192586903370926, loss:0.5285778074122077\n",
      "Epoch:124, w1:2.518942082734439, w2:1.3383648255281848, bias:-1.82577233758343, loss:0.5281481891502279\n",
      "Epoch:125, w1:2.5319347759000843, w2:1.3398364819448387, bias:-1.832257626074885, loss:0.5277206049775486\n",
      "Epoch:126, w1:2.5449056381258233, w2:1.341283318725866, bias:-1.8387149090063277, loss:0.5272950372305655\n",
      "Epoch:127, w1:2.557854627386187, w2:1.3427058189774277, bias:-1.8451445333214114, loss:0.5268714686283816\n",
      "Epoch:128, w1:2.570781703472466, w2:1.3441044564685243, bias:-1.851546839835858, loss:0.5264498822599072\n",
      "Epoch:129, w1:2.583686827957526, w2:1.345479695820328, bias:-1.857922163358077, loss:0.5260302615714416\n",
      "Epoch:130, w1:2.596569964161304, w2:1.346831992691322, bias:-1.8642708328071762, loss:0.5256125903547197\n",
      "Epoch:131, w1:2.6094310771169726, w2:1.3481617939583521, bias:-1.8705931713284367, loss:0.5251968527354035\n",
      "Epoch:132, w1:2.6222701335377554, w2:1.3494695378936876, bias:-1.8768894964063034, loss:0.524783033162003\n",
      "Epoch:133, w1:2.635087101784378, w2:1.3507556543381913, bias:-1.8831601199749577, loss:0.5243711163952075\n",
      "Epoch:134, w1:2.647881951833145, w2:1.3520205648706964, bias:-1.8894053485265268, loss:0.5239610874976152\n",
      "Epoch:135, w1:2.660654655244622, w2:1.353264682973678, bias:-1.8956254832169885, loss:0.5235529318238407\n",
      "Epoch:136, w1:2.6734051851329177, w2:1.3544884141953148, bias:-1.901820819969824, loss:0.5231466350109902\n",
      "Epoch:137, w1:2.686133516135547, w2:1.3556921563080242, bias:-1.9079916495774736, loss:0.5227421829694884\n",
      "Epoch:138, w1:2.6988396243838655, w2:1.3568762994635601, bias:-1.9141382578006458, loss:0.5223395618742417\n",
      "Epoch:139, w1:2.7115234874740595, w2:1.3580412263447545, bias:-1.920260925465534, loss:0.5219387581561296\n",
      "Epoch:140, w1:2.724185084438686, w2:1.3591873123139828, bias:-1.9263599285589843, loss:0.521539758493806\n",
      "Epoch:141, w1:2.736824395718745, w2:1.3603149255584348, bias:-1.9324355383216678, loss:0.5211425498058037\n",
      "Epoch:142, w1:2.7494414031362733, w2:1.3614244272322646, bias:-1.9384880213393003, loss:0.5207471192429267\n",
      "Epoch:143, w1:2.7620360898674554, w2:1.3625161715956964, bias:-1.9445176396319575, loss:0.5203534541809204\n",
      "Epoch:144, w1:2.7746084404162294, w2:1.363590506151157, bias:-1.9505246507415273, loss:0.5199615422134104\n",
      "Epoch:145, w1:2.787158440588389, w2:1.364647771776508, bias:-1.9565093078173448, loss:0.5195713711450981\n",
      "Epoch:146, w1:2.7996860774661636, w2:1.3656883028554423, bias:-1.9624718597000501, loss:0.5191829289852049\n",
      "Epoch:147, w1:2.812191339383268, w2:1.3667124274051172, bias:-1.9684125510037105, loss:0.5187962039411522\n",
      "Epoch:148, w1:2.824674215900416, w2:1.3677204672010856, bias:-1.974331622196247, loss:0.5184111844124737\n",
      "Epoch:149, w1:2.8371346977812824, w2:1.3687127378995887, bias:-1.9802293096782038, loss:0.5180278589849453\n",
      "Epoch:150, w1:2.8495727769689085, w2:1.3696895491572745, bias:-1.986105845859897, loss:0.5176462164249294\n",
      "Epoch:151, w1:2.861988446562542, w2:1.3706512047484, bias:-1.9919614592369834, loss:0.5172662456739209\n",
      "Epoch:152, w1:2.8743817007948973, w2:1.3715980026795769, bias:-1.9977963744644796, loss:0.5168879358432925\n",
      "Epoch:153, w1:2.886752535009837, w2:1.3725302353021163, bias:-2.003610812429271, loss:0.5165112762092271\n",
      "Epoch:154, w1:2.899100945640455, w2:1.373448189422031, bias:-2.009404990321143, loss:0.5161362562078318\n",
      "Epoch:155, w1:2.9114269301875644, w2:1.3743521464077455, bias:-2.015179121702366, loss:0.515762865430428\n",
      "Epoch:156, w1:2.9237304871985708, w2:1.3752423822955708, bias:-2.0209334165758692, loss:0.5153910936190104\n",
      "Epoch:157, w1:2.9360116162467342, w2:1.376119167892991, bias:-2.0266680814520357, loss:0.515020930661866\n",
      "Epoch:158, w1:2.9482703179108047, w2:1.3769827688798149, bias:-2.032383319414142, loss:0.5146523665893518\n",
      "Epoch:159, w1:2.960506593755025, w2:1.3778334459072408, bias:-2.038079330182483, loss:0.514285391569821\n",
      "Epoch:160, w1:2.9727204463094963, w2:1.3786714546948804, bias:-2.0437563101772027, loss:0.5139199959056945\n",
      "Epoch:161, w1:2.984911879050898, w2:1.3794970461257903, bias:-2.0494144525798648, loss:0.5135561700296716\n",
      "Epoch:162, w1:2.9970808963835545, w2:1.3803104663395542, bias:-2.0550539473937857, loss:0.5131939045010747\n",
      "Epoch:163, w1:3.0092275036208402, w2:1.3811119568234618, bias:-2.0606749815031633, loss:0.5128331900023233\n",
      "Epoch:164, w1:3.0213517069669225, w2:1.3819017545018246, bias:-2.0662777387310216, loss:0.5124740173355311\n",
      "Epoch:165, w1:3.0334535134988276, w2:1.382680091823474, bias:-2.0718623998960024, loss:0.5121163774192251\n",
      "Epoch:166, w1:3.045532931148832, w2:1.3834471968474789, bias:-2.0774291428680245, loss:0.5117602612851783\n",
      "Epoch:167, w1:3.0575899686871653, w2:1.384203293327124, bias:-2.08297814262284, loss:0.511405660075352\n",
      "Epoch:168, w1:3.069624635705023, w2:1.384948600792189, bias:-2.0885095712955057, loss:0.5110525650389491\n",
      "Epoch:169, w1:3.081636942597884, w2:1.385683334629563, bias:-2.094023598232799, loss:0.5107009675295656\n",
      "Epoch:170, w1:3.093626900549122, w2:1.386407706162234, bias:-2.0995203900445953, loss:0.5103508590024443\n",
      "Epoch:171, w1:3.105594521513913, w2:1.387121922726688, bias:-2.1050001106542355, loss:0.5100022310118232\n",
      "Epoch:172, w1:3.117539818203424, w2:1.387826187748753, bias:-2.110462921347898, loss:0.5096550752083747\n",
      "Epoch:173, w1:3.1294628040692873, w2:1.3885207008179221, bias:-2.1159089808230034, loss:0.5093093833367357\n",
      "Epoch:174, w1:3.141363493288346, w2:1.3892056577601883, bias:-2.121338445235668, loss:0.5089651472331199\n",
      "Epoch:175, w1:3.1532419007476733, w2:1.389881250709425, bias:-2.1267514682472277, loss:0.5086223588230153\n",
      "Epoch:176, w1:3.165098042029856, w2:1.390547668177342, bias:-2.132148201069852, loss:0.5082810101189588\n",
      "Epoch:177, w1:3.176931933398537, w2:1.3912050951220503, bias:-2.1375287925112674, loss:0.5079410932183875\n",
      "Epoch:178, w1:3.188743591784215, w2:1.3918537130152622, bias:-2.1428933890186115, loss:0.5076026003015645\n",
      "Epoch:179, w1:3.200533034770296, w2:1.3924936999081612, bias:-2.1482421347214276, loss:0.5072655236295737\n",
      "Epoch:180, w1:3.212300280579388, w2:1.3931252304959654, bias:-2.1535751714738307, loss:0.5069298555423847\n",
      "Epoch:181, w1:3.2240453480598403, w2:1.3937484761812156, bias:-2.158892638895851, loss:0.5065955884569808\n",
      "Epoch:182, w1:3.235768256672519, w2:1.3943636051358148, bias:-2.1641946744139777, loss:0.5062627148655543\n",
      "Epoch:183, w1:3.2474690264778157, w2:1.394970782361845, bias:-2.1694814133009186, loss:0.505931227333758\n",
      "Epoch:184, w1:3.2591476781228836, w2:1.3955701697511878, bias:-2.1747529887145927, loss:0.5056011184990193\n",
      "Epoch:185, w1:3.270804232829102, w2:1.3961619261439753, bias:-2.1800095317363692, loss:0.505272381068909\n",
      "Epoch:186, w1:3.2824387123797556, w2:1.3967462073858943, bias:-2.185251171408572, loss:0.5049450078195657\n",
      "Epoch:187, w1:3.294051139107937, w2:1.3973231663843697, bias:-2.1904780347712607, loss:0.5046189915941715\n",
      "Epoch:188, w1:3.3056415358846545, w2:1.3978929531636493, bias:-2.1956902468983084, loss:0.5042943253014793\n",
      "Epoch:189, w1:3.317209926107157, w2:1.3984557149188142, bias:-2.2008879309327845, loss:0.5039710019143897\n",
      "Epoch:190, w1:3.3287563336874557, w2:1.3990115960687382, bias:-2.2060712081216627, loss:0.5036490144685731\n",
      "Epoch:191, w1:3.340280783041054, w2:1.3995607383080155, bias:-2.211240197849864, loss:0.5033283560611389\n",
      "Epoch:192, w1:3.351783299075871, w2:1.400103280657881, bias:-2.21639501767365, loss:0.5030090198493474\n",
      "Epoch:193, w1:3.3632639071813593, w2:1.4006393595161428, bias:-2.221535783353378, loss:0.502690999049364\n",
      "Epoch:194, w1:3.3747226332178184, w2:1.401169108706148, bias:-2.2266626088856363, loss:0.502374286935055\n",
      "Epoch:195, w1:3.3861595035058896, w2:1.4016926595248012, bias:-2.231775606534763, loss:0.5020588768368214\n",
      "Epoch:196, w1:3.3975745448162384, w2:1.4022101407896574, bias:-2.236874886863771, loss:0.5017447621404708\n",
      "Epoch:197, w1:3.408967784359416, w2:1.4027216788851056, bias:-2.2419605587646827, loss:0.5014319362861261\n",
      "Epoch:198, w1:3.4203392497759015, w2:1.4032273978076624, bias:-2.247032729488292, loss:0.5011203927671694\n",
      "Epoch:199, w1:3.4316889691263146, w2:1.4037274192103975, bias:-2.252091504673362, loss:0.5008101251292182\n",
      "Epoch:200, w1:3.443016970881803, w2:1.4042218624465033, bias:-2.2571369883752723, loss:0.5005011269691375\n",
      "Epoch:201, w1:3.4543232839145968, w2:1.4047108446120309, bias:-2.2621692830941247, loss:0.5001933919340792\n",
      "Epoch:202, w1:3.4656079374887283, w2:1.4051944805878065, bias:-2.2671884898023182, loss:0.4998869137205552\n",
      "Epoch:203, w1:3.4768709612509157, w2:1.4056728830805474, bias:-2.2721947079716065, loss:0.499581686073539\n",
      "Epoch:204, w1:3.4881123852216054, w2:1.4061461626631908, bias:-2.2771880355996448, loss:0.4992777027855931\n",
      "Epoch:205, w1:3.4993322397861726, w2:1.406614427814455, bias:-2.282168569236039, loss:0.4989749576960279\n",
      "Epoch:206, w1:3.510530555686274, w2:1.407077784957646, bias:-2.287136404007907, loss:0.4986734446900829\n",
      "Epoch:207, w1:3.5217073640113545, w2:1.407536338498725, bias:-2.2920916336449575, loss:0.49837315769813556\n",
      "Epoch:208, w1:3.5328626961903016, w2:1.4079901908636536, bias:-2.2970343505041027, loss:0.49807409069493364\n",
      "Epoch:209, w1:3.5439965839832466, w2:1.4084394425350295, bias:-2.30196464559361, loss:0.49777623769885115\n",
      "Epoch:210, w1:3.5551090594735104, w2:1.4088841920880264, bias:-2.3068826085968004, loss:0.49747959277116743\n",
      "Epoch:211, w1:3.5662001550596885, w2:1.4093245362256548, bias:-2.3117883278953073, loss:0.4971841500153676\n",
      "Epoch:212, w1:3.577269903447877, w2:1.4097605698133546, bias:-2.3166818905919, loss:0.4968899035764641\n",
      "Epoch:213, w1:3.5883183376440364, w2:1.4101923859129344, bias:-2.321563382532884, loss:0.49659684764033973\n",
      "Epoch:214, w1:3.5993454909464844, w2:1.4106200758158696, bias:-2.32643288833008, loss:0.49630497643310856\n",
      "Epoch:215, w1:3.610351396938527, w2:1.4110437290759732, bias:-2.331290491382403, loss:0.49601428422049737\n",
      "Epoch:216, w1:3.6213360894812157, w2:1.4114634335414504, bias:-2.3361362738970306, loss:0.4957247653072439\n",
      "Epoch:217, w1:3.6322996027062318, w2:1.4118792753863514, bias:-2.3409703169101865, loss:0.49543641403651506\n",
      "Epoch:218, w1:3.6432419710088983, w2:1.4122913391414305, bias:-2.345792700307536, loss:0.49514922478933926\n",
      "Epoch:219, w1:3.6541632290413135, w2:1.4126997077244283, bias:-2.350603502844203, loss:0.4948631919840572\n",
      "Epoch:220, w1:3.6650634117056042, w2:1.4131044624697842, bias:-2.3554028021644196, loss:0.49457831007578845\n",
      "Epoch:221, w1:3.6759425541473023, w2:1.4135056831577921, bias:-2.360190674820809, loss:0.4942945735559119\n",
      "Epoch:222, w1:3.6868006917488327, w2:1.4139034480432113, bias:-2.3649671962933168, loss:0.49401197695156235\n",
      "Epoch:223, w1:3.6976378601231215, w2:1.4142978338833405, bias:-2.3697324410077902, loss:0.4937305148251413\n",
      "Epoch:224, w1:3.7084540951073124, w2:1.4146889159655687, bias:-2.3744864823542158, loss:0.49345018177384004\n",
      "Epoch:225, w1:3.719249432756598, w2:1.4150767681344103, bias:-2.379229392704622, loss:0.49317097242917785\n",
      "Epoch:226, w1:3.7300239093381586, w2:1.4154614628180373, bias:-2.383961243430653, loss:0.4928928814565522\n",
      "Epoch:227, w1:3.740777561325208, w2:1.4158430710543157, bias:-2.388682104920817, loss:0.4926159035548014\n",
      "Epoch:228, w1:3.751510425391147, w2:1.4162216625163582, bias:-2.393392046597421, loss:0.4923400334557782\n",
      "Epoch:229, w1:3.7622225384038157, w2:1.4165973055376, bias:-2.398091136933194, loss:0.4920652659239369\n",
      "Epoch:230, w1:3.772913937419856, w2:1.4169700671364103, bias:-2.4027794434676064, loss:0.4917915957559304\n",
      "Epoch:231, w1:3.783584659679165, w2:1.417340013040245, bias:-2.407457032822888, loss:0.49151901778021734\n",
      "Epoch:232, w1:3.7942347425994543, w2:1.4177072077093518, bias:-2.412123970719756, loss:0.4912475268566808\n",
      "Epoch:233, w1:3.804864223770903, w2:1.4180717143600363, bias:-2.4167803219928548, loss:0.4909771178762567\n",
      "Epoch:234, w1:3.8154731409509055, w2:1.418433594987496, bias:-2.4214261506059125, loss:0.4907077857605718\n",
      "Epoch:235, w1:3.8260615320589157, w2:1.4187929103882317, bias:-2.426061519666623, loss:0.49043952546159064\n",
      "Epoch:236, w1:3.83662943517138, w2:1.4191497201820455, bias:-2.4306864914412545, loss:0.4901723319612717\n",
      "Epoch:237, w1:3.8471768885167634, w2:1.41950408283363, bias:-2.4353011273689953, loss:0.4899062002712329\n",
      "Epoch:238, w1:3.857703930470663, w2:1.4198560556737607, bias:-2.4399054880760342, loss:0.48964112543242444\n",
      "Epoch:239, w1:3.8682105995510105, w2:1.4202056949200956, bias:-2.444499633389389, loss:0.48937710251481087\n",
      "Epoch:240, w1:3.8786969344133597, w2:1.4205530556975927, bias:-2.4490836223504795, loss:0.48911412661705983\n",
      "Epoch:241, w1:3.8891629738462594, w2:1.4208981920585493, bias:-2.45365751322846, loss:0.48885219286623943\n",
      "Epoch:242, w1:3.8996087567667086, w2:1.4212411570022738, bias:-2.4582213635333026, loss:0.48859129641752214\n",
      "Epoch:243, w1:3.910034322215694, w2:1.4215820024943946, bias:-2.4627752300286496, loss:0.48833143245389626\n",
      "Epoch:244, w1:3.920439709353808, w2:1.4219207794858135, bias:-2.4673191687444302, loss:0.48807259618588394\n",
      "Epoch:245, w1:3.930824957456947, w2:1.4222575379313118, bias:-2.471853234989249, loss:0.48781478285126634\n",
      "Epoch:246, w1:3.9411901059120837, w2:1.422592326807813, bias:-2.4763774833625503, loss:0.4875579877148143\n",
      "Epoch:247, w1:3.9515351942131214, w2:1.422925194132311, bias:-2.4808919677665644, loss:0.4873022060680255\n",
      "Epoch:248, w1:3.9618602619568177, w2:1.4232561869794709, bias:-2.485396741418036, loss:0.487047433228868\n",
      "Epoch:249, w1:3.972165348838788, w2:1.4235853514989025, bias:-2.489891856859742, loss:0.4867936645415293\n",
      "Epoch:250, w1:3.982450494649576, w2:1.4239127329321233, bias:-2.494377365971801, loss:0.48654089537617085\n",
      "Epoch:251, w1:3.9927157392707997, w2:1.4242383756292052, bias:-2.49885331998278, loss:0.48628912112868766\n",
      "Epoch:252, w1:4.002961122671366, w2:1.42456232306512, bias:-2.503319769480601, loss:0.48603833722047357\n",
      "Epoch:253, w1:4.013186684903756, w2:1.4248846178557855, bias:-2.50777676442325, loss:0.48578853909819186\n",
      "Epoch:254, w1:4.023392466100375, w2:1.4252053017738153, bias:-2.512224354149295, loss:0.4855397222335499\n",
      "Epoch:255, w1:4.033578506469971, w2:1.425524415763985, bias:-2.516662587388215, loss:0.4852918821230787\n",
      "Epoch:256, w1:4.043744846294124, w2:1.4258419999584127, bias:-2.5210915122705426, loss:0.4850450142879177\n",
      "Epoch:257, w1:4.053891525923789, w2:1.4261580936914633, bias:-2.525511176337824, loss:0.48479911427360317\n",
      "Epoch:258, w1:4.064018585775913, w2:1.4264727355143816, bias:-2.529921626552404, loss:0.48455417764986114\n",
      "Epoch:259, w1:4.074126066330109, w2:1.4267859632096573, bias:-2.534322909307031, loss:0.48431020001040465\n",
      "Epoch:260, w1:4.084214008125393, w2:1.4270978138051291, bias:-2.5387150704342933, loss:0.48406717697273477\n",
      "Epoch:261, w1:4.094282451756979, w2:1.4274083235878308, bias:-2.5430981552158864, loss:0.4838251041779449\n",
      "Epoch:262, w1:4.104331437873139, w2:1.4277175281175865, bias:-2.5474722083917123, loss:0.48358397729053065\n",
      "Epoch:263, w1:4.114361007172114, w2:1.428025462240357, bias:-2.5518372741688182, loss:0.4833437919982009\n",
      "Epoch:264, w1:4.124371200399091, w2:1.4283321601013441, bias:-2.5561933962301766, loss:0.4831045440116944\n",
      "Epoch:265, w1:4.134362058343228, w2:1.4286376551578572, bias:-2.5605406177433045, loss:0.48286622906459864\n",
      "Epoch:266, w1:4.144333621834739, w2:1.4289419801919439, bias:-2.564878981368735, loss:0.48262884291317154\n",
      "Epoch:267, w1:4.1542859317420335, w2:1.429245167322793, bias:-2.569208529268332, loss:0.48239238133616846\n",
      "Epoch:268, w1:4.164219028968911, w2:1.4295472480189122, bias:-2.573529303113461, loss:0.48215684013466936\n",
      "Epoch:269, w1:4.174132954451802, w2:1.4298482531100827, bias:-2.577841344093013, loss:0.481922215131912\n",
      "Epoch:270, w1:4.184027749157071, w2:1.430148212799099, bias:-2.5821446929212852, loss:0.4816885021731251\n",
      "Epoch:271, w1:4.1939034540783595, w2:1.4304471566732948, bias:-2.5864393898457227, loss:0.4814556971253665\n",
      "Epoch:272, w1:4.203760110233989, w2:1.4307451137158596, bias:-2.5907254746545223, loss:0.4812237958773629\n",
      "Epoch:273, w1:4.213597758664405, w2:1.4310421123169506, bias:-2.5950029866841016, loss:0.480992794339352\n",
      "Epoch:274, w1:4.223416440429678, w2:1.4313381802846028, bias:-2.5992719648264337, loss:0.48076268844292946\n",
      "Epoch:275, w1:4.233216196607044, w2:1.4316333448554421, bias:-2.6035324475362565, loss:0.48053347414089403\n",
      "Epoch:276, w1:4.242997068288498, w2:1.4319276327052033, bias:-2.607784472838149, loss:0.48030514740709995\n",
      "Epoch:277, w1:4.252759096578431, w2:1.4322210699590585, bias:-2.612028078333486, loss:0.4800777042363081\n",
      "Epoch:278, w1:4.262502322591309, w2:1.4325136822017583, bias:-2.616263301207267, loss:0.4798511406440404\n",
      "Epoch:279, w1:4.272226787449408, w2:1.4328054944875899, bias:-2.620490178234828, loss:0.47962545266643786\n",
      "Epoch:280, w1:4.281932532280578, w2:1.433096531350154, bias:-2.6247087457884315, loss:0.4794006363601184\n",
      "Epoch:281, w1:4.291619598216061, w2:1.4333868168119661, bias:-2.628919039843741, loss:0.4791766878020384\n",
      "Epoch:282, w1:4.301288026388348, w2:1.4336763743938834, bias:-2.633121095986182, loss:0.4789536030893553\n",
      "Epoch:283, w1:4.3109378579290745, w2:1.4339652271243617, bias:-2.637314949417191, loss:0.478731378339293\n",
      "Epoch:284, w1:4.320569133966964, w2:1.4342533975485452, bias:-2.6415006349603525, loss:0.47851000968900853\n",
      "Epoch:285, w1:4.330181895625803, w2:1.4345409077371913, bias:-2.6456781870674306, loss:0.4782894932954603\n",
      "Epoch:286, w1:4.339776184022467, w2:1.4348277792954356, bias:-2.6498476398242916, loss:0.47806982533527886\n",
      "Epoch:287, w1:4.349352040264972, w2:1.435114033371397, bias:-2.6540090269567256, loss:0.47785100200463954\n",
      "Epoch:288, w1:4.358909505450577, w2:1.4353996906646287, bias:-2.658162381836163, loss:0.4776330195191349\n",
      "Epoch:289, w1:4.368448620663914, w2:1.4356847714344168, bias:-2.6623077374852917, loss:0.47741587411365194\n",
      "Epoch:290, w1:4.377969426975163, w2:1.4359692955079275, bias:-2.666445126583577, loss:0.4771995620422475\n",
      "Epoch:291, w1:4.387471965438257, w2:1.43625328228821, bias:-2.6705745814726813, loss:0.47698407957802763\n",
      "Epoch:292, w1:4.396956277089129, w2:1.436536750762052, bias:-2.674696134161793, loss:0.476769423013028\n",
      "Epoch:293, w1:4.406422402943988, w2:1.4368197195076962, bias:-2.6788098163328593, loss:0.47655558865809444\n",
      "Epoch:294, w1:4.415870383997634, w2:1.4371022067024166, bias:-2.682915659345727, loss:0.4763425728427668\n",
      "Epoch:295, w1:4.425300261221806, w2:1.437384230129958, bias:-2.6870136942431952, loss:0.476130371915163\n",
      "Epoch:296, w1:4.434712075563564, w2:1.4376658071878416, bias:-2.69110395175598, loss:0.47591898224186396\n",
      "Epoch:297, w1:4.4441058679436996, w2:1.4379469548945394, bias:-2.6951864623075887, loss:0.4757084002078021\n",
      "Epoch:298, w1:4.453481679255187, w2:1.4382276898965187, bias:-2.6992612560191143, loss:0.47549862221614797\n",
      "Epoch:299, w1:4.462839550361659, w2:1.4385080284751603, bias:-2.703328362713941, loss:0.4752896446882009\n",
      "Epoch:300, w1:4.472179522095915, w2:1.438787986553552, bias:-2.707387811922373, loss:0.4750814640632793\n",
      "Epoch:301, w1:4.4815016352584625, w2:1.439067579703159, bias:-2.711439632886177, loss:0.47487407679861204\n",
      "Epoch:302, w1:4.49080593061609, w2:1.4393468231503754, bias:-2.7154838545630504, loss:0.47466747936923254\n",
      "Epoch:303, w1:4.500092448900464, w2:1.4396257317829577, bias:-2.7195205056310083, loss:0.47446166826787173\n",
      "Epoch:304, w1:4.5093612308067605, w2:1.4399043201563404, bias:-2.723549614492697, loss:0.4742566400048545\n",
      "Epoch:305, w1:4.518612316992322, w2:1.440182602499841, bias:-2.72757120927963, loss:0.4740523911079949\n",
      "Epoch:306, w1:4.527845748075346, w2:1.4404605927227512, bias:-2.731585317856352, loss:0.4738489181224942\n",
      "Epoch:307, w1:4.537061564633595, w2:1.440738304420319, bias:-2.7355919678245306, loss:0.47364621761083875\n",
      "Epoch:308, w1:4.546259807203141, w2:1.441015750879624, bias:-2.7395911865269764, loss:0.47344428615270023\n",
      "Epoch:309, w1:4.555440516277136, w2:1.4412929450853456, bias:-2.7435830010515936, loss:0.4732431203448344\n",
      "Epoch:310, w1:4.564603732304602, w2:1.4415698997254285, bias:-2.747567438235262, loss:0.473042716800984\n",
      "Epoch:311, w1:4.573749495689255, w2:1.441846627196646, bias:-2.7515445246676515, loss:0.4728430721517801\n",
      "Epoch:312, w1:4.58287784678835, w2:1.4421231396100629, bias:-2.7555142866949733, loss:0.4726441830446452\n",
      "Epoch:313, w1:4.591988825911552, w2:1.4423994487964005, bias:-2.759476750423661, loss:0.4724460461436974\n",
      "Epoch:314, w1:4.601082473319831, w2:1.4426755663113053, bias:-2.763431941723993, loss:0.47224865812965516\n",
      "Epoch:315, w1:4.610158829224385, w2:1.4429515034405223, bias:-2.7673798862336514, loss:0.47205201569974303\n",
      "Epoch:316, w1:4.619217933785582, w2:1.4432272712049754, bias:-2.7713206093612155, loss:0.47185611556759816\n",
      "Epoch:317, w1:4.628259827111926, w2:1.4435028803657577, bias:-2.7752541362896017, loss:0.4716609544631776\n",
      "Epoch:318, w1:4.63728454925905, w2:1.44377834142903, bias:-2.7791804919794383, loss:0.47146652913266657\n",
      "Epoch:319, w1:4.646292140228726, w2:1.4440536646508326, bias:-2.7830997011723855, loss:0.4712728363383867\n",
      "Epoch:320, w1:4.655282639967903, w2:1.4443288600418103, bias:-2.787011788394397, loss:0.4710798728587066\n",
      "Epoch:321, w1:4.664256088367763, w2:1.4446039373718518, bias:-2.7909167779589263, loss:0.4708876354879519\n",
      "Epoch:322, w1:4.673212525262796, w2:1.4448789061746472, bias:-2.7948146939700766, loss:0.470696121036316\n",
      "Epoch:323, w1:4.682151990429907, w2:1.445153775752162, bias:-2.7987055603256983, loss:0.4705053263297723\n",
      "Epoch:324, w1:4.691074523587528, w2:1.445428555179031, bias:-2.8025894007204317, loss:0.4703152482099871\n",
      "Epoch:325, w1:4.6999801643947645, w2:1.4457032533068734, bias:-2.8064662386487, loss:0.47012588353423135\n",
      "Epoch:326, w1:4.708868952450553, w2:1.445977878768531, bias:-2.8103360974076472, loss:0.4699372291752969\n",
      "Epoch:327, w1:4.7177409272928434, w2:1.4462524399822285, bias:-2.81419900010003, loss:0.46974928202140903\n",
      "Epoch:328, w1:4.726596128397797, w2:1.4465269451556608, bias:-2.818054969637057, loss:0.4695620389761421\n",
      "Epoch:329, w1:4.735434595179007, w2:1.446801402290005, bias:-2.82190402874118, loss:0.4693754969583367\n",
      "Epoch:330, w1:4.744256366986734, w2:1.4470758191838622, bias:-2.82574619994884, loss:0.46918965290201436\n",
      "Epoch:331, w1:4.753061483107164, w2:1.4473502034371264, bias:-2.8295815056131626, loss:0.469004503756296\n",
      "Epoch:332, w1:4.76184998276168, w2:1.4476245624547852, bias:-2.833409967906611, loss:0.46882004648531833\n",
      "Epoch:333, w1:4.770621905106156, w2:1.4478989034506518, bias:-2.8372316088235907, loss:0.46863627806815394\n",
      "Epoch:334, w1:4.779377289230264, w2:1.448173233451029, bias:-2.841046450183012, loss:0.4684531954987285\n",
      "Epoch:335, w1:4.7881161741568015, w2:1.4484475592983093, bias:-2.8448545136308083, loss:0.46827079578574116\n",
      "Epoch:336, w1:4.796838598841035, w2:1.448721887654507, bias:-2.848655820642411, loss:0.46808907595258414\n",
      "Epoch:337, w1:4.805544602170057, w2:1.4489962250047304, bias:-2.852450392525183, loss:0.467908033037264\n",
      "Epoch:338, w1:4.814234222962166, w2:1.4492705776605888, bias:-2.8562382504208115, loss:0.4677276640923221\n",
      "Epoch:339, w1:4.822907499966253, w2:1.4495449517635393, bias:-2.860019415307658, loss:0.4675479661847561\n",
      "Epoch:340, w1:4.831564471861215, w2:1.4498193532881727, bias:-2.8637939080030708, loss:0.46736893639594346\n",
      "Epoch:341, w1:4.840205177255373, w2:1.4500937880454414, bias:-2.8675617491656573, loss:0.4671905718215625\n",
      "Epoch:342, w1:4.848829654685914, w2:1.4503682616858278, bias:-2.8713229592975185, loss:0.46701286957151705\n",
      "Epoch:343, w1:4.85743794261834, w2:1.4506427797024561, bias:-2.875077558746444, loss:0.46683582676985935\n",
      "Epoch:344, w1:4.866030079445939, w2:1.450917347434149, bias:-2.8788255677080725, loss:0.4666594405547149\n",
      "Epoch:345, w1:4.874606103489267, w2:1.4511919700684275, bias:-2.882567006228014, loss:0.46648370807820677\n",
      "Epoch:346, w1:4.883166052995643, w2:1.4514666526444582, bias:-2.8863018942039362, loss:0.4663086265063812\n",
      "Epoch:347, w1:4.891709966138657, w2:1.4517414000559465, bias:-2.8900302513876173, loss:0.466134193019133\n",
      "Epoch:348, w1:4.900237881017698, w2:1.4520162170539788, bias:-2.893752097386962, loss:0.4659604048101324\n",
      "Epoch:349, w1:4.9087498356574875, w2:1.4522911082498116, bias:-2.8974674516679864, loss:0.4657872590867513\n",
      "Epoch:350, w1:4.917245868007634, w2:1.4525660781176122, bias:-2.901176333556766, loss:0.46561475306999006\n",
      "Epoch:351, w1:4.925726015942192, w2:1.4528411309971487, bias:-2.9048787622413546, loss:0.4654428839944057\n",
      "Epoch:352, w1:4.9341903172592385, w2:1.453116271096432, bias:-2.9085747567736684, loss:0.4652716491080398\n",
      "Epoch:353, w1:4.942638809680464, w2:1.45339150249431, bias:-2.91226433607134, loss:0.46510104567234706\n",
      "Epoch:354, w1:4.95107153085077, w2:1.453666829143015, bias:-2.9159475189195407, loss:0.4649310709621242\n",
      "Epoch:355, w1:4.959488518337886, w2:1.453942254870665, bias:-2.919624323972772, loss:0.46476172226543927\n",
      "Epoch:356, w1:4.967889809631988, w2:1.4542177833837202, bias:-2.9232947697566276, loss:0.4645929968835612\n",
      "Epoch:357, w1:4.976275442145338, w2:1.4544934182693938, bias:-2.9269588746695274, loss:0.46442489213089116\n",
      "Epoch:358, w1:4.984645453211936, w2:1.4547691629980217, bias:-2.93061665698442, loss:0.464257405334892\n",
      "Epoch:359, w1:4.9929998800871696, w2:1.4550450209253871, bias:-2.934268134850457, loss:0.46409053383601956\n",
      "Epoch:360, w1:5.001338759947489, w2:1.4553209952950035, bias:-2.9379133262946424, loss:0.46392427498765465\n",
      "Epoch:361, w1:5.00966212989009, w2:1.4555970892403576, bias:-2.9415522492234514, loss:0.46375862615603475\n",
      "Epoch:362, w1:5.0179700269326, w2:1.45587330578711, bias:-2.9451849214244237, loss:0.46359358472018636\n",
      "Epoch:363, w1:5.026262488012782, w2:1.456149647855258, bias:-2.94881136056773, loss:0.4634291480718573\n",
      "Epoch:364, w1:5.0345395499882475, w2:1.456426118261257, bias:-2.952431584207713, loss:0.46326531361545026\n",
      "Epoch:365, w1:5.042801249636176, w2:1.4567027197201048, bias:-2.956045609784402, loss:0.46310207876795667\n",
      "Epoch:366, w1:5.051047623653049, w2:1.4569794548473887, bias:-2.9596534546250037, loss:0.46293944095888917\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(5.051047623653049),\n",
       " np.float64(1.4569794548473887),\n",
       " np.float64(-2.9596534546250037))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(X_train_scaled['age'], X_train_scaled['affordibility'], y_train, 1000, 0.4631)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43466fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[9.2022505],\n",
       "        [1.7556683]], dtype=float32),\n",
       " array([-4.9159713], dtype=float32))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef, intercept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d4143478",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNNE:\n",
    "    \n",
    "    \n",
    "    def __init__(self,learning_rate,epoch,loss_threshold):\n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.epoch = epoch\n",
    "        self.loss_threshold = loss_threshold\n",
    "        \n",
    "    \n",
    "    # fit function to train the model\n",
    "    def fit(self, X, Y):\n",
    "        \n",
    "        self.m, self.n = X.shape\n",
    "        \n",
    "        self.weights = np.ones(self.n)\n",
    "        self.bias = 0\n",
    "        \n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "        # implementing gradient descent\n",
    "        for i in range(self.epoch):\n",
    "            self.update_weights()\n",
    "            \n",
    "            print(f'epoch:{i}, weight:{self.weights}, bias:{self.bias}, loss:{self.loss}')    \n",
    "            \n",
    "            if self.loss <= self.loss_threshold:\n",
    "                break\n",
    "            \n",
    "    # cost function\n",
    "    \n",
    "        \n",
    "        \n",
    "    def update_weights(self):\n",
    "        \n",
    "        # calculate y_predicted\n",
    "        weighted_sum = np.dot(self.X, self.weights) + self.bias\n",
    "        y_predicted = 1 / (1 + np.exp(-weighted_sum))\n",
    "        \n",
    "        \n",
    "        # calculate loss\n",
    "        epsilon = 1e-15\n",
    "        y_predicted_new = [max(epsilon,i)for i in y_predicted]\n",
    "        y_predicted_new = [min(epsilon,i)for i in y_predicted_new]\n",
    "        log_loss = -np.mean(self.Y*np.log(y_predicted_new)+(1-self.Y)*np.log(1-np.array(y_predicted_new)))\n",
    "        \n",
    "        self.loss = log_loss\n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "        # derivaties\n",
    "        dw = 1/self.m *(np.dot(self.X.T, (y_predicted - self.Y)))\n",
    "        db = np.mean(y_predicted - self.Y)\n",
    "        \n",
    "        \n",
    "        # updating weights\n",
    "        self.weights -= self.learning_rate *dw\n",
    "        self.bias -= self.learning_rate * db\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \n",
    "        weighted_sum = np.dot(self.X, self.weights) + self.bias\n",
    "        y_predicted = 1 / (1 + np.exp(-weighted_sum))\n",
    "        \n",
    "        return y_predicted\n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c93c523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, weight:[0.99949815 0.99896696], bias:-0.0022683735472737165, loss:0.7113403233723417\n",
      "epoch:1, weight:[0.99899854 0.99793742], bias:-0.004531110245838688, loss:0.7106947453938027\n",
      "epoch:2, weight:[0.99850116 0.99691136], bias:-0.006788217377105742, loss:0.7100526623879727\n",
      "epoch:3, weight:[0.99800601 0.9958888 ], bias:-0.009039702278981612, loss:0.7094140604774263\n",
      "epoch:4, weight:[0.99751308 0.99486972], bias:-0.011285572345427677, loss:0.7087789257803064\n",
      "epoch:5, weight:[0.99702238 0.99385412], bias:-0.013525835026017508, loss:0.708147244410992\n",
      "epoch:6, weight:[0.99653391 0.992842  ], bias:-0.015760497825493266, loss:0.7075190024807606\n",
      "epoch:7, weight:[0.99604764 0.99183336], bias:-0.01798956830332102, loss:0.7068941860984489\n",
      "epoch:8, weight:[0.9955636 0.9908282], bias:-0.020213054073245, loss:0.7062727813711064\n",
      "epoch:9, weight:[0.99508177 0.9898265 ], bias:-0.022430962802840876, loss:0.7056547744046482\n",
      "epoch:10, weight:[0.99460215 0.98882828], bias:-0.024643302213068055, loss:0.7050401513045004\n",
      "epoch:11, weight:[0.99412473 0.98783351], bias:-0.026850080077821113, loss:0.7044288981762432\n",
      "epoch:12, weight:[0.99364952 0.98684221], bias:-0.029051304223480342, loss:0.7038210011262495\n",
      "epoch:13, weight:[0.99317651 0.98585437], bias:-0.03124698252846151, loss:0.7032164462623174\n",
      "epoch:14, weight:[0.9927057  0.98486999], bias:-0.03343712292276484, loss:0.7026152196943014\n",
      "epoch:15, weight:[0.99223709 0.98388906], bias:-0.03562173338752331, loss:0.7020173075347361\n",
      "epoch:16, weight:[0.99177067 0.98291157], bias:-0.03780082195455023, loss:0.7014226958994565\n",
      "epoch:17, weight:[0.99130643 0.98193753], bias:-0.03997439670588627, loss:0.7008313709082156\n",
      "epoch:18, weight:[0.99084439 0.98096694], bias:-0.042142465773345836, loss:0.700243318685294\n",
      "epoch:19, weight:[0.99038452 0.97999978], bias:-0.04430503733806299, loss:0.6996585253601076\n",
      "epoch:20, weight:[0.98992684 0.97903606], bias:-0.04646211963003683, loss:0.6990769770678098\n",
      "epoch:21, weight:[0.98947134 0.97807578], bias:-0.04861372092767645, loss:0.6984986599498891\n",
      "epoch:22, weight:[0.98901801 0.97711892], bias:-0.050759849557345506, loss:0.6979235601547609\n",
      "epoch:23, weight:[0.98856685 0.97616549], bias:-0.05290051389290646, loss:0.6973516638383569\n",
      "epoch:24, weight:[0.98811785 0.97521547], bias:-0.05503572235526446, loss:0.6967829571647078\n",
      "epoch:25, weight:[0.98767103 0.97426888], bias:-0.057165483411911, loss:0.6962174263065225\n",
      "epoch:26, weight:[0.98722636 0.9733257 ], bias:-0.05928980557646737, loss:0.6956550574457601\n",
      "epoch:27, weight:[0.98678386 0.97238593], bias:-0.06140869740822787, loss:0.6950958367742014\n",
      "epoch:28, weight:[0.9863435  0.97144956], bias:-0.063522167511703, loss:0.69453975049401\n",
      "epoch:29, weight:[0.9859053 0.9705166], bias:-0.06563022453616243, loss:0.6939867848182939\n",
      "epoch:30, weight:[0.98546925 0.96958704], bias:-0.06773287717517802, loss:0.6934369259716588\n",
      "epoch:31, weight:[0.98503535 0.96866087], bias:-0.06983013416616679, loss:0.6928901601907568\n",
      "epoch:32, weight:[0.98460358 0.9677381 ], bias:-0.07192200428993396, loss:0.692346473724831\n",
      "epoch:33, weight:[0.98417396 0.96681871], bias:-0.07400849637021605, loss:0.6918058528362555\n",
      "epoch:34, weight:[0.98374647 0.9659027 ], bias:-0.07608961927322401, loss:0.6912682838010689\n",
      "epoch:35, weight:[0.98332111 0.96499007], bias:-0.07816538190718672, loss:0.6907337529095036\n",
      "epoch:36, weight:[0.98289789 0.96408082], bias:-0.08023579322189446, loss:0.690202246466511\n",
      "epoch:37, weight:[0.98247678 0.96317494], bias:-0.08230086220824277, loss:0.689673750792279\n",
      "epoch:38, weight:[0.9820578  0.96227242], bias:-0.08436059789777652, loss:0.6891482522227479\n",
      "epoch:39, weight:[0.98164094 0.96137326], bias:-0.08641500936223429, loss:0.6886257371101183\n",
      "epoch:40, weight:[0.98122619 0.96047746], bias:-0.08846410571309318, loss:0.6881061918233548\n",
      "epoch:41, weight:[0.98081356 0.95958502], bias:-0.09050789610111391, loss:0.6875896027486861\n",
      "epoch:42, weight:[0.98040303 0.95869592], bias:-0.09254638971588643, loss:0.6870759562900971\n",
      "epoch:43, weight:[0.97999461 0.95781017], bias:-0.09457959578537596, loss:0.6865652388698186\n",
      "epoch:44, weight:[0.97958829 0.95692776], bias:-0.09660752357546955, loss:0.68605743692881\n",
      "epoch:45, weight:[0.97918406 0.95604868], bias:-0.09863018238952317, loss:0.6855525369272379\n",
      "epoch:46, weight:[0.97878193 0.95517294], bias:-0.10064758156790943, loss:0.6850505253449485\n",
      "epoch:47, weight:[0.97838189 0.95430052], bias:-0.10265973048756578, loss:0.6845513886819368\n",
      "epoch:48, weight:[0.97798394 0.95343142], bias:-0.10466663856154357, loss:0.6840551134588074\n",
      "epoch:49, weight:[0.97758807 0.95256564], bias:-0.10666831523855756, loss:0.6835616862172337\n",
      "epoch:50, weight:[0.97719428 0.95170317], bias:-0.10866477000253635, loss:0.6830710935204094\n",
      "epoch:51, weight:[0.97680257 0.95084401], bias:-0.11065601237217347, loss:0.6825833219534952\n",
      "epoch:52, weight:[0.97641293 0.94998816], bias:-0.11264205190047921, loss:0.6820983581240623\n",
      "epoch:53, weight:[0.97602536 0.9491356 ], bias:-0.1146228981743334, loss:0.6816161886625267\n",
      "epoch:54, weight:[0.97563985 0.94828633], bias:-0.11659856081403892, loss:0.6811368002225829\n",
      "epoch:55, weight:[0.97525641 0.94744035], bias:-0.1185690494728762, loss:0.6806601794816293\n",
      "epoch:56, weight:[0.97487502 0.94659766], bias:-0.12053437383665856, loss:0.6801863131411888\n",
      "epoch:57, weight:[0.97449568 0.94575825], bias:-0.12249454362328852, loss:0.6797151879273255\n",
      "epoch:58, weight:[0.9741184 0.9449221], bias:-0.12444956858231511, loss:0.6792467905910556\n",
      "epoch:59, weight:[0.97374316 0.94408923], bias:-0.12639945849449222, loss:0.6787811079087517\n",
      "epoch:60, weight:[0.97336997 0.94325962], bias:-0.12834422317133792, loss:0.6783181266825439\n",
      "epoch:61, weight:[0.97299882 0.94243327], bias:-0.13028387245469492, loss:0.6778578337407153\n",
      "epoch:62, weight:[0.9726297  0.94161018], bias:-0.13221841621629207, loss:0.6774002159380907\n",
      "epoch:63, weight:[0.97226261 0.94079033], bias:-0.1341478643573071, loss:0.6769452601564231\n",
      "epoch:64, weight:[0.97189755 0.93997372], bias:-0.13607222680793035, loss:0.6764929533047712\n",
      "epoch:65, weight:[0.97153451 0.93916035], bias:-0.1379915135269299, loss:0.676043282319876\n",
      "epoch:66, weight:[0.9711735  0.93835022], bias:-0.1399057345012177, loss:0.6755962341665279\n",
      "epoch:67, weight:[0.9708145  0.93754331], bias:-0.14181489974541722, loss:0.675151795837933\n",
      "epoch:68, weight:[0.97045751 0.93673963], bias:-0.143719019301432, loss:0.6747099543560701\n",
      "epoch:69, weight:[0.97010253 0.93593916], bias:-0.14561810323801583, loss:0.6742706967720457\n",
      "epoch:70, weight:[0.96974955 0.93514191], bias:-0.14751216165034417, loss:0.6738340101664425\n",
      "epoch:71, weight:[0.96939858 0.93434786], bias:-0.14940120465958684, loss:0.6733998816496635\n",
      "epoch:72, weight:[0.9690496  0.93355701], bias:-0.15128524241248206, loss:0.672968298362269\n",
      "epoch:73, weight:[0.96870262 0.93276936], bias:-0.15316428508091207, loss:0.6725392474753118\n",
      "epoch:74, weight:[0.96835762 0.93198489], bias:-0.15503834286148005, loss:0.6721127161906647\n",
      "epoch:75, weight:[0.96801461 0.93120362], bias:-0.15690742597508853, loss:0.6716886917413443\n",
      "epoch:76, weight:[0.96767358 0.93042552], bias:-0.15877154466651916, loss:0.6712671613918284\n",
      "epoch:77, weight:[0.96733452 0.92965059], bias:-0.16063070920401423, loss:0.6708481124383708\n",
      "epoch:78, weight:[0.96699744 0.92887884], bias:-0.16248492987885946, loss:0.6704315322093081\n",
      "epoch:79, weight:[0.96666233 0.92811024], bias:-0.16433421700496842, loss:0.6700174080653636\n",
      "epoch:80, weight:[0.96632919 0.9273448 ], bias:-0.1661785809184686, loss:0.6696057273999457\n",
      "epoch:81, weight:[0.965998   0.92658252], bias:-0.16801803197728898, loss:0.6691964776394415\n",
      "epoch:82, weight:[0.96566878 0.92582337], bias:-0.1698525805607492, loss:0.6687896462435043\n",
      "epoch:83, weight:[0.9653415  0.92506737], bias:-0.1716822370691504, loss:0.6683852207053382\n",
      "epoch:84, weight:[0.96501617 0.92431451], bias:-0.17350701192336768, loss:0.6679831885519761\n",
      "epoch:85, weight:[0.96469279 0.92356477], bias:-0.1753269155644443, loss:0.6675835373445534\n",
      "epoch:86, weight:[0.96437135 0.92281815], bias:-0.17714195845318748, loss:0.6671862546785771\n",
      "epoch:87, weight:[0.96405185 0.92207465], bias:-0.17895215106976592, loss:0.6667913281841898\n",
      "epoch:88, weight:[0.96373428 0.92133426], bias:-0.18075750391330916, loss:0.6663987455264286\n",
      "epoch:89, weight:[0.96341864 0.92059698], bias:-0.18255802750150857, loss:0.6660084944054808\n",
      "epoch:90, weight:[0.96310492 0.91986279], bias:-0.18435373237022004, loss:0.6656205625569313\n",
      "epoch:91, weight:[0.96279312 0.9191317 ], bias:-0.18614462907306872, loss:0.6652349377520096\n",
      "epoch:92, weight:[0.96248324 0.9184037 ], bias:-0.18793072818105527, loss:0.6648516077978288\n",
      "epoch:93, weight:[0.96217528 0.91767878], bias:-0.1897120402821641, loss:0.6644705605376213\n",
      "epoch:94, weight:[0.96186922 0.91695693], bias:-0.19148857598097335, loss:0.6640917838509703\n",
      "epoch:95, weight:[0.96156506 0.91623816], bias:-0.19326034589826682, loss:0.663715265654035\n",
      "epoch:96, weight:[0.9612628  0.91552244], bias:-0.19502736067064766, loss:0.6633409938997725\n",
      "epoch:97, weight:[0.96096244 0.91480979], bias:-0.19678963095015398, loss:0.6629689565781548\n",
      "epoch:98, weight:[0.96066398 0.91410018], bias:-0.19854716740387637, loss:0.662599141716381\n",
      "epoch:99, weight:[0.96036739 0.91339363], bias:-0.20029998071357738, loss:0.6622315373790851\n",
      "epoch:100, weight:[0.9600727  0.91269011], bias:-0.20204808157531276, loss:0.6618661316685395\n",
      "epoch:101, weight:[0.95977988 0.91198962], bias:-0.2037914806990548, loss:0.661502912724853\n",
      "epoch:102, weight:[0.95948893 0.91129216], bias:-0.20553018880831755, loss:0.6611418687261663\n",
      "epoch:103, weight:[0.95919986 0.91059773], bias:-0.20726421663978403, loss:0.6607829878888407\n",
      "epoch:104, weight:[0.95891265 0.90990631], bias:-0.20899357494293538, loss:0.6604262584676442\n",
      "epoch:105, weight:[0.95862731 0.90921789], bias:-0.21071827447968206, loss:0.660071668755932\n",
      "epoch:106, weight:[0.95834382 0.90853248], bias:-0.21243832602399693, loss:0.6597192070858239\n",
      "epoch:107, weight:[0.95806219 0.90785007], bias:-0.21415374036155052, loss:0.6593688618283757\n",
      "epoch:108, weight:[0.9577824  0.90717064], bias:-0.21586452828934816, loss:0.6590206213937482\n",
      "epoch:109, weight:[0.95750447 0.9064942 ], bias:-0.21757070061536923, loss:0.6586744742313704\n",
      "epoch:110, weight:[0.95722837 0.90582074], bias:-0.2192722681582085, loss:0.6583304088300987\n",
      "epoch:111, weight:[0.95695411 0.90515025], bias:-0.2209692417467193, loss:0.657988413718373\n",
      "epoch:112, weight:[0.95668168 0.90448273], bias:-0.22266163221965915, loss:0.6576484774643672\n",
      "epoch:113, weight:[0.95641109 0.90381816], bias:-0.224349450425337, loss:0.6573105886761362\n",
      "epoch:114, weight:[0.95614231 0.90315654], bias:-0.2260327072212629, loss:0.6569747360017595\n",
      "epoch:115, weight:[0.95587536 0.90249787], bias:-0.22771141347379964, loss:0.6566409081294786\n",
      "epoch:116, weight:[0.95561022 0.90184215], bias:-0.22938558005781648, loss:0.6563090937878322\n",
      "epoch:117, weight:[0.95534689 0.90118935], bias:-0.23105521785634503, loss:0.6559792817457879\n",
      "epoch:118, weight:[0.95508537 0.90053948], bias:-0.23272033776023715, loss:0.6556514608128666\n",
      "epoch:119, weight:[0.95482566 0.89989253], bias:-0.2343809506678251, loss:0.6553256198392682\n",
      "epoch:120, weight:[0.95456774 0.8992485 ], bias:-0.2360370674845838, loss:0.6550017477159865\n",
      "epoch:121, weight:[0.95431161 0.89860737], bias:-0.23768869912279508, loss:0.6546798333749279\n",
      "epoch:122, weight:[0.95405728 0.89796915], bias:-0.23933585650121425, loss:0.6543598657890191\n",
      "epoch:123, weight:[0.95380473 0.89733382], bias:-0.2409785505447388, loss:0.6540418339723161\n",
      "epoch:124, weight:[0.95355396 0.89670138], bias:-0.24261679218407908, loss:0.653725726980107\n",
      "epoch:125, weight:[0.95330497 0.89607182], bias:-0.24425059235543145, loss:0.6534115339090117\n",
      "epoch:126, weight:[0.95305776 0.89544513], bias:-0.24587996200015325, loss:0.6530992438970766\n",
      "epoch:127, weight:[0.95281231 0.89482132], bias:-0.2475049120644402, loss:0.6527888461238679\n",
      "epoch:128, weight:[0.95256863 0.89420036], bias:-0.24912545349900583, loss:0.6524803298105594\n",
      "epoch:129, weight:[0.9523267  0.89358227], bias:-0.2507415972587632, loss:0.6521736842200165\n",
      "epoch:130, weight:[0.95208653 0.89296702], bias:-0.25235335430250877, loss:0.651868898656879\n",
      "epoch:131, weight:[0.95184812 0.89235461], bias:-0.2539607355926083, loss:0.6515659624676367\n",
      "epoch:132, weight:[0.95161145 0.89174504], bias:-0.25556375209468524, loss:0.6512648650407047\n",
      "epoch:133, weight:[0.95137652 0.8911383 ], bias:-0.257162414777311, loss:0.6509655958064932\n",
      "epoch:134, weight:[0.95114333 0.89053438], bias:-0.25875673461169774, loss:0.6506681442374735\n",
      "epoch:135, weight:[0.95091187 0.88993328], bias:-0.260346722571393, loss:0.6503724998482444\n",
      "epoch:136, weight:[0.95068215 0.88933499], bias:-0.26193238963197696, loss:0.6500786521955881\n",
      "epoch:137, weight:[0.95045415 0.8887395 ], bias:-0.2635137467707614, loss:0.6497865908785309\n",
      "epoch:138, weight:[0.95022787 0.88814681], bias:-0.26509080496649123, loss:0.6494963055383933\n",
      "epoch:139, weight:[0.95000331 0.88755691], bias:-0.2666635751990482, loss:0.6492077858588421\n",
      "epoch:140, weight:[0.94978046 0.88696979], bias:-0.26823206844915676, loss:0.6489210215659362\n",
      "epoch:141, weight:[0.94955932 0.88638545], bias:-0.26979629569809194, loss:0.6486360024281702\n",
      "epoch:142, weight:[0.94933988 0.88580387], bias:-0.2713562679273898, loss:0.648352718256514\n",
      "epoch:143, weight:[0.94912214 0.88522506], bias:-0.2729119961185598, loss:0.6480711589044511\n",
      "epoch:144, weight:[0.9489061  0.88464901], bias:-0.27446349125279956, loss:0.6477913142680115\n",
      "epoch:145, weight:[0.94869174 0.88407571], bias:-0.27601076431071164, loss:0.6475131742858028\n",
      "epoch:146, weight:[0.94847908 0.88350515], bias:-0.2775538262720228, loss:0.6472367289390376\n",
      "epoch:147, weight:[0.94826809 0.88293732], bias:-0.27909268811530524, loss:0.6469619682515583\n",
      "epoch:148, weight:[0.94805879 0.88237223], bias:-0.2806273608177002, loss:0.6466888822898592\n",
      "epoch:149, weight:[0.94785115 0.88180986], bias:-0.28215785535464344, loss:0.6464174611631036\n",
      "epoch:150, weight:[0.94764519 0.8812502 ], bias:-0.2836841826995936, loss:0.6461476950231416\n",
      "epoch:151, weight:[0.94744089 0.88069326], bias:-0.285206353823762, loss:0.6458795740645201\n",
      "epoch:152, weight:[0.94723825 0.88013901], bias:-0.2867243796958452, loss:0.6456130885244956\n",
      "epoch:153, weight:[0.94703727 0.87958747], bias:-0.2882382712817594, loss:0.6453482286830391\n",
      "epoch:154, weight:[0.94683794 0.87903861], bias:-0.28974803954437733, loss:0.6450849848628405\n",
      "epoch:155, weight:[0.94664025 0.87849243], bias:-0.2912536954432672, loss:0.6448233474293105\n",
      "epoch:156, weight:[0.94644421 0.87794893], bias:-0.2927552499344337, loss:0.6445633067905793\n",
      "epoch:157, weight:[0.94624981 0.8774081 ], bias:-0.29425271397006153, loss:0.6443048533974918\n",
      "epoch:158, weight:[0.94605704 0.87686993], bias:-0.29574609849826083, loss:0.6440479777436012\n",
      "epoch:159, weight:[0.9458659  0.87633442], bias:-0.29723541446281493, loss:0.6437926703651596\n",
      "epoch:160, weight:[0.94567639 0.87580155], bias:-0.29872067280293024, loss:0.6435389218411053\n",
      "epoch:161, weight:[0.9454885  0.87527133], bias:-0.30020188445298834, loss:0.6432867227930484\n",
      "epoch:162, weight:[0.94530222 0.87474374], bias:-0.30167906034230024, loss:0.6430360638852544\n",
      "epoch:163, weight:[0.94511756 0.87421878], bias:-0.3031522113948628, loss:0.6427869358246225\n",
      "epoch:164, weight:[0.94493451 0.87369644], bias:-0.3046213485291174, loss:0.6425393293606654\n",
      "epoch:165, weight:[0.94475306 0.87317672], bias:-0.30608648265771055, loss:0.6422932352854827\n",
      "epoch:166, weight:[0.94457321 0.8726596 ], bias:-0.307547624687257, loss:0.6420486444337347\n",
      "epoch:167, weight:[0.94439495 0.87214508], bias:-0.3090047855181047, loss:0.6418055476826127\n",
      "epoch:168, weight:[0.94421829 0.87163316], bias:-0.310457976044102, loss:0.6415639359518066\n",
      "epoch:169, weight:[0.94404321 0.87112383], bias:-0.31190720715236736, loss:0.6413238002034711\n",
      "epoch:170, weight:[0.94386972 0.87061708], bias:-0.31335248972306023, loss:0.6410851314421886\n",
      "epoch:171, weight:[0.9436978 0.8701129], bias:-0.31479383462915533, loss:0.6408479207149301\n",
      "epoch:172, weight:[0.94352746 0.86961128], bias:-0.31623125273621805, loss:0.6406121591110151\n",
      "epoch:173, weight:[0.94335869 0.86911223], bias:-0.3176647549021825, loss:0.6403778377620667\n",
      "epoch:174, weight:[0.94319148 0.86861573], bias:-0.31909435197713154, loss:0.6401449478419675\n",
      "epoch:175, weight:[0.94302583 0.86812178], bias:-0.32052005480307894, loss:0.6399134805668102\n",
      "epoch:176, weight:[0.94286174 0.86763036], bias:-0.3219418742137534, loss:0.6396834271948497\n",
      "epoch:177, weight:[0.9426992  0.86714148], bias:-0.3233598210343853, loss:0.6394547790264496\n",
      "epoch:178, weight:[0.94253821 0.86665513], bias:-0.3247739060814948, loss:0.6392275274040289\n",
      "epoch:179, weight:[0.94237876 0.86617129], bias:-0.3261841401626825, loss:0.6390016637120054\n",
      "epoch:180, weight:[0.94222085 0.86568997], bias:-0.3275905340764219, loss:0.6387771793767386\n",
      "epoch:181, weight:[0.94206448 0.86521115], bias:-0.32899309861185444, loss:0.6385540658664685\n",
      "epoch:182, weight:[0.94190963 0.86473483], bias:-0.3303918445485859, loss:0.6383323146912544\n",
      "epoch:183, weight:[0.94175632 0.864261  ], bias:-0.3317867826564853, loss:0.638111917402911\n",
      "epoch:184, weight:[0.94160452 0.86378966], bias:-0.33317792369548593, loss:0.6378928655949422\n",
      "epoch:185, weight:[0.94145425 0.86332079], bias:-0.33456527841538797, loss:0.6376751509024735\n",
      "epoch:186, weight:[0.94130548 0.8628544 ], bias:-0.3359488575556638, loss:0.6374587650021833\n",
      "epoch:187, weight:[0.94115823 0.86239047], bias:-0.3373286718452646, loss:0.6372436996122303\n",
      "epoch:188, weight:[0.94101248 0.86192899], bias:-0.33870473200242973, loss:0.6370299464921813\n",
      "epoch:189, weight:[0.94086823 0.86146997], bias:-0.34007704873449746, loss:0.6368174974429374\n",
      "epoch:190, weight:[0.94072548 0.8610134 ], bias:-0.34144563273771816, loss:0.6366063443066544\n",
      "epoch:191, weight:[0.94058422 0.86055926], bias:-0.3428104946970693, loss:0.6363964789666686\n",
      "epoch:192, weight:[0.94044445 0.86010755], bias:-0.3441716452860726, loss:0.636187893347414\n",
      "epoch:193, weight:[0.94030616 0.85965826], bias:-0.3455290951666127, loss:0.6359805794143417\n",
      "epoch:194, weight:[0.94016935 0.85921139], bias:-0.34688285498875854, loss:0.6357745291738368\n",
      "epoch:195, weight:[0.94003402 0.85876693], bias:-0.34823293539058614, loss:0.6355697346731349\n",
      "epoch:196, weight:[0.93990015 0.85832488], bias:-0.3495793469980035, loss:0.6353661880002337\n",
      "epoch:197, weight:[0.93976776 0.85788522], bias:-0.3509221004245776, loss:0.6351638812838067\n",
      "epoch:198, weight:[0.93963683 0.85744794], bias:-0.35226120627136304, loss:0.634962806693114\n",
      "epoch:199, weight:[0.93950735 0.85701306], bias:-0.35359667512673293, loss:0.6347629564379109\n",
      "epoch:200, weight:[0.93937933 0.85658054], bias:-0.3549285175662115, loss:0.6345643227683564\n",
      "epoch:201, weight:[0.93925276 0.8561504 ], bias:-0.3562567441523088, loss:0.6343668979749192\n",
      "epoch:202, weight:[0.93912763 0.85572262], bias:-0.35758136543435703, loss:0.6341706743882828\n",
      "epoch:203, weight:[0.93900395 0.85529719], bias:-0.3589023919483491, loss:0.6339756443792498\n",
      "epoch:204, weight:[0.9388817  0.85487412], bias:-0.36021983421677883, loss:0.6337818003586431\n",
      "epoch:205, weight:[0.93876088 0.85445338], bias:-0.3615337027484832, loss:0.633589134777208\n",
      "epoch:206, weight:[0.9386415  0.85403498], bias:-0.3628440080384863, loss:0.6333976401255114\n",
      "epoch:207, weight:[0.93852354 0.85361891], bias:-0.3641507605678455, loss:0.63320730893384\n",
      "epoch:208, weight:[0.93840699 0.85320516], bias:-0.3654539708034988, loss:0.6330181337720983\n",
      "epoch:209, weight:[0.93829187 0.85279373], bias:-0.3667536491981147, loss:0.6328301072497046\n",
      "epoch:210, weight:[0.93817816 0.8523846 ], bias:-0.3680498061899438, loss:0.6326432220154841\n",
      "epoch:211, weight:[0.93806585 0.85197777], bias:-0.36934245220267176, loss:0.6324574707575651\n",
      "epoch:212, weight:[0.93795495 0.85157324], bias:-0.3706315976452745, loss:0.6322728462032697\n",
      "epoch:213, weight:[0.93784545 0.851171  ], bias:-0.37191725291187516, loss:0.632089341119006\n",
      "epoch:214, weight:[0.93773734 0.85077104], bias:-0.3731994283816028, loss:0.6319069483101583\n",
      "epoch:215, weight:[0.93763063 0.85037335], bias:-0.37447813441845285, loss:0.6317256606209756\n",
      "epoch:216, weight:[0.9375253  0.84997793], bias:-0.3757533813711493, loss:0.6315454709344607\n",
      "epoch:217, weight:[0.93742135 0.84958477], bias:-0.37702517957300874, loss:0.6313663721722569\n",
      "epoch:218, weight:[0.93731879 0.84919386], bias:-0.3782935393418064, loss:0.6311883572945347\n",
      "epoch:219, weight:[0.93721759 0.8488052 ], bias:-0.3795584709796433, loss:0.6310114192998757\n",
      "epoch:220, weight:[0.93711777 0.84841879], bias:-0.38081998477281587, loss:0.6308355512251578\n",
      "epoch:221, weight:[0.93701932 0.8480346 ], bias:-0.38207809099168677, loss:0.6306607461454384\n",
      "epoch:222, weight:[0.93692222 0.84765265], bias:-0.3833327998905576, loss:0.6304869971738365\n",
      "epoch:223, weight:[0.93682649 0.84727291], bias:-0.3845841217075433, loss:0.6303142974614139\n",
      "epoch:224, weight:[0.93673211 0.84689539], bias:-0.38583206666444864, loss:0.6301426401970563\n",
      "epoch:225, weight:[0.93663908 0.84652008], bias:-0.3870766449666455, loss:0.6299720186073531\n",
      "epoch:226, weight:[0.93654739 0.84614696], bias:-0.3883178668029528, loss:0.6298024259564747\n",
      "epoch:227, weight:[0.93645705 0.84577604], bias:-0.3895557423455175, loss:0.6296338555460532\n",
      "epoch:228, weight:[0.93636805 0.84540731], bias:-0.3907902817496974, loss:0.6294663007150578\n",
      "epoch:229, weight:[0.93628037 0.84504076], bias:-0.39202149515394563, loss:0.6292997548396713\n",
      "epoch:230, weight:[0.93619403 0.84467638], bias:-0.39324939267969694, loss:0.629134211333167\n",
      "epoch:231, weight:[0.93610902 0.84431417], bias:-0.3944739844312552, loss:0.6289696636457828\n",
      "epoch:232, weight:[0.93602532 0.84395412], bias:-0.39569528049568287, loss:0.6288061052645959\n",
      "epoch:233, weight:[0.93594294 0.84359623], bias:-0.396913290942692, loss:0.6286435297133962\n",
      "epoch:234, weight:[0.93586188 0.84324048], bias:-0.3981280258245368, loss:0.6284819305525601\n",
      "epoch:235, weight:[0.93578213 0.84288687], bias:-0.3993394951759078, loss:0.6283213013789205\n",
      "epoch:236, weight:[0.93570368 0.8425354 ], bias:-0.40054770901382736, loss:0.6281616358256419\n",
      "epoch:237, weight:[0.93562653 0.84218605], bias:-0.4017526773375474, loss:0.6280029275620888\n",
      "epoch:238, weight:[0.93555068 0.84183883], bias:-0.4029544101284479, loss:0.6278451702936962\n",
      "epoch:239, weight:[0.93547612 0.84149372], bias:-0.4041529173499375, loss:0.6276883577618422\n",
      "epoch:240, weight:[0.93540285 0.84115072], bias:-0.4053482089473554, loss:0.6275324837437137\n",
      "epoch:241, weight:[0.93533087 0.84080982], bias:-0.4065402948478747, loss:0.6273775420521776\n",
      "epoch:242, weight:[0.93526017 0.84047101], bias:-0.4077291849604075, loss:0.6272235265356485\n",
      "epoch:243, weight:[0.93519075 0.8401343 ], bias:-0.40891488917551144, loss:0.6270704310779557\n",
      "epoch:244, weight:[0.9351226  0.83979966], bias:-0.41009741736529753, loss:0.6269182495982119\n",
      "epoch:245, weight:[0.93505572 0.8394671 ], bias:-0.4112767793833398, loss:0.6267669760506783\n",
      "epoch:246, weight:[0.9349901  0.83913661], bias:-0.41245298506458605, loss:0.6266166044246323\n",
      "epoch:247, weight:[0.93492575 0.83880818], bias:-0.41362604422527044, loss:0.6264671287442332\n",
      "epoch:248, weight:[0.93486265 0.83848181], bias:-0.4147959666628272, loss:0.6263185430683863\n",
      "epoch:249, weight:[0.93480081 0.83815749], bias:-0.41596276215580597, loss:0.6261708414906102\n",
      "epoch:250, weight:[0.93474022 0.83783521], bias:-0.41712644046378866, loss:0.6260240181388996\n",
      "epoch:251, weight:[0.93468087 0.83751496], bias:-0.41828701132730745, loss:0.6258780671755908\n",
      "epoch:252, weight:[0.93462277 0.83719675], bias:-0.4194444844677644, loss:0.6257329827972244\n",
      "epoch:253, weight:[0.9345659  0.83688056], bias:-0.4205988695873525, loss:0.6255887592344107\n",
      "epoch:254, weight:[0.93451027 0.83656638], bias:-0.42175017636897794, loss:0.6254453907516914\n",
      "epoch:255, weight:[0.93445587 0.83625422], bias:-0.4228984144761839, loss:0.6253028716474028\n",
      "epoch:256, weight:[0.93440269 0.83594406], bias:-0.4240435935530758, loss:0.6251611962535395\n",
      "epoch:257, weight:[0.93435074 0.8356359 ], bias:-0.42518572322424747, loss:0.6250203589356156\n",
      "epoch:258, weight:[0.9343     0.83532973], bias:-0.42632481309470927, loss:0.6248803540925275\n",
      "epoch:259, weight:[0.93425048 0.83502554], bias:-0.4274608727498171, loss:0.6247411761564153\n",
      "epoch:260, weight:[0.93420217 0.83472334], bias:-0.428593911755203, loss:0.6246028195925253\n",
      "epoch:261, weight:[0.93415507 0.8344231 ], bias:-0.429723939656707, loss:0.62446527889907\n",
      "epoch:262, weight:[0.93410917 0.83412484], bias:-0.4308509659803101, loss:0.6243285486070906\n",
      "epoch:263, weight:[0.93406447 0.83382853], bias:-0.4319750002320688, loss:0.6241926232803173\n",
      "epoch:264, weight:[0.93402097 0.83353417], bias:-0.43309605189805095, loss:0.6240574975150305\n",
      "epoch:265, weight:[0.93397866 0.83324176], bias:-0.4342141304442725, loss:0.6239231659399208\n",
      "epoch:266, weight:[0.93393753 0.83295129], bias:-0.4353292453166359, loss:0.6237896232159502\n",
      "epoch:267, weight:[0.93389759 0.83266276], bias:-0.4364414059408698, loss:0.6236568640362122\n",
      "epoch:268, weight:[0.93385883 0.83237616], bias:-0.4375506217224695, loss:0.623524883125792\n",
      "epoch:269, weight:[0.93382125 0.83209147], bias:-0.4386569020466393, loss:0.623393675241626\n",
      "epoch:270, weight:[0.93378484 0.8318087 ], bias:-0.43976025627823556, loss:0.623263235172363\n",
      "epoch:271, weight:[0.9337496  0.83152784], bias:-0.4408606937617112, loss:0.6231335577382231\n",
      "epoch:272, weight:[0.93371552 0.83124889], bias:-0.4419582238210615, loss:0.6230046377908575\n",
      "epoch:273, weight:[0.93368261 0.83097182], bias:-0.4430528557597708, loss:0.6228764702132091\n",
      "epoch:274, weight:[0.93365085 0.83069665], bias:-0.44414459886076085, loss:0.6227490499193712\n",
      "epoch:275, weight:[0.93362025 0.83042337], bias:-0.44523346238633976, loss:0.6226223718544477\n",
      "epoch:276, weight:[0.9335908  0.83015196], bias:-0.44631945557815267, loss:0.6224964309944125\n",
      "epoch:277, weight:[0.93356249 0.82988243], bias:-0.4474025876571332, loss:0.622371222345969\n",
      "epoch:278, weight:[0.93353533 0.82961475], bias:-0.44848286782345625, loss:0.6222467409464097\n",
      "epoch:279, weight:[0.9335093  0.82934894], bias:-0.44956030525649193, loss:0.6221229818634763\n",
      "epoch:280, weight:[0.93348441 0.82908499], bias:-0.45063490911476045, loss:0.6219999401952178\n",
      "epoch:281, weight:[0.93346066 0.82882288], bias:-0.45170668853588836, loss:0.6218776110698515\n",
      "epoch:282, weight:[0.93343803 0.82856261], bias:-0.4527756526365658, loss:0.6217559896456225\n",
      "epoch:283, weight:[0.93341652 0.82830417], bias:-0.4538418105125048, loss:0.6216350711106623\n",
      "epoch:284, weight:[0.93339614 0.82804756], bias:-0.4549051712383988, loss:0.6215148506828497\n",
      "epoch:285, weight:[0.93337687 0.82779278], bias:-0.45596574386788313, loss:0.6213953236096695\n",
      "epoch:286, weight:[0.93335872 0.82753981], bias:-0.4570235374334966, loss:0.6212764851680735\n",
      "epoch:287, weight:[0.93334168 0.82728866], bias:-0.4580785609466443, loss:0.6211583306643391\n",
      "epoch:288, weight:[0.93332574 0.82703931], bias:-0.45913082339756106, loss:0.6210408554339303\n",
      "epoch:289, weight:[0.9333109  0.82679175], bias:-0.46018033375527656, loss:0.6209240548413569\n",
      "epoch:290, weight:[0.93329717 0.82654599], bias:-0.46122710096758096, loss:0.6208079242800361\n",
      "epoch:291, weight:[0.93328453 0.82630201], bias:-0.4622711339609918, loss:0.6206924591721509\n",
      "epoch:292, weight:[0.93327298 0.82605982], bias:-0.46331244164072166, loss:0.6205776549685127\n",
      "epoch:293, weight:[0.93326252 0.8258194 ], bias:-0.4643510328906474, loss:0.6204635071484196\n",
      "epoch:294, weight:[0.93325314 0.82558075], bias:-0.46538691657327974, loss:0.6203500112195187\n",
      "epoch:295, weight:[0.93324484 0.82534386], bias:-0.4664201015297342, loss:0.6202371627176668\n",
      "epoch:296, weight:[0.93323763 0.82510872], bias:-0.46745059657970295, loss:0.6201249572067911\n",
      "epoch:297, weight:[0.93323148 0.82487534], bias:-0.4684784105214277, loss:0.6200133902787495\n",
      "epoch:298, weight:[0.93322641 0.8246437 ], bias:-0.4695035521316733, loss:0.6199024575531937\n",
      "epoch:299, weight:[0.9332224 0.8244138], bias:-0.47052603016570266, loss:0.6197921546774302\n",
      "epoch:300, weight:[0.93321946 0.82418563], bias:-0.4715458533572524, loss:0.6196824773262809\n",
      "epoch:301, weight:[0.93321757 0.82395918], bias:-0.4725630304185094, loss:0.6195734212019466\n",
      "epoch:302, weight:[0.93321674 0.82373446], bias:-0.47357757004008827, loss:0.6194649820338681\n",
      "epoch:303, weight:[0.93321697 0.82351146], bias:-0.4745894808910101, loss:0.6193571555785888\n",
      "epoch:304, weight:[0.93321824 0.82329016], bias:-0.4755987716186816, loss:0.6192499376196179\n",
      "epoch:305, weight:[0.93322056 0.82307056], bias:-0.47660545084887534, loss:0.6191433239672919\n",
      "epoch:306, weight:[0.93322392 0.82285267], bias:-0.4776095271857112, loss:0.6190373104586392\n",
      "epoch:307, weight:[0.93322832 0.82263646], bias:-0.4786110092116382, loss:0.618931892957242\n",
      "epoch:308, weight:[0.93323376 0.82242194], bias:-0.4796099054874174, loss:0.618827067353101\n",
      "epoch:309, weight:[0.93324023 0.8222091 ], bias:-0.480606224552106, loss:0.6187228295624982\n",
      "epoch:310, weight:[0.93324772 0.82199793], bias:-0.4815999749230417, loss:0.6186191755278616\n",
      "epoch:311, weight:[0.93325624 0.82178843], bias:-0.4825911650958283, loss:0.6185161012176292\n",
      "epoch:312, weight:[0.93326578 0.8215806 ], bias:-0.48357980354432206, loss:0.6184136026261134\n",
      "epoch:313, weight:[0.93327634 0.82137442], bias:-0.48456589872061906, loss:0.618311675773367\n",
      "epoch:314, weight:[0.93328792 0.82116989], bias:-0.48554945905504293, loss:0.6182103167050463\n",
      "epoch:315, weight:[0.9333005  0.82096701], bias:-0.48653049295613393, loss:0.618109521492279\n",
      "epoch:316, weight:[0.9333141  0.82076576], bias:-0.48750900881063836, loss:0.6180092862315276\n",
      "epoch:317, weight:[0.93332869 0.82056615], bias:-0.4884850149834993, loss:0.6179096070444572\n",
      "epoch:318, weight:[0.93334429 0.82036817], bias:-0.4894585198178475, loss:0.617810480077801\n",
      "epoch:319, weight:[0.93336089 0.82017181], bias:-0.49042953163499375, loss:0.6177119015032273\n",
      "epoch:320, weight:[0.93337848 0.81997707], bias:-0.4913980587344215, loss:0.6176138675172061\n",
      "epoch:321, weight:[0.93339706 0.81978393], bias:-0.49236410939378034, loss:0.6175163743408772\n",
      "epoch:322, weight:[0.93341663 0.81959241], bias:-0.49332769186888054, loss:0.6174194182199165\n",
      "epoch:323, weight:[0.93343718 0.81940248], bias:-0.49428881439368805, loss:0.617322995424406\n",
      "epoch:324, weight:[0.93345872 0.81921415], bias:-0.4952474851803203, loss:0.6172271022486996\n",
      "epoch:325, weight:[0.93348123 0.8190274 ], bias:-0.49620371241904276, loss:0.6171317350112941\n",
      "epoch:326, weight:[0.93350472 0.81884224], bias:-0.49715750427826627, loss:0.6170368900546969\n",
      "epoch:327, weight:[0.93352918 0.81865866], bias:-0.4981088689045451, loss:0.6169425637452955\n",
      "epoch:328, weight:[0.9335546  0.81847665], bias:-0.4990578144225756, loss:0.6168487524732277\n",
      "epoch:329, weight:[0.93358099 0.8182962 ], bias:-0.5000043489351956, loss:0.6167554526522511\n",
      "epoch:330, weight:[0.93360834 0.81811731], bias:-0.5009484805233849, loss:0.6166626607196138\n",
      "epoch:331, weight:[0.93363665 0.81793998], bias:-0.5018902172462655, loss:0.6165703731359264\n",
      "epoch:332, weight:[0.93366591 0.8177642 ], bias:-0.5028295671411036, loss:0.6164785863850305\n",
      "epoch:333, weight:[0.93369613 0.81758997], bias:-0.5037665382233116, loss:0.6163872969738726\n",
      "epoch:334, weight:[0.93372729 0.81741727], bias:-0.5047011384864512, loss:0.6162965014323758\n",
      "epoch:335, weight:[0.9337594  0.81724611], bias:-0.5056333759022363, loss:0.6162061963133109\n",
      "epoch:336, weight:[0.93379245 0.81707647], bias:-0.5065632584205382, loss:0.6161163781921701\n",
      "epoch:337, weight:[0.93382643 0.81690836], bias:-0.5074907939693892, loss:0.6160270436670403\n",
      "epoch:338, weight:[0.93386136 0.81674176], bias:-0.5084159904549892, loss:0.6159381893584762\n",
      "epoch:339, weight:[0.93389721 0.81657668], bias:-0.509338855761711, loss:0.6158498119093742\n",
      "epoch:340, weight:[0.93393399 0.8164131 ], bias:-0.5102593977521075, loss:0.6157619079848463\n",
      "epoch:341, weight:[0.9339717  0.81625102], bias:-0.5111776242669188, loss:0.615674474272097\n",
      "epoch:342, weight:[0.93401034 0.81609044], bias:-0.5120935431250803, loss:0.6155875074802953\n",
      "epoch:343, weight:[0.93404989 0.81593135], bias:-0.513007162123731, loss:0.6155010043404524\n",
      "epoch:344, weight:[0.93409035 0.81577374], bias:-0.5139184890382231, loss:0.6154149616052974\n",
      "epoch:345, weight:[0.93413173 0.81561761], bias:-0.5148275316221315, loss:0.6153293760491529\n",
      "epoch:346, weight:[0.93417402 0.81546296], bias:-0.5157342976072639, loss:0.6152442444678128\n",
      "epoch:347, weight:[0.93421722 0.81530977], bias:-0.5166387947036721, loss:0.6151595636784187\n",
      "epoch:348, weight:[0.93426132 0.81515805], bias:-0.5175410305996637, loss:0.6150753305193383\n",
      "epoch:349, weight:[0.93430632 0.81500779], bias:-0.5184410129618132, loss:0.614991541850043\n",
      "epoch:350, weight:[0.93435222 0.81485897], bias:-0.5193387494349757, loss:0.6149081945509868\n",
      "epoch:351, weight:[0.93439901 0.81471161], bias:-0.5202342476422993, loss:0.6148252855234848\n",
      "epoch:352, weight:[0.9344467  0.81456569], bias:-0.5211275151852391, loss:0.6147428116895933\n",
      "epoch:353, weight:[0.93449527 0.81442121], bias:-0.5220185596435717, loss:0.6146607699919889\n",
      "epoch:354, weight:[0.93454473 0.81427816], bias:-0.5229073885754093, loss:0.6145791573938495\n",
      "epoch:355, weight:[0.93459506 0.81413653], bias:-0.5237940095172157, loss:0.6144979708787347\n",
      "epoch:356, weight:[0.93464628 0.81399633], bias:-0.5246784299838215, loss:0.6144172074504664\n",
      "epoch:357, weight:[0.93469838 0.81385754], bias:-0.5255606574684413, loss:0.6143368641330118\n",
      "epoch:358, weight:[0.93475134 0.81372017], bias:-0.5264406994426895, loss:0.6142569379703641\n",
      "epoch:359, weight:[0.93480518 0.8135842 ], bias:-0.5273185633565982, loss:0.614177426026426\n",
      "epoch:360, weight:[0.93485988 0.81344963], bias:-0.5281942566386353, loss:0.6140983253848923\n",
      "epoch:361, weight:[0.93491545 0.81331646], bias:-0.5290677866957221, loss:0.6140196331491331\n",
      "epoch:362, weight:[0.93497188 0.81318467], bias:-0.5299391609132527, loss:0.6139413464420781\n",
      "epoch:363, weight:[0.93502916 0.81305428], bias:-0.530808386655113, loss:0.613863462406101\n",
      "epoch:364, weight:[0.9350873  0.81292526], bias:-0.5316754712637006, loss:0.6137859782029037\n",
      "epoch:365, weight:[0.9351463  0.81279762], bias:-0.5325404220599449, loss:0.6137088910134026\n",
      "epoch:366, weight:[0.93520614 0.81267135], bias:-0.5334032463433277, loss:0.613632198037613\n",
      "epoch:367, weight:[0.93526682 0.81254645], bias:-0.5342639513919046, loss:0.6135558964945372\n",
      "epoch:368, weight:[0.93532835 0.81242291], bias:-0.5351225444623264, loss:0.6134799836220486\n",
      "epoch:369, weight:[0.93539072 0.81230072], bias:-0.535979032789861, loss:0.613404456676781\n",
      "epoch:370, weight:[0.93545393 0.81217988], bias:-0.5368334235884161, loss:0.6133293129340159\n",
      "epoch:371, weight:[0.93551797 0.81206039], bias:-0.5376857240505619, loss:0.6132545496875692\n",
      "epoch:372, weight:[0.93558285 0.81194224], bias:-0.5385359413475543, loss:0.6131801642496811\n",
      "epoch:373, weight:[0.93564855 0.81182543], bias:-0.539384082629359, loss:0.6131061539509052\n",
      "epoch:374, weight:[0.93571507 0.81170994], bias:-0.5402301550246753, loss:0.6130325161399964\n",
      "epoch:375, weight:[0.93578242 0.81159578], bias:-0.5410741656409607, loss:0.6129592481838025\n",
      "epoch:376, weight:[0.93585059 0.81148294], bias:-0.5419161215644558, loss:0.6128863474671543\n",
      "epoch:377, weight:[0.93591957 0.81137142], bias:-0.5427560298602099, loss:0.6128138113927561\n",
      "epoch:378, weight:[0.93598937 0.81126121], bias:-0.5435938975721064, loss:0.6127416373810768\n",
      "epoch:379, weight:[0.93605998 0.81115231], bias:-0.5444297317228892, loss:0.6126698228702424\n",
      "epoch:380, weight:[0.9361314 0.8110447], bias:-0.545263539314189, loss:0.6125983653159284\n",
      "epoch:381, weight:[0.93620363 0.8109384 ], bias:-0.5460953273265501, loss:0.612527262191252\n",
      "epoch:382, weight:[0.93627665 0.81083338], bias:-0.5469251027194578, loss:0.6124565109866654\n",
      "epoch:383, weight:[0.93635048 0.81072965], bias:-0.5477528724313661, loss:0.6123861092098507\n",
      "epoch:384, weight:[0.9364251  0.81062721], bias:-0.5485786433797253, loss:0.6123160543856124\n",
      "epoch:385, weight:[0.93650052 0.81052604], bias:-0.5494024224610108, loss:0.6122463440557736\n",
      "epoch:386, weight:[0.93657673 0.81042614], bias:-0.5502242165507514, loss:0.6121769757790699\n",
      "epoch:387, weight:[0.93665372 0.81032751], bias:-0.5510440325035583, loss:0.6121079471310469\n",
      "epoch:388, weight:[0.93673151 0.81023015], bias:-0.5518618771531548, loss:0.6120392557039535\n",
      "epoch:389, weight:[0.93681007 0.81013404], bias:-0.5526777573124058, loss:0.6119708991066418\n",
      "epoch:390, weight:[0.93688942 0.81003918], bias:-0.5534916797733475, loss:0.6119028749644618\n",
      "epoch:391, weight:[0.93696954 0.80994558], bias:-0.5543036513072183, loss:0.6118351809191602\n",
      "epoch:392, weight:[0.93705044 0.80985322], bias:-0.555113678664489, loss:0.6117678146287774\n",
      "epoch:393, weight:[0.93713211 0.8097621 ], bias:-0.5559217685748943, loss:0.6117007737675476\n",
      "epoch:394, weight:[0.93721455 0.80967221], bias:-0.5567279277474634, loss:0.6116340560257961\n",
      "epoch:395, weight:[0.93729775 0.80958355], bias:-0.5575321628705522, loss:0.6115676591098403\n",
      "epoch:396, weight:[0.93738172 0.80949612], bias:-0.558334480611875, loss:0.6115015807418887\n",
      "epoch:397, weight:[0.93746645 0.80940991], bias:-0.5591348876185365, loss:0.6114358186599413\n",
      "epoch:398, weight:[0.93755194 0.80932492], bias:-0.5599333905170646, loss:0.611370370617692\n",
      "epoch:399, weight:[0.93763818 0.80924114], bias:-0.560729995913443, loss:0.6113052343844275\n",
      "epoch:400, weight:[0.93772518 0.80915856], bias:-0.5615247103931441, loss:0.6112404077449316\n",
      "epoch:401, weight:[0.93781293 0.80907719], bias:-0.562317540521163, loss:0.6111758884993864\n",
      "epoch:402, weight:[0.93790142 0.80899701], bias:-0.5631084928420502, loss:0.6111116744632753\n",
      "epoch:403, weight:[0.93799066 0.80891803], bias:-0.5638975738799462, loss:0.6110477634672861\n",
      "epoch:404, weight:[0.93808064 0.80884024], bias:-0.5646847901386154, loss:0.6109841533572152\n",
      "epoch:405, weight:[0.93817136 0.80876363], bias:-0.5654701481014803, loss:0.6109208419938714\n",
      "epoch:406, weight:[0.93826282 0.8086882 ], bias:-0.5662536542316566, loss:0.610857827252982\n",
      "epoch:407, weight:[0.93835502 0.80861395], bias:-0.567035314971988, loss:0.6107951070250959\n",
      "epoch:408, weight:[0.93844794 0.80854087], bias:-0.567815136745081, loss:0.6107326792154909\n",
      "epoch:409, weight:[0.93854159 0.80846895], bias:-0.5685931259533409, loss:0.6106705417440792\n",
      "epoch:410, weight:[0.93863597 0.8083982 ], bias:-0.5693692889790071, loss:0.6106086925453144\n",
      "epoch:411, weight:[0.93873108 0.80832861], bias:-0.570143632184189, loss:0.6105471295680985\n",
      "epoch:412, weight:[0.93882691 0.80826016], bias:-0.5709161619109022, loss:0.6104858507756893\n",
      "epoch:413, weight:[0.93892345 0.80819287], bias:-0.5716868844811052, loss:0.6104248541456085\n",
      "epoch:414, weight:[0.93902071 0.80812672], bias:-0.5724558061967353, loss:0.6103641376695506\n",
      "epoch:415, weight:[0.93911869 0.80806171], bias:-0.573222933339746, loss:0.6103036993532914\n",
      "epoch:416, weight:[0.93921737 0.80799784], bias:-0.573988272172144, loss:0.6102435372165982\n",
      "epoch:417, weight:[0.93931677 0.80793509], bias:-0.5747518289360258, loss:0.6101836492931386\n",
      "epoch:418, weight:[0.93941687 0.80787348], bias:-0.5755136098536161, loss:0.6101240336303921\n",
      "epoch:419, weight:[0.93951767 0.80781298], bias:-0.5762736211273046, loss:0.6100646882895604\n",
      "epoch:420, weight:[0.93961918 0.80775361], bias:-0.5770318689396846, loss:0.6100056113454784\n",
      "epoch:421, weight:[0.93972138 0.80769535], bias:-0.5777883594535905, loss:0.609946800886527\n",
      "epoch:422, weight:[0.93982428 0.8076382 ], bias:-0.5785430988121364, loss:0.6098882550145442\n",
      "epoch:423, weight:[0.93992787 0.80758215], bias:-0.5792960931387542, loss:0.6098299718447392\n",
      "epoch:424, weight:[0.94003216 0.8075272 ], bias:-0.5800473485372328, loss:0.6097719495056038\n",
      "epoch:425, weight:[0.94013713 0.80747336], bias:-0.5807968710917565, loss:0.6097141861388278\n",
      "epoch:426, weight:[0.94024279 0.8074206 ], bias:-0.5815446668669438, loss:0.6096566798992126\n",
      "epoch:427, weight:[0.94034913 0.80736893], bias:-0.5822907419078873, loss:0.6095994289545849\n",
      "epoch:428, weight:[0.94045615 0.80731835], bias:-0.5830351022401925, loss:0.6095424314857124\n",
      "epoch:429, weight:[0.94056385 0.80726885], bias:-0.5837777538700174, loss:0.6094856856862201\n",
      "epoch:430, weight:[0.94067223 0.80722042], bias:-0.5845187027841122, loss:0.6094291897625048\n",
      "epoch:431, weight:[0.94078128 0.80717306], bias:-0.5852579549498595, loss:0.6093729419336525\n",
      "epoch:432, weight:[0.94089101 0.80712677], bias:-0.5859955163153139, loss:0.6093169404313546\n",
      "epoch:433, weight:[0.9410014  0.80708155], bias:-0.5867313928092422, loss:0.6092611834998258\n",
      "epoch:434, weight:[0.94111246 0.80703738], bias:-0.5874655903411642, loss:0.6092056693957214\n",
      "epoch:435, weight:[0.94122418 0.80699427], bias:-0.5881981148013926, loss:0.609150396388056\n",
      "epoch:436, weight:[0.94133656 0.80695221], bias:-0.588928972061074, loss:0.6090953627581214\n",
      "epoch:437, weight:[0.94144961 0.8069112 ], bias:-0.5896581679722294, loss:0.6090405667994064\n",
      "epoch:438, weight:[0.94156331 0.80687123], bias:-0.5903857083677956, loss:0.6089860068175162\n",
      "epoch:439, weight:[0.94167766 0.8068323 ], bias:-0.5911115990616657, loss:0.6089316811300928\n",
      "epoch:440, weight:[0.94179267 0.8067944 ], bias:-0.5918358458487306, loss:0.6088775880667339\n",
      "epoch:441, weight:[0.94190833 0.80675753], bias:-0.5925584545049204, loss:0.6088237259689154\n",
      "epoch:442, weight:[0.94202463 0.80672169], bias:-0.5932794307872457, loss:0.6087700931899126\n",
      "epoch:443, weight:[0.94214158 0.80668687], bias:-0.593998780433839, loss:0.6087166880947209\n",
      "epoch:444, weight:[0.94225918 0.80665307], bias:-0.5947165091639971, loss:0.6086635090599791\n",
      "epoch:445, weight:[0.94237741 0.80662029], bias:-0.595432622678222, loss:0.6086105544738912\n",
      "epoch:446, weight:[0.94249628 0.80658851], bias:-0.5961471266582635, loss:0.6085578227361502\n",
      "epoch:447, weight:[0.94261579 0.80655775], bias:-0.5968600267671612, loss:0.6085053122578613\n",
      "epoch:448, weight:[0.94273593 0.80652798], bias:-0.5975713286492863, loss:0.6084530214614658\n",
      "epoch:449, weight:[0.9428567  0.80649922], bias:-0.5982810379303843, loss:0.6084009487806656\n",
      "epoch:450, weight:[0.9429781  0.80647144], bias:-0.5989891602176173, loss:0.6083490926603475\n",
      "epoch:451, weight:[0.94310013 0.80644466], bias:-0.5996957010996062, loss:0.6082974515565098\n",
      "epoch:452, weight:[0.94322278 0.80641887], bias:-0.6004006661464738, loss:0.608246023936186\n",
      "epoch:453, weight:[0.94334606 0.80639406], bias:-0.601104060909887, loss:0.6081948082773724\n",
      "epoch:454, weight:[0.94346995 0.80637023], bias:-0.6018058909230999, loss:0.6081438030689544\n",
      "epoch:455, weight:[0.94359446 0.80634737], bias:-0.6025061617009967, loss:0.608093006810633\n",
      "epoch:456, weight:[0.94371959 0.80632548], bias:-0.6032048787401345, loss:0.6080424180128523\n",
      "epoch:457, weight:[0.94384533 0.80630457], bias:-0.6039020475187865, loss:0.6079920351967274\n",
      "epoch:458, weight:[0.94397168 0.80628461], bias:-0.604597673496985, loss:0.6079418568939725\n",
      "epoch:459, weight:[0.94409864 0.80626562], bias:-0.6052917621165649, loss:0.6078918816468298\n",
      "epoch:460, weight:[0.94422621 0.80624758], bias:-0.6059843188012067, loss:0.607842108007998\n",
      "epoch:461, weight:[0.94435438 0.80623049], bias:-0.6066753489564802, loss:0.6077925345405624\n",
      "epoch:462, weight:[0.94448315 0.80621436], bias:-0.6073648579698878, loss:0.6077431598179239\n",
      "epoch:463, weight:[0.94461252 0.80619916], bias:-0.6080528512109079, loss:0.6076939824237302\n",
      "epoch:464, weight:[0.94474249 0.80618491], bias:-0.608739334031039, loss:0.6076450009518063\n",
      "epoch:465, weight:[0.94487306 0.8061716 ], bias:-0.6094243117638427, loss:0.6075962140060845\n",
      "epoch:466, weight:[0.94500422 0.80615922], bias:-0.6101077897249882, loss:0.6075476202005377\n",
      "epoch:467, weight:[0.94513597 0.80614777], bias:-0.6107897732122956, loss:0.60749921815911\n",
      "epoch:468, weight:[0.94526831 0.80613724], bias:-0.6114702675057797, loss:0.6074510065156493\n",
      "epoch:469, weight:[0.94540123 0.80612764], bias:-0.6121492778676946, loss:0.6074029839138401\n",
      "epoch:470, weight:[0.94553475 0.80611895], bias:-0.6128268095425768, loss:0.6073551490071368\n",
      "epoch:471, weight:[0.94566884 0.80611118], bias:-0.6135028677572902, loss:0.6073075004586969\n",
      "epoch:472, weight:[0.94580351 0.80610433], bias:-0.6141774577210694, loss:0.6072600369413146\n",
      "epoch:473, weight:[0.94593876 0.80609838], bias:-0.614850584625564, loss:0.6072127571373562\n",
      "epoch:474, weight:[0.94607459 0.80609333], bias:-0.6155222536448832, loss:0.6071656597386936\n",
      "epoch:475, weight:[0.946211   0.80608919], bias:-0.6161924699356399, loss:0.6071187434466402\n",
      "epoch:476, weight:[0.94634797 0.80608594], bias:-0.6168612386369948, loss:0.6070720069718859\n",
      "epoch:477, weight:[0.94648551 0.80608358], bias:-0.617528564870701, loss:0.6070254490344331\n",
      "epoch:478, weight:[0.94662363 0.80608211], bias:-0.6181944537411479, loss:0.6069790683635332\n",
      "epoch:479, weight:[0.9467623  0.80608154], bias:-0.6188589103354063, loss:0.6069328636976226\n",
      "epoch:480, weight:[0.94690155 0.80608184], bias:-0.6195219397232723, loss:0.6068868337842604\n",
      "epoch:481, weight:[0.94704135 0.80608302], bias:-0.6201835469573121, loss:0.6068409773800659\n",
      "epoch:482, weight:[0.94718171 0.80608508], bias:-0.6208437370729065, loss:0.6067952932506553\n",
      "epoch:483, weight:[0.94732263 0.806088  ], bias:-0.6215025150882951, loss:0.6067497801705812\n",
      "epoch:484, weight:[0.94746411 0.8060918 ], bias:-0.6221598860046215, loss:0.6067044369232704\n",
      "epoch:485, weight:[0.94760614 0.80609646], bias:-0.6228158548059771, loss:0.6066592623009627\n",
      "epoch:486, weight:[0.94774872 0.80610199], bias:-0.6234704264594467, loss:0.6066142551046507\n",
      "epoch:487, weight:[0.94789185 0.80610837], bias:-0.6241236059151524, loss:0.6065694141440192\n",
      "epoch:488, weight:[0.94803552 0.8061156 ], bias:-0.6247753981062985, loss:0.6065247382373855\n",
      "epoch:489, weight:[0.94817975 0.80612369], bias:-0.6254258079492162, loss:0.6064802262116391\n",
      "epoch:490, weight:[0.94832451 0.80613262], bias:-0.6260748403434085, loss:0.6064358769021831\n",
      "epoch:491, weight:[0.94846982 0.8061424 ], bias:-0.6267225001715947, loss:0.6063916891528754\n",
      "epoch:492, weight:[0.94861567 0.80615302], bias:-0.6273687922997552, loss:0.6063476618159697\n",
      "epoch:493, weight:[0.94876205 0.80616447], bias:-0.6280137215771762, loss:0.6063037937520578\n",
      "epoch:494, weight:[0.94890897 0.80617676], bias:-0.6286572928364946, loss:0.6062600838300116\n",
      "epoch:495, weight:[0.94905642 0.80618988], bias:-0.629299510893743, loss:0.6062165309269261\n",
      "epoch:496, weight:[0.9492044  0.80620383], bias:-0.6299403805483939, loss:0.6061731339280612\n",
      "epoch:497, weight:[0.94935292 0.8062186 ], bias:-0.6305799065834047, loss:0.6061298917267867\n",
      "epoch:498, weight:[0.94950196 0.80623419], bias:-0.6312180937652629, loss:0.6060868032245248\n",
      "epoch:499, weight:[0.94965152 0.8062506 ], bias:-0.6318549468440307, loss:0.6060438673306942\n",
      "epoch:500, weight:[0.94980161 0.80626782], bias:-0.6324904705533893, loss:0.6060010829626546\n",
      "epoch:501, weight:[0.94995223 0.80628585], bias:-0.6331246696106844, loss:0.6059584490456514\n",
      "epoch:502, weight:[0.95010336 0.80630469], bias:-0.6337575487169707, loss:0.6059159645127613\n",
      "epoch:503, weight:[0.95025501 0.80632433], bias:-0.6343891125570565, loss:0.6058736283048367\n",
      "epoch:504, weight:[0.95040717 0.80634477], bias:-0.6350193657995491, loss:0.6058314393704521\n",
      "epoch:505, weight:[0.95055985 0.80636601], bias:-0.6356483130968988, loss:0.60578939666585\n",
      "epoch:506, weight:[0.95071304 0.80638804], bias:-0.6362759590854443, loss:0.6057474991548873\n",
      "epoch:507, weight:[0.95086675 0.80641086], bias:-0.636902308385457, loss:0.6057057458089824\n",
      "epoch:508, weight:[0.95102096 0.80643447], bias:-0.6375273656011863, loss:0.6056641356070616\n",
      "epoch:509, weight:[0.95117567 0.80645887], bias:-0.6381511353209037, loss:0.6056226675355072\n",
      "epoch:510, weight:[0.95133089 0.80648404], bias:-0.6387736221169482, loss:0.6055813405881052\n",
      "epoch:511, weight:[0.95148662 0.80651   ], bias:-0.6393948305457705, loss:0.605540153765993\n",
      "epoch:512, weight:[0.95164284 0.80653672], bias:-0.640014765147978, loss:0.6054991060776082\n",
      "epoch:513, weight:[0.95179957 0.80656422], bias:-0.6406334304483791, loss:0.6054581965386373\n",
      "epoch:514, weight:[0.95195679 0.80659249], bias:-0.6412508309560285, loss:0.6054174241719649\n",
      "epoch:515, weight:[0.95211451 0.80662152], bias:-0.6418669711642714, loss:0.6053767880076224\n",
      "epoch:516, weight:[0.95227272 0.80665132], bias:-0.642481855550788, loss:0.6053362870827391\n",
      "epoch:517, weight:[0.95243142 0.80668187], bias:-0.6430954885776385, loss:0.6052959204414912\n",
      "epoch:518, weight:[0.95259061 0.80671317], bias:-0.6437078746913076, loss:0.6052556871350523\n",
      "epoch:519, weight:[0.95275029 0.80674523], bias:-0.6443190183227487, loss:0.6052155862215444\n",
      "epoch:520, weight:[0.95291046 0.80677804], bias:-0.6449289238874288, loss:0.6051756167659886\n",
      "epoch:521, weight:[0.95307111 0.8068116 ], bias:-0.6455375957853728, loss:0.6051357778402577\n",
      "epoch:522, weight:[0.95323224 0.8068459 ], bias:-0.6461450384012082, loss:0.6050960685230253\n",
      "epoch:523, weight:[0.95339385 0.80688093], bias:-0.6467512561042091, loss:0.6050564878997204\n",
      "epoch:524, weight:[0.95355595 0.80691671], bias:-0.6473562532483412, loss:0.6050170350624784\n",
      "epoch:525, weight:[0.95371852 0.80695322], bias:-0.6479600341723057, loss:0.6049777091100936\n",
      "epoch:526, weight:[0.95388156 0.80699046], bias:-0.6485626031995838, loss:0.6049385091479721\n",
      "epoch:527, weight:[0.95404508 0.80702842], bias:-0.649163964638481, loss:0.6048994342880863\n",
      "epoch:528, weight:[0.95420908 0.80706711], bias:-0.6497641227821715, loss:0.6048604836489265\n",
      "epoch:529, weight:[0.95437354 0.80710653], bias:-0.6503630819087424, loss:0.6048216563554558\n",
      "epoch:530, weight:[0.95453847 0.80714666], bias:-0.6509608462812375, loss:0.6047829515390643\n",
      "epoch:531, weight:[0.95470387 0.8071875 ], bias:-0.651557420147702, loss:0.6047443683375227\n",
      "epoch:532, weight:[0.95486973 0.80722906], bias:-0.6521528077412265, loss:0.6047059058949379\n",
      "epoch:533, weight:[0.95503606 0.80727133], bias:-0.6527470132799909, loss:0.6046675633617079\n",
      "epoch:534, weight:[0.95520284 0.80731431], bias:-0.6533400409673084, loss:0.6046293398944763\n",
      "epoch:535, weight:[0.95537009 0.80735799], bias:-0.6539318949916697, loss:0.6045912346560889\n",
      "epoch:536, weight:[0.9555378  0.80740237], bias:-0.654522579526787, loss:0.6045532468155487\n",
      "epoch:537, weight:[0.95570596 0.80744745], bias:-0.6551120987316378, loss:0.6045153755479729\n",
      "epoch:538, weight:[0.95587458 0.80749322], bias:-0.6557004567505084, loss:0.604477620034549\n",
      "epoch:539, weight:[0.95604365 0.80753969], bias:-0.6562876577130383, loss:0.6044399794624912\n",
      "epoch:540, weight:[0.95621317 0.80758684], bias:-0.6568737057342638, loss:0.604402453024998\n",
      "epoch:541, weight:[0.95638314 0.80763468], bias:-0.6574586049146615, loss:0.6043650399212096\n",
      "epoch:542, weight:[0.95655356 0.80768321], bias:-0.658042359340192, loss:0.6043277393561648\n",
      "epoch:543, weight:[0.95672442 0.80773241], bias:-0.6586249730823438, loss:0.6042905505407593\n",
      "epoch:544, weight:[0.95689573 0.80778229], bias:-0.6592064501981767, loss:0.6042534726917044\n",
      "epoch:545, weight:[0.95706749 0.80783285], bias:-0.6597867947303652, loss:0.6042165050314839\n",
      "epoch:546, weight:[0.95723968 0.80788408], bias:-0.660366010707242, loss:0.6041796467883149\n",
      "epoch:547, weight:[0.95741232 0.80793597], bias:-0.6609441021428417, loss:0.6041428971961053\n",
      "epoch:548, weight:[0.95758539 0.80798854], bias:-0.6615210730369437, loss:0.6041062554944134\n",
      "epoch:549, weight:[0.9577589  0.80804177], bias:-0.6620969273751158, loss:0.6040697209284076\n",
      "epoch:550, weight:[0.95793284 0.80809565], bias:-0.6626716691287574, loss:0.6040332927488262\n",
      "epoch:551, weight:[0.95810722 0.8081502 ], bias:-0.6632453022551427, loss:0.6039969702119378\n",
      "epoch:552, weight:[0.95828203 0.8082054 ], bias:-0.6638178306974635, loss:0.6039607525795001\n",
      "epoch:553, weight:[0.95845727 0.80826125], bias:-0.6643892583848727, loss:0.6039246391187232\n",
      "epoch:554, weight:[0.95863294 0.80831775], bias:-0.6649595892325274, loss:0.6038886291022278\n",
      "epoch:555, weight:[0.95880903 0.8083749 ], bias:-0.6655288271416312, loss:0.6038527218080081\n",
      "epoch:556, weight:[0.95898555 0.80843269], bias:-0.6660969759994777, loss:0.6038169165193925\n",
      "epoch:557, weight:[0.9591625  0.80849113], bias:-0.6666640396794931, loss:0.6037812125250048\n",
      "epoch:558, weight:[0.95933986 0.8085502 ], bias:-0.6672300220412788, loss:0.6037456091187277\n",
      "epoch:559, weight:[0.95951765 0.80860991], bias:-0.6677949269306545, loss:0.603710105599663\n",
      "epoch:560, weight:[0.95969585 0.80867025], bias:-0.6683587581797005, loss:0.6036747012720953\n",
      "epoch:561, weight:[0.95987447 0.80873122], bias:-0.6689215196068004, loss:0.6036393954454545\n",
      "epoch:562, weight:[0.96005351 0.80879282], bias:-0.6694832150166835, loss:0.6036041874342783\n",
      "epoch:563, weight:[0.96023296 0.80885504], bias:-0.6700438482004675, loss:0.6035690765581756\n",
      "epoch:564, weight:[0.96041283 0.80891789], bias:-0.6706034229357005, loss:0.6035340621417903\n",
      "epoch:565, weight:[0.96059311 0.80898135], bias:-0.6711619429864039, loss:0.6034991435147645\n",
      "epoch:566, weight:[0.96077379 0.80904544], bias:-0.6717194121031137, loss:0.6034643200117021\n",
      "epoch:567, weight:[0.96095488 0.80911013], bias:-0.6722758340229238, loss:0.6034295909721343\n",
      "epoch:568, weight:[0.96113638 0.80917544], bias:-0.672831212469527, loss:0.6033949557404829\n",
      "epoch:569, weight:[0.96131829 0.80924136], bias:-0.673385551153258, loss:0.6033604136660243\n",
      "epoch:570, weight:[0.9615006  0.80930788], bias:-0.6739388537711348, loss:0.6033259641028568\n",
      "epoch:571, weight:[0.96168331 0.80937501], bias:-0.6744911240069006, loss:0.603291606409863\n",
      "epoch:572, weight:[0.96186642 0.80944274], bias:-0.6750423655310658, loss:0.603257339950677\n",
      "epoch:573, weight:[0.96204993 0.80951107], bias:-0.6755925820009498, loss:0.6032231640936495\n",
      "epoch:574, weight:[0.96223384 0.80957999], bias:-0.6761417770607226, loss:0.6031890782118129\n",
      "epoch:575, weight:[0.96241814 0.80964951], bias:-0.6766899543414463, loss:0.6031550816828487\n",
      "epoch:576, weight:[0.96260284 0.80971962], bias:-0.6772371174611166, loss:0.6031211738890531\n",
      "epoch:577, weight:[0.96278793 0.80979032], bias:-0.6777832700247046, loss:0.6030873542173028\n",
      "epoch:578, weight:[0.96297342 0.8098616 ], bias:-0.6783284156241979, loss:0.6030536220590235\n",
      "epoch:579, weight:[0.96315929 0.80993347], bias:-0.6788725578386419, loss:0.6030199768101551\n",
      "epoch:580, weight:[0.96334555 0.81000592], bias:-0.6794157002341812, loss:0.6029864178711203\n",
      "epoch:581, weight:[0.9635322  0.81007894], bias:-0.6799578463641006, loss:0.6029529446467916\n",
      "epoch:582, weight:[0.96371924 0.81015254], bias:-0.6804989997688664, loss:0.6029195565464578\n",
      "epoch:583, weight:[0.96390666 0.81022672], bias:-0.681039163976167, loss:0.6028862529837945\n",
      "epoch:584, weight:[0.96409446 0.81030146], bias:-0.6815783425009544, loss:0.602853033376829\n",
      "epoch:585, weight:[0.96428264 0.81037678], bias:-0.6821165388454844, loss:0.6028198971479118\n",
      "epoch:586, weight:[0.9644712  0.81045266], bias:-0.682653756499358, loss:0.6027868437236826\n",
      "epoch:587, weight:[0.96466015 0.8105291 ], bias:-0.6831899989395617, loss:0.6027538725350404\n",
      "epoch:588, weight:[0.96484947 0.8106061 ], bias:-0.6837252696305081, loss:0.6027209830171122\n",
      "epoch:589, weight:[0.96503916 0.81068367], bias:-0.6842595720240766, loss:0.602688174609222\n",
      "epoch:590, weight:[0.96522923 0.81076179], bias:-0.6847929095596541, loss:0.6026554467548607\n",
      "epoch:591, weight:[0.96541967 0.81084046], bias:-0.6853252856641747, loss:0.6026227989016554\n",
      "epoch:592, weight:[0.96561049 0.81091968], bias:-0.6858567037521607, loss:0.6025902305013383\n",
      "epoch:593, weight:[0.96580167 0.81099946], bias:-0.6863871672257622, loss:0.6025577410097189\n",
      "epoch:594, weight:[0.96599322 0.81107977], bias:-0.6869166794747978, loss:0.6025253298866523\n",
      "epoch:595, weight:[0.96618514 0.81116064], bias:-0.6874452438767943, loss:0.6024929965960107\n",
      "epoch:596, weight:[0.96637743 0.81124204], bias:-0.6879728637970266, loss:0.6024607406056532\n",
      "epoch:597, weight:[0.96657008 0.81132399], bias:-0.688499542588558, loss:0.6024285613873976\n",
      "epoch:598, weight:[0.96676309 0.81140647], bias:-0.6890252835922794, loss:0.6023964584169913\n",
      "epoch:599, weight:[0.96695647 0.81148948], bias:-0.6895500901369499, loss:0.6023644311740811\n",
      "epoch:600, weight:[0.96715021 0.81157303], bias:-0.6900739655392354, loss:0.6023324791421875\n",
      "epoch:601, weight:[0.9673443  0.81165711], bias:-0.6905969131037488, loss:0.6023006018086734\n",
      "epoch:602, weight:[0.96753875 0.81174172], bias:-0.6911189361230896, loss:0.6022687986647178\n",
      "epoch:603, weight:[0.96773356 0.81182685], bias:-0.6916400378778826, loss:0.6022370692052875\n",
      "epoch:604, weight:[0.96792873 0.8119125 ], bias:-0.692160221636818, loss:0.6022054129291091\n",
      "epoch:605, weight:[0.96812425 0.81199868], bias:-0.69267949065669, loss:0.6021738293386409\n",
      "epoch:606, weight:[0.96832012 0.81208537], bias:-0.6931978481824361, loss:0.6021423179400472\n",
      "epoch:607, weight:[0.96851634 0.81217258], bias:-0.6937152974471765, loss:0.6021108782431698\n",
      "epoch:608, weight:[0.96871291 0.8122603 ], bias:-0.6942318416722525, loss:0.6020795097615008\n",
      "epoch:609, weight:[0.96890983 0.81234853], bias:-0.6947474840672657, loss:0.6020482120121566\n",
      "epoch:610, weight:[0.9691071  0.81243728], bias:-0.6952622278301169, loss:0.6020169845158514\n",
      "epoch:611, weight:[0.96930471 0.81252653], bias:-0.6957760761470445, loss:0.6019858267968701\n",
      "epoch:612, weight:[0.96950267 0.81261628], bias:-0.6962890321926631, loss:0.601954738383042\n",
      "epoch:613, weight:[0.96970097 0.81270654], bias:-0.6968010991300025, loss:0.6019237188057164\n",
      "epoch:614, weight:[0.96989962 0.8127973 ], bias:-0.6973122801105456, loss:0.6018927675997335\n",
      "epoch:615, weight:[0.9700986  0.81288856], bias:-0.6978225782742669, loss:0.6018618843034029\n",
      "epoch:616, weight:[0.97029792 0.81298031], bias:-0.6983319967496708, loss:0.601831068458474\n",
      "epoch:617, weight:[0.97049758 0.81307255], bias:-0.6988405386538302, loss:0.6018003196101137\n",
      "epoch:618, weight:[0.97069758 0.81316529], bias:-0.6993482070924237, loss:0.6017696373068797\n",
      "epoch:619, weight:[0.97089792 0.81325852], bias:-0.6998550051597745, loss:0.6017390211006963\n",
      "epoch:620, weight:[0.97109858 0.81335223], bias:-0.7003609359388875, loss:0.6017084705468284\n",
      "epoch:621, weight:[0.97129959 0.81344643], bias:-0.7008660025014877, loss:0.6016779852038586\n",
      "epoch:622, weight:[0.97150092 0.81354111], bias:-0.7013702079080577, loss:0.6016475646336619\n",
      "epoch:623, weight:[0.97170258 0.81363627], bias:-0.7018735552078756, loss:0.6016172084013807\n",
      "epoch:624, weight:[0.97190458 0.81373191], bias:-0.7023760474390521, loss:0.6015869160754023\n",
      "epoch:625, weight:[0.9721069  0.81382803], bias:-0.7028776876285684, loss:0.6015566872273332\n",
      "epoch:626, weight:[0.97230954 0.81392462], bias:-0.7033784787923131, loss:0.6015265214319775\n",
      "epoch:627, weight:[0.97251252 0.81402168], bias:-0.70387842393512, loss:0.6014964182673107\n",
      "epoch:628, weight:[0.97271581 0.81411922], bias:-0.7043775260508051, loss:0.6014663773144585\n",
      "epoch:629, weight:[0.97291944 0.81421722], bias:-0.7048757881222034, loss:0.6014363981576722\n",
      "epoch:630, weight:[0.97312338 0.81431568], bias:-0.7053732131212066, loss:0.6014064803843066\n",
      "epoch:631, weight:[0.97332764 0.81441461], bias:-0.7058698040087992, loss:0.6013766235847962\n",
      "epoch:632, weight:[0.97353223 0.814514  ], bias:-0.7063655637350958, loss:0.6013468273526327\n",
      "epoch:633, weight:[0.97373713 0.81461386], bias:-0.7068604952393781, loss:0.6013170912843425\n",
      "epoch:634, weight:[0.97394234 0.81471416], bias:-0.7073546014501307, loss:0.6012874149794653\n",
      "epoch:635, weight:[0.97414788 0.81481493], bias:-0.7078478852850787, loss:0.6012577980405289\n",
      "epoch:636, weight:[0.97435373 0.81491614], bias:-0.7083403496512234, loss:0.6012282400730302\n",
      "epoch:637, weight:[0.97455989 0.81501781], bias:-0.7088319974448788, loss:0.601198740685412\n",
      "epoch:638, weight:[0.97476637 0.81511993], bias:-0.7093228315517083, loss:0.6011692994890406\n",
      "epoch:639, weight:[0.97497315 0.8152225 ], bias:-0.7098128548467604, loss:0.6011399160981848\n",
      "epoch:640, weight:[0.97518025 0.8153255 ], bias:-0.7103020701945052, loss:0.601110590129995\n",
      "epoch:641, weight:[0.97538765 0.81542896], bias:-0.71079048044887, loss:0.6010813212044803\n",
      "epoch:642, weight:[0.97559536 0.81553285], bias:-0.7112780884532757, loss:0.6010521089444885\n",
      "epoch:643, weight:[0.97580338 0.81563718], bias:-0.711764897040672, loss:0.6010229529756848\n",
      "epoch:644, weight:[0.97601171 0.81574195], bias:-0.7122509090335738, loss:0.6009938529265308\n",
      "epoch:645, weight:[0.97622034 0.81584716], bias:-0.7127361272440965, loss:0.6009648084282638\n",
      "epoch:646, weight:[0.97642927 0.8159528 ], bias:-0.7132205544739916, loss:0.6009358191148761\n",
      "epoch:647, weight:[0.9766385  0.81605887], bias:-0.713704193514682, loss:0.6009068846230946\n",
      "epoch:648, weight:[0.97684803 0.81616537], bias:-0.7141870471472976, loss:0.600878004592361\n",
      "epoch:649, weight:[0.97705787 0.81627229], bias:-0.7146691181427106, loss:0.6008491786648106\n",
      "epoch:650, weight:[0.977268   0.81637964], bias:-0.7151504092615705, loss:0.6008204064852531\n",
      "epoch:651, weight:[0.97747843 0.81648742], bias:-0.7156309232543392, loss:0.6007916877011529\n",
      "epoch:652, weight:[0.97768916 0.81659561], bias:-0.7161106628613262, loss:0.6007630219626081\n",
      "epoch:653, weight:[0.97790018 0.81670423], bias:-0.7165896308127232, loss:0.6007344089223329\n",
      "epoch:654, weight:[0.97811149 0.81681326], bias:-0.7170678298286391, loss:0.600705848235636\n",
      "epoch:655, weight:[0.9783231  0.81692271], bias:-0.717545262619135, loss:0.6006773395604033\n",
      "epoch:656, weight:[0.978535   0.81703257], bias:-0.718021931884258, loss:0.6006488825570773\n",
      "epoch:657, weight:[0.97874719 0.81714285], bias:-0.7184978403140766, loss:0.6006204768886386\n",
      "epoch:658, weight:[0.97895967 0.81725353], bias:-0.7189729905887148, loss:0.6005921222205871\n",
      "epoch:659, weight:[0.97917243 0.81736462], bias:-0.7194473853783862, loss:0.6005638182209225\n",
      "epoch:660, weight:[0.97938549 0.81747612], bias:-0.7199210273434287, loss:0.600535564560128\n",
      "epoch:661, weight:[0.97959883 0.81758803], bias:-0.7203939191343385, loss:0.6005073609111482\n",
      "epoch:662, weight:[0.97981246 0.81770033], bias:-0.7208660633918039, loss:0.6004792069493735\n",
      "epoch:663, weight:[0.98002637 0.81781304], bias:-0.7213374627467397, loss:0.6004511023526216\n",
      "epoch:664, weight:[0.98024056 0.81792614], bias:-0.7218081198203208, loss:0.6004230468011178\n",
      "epoch:665, weight:[0.98045504 0.81803964], bias:-0.7222780372240161, loss:0.6003950399774786\n",
      "epoch:666, weight:[0.98066979 0.81815354], bias:-0.7227472175596222, loss:0.600367081566694\n",
      "epoch:667, weight:[0.98088483 0.81826783], bias:-0.723215663419297, loss:0.6003391712561084\n",
      "epoch:668, weight:[0.98110015 0.81838251], bias:-0.7236833773855931, loss:0.600311308735404\n",
      "epoch:669, weight:[0.98131574 0.81849758], bias:-0.7241503620314913, loss:0.6002834936965831\n",
      "epoch:670, weight:[0.98153161 0.81861304], bias:-0.7246166199204341, loss:0.6002557258339511\n",
      "epoch:671, weight:[0.98174775 0.81872888], bias:-0.7250821536063587, loss:0.6002280048440993\n",
      "epoch:672, weight:[0.98196417 0.81884511], bias:-0.7255469656337303, loss:0.6002003304258872\n",
      "epoch:673, weight:[0.98218087 0.81896172], bias:-0.7260110585375749, loss:0.600172702280426\n",
      "epoch:674, weight:[0.98239783 0.81907871], bias:-0.7264744348435124, loss:0.6001451201110618\n",
      "epoch:675, weight:[0.98261507 0.81919608], bias:-0.7269370970677896, loss:0.6001175836233592\n",
      "epoch:676, weight:[0.98283258 0.81931383], bias:-0.727399047717313, loss:0.6000900925250837\n",
      "epoch:677, weight:[0.98305035 0.81943195], bias:-0.7278602892896809, loss:0.6000626465261863\n",
      "epoch:678, weight:[0.9832684  0.81955045], bias:-0.728320824273217, loss:0.6000352453387873\n",
      "epoch:679, weight:[0.98348671 0.81966931], bias:-0.7287806551470017, loss:0.6000078886771586\n",
      "epoch:680, weight:[0.98370529 0.81978855], bias:-0.7292397843809058, loss:0.5999805762577088\n",
      "epoch:681, weight:[0.98392414 0.81990816], bias:-0.7296982144356214, loss:0.5999533077989679\n",
      "epoch:682, weight:[0.98414325 0.82002813], bias:-0.7301559477626954, loss:0.5999260830215692\n",
      "epoch:683, weight:[0.98436262 0.82014847], bias:-0.7306129868045608, loss:0.5998989016482361\n",
      "epoch:684, weight:[0.98458225 0.82026917], bias:-0.731069333994569, loss:0.5998717634037642\n",
      "epoch:685, weight:[0.98480215 0.82039023], bias:-0.7315249917570218, loss:0.5998446680150072\n",
      "epoch:686, weight:[0.9850223  0.82051165], bias:-0.7319799625072031, loss:0.5998176152108614\n",
      "epoch:687, weight:[0.98524272 0.82063343], bias:-0.7324342486514108, loss:0.5997906047222498\n",
      "epoch:688, weight:[0.98546339 0.82075557], bias:-0.7328878525869885, loss:0.599763636282107\n",
      "epoch:689, weight:[0.98568433 0.82087806], bias:-0.7333407767023569, loss:0.5997367096253648\n",
      "epoch:690, weight:[0.98590551 0.8210009 ], bias:-0.7337930233770451, loss:0.5997098244889367\n",
      "epoch:691, weight:[0.98612696 0.82112409], bias:-0.7342445949817226, loss:0.5996829806117028\n",
      "epoch:692, weight:[0.98634865 0.82124764], bias:-0.7346954938782299, loss:0.5996561777344956\n",
      "epoch:693, weight:[0.98657061 0.82137153], bias:-0.7351457224196103, loss:0.5996294156000852\n",
      "epoch:694, weight:[0.98679281 0.82149577], bias:-0.7355952829501406, loss:0.5996026939531646\n",
      "epoch:695, weight:[0.98701527 0.82162035], bias:-0.7360441778053625, loss:0.5995760125403351\n",
      "epoch:696, weight:[0.98723797 0.82174528], bias:-0.7364924093121128, loss:0.5995493711100932\n",
      "epoch:697, weight:[0.98746093 0.82187055], bias:-0.7369399797885552, loss:0.5995227694128141\n",
      "epoch:698, weight:[0.98768413 0.82199615], bias:-0.7373868915442103, loss:0.59949620720074\n",
      "epoch:699, weight:[0.98790758 0.8221221 ], bias:-0.7378331468799868, loss:0.5994696842279645\n",
      "epoch:700, weight:[0.98813128 0.82224838], bias:-0.7382787480882116, loss:0.5994432002504196\n",
      "epoch:701, weight:[0.98835523 0.822375  ], bias:-0.7387236974526604, loss:0.5994167550258609\n",
      "epoch:702, weight:[0.98857942 0.82250195], bias:-0.7391679972485884, loss:0.5993903483138551\n",
      "epoch:703, weight:[0.98880385 0.82262923], bias:-0.7396116497427601, loss:0.5993639798757656\n",
      "epoch:704, weight:[0.98902853 0.82275684], bias:-0.7400546571934798, loss:0.5993376494747392\n",
      "epoch:705, weight:[0.98925345 0.82288478], bias:-0.7404970218506219, loss:0.5993113568756926\n",
      "epoch:706, weight:[0.98947861 0.82301305], bias:-0.7409387459556603, loss:0.5992851018452993\n",
      "epoch:707, weight:[0.98970401 0.82314164], bias:-0.7413798317416991, loss:0.5992588841519763\n",
      "epoch:708, weight:[0.98992965 0.82327056], bias:-0.7418202814335015, loss:0.5992327035658709\n",
      "epoch:709, weight:[0.99015553 0.82339979], bias:-0.7422600972475207, loss:0.5992065598588477\n",
      "epoch:710, weight:[0.99038165 0.82352935], bias:-0.7426992813919285, loss:0.5991804528044763\n",
      "epoch:711, weight:[0.990608   0.82365923], bias:-0.7431378360666455, loss:0.5991543821780172\n",
      "epoch:712, weight:[0.99083459 0.82378943], bias:-0.7435757634633704, loss:0.5991283477564101\n",
      "epoch:713, weight:[0.99106141 0.82391994], bias:-0.7440130657656093, loss:0.5991023493182609\n",
      "epoch:714, weight:[0.99128847 0.82405077], bias:-0.7444497451487052, loss:0.5990763866438292\n",
      "epoch:715, weight:[0.99151576 0.8241819 ], bias:-0.744885803779867, loss:0.599050459515016\n",
      "epoch:716, weight:[0.99174329 0.82431336], bias:-0.7453212438181989, loss:0.5990245677153515\n",
      "epoch:717, weight:[0.99197104 0.82444512], bias:-0.7457560674147289, loss:0.5989987110299814\n",
      "epoch:718, weight:[0.99219903 0.82457719], bias:-0.7461902767124383, loss:0.5989728892456574\n",
      "epoch:719, weight:[0.99242724 0.82470956], bias:-0.7466238738462905, loss:0.5989471021507223\n",
      "epoch:720, weight:[0.99265569 0.82484224], bias:-0.7470568609432592, loss:0.5989213495351001\n",
      "epoch:721, weight:[0.99288436 0.82497523], bias:-0.7474892401223578, loss:0.5988956311902828\n",
      "epoch:722, weight:[0.99311326 0.82510852], bias:-0.7479210134946677, loss:0.5988699469093194\n",
      "epoch:723, weight:[0.99334238 0.82524211], bias:-0.7483521831633664, loss:0.5988442964868035\n",
      "epoch:724, weight:[0.99357173 0.82537599], bias:-0.7487827512237566, loss:0.5988186797188622\n",
      "epoch:725, weight:[0.99380131 0.82551018], bias:-0.7492127197632942, loss:0.5987930964031436\n",
      "epoch:726, weight:[0.99403111 0.82564466], bias:-0.7496420908616164, loss:0.5987675463388077\n",
      "epoch:727, weight:[0.99426113 0.82577944], bias:-0.75007086659057, loss:0.5987420293265113\n",
      "epoch:728, weight:[0.99449137 0.82591451], bias:-0.7504990490142395, loss:0.5987165451684006\n",
      "epoch:729, weight:[0.99472184 0.82604988], bias:-0.7509266401889748, loss:0.5986910936680965\n",
      "epoch:730, weight:[0.99495252 0.82618553], bias:-0.7513536421634196, loss:0.5986656746306859\n",
      "epoch:731, weight:[0.99518342 0.82632148], bias:-0.7517800569785387, loss:0.59864028786271\n",
      "epoch:732, weight:[0.99541455 0.82645771], bias:-0.7522058866676459, loss:0.5986149331721523\n",
      "epoch:733, weight:[0.99564589 0.82659423], bias:-0.7526311332564316, loss:0.5985896103684295\n",
      "epoch:734, weight:[0.99587744 0.82673103], bias:-0.7530557987629903, loss:0.5985643192623793\n",
      "epoch:735, weight:[0.99610921 0.82686812], bias:-0.7534798851978484, loss:0.5985390596662499\n",
      "epoch:736, weight:[0.9963412  0.82700548], bias:-0.7539033945639907, loss:0.5985138313936897\n",
      "epoch:737, weight:[0.99657341 0.82714313], bias:-0.7543263288568888, loss:0.5984886342597368\n",
      "epoch:738, weight:[0.99680582 0.82728106], bias:-0.7547486900645273, loss:0.5984634680808075\n",
      "epoch:739, weight:[0.99703845 0.82741927], bias:-0.7551704801674314, loss:0.5984383326746877\n",
      "epoch:740, weight:[0.99727129 0.82755776], bias:-0.755591701138694, loss:0.598413227860521\n",
      "epoch:741, weight:[0.99750434 0.82769652], bias:-0.7560123549440023, loss:0.5983881534587985\n",
      "epoch:742, weight:[0.99773761 0.82783555], bias:-0.756432443541665, loss:0.59836310929135\n",
      "epoch:743, weight:[0.99797108 0.82797485], bias:-0.7568519688826385, loss:0.5983380951813315\n",
      "epoch:744, weight:[0.99820476 0.82811443], bias:-0.7572709329105543, loss:0.5983131109532186\n",
      "epoch:745, weight:[0.99843865 0.82825428], bias:-0.757689337561745, loss:0.5982881564327929\n",
      "epoch:746, weight:[0.99867274 0.82839439], bias:-0.758107184765271, loss:0.5982632314471342\n",
      "epoch:747, weight:[0.99890705 0.82853478], bias:-0.7585244764429471, loss:0.5982383358246103\n",
      "epoch:748, weight:[0.99914155 0.82867542], bias:-0.7589412145093686, loss:0.5982134693948674\n",
      "epoch:749, weight:[0.99937627 0.82881634], bias:-0.7593574008719377, loss:0.5981886319888198\n",
      "epoch:750, weight:[0.99961118 0.82895751], bias:-0.7597730374308894, loss:0.5981638234386412\n",
      "epoch:751, weight:[0.9998463  0.82909895], bias:-0.7601881260793178, loss:0.5981390435777537\n",
      "epoch:752, weight:[1.00008162 0.82924065], bias:-0.7606026687032024, loss:0.5981142922408208\n",
      "epoch:753, weight:[1.00031715 0.8293826 ], bias:-0.761016667181433, loss:0.5980895692637355\n",
      "epoch:754, weight:[1.00055287 0.82952482], bias:-0.7614301233858368, loss:0.5980648744836122\n",
      "epoch:755, weight:[1.0007888  0.82966729], bias:-0.7618430391812033, loss:0.5980402077387775\n",
      "epoch:756, weight:[1.00102492 0.82981002], bias:-0.7622554164253101, loss:0.5980155688687607\n",
      "epoch:757, weight:[1.00126125 0.829953  ], bias:-0.7626672569689489, loss:0.5979909577142849\n",
      "epoch:758, weight:[1.00149777 0.83009623], bias:-0.7630785626559502, loss:0.5979663741172574\n",
      "epoch:759, weight:[1.00173449 0.83023971], bias:-0.7634893353232096, loss:0.5979418179207617\n",
      "epoch:760, weight:[1.0019714  0.83038345], bias:-0.7638995768007124, loss:0.597917288969048\n",
      "epoch:761, weight:[1.00220851 0.83052743], bias:-0.7643092889115594, loss:0.5978927871075244\n",
      "epoch:762, weight:[1.00244582 0.83067166], bias:-0.7647184734719916, loss:0.5978683121827477\n",
      "epoch:763, weight:[1.00268332 0.83081613], bias:-0.7651271322914157, loss:0.5978438640424159\n",
      "epoch:764, weight:[1.00292101 0.83096086], bias:-0.7655352671724286, loss:0.5978194425353581\n",
      "epoch:765, weight:[1.0031589  0.83110582], bias:-0.7659428799108429, loss:0.5977950475115276\n",
      "epoch:766, weight:[1.00339697 0.83125103], bias:-0.7663499722957112, loss:0.5977706788219911\n",
      "epoch:767, weight:[1.00363524 0.83139648], bias:-0.7667565461093514, loss:0.5977463363189225\n",
      "epoch:768, weight:[1.0038737  0.83154216], bias:-0.7671626031273708, loss:0.597722019855593\n",
      "epoch:769, weight:[1.00411235 0.83168809], bias:-0.7675681451186911, loss:0.5976977292863643\n",
      "epoch:770, weight:[1.00435119 0.83183426], bias:-0.7679731738455725, loss:0.5976734644666782\n",
      "epoch:771, weight:[1.00459022 0.83198066], bias:-0.7683776910636387, loss:0.5976492252530503\n",
      "epoch:772, weight:[1.00482943 0.83212729], bias:-0.7687816985219009, loss:0.5976250115030608\n",
      "epoch:773, weight:[1.00506883 0.83227416], bias:-0.7691851979627821, loss:0.5976008230753472\n",
      "epoch:774, weight:[1.00530842 0.83242126], bias:-0.7695881911221409, loss:0.5975766598295954\n",
      "epoch:775, weight:[1.00554819 0.8325686 ], bias:-0.7699906797292967, loss:0.597552521626532\n",
      "epoch:776, weight:[1.00578815 0.83271616], bias:-0.7703926655070524, loss:0.5975284083279173\n",
      "epoch:777, weight:[1.00602829 0.83286395], bias:-0.7707941501717194, loss:0.5975043197965362\n",
      "epoch:778, weight:[1.00626861 0.83301197], bias:-0.7711951354331408, loss:0.5974802558961909\n",
      "epoch:779, weight:[1.00650912 0.83316022], bias:-0.7715956229947155, loss:0.5974562164916939\n",
      "epoch:780, weight:[1.00674981 0.83330869], bias:-0.7719956145534218, loss:0.5974322014488587\n",
      "epoch:781, weight:[1.00699068 0.83345739], bias:-0.7723951117998411, loss:0.5974082106344938\n",
      "epoch:782, weight:[1.00723173 0.8336063 ], bias:-0.7727941164181815, loss:0.5973842439163944\n",
      "epoch:783, weight:[1.00747297 0.83375545], bias:-0.7731926300863011, loss:0.5973603011633352\n",
      "epoch:784, weight:[1.00771438 0.83390481], bias:-0.7735906544757314, loss:0.5973363822450624\n",
      "epoch:785, weight:[1.00795596 0.83405439], bias:-0.7739881912517008, loss:0.5973124870322862\n",
      "epoch:786, weight:[1.00819773 0.83420419], bias:-0.7743852420731577, loss:0.5972886153966759\n",
      "epoch:787, weight:[1.00843968 0.8343542 ], bias:-0.7747818085927938, loss:0.5972647672108484\n",
      "epoch:788, weight:[1.0086818  0.83450444], bias:-0.7751778924570668, loss:0.5972409423483648\n",
      "epoch:789, weight:[1.00892409 0.83465488], bias:-0.7755734953062241, loss:0.5972171406837208\n",
      "epoch:790, weight:[1.00916656 0.83480554], bias:-0.7759686187743249, loss:0.5971933620923413\n",
      "epoch:791, weight:[1.00940921 0.83495642], bias:-0.7763632644892635, loss:0.5971696064505718\n",
      "epoch:792, weight:[1.00965203 0.8351075 ], bias:-0.7767574340727924, loss:0.597145873635673\n",
      "epoch:793, weight:[1.00989502 0.8352588 ], bias:-0.7771511291405442, loss:0.5971221635258123\n",
      "epoch:794, weight:[1.01013819 0.8354103 ], bias:-0.7775443513020547, loss:0.5970984760000573\n",
      "epoch:795, weight:[1.01038152 0.83556201], bias:-0.7779371021607856, loss:0.5970748109383704\n",
      "epoch:796, weight:[1.01062503 0.83571393], bias:-0.7783293833141466, loss:0.5970511682216002\n",
      "epoch:797, weight:[1.01086871 0.83586606], bias:-0.7787211963535178, loss:0.5970275477314749\n",
      "epoch:798, weight:[1.01111256 0.83601839], bias:-0.7791125428642723, loss:0.5970039493505972\n",
      "epoch:799, weight:[1.01135658 0.83617092], bias:-0.7795034244257985, loss:0.5969803729624356\n",
      "epoch:800, weight:[1.01160076 0.83632366], bias:-0.7798938426115216, loss:0.5969568184513195\n",
      "epoch:801, weight:[1.01184512 0.8364766 ], bias:-0.7802837989889264, loss:0.5969332857024315\n",
      "epoch:802, weight:[1.01208964 0.83662973], bias:-0.7806732951195791, loss:0.5969097746018015\n",
      "epoch:803, weight:[1.01233433 0.83678307], bias:-0.7810623325591489, loss:0.5968862850363\n",
      "epoch:804, weight:[1.01257918 0.83693661], bias:-0.7814509128574305, loss:0.5968628168936324\n",
      "epoch:805, weight:[1.0128242  0.83709034], bias:-0.7818390375583653, loss:0.596839370062331\n",
      "epoch:806, weight:[1.01306939 0.83724427], bias:-0.7822267082000632, loss:0.5968159444317508\n",
      "epoch:807, weight:[1.01331474 0.83739839], bias:-0.782613926314825, loss:0.5967925398920614\n",
      "epoch:808, weight:[1.01356025 0.83755271], bias:-0.7830006934291626, loss:0.5967691563342418\n",
      "epoch:809, weight:[1.01380592 0.83770722], bias:-0.7833870110638217, loss:0.5967457936500744\n",
      "epoch:810, weight:[1.01405176 0.83786192], bias:-0.7837728807338027, loss:0.5967224517321384\n",
      "epoch:811, weight:[1.01429776 0.83801681], bias:-0.7841583039483819, loss:0.596699130473804\n",
      "epoch:812, weight:[1.01454392 0.8381719 ], bias:-0.7845432822111333, loss:0.5966758297692252\n",
      "epoch:813, weight:[1.01479024 0.83832717], bias:-0.7849278170199492, loss:0.5966525495133363\n",
      "epoch:814, weight:[1.01503672 0.83848262], bias:-0.7853119098670617, loss:0.5966292896018438\n",
      "epoch:815, weight:[1.01528336 0.83863827], bias:-0.7856955622390637, loss:0.5966060499312212\n",
      "epoch:816, weight:[1.01553016 0.8387941 ], bias:-0.7860787756169297, loss:0.5965828303987034\n",
      "epoch:817, weight:[1.01577711 0.83895012], bias:-0.786461551476037, loss:0.5965596309022811\n",
      "epoch:818, weight:[1.01602423 0.83910631], bias:-0.7868438912861863, loss:0.5965364513406937\n",
      "epoch:819, weight:[1.0162715 0.8392627], bias:-0.7872257965116224, loss:0.5965132916134253\n",
      "epoch:820, weight:[1.01651892 0.83941926], bias:-0.7876072686110552, loss:0.5964901516206981\n",
      "epoch:821, weight:[1.01676651 0.839576  ], bias:-0.7879883090376804, loss:0.5964670312634669\n",
      "epoch:822, weight:[1.01701424 0.83973292], bias:-0.7883689192391992, loss:0.5964439304434136\n",
      "epoch:823, weight:[1.01726213 0.83989002], bias:-0.7887491006578398, loss:0.5964208490629419\n",
      "epoch:824, weight:[1.01751018 0.8400473 ], bias:-0.7891288547303772, loss:0.5963977870251707\n",
      "epoch:825, weight:[1.01775838 0.84020476], bias:-0.7895081828881539, loss:0.5963747442339307\n",
      "epoch:826, weight:[1.01800673 0.84036239], bias:-0.7898870865571, loss:0.5963517205937569\n",
      "epoch:827, weight:[1.01825523 0.84052019], bias:-0.7902655671577532, loss:0.5963287160098844\n",
      "epoch:828, weight:[1.01850388 0.84067817], bias:-0.7906436261052792, loss:0.5963057303882425\n",
      "epoch:829, weight:[1.01875269 0.84083632], bias:-0.7910212648094916, loss:0.5962827636354505\n",
      "epoch:830, weight:[1.01900165 0.84099464], bias:-0.7913984846748722, loss:0.5962598156588101\n",
      "epoch:831, weight:[1.01925075 0.84115313], bias:-0.7917752871005903, loss:0.5962368863663035\n",
      "epoch:832, weight:[1.01950001 0.8413118 ], bias:-0.7921516734805232, loss:0.596213975666585\n",
      "epoch:833, weight:[1.01974941 0.84147063], bias:-0.7925276452032756, loss:0.5961910834689781\n",
      "epoch:834, weight:[1.01999896 0.84162963], bias:-0.7929032036521994, loss:0.5961682096834693\n",
      "epoch:835, weight:[1.02024866 0.84178879], bias:-0.7932783502054134, loss:0.5961453542207035\n",
      "epoch:836, weight:[1.0204985  0.84194812], bias:-0.7936530862358228, loss:0.5961225169919786\n",
      "epoch:837, weight:[1.02074849 0.84210762], bias:-0.7940274131111386, loss:0.5960996979092409\n",
      "epoch:838, weight:[1.02099863 0.84226728], bias:-0.7944013321938973, loss:0.59607689688508\n",
      "epoch:839, weight:[1.02124892 0.8424271 ], bias:-0.7947748448414801, loss:0.5960541138327241\n",
      "epoch:840, weight:[1.02149934 0.84258708], bias:-0.7951479524061321, loss:0.5960313486660346\n",
      "epoch:841, weight:[1.02174991 0.84274723], bias:-0.7955206562349818, loss:0.5960086012995016\n",
      "epoch:842, weight:[1.02200063 0.84290753], bias:-0.7958929576700601, loss:0.5959858716482395\n",
      "epoch:843, weight:[1.02225149 0.843068  ], bias:-0.7962648580483193, loss:0.5959631596279814\n",
      "epoch:844, weight:[1.02250249 0.84322862], bias:-0.7966363587016523, loss:0.5959404651550753\n",
      "epoch:845, weight:[1.02275363 0.8433894 ], bias:-0.7970074609569116, loss:0.5959177881464783\n",
      "epoch:846, weight:[1.02300491 0.84355034], bias:-0.7973781661359279, loss:0.5958951285197533\n",
      "epoch:847, weight:[1.02325634 0.84371143], bias:-0.7977484755555294, loss:0.5958724861930631\n",
      "epoch:848, weight:[1.0235079  0.84387267], bias:-0.7981183905275601, loss:0.5958498610851669\n",
      "epoch:849, weight:[1.02375961 0.84403407], bias:-0.7984879123588986, loss:0.5958272531154146\n",
      "epoch:850, weight:[1.02401145 0.84419563], bias:-0.7988570423514771, loss:0.5958046622037437\n",
      "epoch:851, weight:[1.02426344 0.84435733], bias:-0.7992257818022995, loss:0.5957820882706735\n",
      "epoch:852, weight:[1.02451556 0.84451919], bias:-0.7995941320034602, loss:0.5957595312373013\n",
      "epoch:853, weight:[1.02476782 0.84468119], bias:-0.7999620942421622, loss:0.5957369910252982\n",
      "epoch:854, weight:[1.02502021 0.84484335], bias:-0.8003296698007359, loss:0.5957144675569045\n",
      "epoch:855, weight:[1.02527274 0.84500565], bias:-0.8006968599566573, loss:0.5956919607549243\n",
      "epoch:856, weight:[1.02552541 0.8451681 ], bias:-0.8010636659825657, loss:0.5956694705427235\n",
      "epoch:857, weight:[1.02577822 0.8453307 ], bias:-0.8014300891462829, loss:0.5956469968442235\n",
      "epoch:858, weight:[1.02603116 0.84549344], bias:-0.8017961307108302, loss:0.5956245395838979\n",
      "epoch:859, weight:[1.02628423 0.84565633], bias:-0.8021617919344474, loss:0.5956020986867675\n",
      "epoch:860, weight:[1.02653744 0.84581936], bias:-0.8025270740706099, loss:0.5955796740783977\n",
      "epoch:861, weight:[1.02679078 0.84598253], bias:-0.8028919783680474, loss:0.5955572656848923\n",
      "epoch:862, weight:[1.02704425 0.84614585], bias:-0.8032565060707614, loss:0.5955348734328911\n",
      "epoch:863, weight:[1.02729786 0.84630931], bias:-0.8036206584180429, loss:0.5955124972495647\n",
      "epoch:864, weight:[1.0275516  0.84647291], bias:-0.8039844366444904, loss:0.595490137062611\n",
      "epoch:865, weight:[1.02780547 0.84663665], bias:-0.8043478419800272, loss:0.5954677928002511\n",
      "epoch:866, weight:[1.02805947 0.84680052], bias:-0.8047108756499194, loss:0.5954454643912253\n",
      "epoch:867, weight:[1.0283136  0.84696454], bias:-0.8050735388747932, loss:0.5954231517647887\n",
      "epoch:868, weight:[1.02856786 0.84712869], bias:-0.8054358328706523, loss:0.5954008548507081\n",
      "epoch:869, weight:[1.02882225 0.84729298], bias:-0.8057977588488958, loss:0.5953785735792576\n",
      "epoch:870, weight:[1.02907677 0.8474574 ], bias:-0.8061593180163348, loss:0.5953563078812146\n",
      "epoch:871, weight:[1.02933142 0.84762196], bias:-0.8065205115752102, loss:0.595334057687856\n",
      "epoch:872, weight:[1.0295862  0.84778665], bias:-0.80688134072321, loss:0.595311822930955\n",
      "epoch:873, weight:[1.0298411  0.84795148], bias:-0.8072418066534862, loss:0.5952896035427764\n",
      "epoch:874, weight:[1.03009613 0.84811644], bias:-0.807601910554672, loss:0.5952673994560734\n",
      "epoch:875, weight:[1.03035129 0.84828152], bias:-0.8079616536108987, loss:0.595245210604084\n",
      "epoch:876, weight:[1.03060657 0.84844674], bias:-0.8083210370018129, loss:0.5952230369205265\n",
      "epoch:877, weight:[1.03086198 0.84861209], bias:-0.8086800619025936, loss:0.595200878339597\n",
      "epoch:878, weight:[1.03111751 0.84877757], bias:-0.8090387294839684, loss:0.5951787347959648\n",
      "epoch:879, weight:[1.03137317 0.84894318], bias:-0.8093970409122309, loss:0.5951566062247691\n",
      "epoch:880, weight:[1.03162896 0.84910891], bias:-0.8097549973492573, loss:0.5951344925616154\n",
      "epoch:881, weight:[1.03188486 0.84927477], bias:-0.810112599952523, loss:0.5951123937425722\n",
      "epoch:882, weight:[1.03214089 0.84944076], bias:-0.8104698498751194, loss:0.5950903097041672\n",
      "epoch:883, weight:[1.03239704 0.84960687], bias:-0.81082674826577, loss:0.5950682403833837\n",
      "epoch:884, weight:[1.03265332 0.8497731 ], bias:-0.8111832962688474, loss:0.5950461857176573\n",
      "epoch:885, weight:[1.03290972 0.84993946], bias:-0.8115394950243898, loss:0.5950241456448723\n",
      "epoch:886, weight:[1.03316623 0.85010594], bias:-0.8118953456681167, loss:0.5950021201033586\n",
      "epoch:887, weight:[1.03342287 0.85027254], bias:-0.812250849331446, loss:0.594980109031888\n",
      "epoch:888, weight:[1.03367963 0.85043927], bias:-0.8126060071415098, loss:0.5949581123696709\n",
      "epoch:889, weight:[1.03393651 0.85060611], bias:-0.8129608202211708, loss:0.5949361300563525\n",
      "epoch:890, weight:[1.03419351 0.85077307], bias:-0.8133152896890384, loss:0.594914162032011\n",
      "epoch:891, weight:[1.03445063 0.85094015], bias:-0.813669416659485, loss:0.5948922082371518\n",
      "epoch:892, weight:[1.03470786 0.85110735], bias:-0.8140232022426614, loss:0.5948702686127071\n",
      "epoch:893, weight:[1.03496522 0.85127467], bias:-0.8143766475445136, loss:0.5948483431000301\n",
      "epoch:894, weight:[1.03522269 0.8514421 ], bias:-0.814729753666798, loss:0.5948264316408935\n",
      "epoch:895, weight:[1.03548028 0.85160965], bias:-0.8150825217070978, loss:0.5948045341774855\n",
      "epoch:896, weight:[1.03573798 0.85177732], bias:-0.8154349527588386, loss:0.5947826506524067\n",
      "epoch:897, weight:[1.0359958  0.85194509], bias:-0.8157870479113039, loss:0.594760781008667\n",
      "epoch:898, weight:[1.03625374 0.85211299], bias:-0.8161388082496512, loss:0.5947389251896832\n",
      "epoch:899, weight:[1.0365118  0.85228099], bias:-0.8164902348549276, loss:0.5947170831392742\n",
      "epoch:900, weight:[1.03676996 0.85244911], bias:-0.8168413288040848, loss:0.5946952548016599\n",
      "epoch:901, weight:[1.03702825 0.85261733], bias:-0.8171920911699954, loss:0.5946734401214562\n",
      "epoch:902, weight:[1.03728664 0.85278567], bias:-0.8175425230214678, loss:0.5946516390436745\n",
      "epoch:903, weight:[1.03754515 0.85295412], bias:-0.817892625423262, loss:0.5946298515137154\n",
      "epoch:904, weight:[1.03780378 0.85312267], bias:-0.8182423994361048, loss:0.5946080774773684\n",
      "epoch:905, weight:[1.03806252 0.85329134], bias:-0.8185918461167047, loss:0.5945863168808084\n",
      "epoch:906, weight:[1.03832136 0.85346011], bias:-0.8189409665177678, loss:0.5945645696705912\n",
      "epoch:907, weight:[1.03858033 0.85362899], bias:-0.8192897616880127, loss:0.5945428357936529\n",
      "epoch:908, weight:[1.0388394  0.85379798], bias:-0.8196382326721855, loss:0.5945211151973053\n",
      "epoch:909, weight:[1.03909858 0.85396707], bias:-0.8199863805110751, loss:0.5944994078292336\n",
      "epoch:910, weight:[1.03935788 0.85413626], bias:-0.8203342062415279, loss:0.5944777136374935\n",
      "epoch:911, weight:[1.03961728 0.85430556], bias:-0.8206817108964631, loss:0.5944560325705088\n",
      "epoch:912, weight:[1.0398768  0.85447497], bias:-0.8210288955048877, loss:0.5944343645770674\n",
      "epoch:913, weight:[1.04013642 0.85464447], bias:-0.8213757610919107, loss:0.5944127096063209\n",
      "epoch:914, weight:[1.04039615 0.85481408], bias:-0.8217223086787585, loss:0.5943910676077778\n",
      "epoch:915, weight:[1.04065599 0.85498379], bias:-0.8220685392827898, loss:0.5943694385313056\n",
      "epoch:916, weight:[1.04091594 0.8551536 ], bias:-0.8224144539175094, loss:0.5943478223271241\n",
      "epoch:917, weight:[1.041176  0.8553235], bias:-0.8227600535925841, loss:0.5943262189458048\n",
      "epoch:918, weight:[1.04143616 0.85549351], bias:-0.823105339313856, loss:0.5943046283382682\n",
      "epoch:919, weight:[1.04169644 0.85566362], bias:-0.823450312083358, loss:0.5942830504557798\n",
      "epoch:920, weight:[1.04195681 0.85583382], bias:-0.8237949728993277, loss:0.5942614852499489\n",
      "epoch:921, weight:[1.0422173  0.85600413], bias:-0.8241393227562223, loss:0.5942399326727249\n",
      "epoch:922, weight:[1.04247789 0.85617452], bias:-0.8244833626447324, loss:0.5942183926763954\n",
      "epoch:923, weight:[1.04273858 0.85634502], bias:-0.8248270935517971, loss:0.5941968652135837\n",
      "epoch:924, weight:[1.04299938 0.85651561], bias:-0.8251705164606172, loss:0.5941753502372455\n",
      "epoch:925, weight:[1.04326029 0.85668629], bias:-0.8255136323506707, loss:0.594153847700667\n",
      "epoch:926, weight:[1.0435213  0.85685707], bias:-0.8258564421977257, loss:0.5941323575574619\n",
      "epoch:927, weight:[1.04378241 0.85702794], bias:-0.8261989469738557, loss:0.5941108797615695\n",
      "epoch:928, weight:[1.04404362 0.8571989 ], bias:-0.8265411476474525, loss:0.5940894142672519\n",
      "epoch:929, weight:[1.04430494 0.85736995], bias:-0.8268830451832411, loss:0.5940679610290912\n",
      "epoch:930, weight:[1.04456636 0.8575411 ], bias:-0.8272246405422934, loss:0.5940465200019877\n",
      "epoch:931, weight:[1.04482789 0.85771233], bias:-0.8275659346820419, loss:0.5940250911411569\n",
      "epoch:932, weight:[1.04508951 0.85788366], bias:-0.8279069285562937, loss:0.5940036744021274\n",
      "epoch:933, weight:[1.04535124 0.85805507], bias:-0.8282476231152444, loss:0.5939822697407388\n",
      "epoch:934, weight:[1.04561306 0.85822658], bias:-0.8285880193054918, loss:0.5939608771131387\n",
      "epoch:935, weight:[1.04587499 0.85839817], bias:-0.8289281180700494, loss:0.5939394964757803\n",
      "epoch:936, weight:[1.04613702 0.85856984], bias:-0.8292679203483604, loss:0.593918127785421\n",
      "epoch:937, weight:[1.04639915 0.85874161], bias:-0.8296074270763111, loss:0.593896770999119\n",
      "epoch:938, weight:[1.04666137 0.85891346], bias:-0.8299466391862443, loss:0.593875426074232\n",
      "epoch:939, weight:[1.0469237 0.8590854], bias:-0.8302855576069734, loss:0.593854092968414\n",
      "epoch:940, weight:[1.04718612 0.85925742], bias:-0.8306241832637952, loss:0.5938327716396133\n",
      "epoch:941, weight:[1.04744865 0.85942952], bias:-0.8309625170785033, loss:0.5938114620460706\n",
      "epoch:942, weight:[1.04771127 0.85960171], bias:-0.8313005599694022, loss:0.593790164146317\n",
      "epoch:943, weight:[1.04797399 0.85977398], bias:-0.8316383128513197, loss:0.5937688778991705\n",
      "epoch:944, weight:[1.0482368  0.85994634], bias:-0.831975776635621, loss:0.5937476032637353\n",
      "epoch:945, weight:[1.04849971 0.86011877], bias:-0.8323129522302208, loss:0.5937263401993985\n",
      "epoch:946, weight:[1.04876272 0.86029129], bias:-0.832649840539598, loss:0.5937050886658288\n",
      "epoch:947, weight:[1.04902583 0.86046388], bias:-0.8329864424648072, loss:0.5936838486229741\n",
      "epoch:948, weight:[1.04928903 0.86063656], bias:-0.833322758903493, loss:0.5936626200310582\n",
      "epoch:949, weight:[1.04955232 0.86080931], bias:-0.8336587907499023, loss:0.5936414028505811\n",
      "epoch:950, weight:[1.04981572 0.86098215], bias:-0.8339945388948976, loss:0.5936201970423145\n",
      "epoch:951, weight:[1.0500792  0.86115506], bias:-0.8343300042259697, loss:0.5935990025673014\n",
      "epoch:952, weight:[1.05034278 0.86132805], bias:-0.8346651876272507, loss:0.5935778193868531\n",
      "epoch:953, weight:[1.05060645 0.86150111], bias:-0.835000089979527, loss:0.5935566474625472\n",
      "epoch:954, weight:[1.05087022 0.86167426], bias:-0.8353347121602516, loss:0.5935354867562264\n",
      "epoch:955, weight:[1.05113408 0.86184747], bias:-0.8356690550435573, loss:0.5935143372299952\n",
      "epoch:956, weight:[1.05139803 0.86202077], bias:-0.8360031195002691, loss:0.5934931988462191\n",
      "epoch:957, weight:[1.05166208 0.86219413], bias:-0.836336906397917, loss:0.5934720715675219\n",
      "epoch:958, weight:[1.05192622 0.86236758], bias:-0.8366704166007485, loss:0.5934509553567838\n",
      "epoch:959, weight:[1.05219044 0.86254109], bias:-0.8370036509697412, loss:0.5934298501771398\n",
      "epoch:960, weight:[1.05245477 0.86271468], bias:-0.837336610362615, loss:0.5934087559919775\n",
      "epoch:961, weight:[1.05271918 0.86288834], bias:-0.8376692956338452, loss:0.5933876727649351\n",
      "epoch:962, weight:[1.05298368 0.86306207], bias:-0.8380017076346742, loss:0.5933666004598992\n",
      "epoch:963, weight:[1.05324827 0.86323587], bias:-0.8383338472131242, loss:0.5933455390410043\n",
      "epoch:964, weight:[1.05351295 0.86340974], bias:-0.8386657152140096, loss:0.5933244884726289\n",
      "epoch:965, weight:[1.05377773 0.86358368], bias:-0.838997312478949, loss:0.5933034487193954\n",
      "epoch:966, weight:[1.05404259 0.86375769], bias:-0.8393286398463777, loss:0.5932824197461668\n",
      "epoch:967, weight:[1.05430754 0.86393177], bias:-0.8396596981515596, loss:0.5932614015180462\n",
      "epoch:968, weight:[1.05457258 0.86410592], bias:-0.8399904882265994, loss:0.5932403940003736\n",
      "epoch:969, weight:[1.0548377  0.86428013], bias:-0.8403210109004549, loss:0.5932193971587258\n",
      "epoch:970, weight:[1.05510292 0.86445441], bias:-0.8406512669989488, loss:0.5931984109589129\n",
      "epoch:971, weight:[1.05536822 0.86462876], bias:-0.8409812573447808, loss:0.5931774353669769\n",
      "epoch:972, weight:[1.05563361 0.86480318], bias:-0.8413109827575395, loss:0.5931564703491913\n",
      "epoch:973, weight:[1.05589909 0.86497766], bias:-0.8416404440537142, loss:0.5931355158720576\n",
      "epoch:974, weight:[1.05616465 0.8651522 ], bias:-0.8419696420467071, loss:0.5931145719023043\n",
      "epoch:975, weight:[1.0564303  0.86532681], bias:-0.8422985775468449, loss:0.5930936384068852\n",
      "epoch:976, weight:[1.05669604 0.86550148], bias:-0.8426272513613903, loss:0.5930727153529781\n",
      "epoch:977, weight:[1.05696186 0.86567622], bias:-0.8429556642945543, loss:0.5930518027079819\n",
      "epoch:978, weight:[1.05722777 0.86585101], bias:-0.8432838171475074, loss:0.5930309004395161\n",
      "epoch:979, weight:[1.05749376 0.86602588], bias:-0.8436117107183916, loss:0.5930100085154183\n",
      "epoch:980, weight:[1.05775984 0.8662008 ], bias:-0.8439393458023317, loss:0.5929891269037431\n",
      "epoch:981, weight:[1.058026   0.86637578], bias:-0.8442667231914469, loss:0.5929682555727602\n",
      "epoch:982, weight:[1.05829224 0.86655082], bias:-0.8445938436748626, loss:0.5929473944909529\n",
      "epoch:983, weight:[1.05855857 0.86672593], bias:-0.8449207080387215, loss:0.5929265436270165\n",
      "epoch:984, weight:[1.05882498 0.86690109], bias:-0.8452473170661954, loss:0.5929057029498561\n",
      "epoch:985, weight:[1.05909148 0.86707631], bias:-0.845573671537496, loss:0.5928848724285858\n",
      "epoch:986, weight:[1.05935805 0.86725159], bias:-0.8458997722298869, loss:0.5928640520325265\n",
      "epoch:987, weight:[1.05962471 0.86742693], bias:-0.8462256199176945, loss:0.5928432417312051\n",
      "epoch:988, weight:[1.05989145 0.86760232], bias:-0.8465512153723196, loss:0.5928224414943519\n",
      "epoch:989, weight:[1.06015828 0.86777777], bias:-0.8468765593622479, loss:0.5928016512919\n",
      "epoch:990, weight:[1.06042518 0.86795328], bias:-0.8472016526530621, loss:0.5927808710939829\n",
      "epoch:991, weight:[1.06069217 0.86812885], bias:-0.8475264960074524, loss:0.5927601008709336\n",
      "epoch:992, weight:[1.06095924 0.86830447], bias:-0.8478510901852279, loss:0.5927393405932833\n",
      "epoch:993, weight:[1.06122638 0.86848014], bias:-0.8481754359433271, loss:0.5927185902317589\n",
      "epoch:994, weight:[1.06149361 0.86865587], bias:-0.8484995340358298, loss:0.5926978497572823\n",
      "epoch:995, weight:[1.06176092 0.86883165], bias:-0.8488233852139674, loss:0.592677119140969\n",
      "epoch:996, weight:[1.06202831 0.86900749], bias:-0.8491469902261339, loss:0.592656398354126\n",
      "epoch:997, weight:[1.06229577 0.86918337], bias:-0.8494703498178973, loss:0.5926356873682507\n",
      "epoch:998, weight:[1.06256332 0.86935932], bias:-0.8497934647320095, loss:0.5926149861550295\n",
      "epoch:999, weight:[1.06283094 0.86953531], bias:-0.8501163357084178, loss:0.5925942946863365\n",
      "epoch:1000, weight:[1.06309865 0.86971135], bias:-0.8504389634842758, loss:0.5925736129342317\n",
      "epoch:1001, weight:[1.06336643 0.86988745], bias:-0.8507613487939535, loss:0.5925529408709594\n",
      "epoch:1002, weight:[1.06363429 0.87006359], bias:-0.8510834923690483, loss:0.5925322784689482\n",
      "epoch:1003, weight:[1.06390222 0.87023979], bias:-0.851405394938396, loss:0.5925116257008072\n",
      "epoch:1004, weight:[1.06417023 0.87041603], bias:-0.8517270572280805, loss:0.5924909825393272\n",
      "epoch:1005, weight:[1.06443833 0.87059232], bias:-0.8520484799614453, loss:0.5924703489574774\n",
      "epoch:1006, weight:[1.06470649 0.87076866], bias:-0.8523696638591034, loss:0.5924497249284048\n",
      "epoch:1007, weight:[1.06497474 0.87094505], bias:-0.8526906096389482, loss:0.5924291104254329\n",
      "epoch:1008, weight:[1.06524305 0.87112149], bias:-0.8530113180161635, loss:0.5924085054220609\n",
      "epoch:1009, weight:[1.06551145 0.87129797], bias:-0.8533317897032344, loss:0.5923879098919604\n",
      "epoch:1010, weight:[1.06577992 0.8714745 ], bias:-0.8536520254099573, loss:0.5923673238089767\n",
      "epoch:1011, weight:[1.06604846 0.87165108], bias:-0.8539720258434502, loss:0.5923467471471251\n",
      "epoch:1012, weight:[1.06631709 0.8718277 ], bias:-0.8542917917081634, loss:0.592326179880592\n",
      "epoch:1013, weight:[1.06658578 0.87200437], bias:-0.8546113237058891, loss:0.5923056219837307\n",
      "epoch:1014, weight:[1.06685455 0.87218108], bias:-0.8549306225357723, loss:0.592285073431063\n",
      "epoch:1015, weight:[1.06712339 0.87235784], bias:-0.8552496888943206, loss:0.5922645341972764\n",
      "epoch:1016, weight:[1.06739231 0.87253464], bias:-0.8555685234754142, loss:0.5922440042572228\n",
      "epoch:1017, weight:[1.0676613  0.87271148], bias:-0.8558871269703164, loss:0.5922234835859177\n",
      "epoch:1018, weight:[1.06793036 0.87288836], bias:-0.8562055000676833, loss:0.5922029721585388\n",
      "epoch:1019, weight:[1.0681995  0.87306529], bias:-0.8565236434535738, loss:0.5921824699504249\n",
      "epoch:1020, weight:[1.06846871 0.87324226], bias:-0.8568415578114601, loss:0.5921619769370744\n",
      "epoch:1021, weight:[1.06873799 0.87341927], bias:-0.857159243822237, loss:0.5921414930941444\n",
      "epoch:1022, weight:[1.06900734 0.87359632], bias:-0.857476702164232, loss:0.5921210183974489\n",
      "epoch:1023, weight:[1.06927677 0.87377342], bias:-0.8577939335132154, loss:0.5921005528229589\n",
      "epoch:1024, weight:[1.06954627 0.87395055], bias:-0.85811093854241, loss:0.5920800963467997\n",
      "epoch:1025, weight:[1.06981583 0.87412772], bias:-0.8584277179225009, loss:0.5920596489452504\n",
      "epoch:1026, weight:[1.07008547 0.87430493], bias:-0.8587442723216451, loss:0.5920392105947433\n",
      "epoch:1027, weight:[1.07035518 0.87448218], bias:-0.8590606024054813, loss:0.5920187812718614\n",
      "epoch:1028, weight:[1.07062496 0.87465947], bias:-0.8593767088371398, loss:0.5919983609533384\n",
      "epoch:1029, weight:[1.07089481 0.8748368 ], bias:-0.8596925922772519, loss:0.5919779496160572\n",
      "epoch:1030, weight:[1.07116473 0.87501416], bias:-0.8600082533839596, loss:0.5919575472370487\n",
      "epoch:1031, weight:[1.07143472 0.87519157], bias:-0.860323692812925, loss:0.5919371537934911\n",
      "epoch:1032, weight:[1.07170478 0.875369  ], bias:-0.8606389112173402, loss:0.5919167692627078\n",
      "epoch:1033, weight:[1.07197491 0.87554648], bias:-0.8609539092479365, loss:0.5918963936221672\n",
      "epoch:1034, weight:[1.07224511 0.87572399], bias:-0.861268687552994, loss:0.5918760268494809\n",
      "epoch:1035, weight:[1.07251537 0.87590153], bias:-0.8615832467783511, loss:0.5918556689224042\n",
      "epoch:1036, weight:[1.0727857  0.87607911], bias:-0.8618975875674135, loss:0.5918353198188325\n",
      "epoch:1037, weight:[1.07305611 0.87625673], bias:-0.8622117105611642, loss:0.5918149795168022\n",
      "epoch:1038, weight:[1.07332658 0.87643437], bias:-0.8625256163981722, loss:0.5917946479944892\n",
      "epoch:1039, weight:[1.07359711 0.87661206], bias:-0.8628393057146022, loss:0.5917743252302071\n",
      "epoch:1040, weight:[1.07386772 0.87678977], bias:-0.8631527791442237, loss:0.5917540112024074\n",
      "epoch:1041, weight:[1.07413839 0.87696752], bias:-0.8634660373184202, loss:0.5917337058896772\n",
      "epoch:1042, weight:[1.07440913 0.8771453 ], bias:-0.8637790808661984, loss:0.5917134092707389\n",
      "epoch:1043, weight:[1.07467993 0.87732311], bias:-0.8640919104141974, loss:0.5916931213244493\n",
      "epoch:1044, weight:[1.0749508  0.87750096], bias:-0.8644045265866979, loss:0.5916728420297975\n",
      "epoch:1045, weight:[1.07522174 0.87767883], bias:-0.8647169300056308, loss:0.5916525713659061\n",
      "epoch:1046, weight:[1.07549274 0.87785674], bias:-0.865029121290587, loss:0.5916323093120274\n",
      "epoch:1047, weight:[1.07576381 0.87803467], bias:-0.8653411010588258, loss:0.5916120558475447\n",
      "epoch:1048, weight:[1.07603494 0.87821264], bias:-0.8656528699252842, loss:0.5915918109519697\n",
      "epoch:1049, weight:[1.07630614 0.87839063], bias:-0.8659644285025857, loss:0.5915715746049433\n",
      "epoch:1050, weight:[1.0765774  0.87856866], bias:-0.8662757774010492, loss:0.5915513467862324\n",
      "epoch:1051, weight:[1.07684873 0.87874671], bias:-0.866586917228698, loss:0.591531127475731\n",
      "epoch:1052, weight:[1.07712012 0.87892479], bias:-0.8668978485912684, loss:0.5915109166534579\n",
      "epoch:1053, weight:[1.07739157 0.8791029 ], bias:-0.8672085720922189, loss:0.5914907142995562\n",
      "epoch:1054, weight:[1.07766309 0.87928104], bias:-0.8675190883327386, loss:0.5914705203942929\n",
      "epoch:1055, weight:[1.07793468 0.87945921], bias:-0.8678293979117561, loss:0.591450334918057\n",
      "epoch:1056, weight:[1.07820632 0.8796374 ], bias:-0.8681395014259481, loss:0.5914301578513588\n",
      "epoch:1057, weight:[1.07847803 0.87981561], bias:-0.8684493994697484, loss:0.5914099891748299\n",
      "epoch:1058, weight:[1.0787498  0.87999386], bias:-0.8687590926353562, loss:0.5913898288692212\n",
      "epoch:1059, weight:[1.07902164 0.88017213], bias:-0.8690685815127448, loss:0.5913696769154023\n",
      "epoch:1060, weight:[1.07929353 0.88035042], bias:-0.8693778666896702, loss:0.5913495332943607\n",
      "epoch:1061, weight:[1.07956549 0.88052874], bias:-0.8696869487516796, loss:0.5913293979872013\n",
      "epoch:1062, weight:[1.07983751 0.88070709], bias:-0.8699958282821201, loss:0.5913092709751445\n",
      "epoch:1063, weight:[1.08010959 0.88088545], bias:-0.8703045058621468, loss:0.5912891522395266\n",
      "epoch:1064, weight:[1.08038173 0.88106385], bias:-0.8706129820707317, loss:0.591269041761798\n",
      "epoch:1065, weight:[1.08065394 0.88124226], bias:-0.8709212574846718, loss:0.5912489395235223\n",
      "epoch:1066, weight:[1.0809262 0.8814207], bias:-0.8712293326785975, loss:0.5912288455063766\n",
      "epoch:1067, weight:[1.08119853 0.88159916], bias:-0.8715372082249813, loss:0.5912087596921485\n",
      "epoch:1068, weight:[1.08147092 0.88177764], bias:-0.8718448846941454, loss:0.5911886820627381\n",
      "epoch:1069, weight:[1.08174336 0.88195615], bias:-0.8721523626542711, loss:0.5911686126001544\n",
      "epoch:1070, weight:[1.08201587 0.88213467], bias:-0.8724596426714056, loss:0.5911485512865166\n",
      "epoch:1071, weight:[1.08228843 0.88231322], bias:-0.8727667253094717, loss:0.5911284981040514\n",
      "epoch:1072, weight:[1.08256106 0.88249179], bias:-0.8730736111302749, loss:0.5911084530350943\n",
      "epoch:1073, weight:[1.08283374 0.88267038], bias:-0.8733803006935121, loss:0.5910884160620868\n",
      "epoch:1074, weight:[1.08310649 0.88284898], bias:-0.8736867945567797, loss:0.5910683871675767\n",
      "epoch:1075, weight:[1.08337929 0.88302761], bias:-0.8739930932755814, loss:0.5910483663342171\n",
      "epoch:1076, weight:[1.08365215 0.88320626], bias:-0.8742991974033367, loss:0.591028353544766\n",
      "epoch:1077, weight:[1.08392507 0.88338493], bias:-0.8746051074913886, loss:0.591008348782084\n",
      "epoch:1078, weight:[1.08419805 0.88356361], bias:-0.8749108240890118, loss:0.5909883520291357\n",
      "epoch:1079, weight:[1.08447108 0.88374231], bias:-0.8752163477434204, loss:0.5909683632689869\n",
      "epoch:1080, weight:[1.08474417 0.88392104], bias:-0.8755216789997762, loss:0.5909483824848055\n",
      "epoch:1081, weight:[1.08501732 0.88409977], bias:-0.8758268184011965, loss:0.5909284096598596\n",
      "epoch:1082, weight:[1.08529053 0.88427853], bias:-0.8761317664887619, loss:0.5909084447775172\n",
      "epoch:1083, weight:[1.0855638 0.8844573], bias:-0.8764365238015243, loss:0.5908884878212457\n",
      "epoch:1084, weight:[1.08583712 0.88463609], bias:-0.8767410908765144, loss:0.5908685387746101\n",
      "epoch:1085, weight:[1.0861105 0.8848149], bias:-0.8770454682487501, loss:0.5908485976212735\n",
      "epoch:1086, weight:[1.08638393 0.88499372], bias:-0.8773496564512434, loss:0.5908286643449959\n",
      "epoch:1087, weight:[1.08665742 0.88517255], bias:-0.8776536560150092, loss:0.5908087389296336\n",
      "epoch:1088, weight:[1.08693097 0.88535141], bias:-0.8779574674690721, loss:0.5907888213591378\n",
      "epoch:1089, weight:[1.08720457 0.88553027], bias:-0.8782610913404745, loss:0.590768911617555\n",
      "epoch:1090, weight:[1.08747823 0.88570915], bias:-0.8785645281542841, loss:0.5907490096890249\n",
      "epoch:1091, weight:[1.08775194 0.88588805], bias:-0.8788677784336018, loss:0.5907291155577811\n",
      "epoch:1092, weight:[1.08802571 0.88606696], bias:-0.8791708426995689, loss:0.5907092292081497\n",
      "epoch:1093, weight:[1.08829953 0.88624588], bias:-0.879473721471375, loss:0.5906893506245487\n",
      "epoch:1094, weight:[1.08857341 0.88642482], bias:-0.8797764152662653, loss:0.5906694797914874\n",
      "epoch:1095, weight:[1.08884734 0.88660376], bias:-0.8800789245995481, loss:0.5906496166935651\n",
      "epoch:1096, weight:[1.08912133 0.88678272], bias:-0.8803812499846025, loss:0.5906297613154716\n",
      "epoch:1097, weight:[1.08939537 0.8869617 ], bias:-0.8806833919328858, loss:0.5906099136419853\n",
      "epoch:1098, weight:[1.08966946 0.88714068], bias:-0.8809853509539406, loss:0.5905900736579734\n",
      "epoch:1099, weight:[1.08994361 0.88731968], bias:-0.8812871275554025, loss:0.5905702413483914\n",
      "epoch:1100, weight:[1.09021781 0.88749869], bias:-0.8815887222430075, loss:0.5905504166982811\n",
      "epoch:1101, weight:[1.09049206 0.8876777 ], bias:-0.8818901355205991, loss:0.5905305996927711\n",
      "epoch:1102, weight:[1.09076637 0.88785673], bias:-0.8821913678901357, loss:0.5905107903170763\n",
      "epoch:1103, weight:[1.09104073 0.88803577], bias:-0.8824924198516981, loss:0.5904909885564964\n",
      "epoch:1104, weight:[1.09131514 0.88821482], bias:-0.8827932919034963, loss:0.5904711943964158\n",
      "epoch:1105, weight:[1.09158961 0.88839388], bias:-0.8830939845418772, loss:0.5904514078223033\n",
      "epoch:1106, weight:[1.09186412 0.88857295], bias:-0.8833944982613313, loss:0.5904316288197101\n",
      "epoch:1107, weight:[1.09213869 0.88875202], bias:-0.8836948335545005, loss:0.5904118573742708\n",
      "epoch:1108, weight:[1.09241331 0.88893111], bias:-0.8839949909121847, loss:0.5903920934717022\n",
      "epoch:1109, weight:[1.09268799 0.8891102 ], bias:-0.884294970823349, loss:0.5903723370978021\n",
      "epoch:1110, weight:[1.09296271 0.8892893 ], bias:-0.884594773775131, loss:0.5903525882384497\n",
      "epoch:1111, weight:[1.09323749 0.88946841], bias:-0.8848944002528476, loss:0.5903328468796041\n",
      "epoch:1112, weight:[1.09351231 0.88964753], bias:-0.8851938507400025, loss:0.5903131130073042\n",
      "epoch:1113, weight:[1.09378719 0.88982665], bias:-0.8854931257182924, loss:0.5902933866076677\n",
      "epoch:1114, weight:[1.09406212 0.89000578], bias:-0.885792225667615, loss:0.5902736676668915\n",
      "epoch:1115, weight:[1.0943371  0.89018492], bias:-0.8860911510660748, loss:0.5902539561712494\n",
      "epoch:1116, weight:[1.09461212 0.89036406], bias:-0.8863899023899913, loss:0.5902342521070936\n",
      "epoch:1117, weight:[1.0948872  0.89054321], bias:-0.8866884801139046, loss:0.5902145554608522\n",
      "epoch:1118, weight:[1.09516233 0.89072236], bias:-0.8869868847105832, loss:0.5901948662190301\n",
      "epoch:1119, weight:[1.09543751 0.89090152], bias:-0.8872851166510305, loss:0.590175184368207\n",
      "epoch:1120, weight:[1.09571273 0.89108069], bias:-0.8875831764044918, loss:0.5901555098950384\n",
      "epoch:1121, weight:[1.09598801 0.89125985], bias:-0.8878810644384607, loss:0.5901358427862543\n",
      "epoch:1122, weight:[1.09626334 0.89143903], bias:-0.8881787812186863, loss:0.5901161830286578\n",
      "epoch:1123, weight:[1.09653871 0.8916182 ], bias:-0.8884763272091798, loss:0.5900965306091265\n",
      "epoch:1124, weight:[1.09681413 0.89179739], bias:-0.888773702872221, loss:0.5900768855146098\n",
      "epoch:1125, weight:[1.09708961 0.89197657], bias:-0.8890709086683652, loss:0.59005724773213\n",
      "epoch:1126, weight:[1.09736513 0.89215576], bias:-0.8893679450564501, loss:0.5900376172487811\n",
      "epoch:1127, weight:[1.09764069 0.89233495], bias:-0.8896648124936019, loss:0.5900179940517282\n",
      "epoch:1128, weight:[1.09791631 0.89251414], bias:-0.889961511435242, loss:0.5899983781282071\n",
      "epoch:1129, weight:[1.09819197 0.89269334], bias:-0.8902580423350944, loss:0.5899787694655237\n",
      "epoch:1130, weight:[1.09846769 0.89287254], bias:-0.8905544056451911, loss:0.5899591680510539\n",
      "epoch:1131, weight:[1.09874344 0.89305174], bias:-0.8908506018158793, loss:0.5899395738722419\n",
      "epoch:1132, weight:[1.09901925 0.89323094], bias:-0.8911466312958278, loss:0.5899199869166017\n",
      "epoch:1133, weight:[1.0992951  0.89341014], bias:-0.8914424945320336, loss:0.5899004071717143\n",
      "epoch:1134, weight:[1.099571   0.89358934], bias:-0.8917381919698281, loss:0.5898808346252289\n",
      "epoch:1135, weight:[1.09984695 0.89376855], bias:-0.8920337240528835, loss:0.5898612692648618\n",
      "epoch:1136, weight:[1.10012294 0.89394775], bias:-0.8923290912232197, loss:0.5898417110783957\n",
      "epoch:1137, weight:[1.10039898 0.89412696], bias:-0.8926242939212102, loss:0.5898221600536793\n",
      "epoch:1138, weight:[1.10067507 0.89430616], bias:-0.8929193325855888, loss:0.5898026161786271\n",
      "epoch:1139, weight:[1.1009512  0.89448536], bias:-0.8932142076534554, loss:0.5897830794412188\n",
      "epoch:1140, weight:[1.10122738 0.89466457], bias:-0.8935089195602831, loss:0.5897635498294985\n",
      "epoch:1141, weight:[1.1015036  0.89484377], bias:-0.8938034687399238, loss:0.5897440273315748\n",
      "epoch:1142, weight:[1.10177987 0.89502297], bias:-0.8940978556246149, loss:0.58972451193562\n",
      "epoch:1143, weight:[1.10205618 0.89520217], bias:-0.8943920806449852, loss:0.5897050036298691\n",
      "epoch:1144, weight:[1.10233254 0.89538136], bias:-0.8946861442300615, loss:0.5896855024026201\n",
      "epoch:1145, weight:[1.10260895 0.89556056], bias:-0.8949800468072746, loss:0.5896660082422337\n",
      "epoch:1146, weight:[1.10288539 0.89573975], bias:-0.8952737888024653, loss:0.5896465211371318\n",
      "epoch:1147, weight:[1.10316189 0.89591894], bias:-0.8955673706398909, loss:0.5896270410757982\n",
      "epoch:1148, weight:[1.10343842 0.89609813], bias:-0.895860792742231, loss:0.5896075680467774\n",
      "epoch:1149, weight:[1.10371501 0.89627731], bias:-0.8961540555305937, loss:0.5895881020386741\n",
      "epoch:1150, weight:[1.10399163 0.8964565 ], bias:-0.8964471594245218, loss:0.5895686430401533\n",
      "epoch:1151, weight:[1.1042683  0.89663567], bias:-0.8967401048419988, loss:0.5895491910399401\n",
      "epoch:1152, weight:[1.10454501 0.89681485], bias:-0.8970328921994549, loss:0.5895297460268173\n",
      "epoch:1153, weight:[1.10482177 0.89699402], bias:-0.897325521911773, loss:0.5895103079896281\n",
      "epoch:1154, weight:[1.10509857 0.89717318], bias:-0.8976179943922944, loss:0.5894908769172728\n",
      "epoch:1155, weight:[1.10537542 0.89735234], bias:-0.8979103100528254, loss:0.5894714527987098\n",
      "epoch:1156, weight:[1.1056523 0.8975315], bias:-0.8982024693036428, loss:0.5894520356229553\n",
      "epoch:1157, weight:[1.10592923 0.89771065], bias:-0.8984944725534999, loss:0.589432625379082\n",
      "epoch:1158, weight:[1.1062062  0.89788979], bias:-0.8987863202096322, loss:0.5894132220562196\n",
      "epoch:1159, weight:[1.10648322 0.89806893], bias:-0.8990780126777638, loss:0.5893938256435535\n",
      "epoch:1160, weight:[1.10676028 0.89824806], bias:-0.8993695503621125, loss:0.589374436130325\n",
      "epoch:1161, weight:[1.10703737 0.89842719], bias:-0.8996609336653963, loss:0.5893550535058312\n",
      "epoch:1162, weight:[1.10731452 0.89860631], bias:-0.899952162988839, loss:0.5893356777594233\n",
      "epoch:1163, weight:[1.1075917  0.89878542], bias:-0.9002432387321755, loss:0.5893163088805079\n",
      "epoch:1164, weight:[1.10786892 0.89896453], bias:-0.9005341612936585, loss:0.5892969468585446\n",
      "epoch:1165, weight:[1.10814619 0.89914363], bias:-0.9008249310700632, loss:0.5892775916830479\n",
      "epoch:1166, weight:[1.1084235  0.89932272], bias:-0.901115548456694, loss:0.5892582433435852\n",
      "epoch:1167, weight:[1.10870085 0.8995018 ], bias:-0.9014060138473892, loss:0.5892389018297765\n",
      "epoch:1168, weight:[1.10897824 0.89968088], bias:-0.9016963276345275, loss:0.5892195671312946\n",
      "epoch:1169, weight:[1.10925567 0.89985995], bias:-0.9019864902090332, loss:0.5892002392378647\n",
      "epoch:1170, weight:[1.10953314 0.90003901], bias:-0.9022765019603821, loss:0.5891809181392632\n",
      "epoch:1171, weight:[1.10981066 0.90021806], bias:-0.9025663632766068, loss:0.5891616038253185\n",
      "epoch:1172, weight:[1.11008821 0.9003971 ], bias:-0.9028560745443023, loss:0.5891422962859095\n",
      "epoch:1173, weight:[1.1103658  0.90057614], bias:-0.903145636148632, loss:0.5891229955109663\n",
      "epoch:1174, weight:[1.11064344 0.90075516], bias:-0.9034350484733327, loss:0.589103701490469\n",
      "epoch:1175, weight:[1.11092111 0.90093417], bias:-0.9037243119007203, loss:0.5890844142144472\n",
      "epoch:1176, weight:[1.11119882 0.90111318], bias:-0.9040134268116957, loss:0.589065133672981\n",
      "epoch:1177, weight:[1.11147658 0.90129217], bias:-0.9043023935857495, loss:0.5890458598561988\n",
      "epoch:1178, weight:[1.11175437 0.90147116], bias:-0.904591212600968, loss:0.5890265927542783\n",
      "epoch:1179, weight:[1.1120322  0.90165013], bias:-0.9048798842340386, loss:0.5890073323574451\n",
      "epoch:1180, weight:[1.11231007 0.90182909], bias:-0.9051684088602552, loss:0.5889880786559739\n",
      "epoch:1181, weight:[1.11258798 0.90200805], bias:-0.9054567868535232, loss:0.5889688316401864\n",
      "epoch:1182, weight:[1.11286593 0.90218699], bias:-0.9057450185863652, loss:0.5889495913004518\n",
      "epoch:1183, weight:[1.11314392 0.90236592], bias:-0.9060331044299268, loss:0.5889303576271868\n",
      "epoch:1184, weight:[1.11342195 0.90254483], bias:-0.9063210447539809, loss:0.588911130610854\n",
      "epoch:1185, weight:[1.11370002 0.90272374], bias:-0.9066088399269339, loss:0.5888919102419633\n",
      "epoch:1186, weight:[1.11397812 0.90290263], bias:-0.9068964903158304, loss:0.58887269651107\n",
      "epoch:1187, weight:[1.11425626 0.90308152], bias:-0.9071839962863589, loss:0.5888534894087756\n",
      "epoch:1188, weight:[1.11453444 0.90326039], bias:-0.907471358202857, loss:0.5888342889257264\n",
      "epoch:1189, weight:[1.11481266 0.90343924], bias:-0.907758576428316, loss:0.5888150950526141\n",
      "epoch:1190, weight:[1.11509092 0.90361809], bias:-0.9080456513243872, loss:0.5887959077801755\n",
      "epoch:1191, weight:[1.11536921 0.90379692], bias:-0.908332583251386, loss:0.5887767270991907\n",
      "epoch:1192, weight:[1.11564754 0.90397573], bias:-0.9086193725682978, loss:0.5887575530004853\n",
      "epoch:1193, weight:[1.11592591 0.90415454], bias:-0.908906019632783, loss:0.5887383854749273\n",
      "epoch:1194, weight:[1.11620431 0.90433332], bias:-0.9091925248011816, loss:0.588719224513429\n",
      "epoch:1195, weight:[1.11648276 0.9045121 ], bias:-0.9094788884285193, loss:0.5887000701069456\n",
      "epoch:1196, weight:[1.11676124 0.90469086], bias:-0.9097651108685116, loss:0.588680922246475\n",
      "epoch:1197, weight:[1.11703975 0.90486961], bias:-0.9100511924735695, loss:0.5886617809230575\n",
      "epoch:1198, weight:[1.1173183  0.90504834], bias:-0.9103371335948042, loss:0.5886426461277761\n",
      "epoch:1199, weight:[1.11759689 0.90522706], bias:-0.9106229345820324, loss:0.5886235178517549\n",
      "epoch:1200, weight:[1.11787552 0.90540576], bias:-0.9109085957837809, loss:0.5886043960861603\n",
      "epoch:1201, weight:[1.11815418 0.90558445], bias:-0.9111941175472923, loss:0.5885852808221999\n",
      "epoch:1202, weight:[1.11843288 0.90576312], bias:-0.9114795002185292, loss:0.5885661720511213\n",
      "epoch:1203, weight:[1.11871161 0.90594177], bias:-0.9117647441421797, loss:0.5885470697642143\n",
      "epoch:1204, weight:[1.11899038 0.90612041], bias:-0.9120498496616619, loss:0.5885279739528081\n",
      "epoch:1205, weight:[1.11926919 0.90629903], bias:-0.9123348171191292, loss:0.5885088846082721\n",
      "epoch:1206, weight:[1.11954803 0.90647764], bias:-0.9126196468554749, loss:0.5884898017220158\n",
      "epoch:1207, weight:[1.1198269  0.90665623], bias:-0.9129043392103373, loss:0.5884707252854878\n",
      "epoch:1208, weight:[1.12010581 0.90683481], bias:-0.9131888945221045, loss:0.5884516552901765\n",
      "epoch:1209, weight:[1.12038476 0.90701336], bias:-0.913473313127919, loss:0.588432591727609\n",
      "epoch:1210, weight:[1.12066374 0.9071919 ], bias:-0.913757595363683, loss:0.5884135345893505\n",
      "epoch:1211, weight:[1.12094276 0.90737042], bias:-0.9140417415640626, loss:0.5883944838670057\n",
      "epoch:1212, weight:[1.12122181 0.90754893], bias:-0.9143257520624931, loss:0.5883754395522165\n",
      "epoch:1213, weight:[1.12150089 0.90772742], bias:-0.9146096271911837, loss:0.5883564016366631\n",
      "epoch:1214, weight:[1.12178001 0.90790588], bias:-0.9148933672811216, loss:0.5883373701120631\n",
      "epoch:1215, weight:[1.12205917 0.90808434], bias:-0.9151769726620778, loss:0.5883183449701714\n",
      "epoch:1216, weight:[1.12233836 0.90826277], bias:-0.9154604436626108, loss:0.58829932620278\n",
      "epoch:1217, weight:[1.12261758 0.90844118], bias:-0.9157437806100721, loss:0.5882803138017176\n",
      "epoch:1218, weight:[1.12289683 0.90861958], bias:-0.9160269838306102, loss:0.5882613077588498\n",
      "epoch:1219, weight:[1.12317612 0.90879795], bias:-0.9163100536491757, loss:0.5882423080660775\n",
      "epoch:1220, weight:[1.12345545 0.90897631], bias:-0.9165929903895258, loss:0.5882233147153384\n",
      "epoch:1221, weight:[1.1237348  0.90915465], bias:-0.9168757943742288, loss:0.5882043276986058\n",
      "epoch:1222, weight:[1.12401419 0.90933297], bias:-0.9171584659246691, loss:0.5881853470078883\n",
      "epoch:1223, weight:[1.12429362 0.90951127], bias:-0.9174410053610511, loss:0.5881663726352296\n",
      "epoch:1224, weight:[1.12457307 0.90968954], bias:-0.9177234130024043, loss:0.5881474045727086\n",
      "epoch:1225, weight:[1.12485256 0.9098678 ], bias:-0.9180056891665879, loss:0.5881284428124391\n",
      "epoch:1226, weight:[1.12513208 0.91004604], bias:-0.9182878341702948, loss:0.5881094873465688\n",
      "epoch:1227, weight:[1.12541164 0.91022426], bias:-0.9185698483290567, loss:0.5880905381672803\n",
      "epoch:1228, weight:[1.12569123 0.91040246], bias:-0.9188517319572483, loss:0.5880715952667891\n",
      "epoch:1229, weight:[1.12597085 0.91058063], bias:-0.9191334853680917, loss:0.5880526586373458\n",
      "epoch:1230, weight:[1.1262505  0.91075879], bias:-0.919415108873661, loss:0.5880337282712333\n",
      "epoch:1231, weight:[1.12653018 0.91093692], bias:-0.9196966027848867, loss:0.5880148041607687\n",
      "epoch:1232, weight:[1.1268099  0.91111504], bias:-0.9199779674115605, loss:0.5879958862983015\n",
      "epoch:1233, weight:[1.12708965 0.91129313], bias:-0.9202592030623387, loss:0.5879769746762138\n",
      "epoch:1234, weight:[1.12736943 0.9114712 ], bias:-0.9205403100447477, loss:0.5879580692869211\n",
      "epoch:1235, weight:[1.12764924 0.91164925], bias:-0.9208212886651879, loss:0.5879391701228706\n",
      "epoch:1236, weight:[1.12792909 0.91182727], bias:-0.9211021392289379, loss:0.5879202771765415\n",
      "epoch:1237, weight:[1.12820896 0.91200528], bias:-0.9213828620401591, loss:0.5879013904404452\n",
      "epoch:1238, weight:[1.12848887 0.91218326], bias:-0.9216634574018998, loss:0.5878825099071247\n",
      "epoch:1239, weight:[1.12876881 0.91236122], bias:-0.9219439256161, loss:0.5878636355691539\n",
      "epoch:1240, weight:[1.12904878 0.91253915], bias:-0.9222242669835948, loss:0.5878447674191387\n",
      "epoch:1241, weight:[1.12932878 0.91271707], bias:-0.9225044818041198, loss:0.5878259054497154\n",
      "epoch:1242, weight:[1.12960881 0.91289496], bias:-0.9227845703763142, loss:0.5878070496535512\n",
      "epoch:1243, weight:[1.12988887 0.91307282], bias:-0.9230645329977261, loss:0.5877882000233436\n",
      "epoch:1244, weight:[1.13016896 0.91325066], bias:-0.9233443699648156, loss:0.5877693565518208\n",
      "epoch:1245, weight:[1.13044908 0.91342848], bias:-0.9236240815729604, loss:0.587750519231741\n",
      "epoch:1246, weight:[1.13072924 0.91360628], bias:-0.9239036681164585, loss:0.5877316880558923\n",
      "epoch:1247, weight:[1.13100942 0.91378405], bias:-0.9241831298885337, loss:0.5877128630170918\n",
      "epoch:1248, weight:[1.13128963 0.9139618 ], bias:-0.9244624671813387, loss:0.5876940441081873\n",
      "epoch:1249, weight:[1.13156988 0.91413952], bias:-0.9247416802859599, loss:0.5876752313220548\n",
      "epoch:1250, weight:[1.13185015 0.91431722], bias:-0.9250207694924214, loss:0.5876564246515996\n",
      "epoch:1251, weight:[1.13213045 0.9144949 ], bias:-0.9252997350896889, loss:0.5876376240897566\n",
      "epoch:1252, weight:[1.13241079 0.91467254], bias:-0.9255785773656738, loss:0.5876188296294881\n",
      "epoch:1253, weight:[1.13269115 0.91485017], bias:-0.9258572966072378, loss:0.5876000412637857\n",
      "epoch:1254, weight:[1.13297154 0.91502777], bias:-0.9261358931001963, loss:0.5875812589856689\n",
      "epoch:1255, weight:[1.13325196 0.91520534], bias:-0.9264143671293227, loss:0.5875624827881858\n",
      "epoch:1256, weight:[1.13353241 0.91538289], bias:-0.9266927189783525, loss:0.5875437126644113\n",
      "epoch:1257, weight:[1.13381289 0.91556041], bias:-0.9269709489299873, loss:0.5875249486074491\n",
      "epoch:1258, weight:[1.1340934  0.91573791], bias:-0.9272490572658988, loss:0.587506190610429\n",
      "epoch:1259, weight:[1.13437394 0.91591538], bias:-0.9275270442667326, loss:0.5874874386665098\n",
      "epoch:1260, weight:[1.13465451 0.91609283], bias:-0.9278049102121125, loss:0.5874686927688758\n",
      "epoch:1261, weight:[1.1349351  0.91627024], bias:-0.9280826553806442, loss:0.587449952910739\n",
      "epoch:1262, weight:[1.13521573 0.91644764], bias:-0.9283602800499191, loss:0.5874312190853378\n",
      "epoch:1263, weight:[1.13549638 0.916625  ], bias:-0.9286377844965188, loss:0.5874124912859376\n",
      "epoch:1264, weight:[1.13577706 0.91680234], bias:-0.9289151689960183, loss:0.5873937695058292\n",
      "epoch:1265, weight:[1.13605777 0.91697965], bias:-0.9291924338229907, loss:0.5873750537383308\n",
      "epoch:1266, weight:[1.1363385  0.91715694], bias:-0.92946957925101, loss:0.5873563439767852\n",
      "epoch:1267, weight:[1.13661927 0.91733419], bias:-0.9297466055526561, loss:0.5873376402145619\n",
      "epoch:1268, weight:[1.13690006 0.91751142], bias:-0.9300235129995178, loss:0.5873189424450556\n",
      "epoch:1269, weight:[1.13718088 0.91768863], bias:-0.930300301862197, loss:0.5873002506616866\n",
      "epoch:1270, weight:[1.13746173 0.9178658 ], bias:-0.9305769724103127, loss:0.5872815648579005\n",
      "epoch:1271, weight:[1.13774261 0.91804295], bias:-0.9308535249125043, loss:0.5872628850271676\n",
      "epoch:1272, weight:[1.13802351 0.91822007], bias:-0.9311299596364359, loss:0.5872442111629839\n",
      "epoch:1273, weight:[1.13830444 0.91839716], bias:-0.9314062768487996, loss:0.5872255432588689\n",
      "epoch:1274, weight:[1.1385854  0.91857422], bias:-0.9316824768153197, loss:0.5872068813083676\n",
      "epoch:1275, weight:[1.13886638 0.91875126], bias:-0.931958559800756, loss:0.5871882253050493\n",
      "epoch:1276, weight:[1.13914739 0.91892826], bias:-0.9322345260689082, loss:0.5871695752425069\n",
      "epoch:1277, weight:[1.13942843 0.91910524], bias:-0.9325103758826188, loss:0.5871509311143581\n",
      "epoch:1278, weight:[1.1397095  0.91928219], bias:-0.9327861095037772, loss:0.587132292914244\n",
      "epoch:1279, weight:[1.13999059 0.91945911], bias:-0.9330617271933235, loss:0.5871136606358295\n",
      "epoch:1280, weight:[1.14027171 0.919636  ], bias:-0.9333372292112521, loss:0.5870950342728031\n",
      "epoch:1281, weight:[1.14055286 0.91981286], bias:-0.9336126158166151, loss:0.5870764138188767\n",
      "epoch:1282, weight:[1.14083403 0.91998969], bias:-0.9338878872675265, loss:0.5870577992677857\n",
      "epoch:1283, weight:[1.14111523 0.92016649], bias:-0.934163043821165, loss:0.5870391906132876\n",
      "epoch:1284, weight:[1.14139645 0.92034326], bias:-0.9344380857337784, loss:0.5870205878491641\n",
      "epoch:1285, weight:[1.1416777 0.92052  ], bias:-0.9347130132606869, loss:0.587001990969219\n",
      "epoch:1286, weight:[1.14195898 0.92069671], bias:-0.9349878266562867, loss:0.5869833999672784\n",
      "epoch:1287, weight:[1.14224028 0.9208734 ], bias:-0.9352625261740533, loss:0.5869648148371911\n",
      "epoch:1288, weight:[1.14252161 0.92105005], bias:-0.9355371120665456, loss:0.5869462355728289\n",
      "epoch:1289, weight:[1.14280296 0.92122667], bias:-0.9358115845854089, loss:0.5869276621680845\n",
      "epoch:1290, weight:[1.14308434 0.92140326], bias:-0.936085943981379, loss:0.586909094616873\n",
      "epoch:1291, weight:[1.14336575 0.92157982], bias:-0.9363601905042852, loss:0.586890532913132\n",
      "epoch:1292, weight:[1.14364718 0.92175635], bias:-0.936634324403054, loss:0.5868719770508201\n",
      "epoch:1293, weight:[1.14392863 0.92193284], bias:-0.9369083459257128, loss:0.5868534270239176\n",
      "epoch:1294, weight:[1.14421011 0.92210931], bias:-0.937182255319393, loss:0.5868348828264262\n",
      "epoch:1295, weight:[1.14449162 0.92228574], bias:-0.9374560528303337, loss:0.5868163444523685\n",
      "epoch:1296, weight:[1.14477315 0.92246215], bias:-0.9377297387038852, loss:0.5867978118957891\n",
      "epoch:1297, weight:[1.14505471 0.92263852], bias:-0.9380033131845121, loss:0.5867792851507527\n",
      "epoch:1298, weight:[1.14533629 0.92281486], bias:-0.9382767765157972, loss:0.5867607642113452\n",
      "epoch:1299, weight:[1.14561789 0.92299117], bias:-0.9385501289404445, loss:0.5867422490716726\n",
      "epoch:1300, weight:[1.14589952 0.92316745], bias:-0.9388233707002829, loss:0.5867237397258624\n",
      "epoch:1301, weight:[1.14618118 0.92334369], bias:-0.9390965020362693, loss:0.586705236168062\n",
      "epoch:1302, weight:[1.14646286 0.9235199 ], bias:-0.9393695231884923, loss:0.5866867383924388\n",
      "epoch:1303, weight:[1.14674456 0.92369608], bias:-0.9396424343961753, loss:0.5866682463931805\n",
      "epoch:1304, weight:[1.14702629 0.92387223], bias:-0.9399152358976799, loss:0.5866497601644951\n",
      "epoch:1305, weight:[1.14730804 0.92404835], bias:-0.9401879279305092, loss:0.5866312797006097\n",
      "epoch:1306, weight:[1.14758982 0.92422443], bias:-0.9404605107313113, loss:0.5866128049957718\n",
      "epoch:1307, weight:[1.14787162 0.92440048], bias:-0.9407329845358825, loss:0.5865943360442486\n",
      "epoch:1308, weight:[1.14815344 0.92457649], bias:-0.9410053495791705, loss:0.586575872840326\n",
      "epoch:1309, weight:[1.14843529 0.92475248], bias:-0.9412776060952777, loss:0.5865574153783094\n",
      "epoch:1310, weight:[1.14871716 0.92492843], bias:-0.9415497543174645, loss:0.5865389636525241\n",
      "epoch:1311, weight:[1.14899905 0.92510434], bias:-0.9418217944781527, loss:0.5865205176573137\n",
      "epoch:1312, weight:[1.14928097 0.92528023], bias:-0.9420937268089288, loss:0.5865020773870409\n",
      "epoch:1313, weight:[1.14956291 0.92545608], bias:-0.9423655515405466, loss:0.5864836428360873\n",
      "epoch:1314, weight:[1.14984488 0.92563189], bias:-0.9426372689029311, loss:0.5864652139988532\n",
      "epoch:1315, weight:[1.15012686 0.92580767], bias:-0.9429088791251815, loss:0.5864467908697574\n",
      "epoch:1316, weight:[1.15040887 0.92598342], bias:-0.9431803824355743, loss:0.5864283734432371\n",
      "epoch:1317, weight:[1.15069091 0.92615914], bias:-0.9434517790615666, loss:0.5864099617137477\n",
      "epoch:1318, weight:[1.15097297 0.92633481], bias:-0.9437230692297991, loss:0.586391555675763\n",
      "epoch:1319, weight:[1.15125504 0.92651046], bias:-0.9439942531660995, loss:0.5863731553237747\n",
      "epoch:1320, weight:[1.15153715 0.92668607], bias:-0.9442653310954854, loss:0.5863547606522924\n",
      "epoch:1321, weight:[1.15181927 0.92686165], bias:-0.9445363032421675, loss:0.5863363716558436\n",
      "epoch:1322, weight:[1.15210142 0.92703719], bias:-0.944807169829553, loss:0.586317988328974\n",
      "epoch:1323, weight:[1.15238359 0.92721269], bias:-0.9450779310802482, loss:0.5862996106662454\n",
      "epoch:1324, weight:[1.15266578 0.92738817], bias:-0.9453485872160619, loss:0.5862812386622389\n",
      "epoch:1325, weight:[1.152948  0.9275636], bias:-0.9456191384580085, loss:0.586262872311552\n",
      "epoch:1326, weight:[1.15323024 0.927739  ], bias:-0.945889585026311, loss:0.5862445116087992\n",
      "epoch:1327, weight:[1.15351249 0.92791437], bias:-0.9461599271404041, loss:0.5862261565486123\n",
      "epoch:1328, weight:[1.15379478 0.9280897 ], bias:-0.9464301650189371, loss:0.5862078071256408\n",
      "epoch:1329, weight:[1.15407708 0.92826499], bias:-0.946700298879777, loss:0.5861894633345505\n",
      "epoch:1330, weight:[1.1543594  0.92844025], bias:-0.9469703289400119, loss:0.5861711251700235\n",
      "epoch:1331, weight:[1.15464175 0.92861548], bias:-0.9472402554159532, loss:0.5861527926267595\n",
      "epoch:1332, weight:[1.15492412 0.92879066], bias:-0.9475100785231395, loss:0.5861344656994745\n",
      "epoch:1333, weight:[1.15520651 0.92896582], bias:-0.947779798476339, loss:0.5861161443829004\n",
      "epoch:1334, weight:[1.15548892 0.92914093], bias:-0.9480494154895525, loss:0.5860978286717861\n",
      "epoch:1335, weight:[1.15577135 0.92931601], bias:-0.9483189297760166, loss:0.5860795185608964\n",
      "epoch:1336, weight:[1.15605381 0.92949105], bias:-0.9485883415482068, loss:0.5860612140450123\n",
      "epoch:1337, weight:[1.15633628 0.92966606], bias:-0.9488576510178398, loss:0.5860429151189315\n",
      "epoch:1338, weight:[1.15661878 0.92984103], bias:-0.9491268583958771, loss:0.5860246217774661\n",
      "epoch:1339, weight:[1.1569013  0.93001596], bias:-0.9493959638925275, loss:0.5860063340154453\n",
      "epoch:1340, weight:[1.15718384 0.93019086], bias:-0.9496649677172502, loss:0.5859880518277137\n",
      "epoch:1341, weight:[1.1574664  0.93036572], bias:-0.9499338700787577, loss:0.5859697752091312\n",
      "epoch:1342, weight:[1.15774898 0.93054054], bias:-0.9502026711850187, loss:0.5859515041545736\n",
      "epoch:1343, weight:[1.15803158 0.93071533], bias:-0.9504713712432605, loss:0.585933238658932\n",
      "epoch:1344, weight:[1.1583142  0.93089007], bias:-0.9507399704599728, loss:0.5859149787171125\n",
      "epoch:1345, weight:[1.15859685 0.93106478], bias:-0.9510084690409097, loss:0.585896724324037\n",
      "epoch:1346, weight:[1.15887951 0.93123946], bias:-0.9512768671910931, loss:0.5858784754746418\n",
      "epoch:1347, weight:[1.15916219 0.93141409], bias:-0.9515451651148148, loss:0.585860232163879\n",
      "epoch:1348, weight:[1.1594449  0.93158869], bias:-0.9518133630156403, loss:0.5858419943867148\n",
      "epoch:1349, weight:[1.15972762 0.93176325], bias:-0.952081461096411, loss:0.5858237621381307\n",
      "epoch:1350, weight:[1.16001037 0.93193777], bias:-0.952349459559247, loss:0.5858055354131232\n",
      "epoch:1351, weight:[1.16029313 0.93211226], bias:-0.95261735860555, loss:0.5857873142067026\n",
      "epoch:1352, weight:[1.16057592 0.9322867 ], bias:-0.9528851584360061, loss:0.5857690985138946\n",
      "epoch:1353, weight:[1.16085872 0.93246111], bias:-0.9531528592505886, loss:0.5857508883297388\n",
      "epoch:1354, weight:[1.16114155 0.93263548], bias:-0.9534204612485605, loss:0.5857326836492893\n",
      "epoch:1355, weight:[1.16142439 0.93280981], bias:-0.9536879646284776, loss:0.5857144844676142\n",
      "epoch:1356, weight:[1.16170726 0.93298411], bias:-0.953955369588191, loss:0.5856962907797966\n",
      "epoch:1357, weight:[1.16199014 0.93315836], bias:-0.9542226763248499, loss:0.5856781025809324\n",
      "epoch:1358, weight:[1.16227304 0.93333258], bias:-0.9544898850349042, loss:0.5856599198661327\n",
      "epoch:1359, weight:[1.16255597 0.93350676], bias:-0.9547569959141072, loss:0.5856417426305218\n",
      "epoch:1360, weight:[1.16283891 0.93368089], bias:-0.9550240091575186, loss:0.5856235708692378\n",
      "epoch:1361, weight:[1.16312187 0.93385499], bias:-0.9552909249595068, loss:0.5856054045774332\n",
      "epoch:1362, weight:[1.16340485 0.93402905], bias:-0.9555577435137519, loss:0.5855872437502728\n",
      "epoch:1363, weight:[1.16368785 0.93420307], bias:-0.9558244650132479, loss:0.5855690883829366\n",
      "epoch:1364, weight:[1.16397087 0.93437706], bias:-0.9560910896503058, loss:0.5855509384706169\n",
      "epoch:1365, weight:[1.16425391 0.934551  ], bias:-0.956357617616556, loss:0.5855327940085195\n",
      "epoch:1366, weight:[1.16453697 0.9347249 ], bias:-0.9566240491029511, loss:0.5855146549918642\n",
      "epoch:1367, weight:[1.16482004 0.93489876], bias:-0.9568903842997681, loss:0.5854965214158828\n",
      "epoch:1368, weight:[1.16510314 0.93507259], bias:-0.9571566233966118, loss:0.5854783932758214\n",
      "epoch:1369, weight:[1.16538625 0.93524637], bias:-0.9574227665824164, loss:0.5854602705669386\n",
      "epoch:1370, weight:[1.16566938 0.93542012], bias:-0.9576888140454489, loss:0.5854421532845059\n",
      "epoch:1371, weight:[1.16595253 0.93559382], bias:-0.9579547659733112, loss:0.5854240414238078\n",
      "epoch:1372, weight:[1.1662357  0.93576748], bias:-0.9582206225529429, loss:0.5854059349801415\n",
      "epoch:1373, weight:[1.16651889 0.93594111], bias:-0.958486383970624, loss:0.585387833948817\n",
      "epoch:1374, weight:[1.1668021  0.93611469], bias:-0.9587520504119769, loss:0.5853697383251572\n",
      "epoch:1375, weight:[1.16708532 0.93628824], bias:-0.9590176220619693, loss:0.5853516481044969\n",
      "epoch:1376, weight:[1.16736856 0.93646174], bias:-0.9592830991049168, loss:0.585333563282184\n",
      "epoch:1377, weight:[1.16765183 0.9366352 ], bias:-0.9595484817244855, loss:0.5853154838535786\n",
      "epoch:1378, weight:[1.1679351  0.93680862], bias:-0.9598137701036938, loss:0.5852974098140528\n",
      "epoch:1379, weight:[1.1682184 0.936982 ], bias:-0.960078964424916, loss:0.5852793411589914\n",
      "epoch:1380, weight:[1.16850172 0.93715534], bias:-0.9603440648698839, loss:0.585261277883791\n",
      "epoch:1381, weight:[1.16878505 0.93732864], bias:-0.9606090716196894, loss:0.5852432199838605\n",
      "epoch:1382, weight:[1.1690684 0.9375019], bias:-0.9608739848547877, loss:0.585225167454621\n",
      "epoch:1383, weight:[1.16935177 0.93767512], bias:-0.9611388047549986, loss:0.5852071202915053\n",
      "epoch:1384, weight:[1.16963515 0.9378483 ], bias:-0.9614035314995099, loss:0.5851890784899578\n",
      "epoch:1385, weight:[1.16991856 0.93802143], bias:-0.9616681652668793, loss:0.5851710420454354\n",
      "epoch:1386, weight:[1.17020198 0.93819453], bias:-0.9619327062350372, loss:0.5851530109534058\n",
      "epoch:1387, weight:[1.17048541 0.93836758], bias:-0.962197154581289, loss:0.5851349852093493\n",
      "epoch:1388, weight:[1.17076887 0.93854059], bias:-0.962461510482317, loss:0.5851169648087573\n",
      "epoch:1389, weight:[1.17105234 0.93871356], bias:-0.9627257741141838, loss:0.5850989497471327\n",
      "epoch:1390, weight:[1.17133583 0.93888649], bias:-0.9629899456523339, loss:0.5850809400199897\n",
      "epoch:1391, weight:[1.17161934 0.93905937], bias:-0.9632540252715961, loss:0.5850629356228544\n",
      "epoch:1392, weight:[1.17190286 0.93923222], bias:-0.9635180131461866, loss:0.5850449365512636\n",
      "epoch:1393, weight:[1.17218641 0.93940502], bias:-0.9637819094497104, loss:0.5850269428007654\n",
      "epoch:1394, weight:[1.17246996 0.93957778], bias:-0.9640457143551644, loss:0.5850089543669198\n",
      "epoch:1395, weight:[1.17275354 0.9397505 ], bias:-0.9643094280349394, loss:0.584990971245297\n",
      "epoch:1396, weight:[1.17303713 0.93992318], bias:-0.9645730506608223, loss:0.5849729934314786\n",
      "epoch:1397, weight:[1.17332074 0.94009581], bias:-0.9648365824039989, loss:0.5849550209210569\n",
      "epoch:1398, weight:[1.17360436 0.9402684 ], bias:-0.9651000234350559, loss:0.5849370537096357\n",
      "epoch:1399, weight:[1.17388801 0.94044095], bias:-0.965363373923983, loss:0.584919091792829\n",
      "epoch:1400, weight:[1.17417166 0.94061346], bias:-0.9656266340401758, loss:0.5849011351662617\n",
      "epoch:1401, weight:[1.17445534 0.94078592], bias:-0.9658898039524375, loss:0.5848831838255699\n",
      "epoch:1402, weight:[1.17473903 0.94095835], bias:-0.9661528838289816, loss:0.5848652377663995\n",
      "epoch:1403, weight:[1.17502274 0.94113072], bias:-0.9664158738374338, loss:0.5848472969844076\n",
      "epoch:1404, weight:[1.17530646 0.94130306], bias:-0.9666787741448346, loss:0.5848293614752614\n",
      "epoch:1405, weight:[1.1755902  0.94147535], bias:-0.9669415849176414, loss:0.584811431234639\n",
      "epoch:1406, weight:[1.17587396 0.9416476 ], bias:-0.9672043063217307, loss:0.5847935062582285\n",
      "epoch:1407, weight:[1.17615773 0.94181981], bias:-0.9674669385224005, loss:0.5847755865417281\n",
      "epoch:1408, weight:[1.17644152 0.94199198], bias:-0.9677294816843725, loss:0.5847576720808471\n",
      "epoch:1409, weight:[1.17672532 0.9421641 ], bias:-0.9679919359717939, loss:0.5847397628713041\n",
      "epoch:1410, weight:[1.17700914 0.94233617], bias:-0.9682543015482404, loss:0.5847218589088284\n",
      "epoch:1411, weight:[1.17729298 0.94250821], bias:-0.9685165785767178, loss:0.5847039601891589\n",
      "epoch:1412, weight:[1.17757683 0.9426802 ], bias:-0.9687787672196642, loss:0.5846860667080451\n",
      "epoch:1413, weight:[1.1778607  0.94285215], bias:-0.9690408676389525, loss:0.584668178461246\n",
      "epoch:1414, weight:[1.17814458 0.94302405], bias:-0.9693028799958925, loss:0.5846502954445308\n",
      "epoch:1415, weight:[1.17842848 0.94319591], bias:-0.9695648044512328, loss:0.584632417653678\n",
      "epoch:1416, weight:[1.17871239 0.94336773], bias:-0.9698266411651635, loss:0.5846145450844765\n",
      "epoch:1417, weight:[1.17899632 0.9435395 ], bias:-0.9700883902973175, loss:0.5845966777327247\n",
      "epoch:1418, weight:[1.17928027 0.94371123], bias:-0.9703500520067736, loss:0.5845788155942304\n",
      "epoch:1419, weight:[1.17956423 0.94388292], bias:-0.970611626452058, loss:0.5845609586648115\n",
      "epoch:1420, weight:[1.1798482  0.94405456], bias:-0.9708731137911467, loss:0.584543106940295\n",
      "epoch:1421, weight:[1.18013219 0.94422615], bias:-0.9711345141814673, loss:0.5845252604165175\n",
      "epoch:1422, weight:[1.1804162  0.94439771], bias:-0.9713958277799017, loss:0.5845074190893255\n",
      "epoch:1423, weight:[1.18070022 0.94456921], bias:-0.9716570547427876, loss:0.5844895829545739\n",
      "epoch:1424, weight:[1.18098426 0.94474068], bias:-0.971918195225921, loss:0.5844717520081281\n",
      "epoch:1425, weight:[1.18126831 0.9449121 ], bias:-0.972179249384558, loss:0.5844539262458619\n",
      "epoch:1426, weight:[1.18155237 0.94508347], bias:-0.972440217373417, loss:0.5844361056636587\n",
      "epoch:1427, weight:[1.18183645 0.9452548 ], bias:-0.9727010993466808, loss:0.5844182902574108\n",
      "epoch:1428, weight:[1.18212055 0.94542609], bias:-0.9729618954579987, loss:0.5844004800230199\n",
      "epoch:1429, weight:[1.18240466 0.94559733], bias:-0.9732226058604885, loss:0.5843826749563971\n",
      "epoch:1430, weight:[1.18268878 0.94576853], bias:-0.9734832307067385, loss:0.5843648750534615\n",
      "epoch:1431, weight:[1.18297292 0.94593968], bias:-0.9737437701488094, loss:0.5843470803101418\n",
      "epoch:1432, weight:[1.18325707 0.94611079], bias:-0.974004224338237, loss:0.5843292907223759\n",
      "epoch:1433, weight:[1.18354124 0.94628185], bias:-0.9742645934260331, loss:0.58431150628611\n",
      "epoch:1434, weight:[1.18382542 0.94645287], bias:-0.9745248775626886, loss:0.584293726997299\n",
      "epoch:1435, weight:[1.18410962 0.94662384], bias:-0.9747850768981748, loss:0.5842759528519074\n",
      "epoch:1436, weight:[1.18439383 0.94679477], bias:-0.9750451915819459, loss:0.5842581838459076\n",
      "epoch:1437, weight:[1.18467806 0.94696565], bias:-0.9753052217629404, loss:0.5842404199752806\n",
      "epoch:1438, weight:[1.1849623  0.94713649], bias:-0.9755651675895837, loss:0.5842226612360167\n",
      "epoch:1439, weight:[1.18524655 0.94730728], bias:-0.9758250292097895, loss:0.5842049076241143\n",
      "epoch:1440, weight:[1.18553082 0.94747802], bias:-0.9760848067709625, loss:0.5841871591355807\n",
      "epoch:1441, weight:[1.1858151  0.94764872], bias:-0.9763445004199997, loss:0.5841694157664307\n",
      "epoch:1442, weight:[1.18609939 0.94781938], bias:-0.9766041103032923, loss:0.5841516775126885\n",
      "epoch:1443, weight:[1.1863837  0.94798999], bias:-0.9768636365667283, loss:0.5841339443703861\n",
      "epoch:1444, weight:[1.18666803 0.94816055], bias:-0.9771230793556939, loss:0.5841162163355645\n",
      "epoch:1445, weight:[1.18695236 0.94833107], bias:-0.9773824388150756, loss:0.5840984934042722\n",
      "epoch:1446, weight:[1.18723671 0.94850154], bias:-0.977641715089262, loss:0.5840807755725664\n",
      "epoch:1447, weight:[1.18752108 0.94867197], bias:-0.9779009083221462, loss:0.584063062836512\n",
      "epoch:1448, weight:[1.18780545 0.94884235], bias:-0.9781600186571268, loss:0.5840453551921827\n",
      "epoch:1449, weight:[1.18808985 0.94901268], bias:-0.9784190462371106, loss:0.5840276526356598\n",
      "epoch:1450, weight:[1.18837425 0.94918297], bias:-0.9786779912045143, loss:0.5840099551630327\n",
      "epoch:1451, weight:[1.18865867 0.94935321], bias:-0.9789368537012662, loss:0.5839922627703991\n",
      "epoch:1452, weight:[1.1889431  0.94952341], bias:-0.979195633868808, loss:0.5839745754538642\n",
      "epoch:1453, weight:[1.18922754 0.94969356], bias:-0.9794543318480973, loss:0.5839568932095415\n",
      "epoch:1454, weight:[1.189512   0.94986366], bias:-0.9797129477796085, loss:0.5839392160335521\n",
      "epoch:1455, weight:[1.18979647 0.95003372], bias:-0.9799714818033355, loss:0.5839215439220253\n",
      "epoch:1456, weight:[1.19008096 0.95020373], bias:-0.9802299340587931, loss:0.5839038768710977\n",
      "epoch:1457, weight:[1.19036546 0.95037369], bias:-0.9804883046850191, loss:0.5838862148769138\n",
      "epoch:1458, weight:[1.19064997 0.95054361], bias:-0.9807465938205758, loss:0.5838685579356261\n",
      "epoch:1459, weight:[1.19093449 0.95071348], bias:-0.9810048016035521, loss:0.5838509060433941\n",
      "epoch:1460, weight:[1.19121903 0.95088331], bias:-0.9812629281715651, loss:0.5838332591963858\n",
      "epoch:1461, weight:[1.19150358 0.95105308], bias:-0.9815209736617623, loss:0.5838156173907761\n",
      "epoch:1462, weight:[1.19178814 0.95122282], bias:-0.981778938210823, loss:0.5837979806227476\n",
      "epoch:1463, weight:[1.19207271 0.9513925 ], bias:-0.9820368219549602, loss:0.5837803488884905\n",
      "epoch:1464, weight:[1.1923573  0.95156214], bias:-0.9822946250299226, loss:0.5837627221842022\n",
      "epoch:1465, weight:[1.1926419  0.95173173], bias:-0.9825523475709962, loss:0.5837451005060879\n",
      "epoch:1466, weight:[1.19292651 0.95190127], bias:-0.9828099897130059, loss:0.5837274838503596\n",
      "epoch:1467, weight:[1.19321114 0.95207077], bias:-0.9830675515903178, loss:0.5837098722132371\n",
      "epoch:1468, weight:[1.19349578 0.95224022], bias:-0.9833250333368403, loss:0.5836922655909477\n",
      "epoch:1469, weight:[1.19378043 0.95240962], bias:-0.9835824350860265, loss:0.5836746639797252\n",
      "epoch:1470, weight:[1.19406509 0.95257897], bias:-0.9838397569708754, loss:0.583657067375811\n",
      "epoch:1471, weight:[1.19434976 0.95274828], bias:-0.9840969991239341, loss:0.5836394757754543\n",
      "epoch:1472, weight:[1.19463445 0.95291754], bias:-0.9843541616772992, loss:0.5836218891749099\n",
      "epoch:1473, weight:[1.19491915 0.95308675], bias:-0.9846112447626186, loss:0.5836043075704411\n",
      "epoch:1474, weight:[1.19520386 0.95325592], bias:-0.9848682485110934, loss:0.583586730958318\n",
      "epoch:1475, weight:[1.19548859 0.95342504], bias:-0.9851251730534795, loss:0.5835691593348172\n",
      "epoch:1476, weight:[1.19577332 0.95359411], bias:-0.9853820185200891, loss:0.5835515926962227\n",
      "epoch:1477, weight:[1.19605807 0.95376313], bias:-0.9856387850407928, loss:0.5835340310388255\n",
      "epoch:1478, weight:[1.19634283 0.95393211], bias:-0.9858954727450211, loss:0.5835164743589227\n",
      "epoch:1479, weight:[1.1966276  0.95410103], bias:-0.9861520817617659, loss:0.5834989226528199\n",
      "epoch:1480, weight:[1.19691239 0.95426991], bias:-0.9864086122195828, loss:0.5834813759168278\n",
      "epoch:1481, weight:[1.19719718 0.95443875], bias:-0.9866650642465917, loss:0.583463834147265\n",
      "epoch:1482, weight:[1.19748199 0.95460753], bias:-0.9869214379704797, loss:0.5834462973404565\n",
      "epoch:1483, weight:[1.19776681 0.95477627], bias:-0.9871777335185018, loss:0.5834287654927341\n",
      "epoch:1484, weight:[1.19805164 0.95494495], bias:-0.9874339510174832, loss:0.5834112386004362\n",
      "epoch:1485, weight:[1.19833648 0.95511359], bias:-0.9876900905938205, loss:0.5833937166599079\n",
      "epoch:1486, weight:[1.19862134 0.95528219], bias:-0.9879461523734836, loss:0.5833761996675009\n",
      "epoch:1487, weight:[1.1989062  0.95545073], bias:-0.9882021364820173, loss:0.5833586876195742\n",
      "epoch:1488, weight:[1.19919108 0.95561923], bias:-0.9884580430445429, loss:0.5833411805124916\n",
      "epoch:1489, weight:[1.19947597 0.95578767], bias:-0.9887138721857597, loss:0.5833236783426258\n",
      "epoch:1490, weight:[1.19976087 0.95595607], bias:-0.9889696240299468, loss:0.5833061811063536\n",
      "epoch:1491, weight:[1.20004578 0.95612442], bias:-0.9892252987009649, loss:0.5832886888000602\n",
      "epoch:1492, weight:[1.2003307  0.95629273], bias:-0.9894808963222572, loss:0.5832712014201363\n",
      "epoch:1493, weight:[1.20061564 0.95646098], bias:-0.9897364170168518, loss:0.5832537189629787\n",
      "epoch:1494, weight:[1.20090058 0.95662919], bias:-0.9899918609073628, loss:0.5832362414249915\n",
      "epoch:1495, weight:[1.20118554 0.95679734], bias:-0.9902472281159922, loss:0.5832187688025844\n",
      "epoch:1496, weight:[1.20147051 0.95696545], bias:-0.9905025187645311, loss:0.5832013010921736\n",
      "epoch:1497, weight:[1.20175548 0.95713351], bias:-0.9907577329743616, loss:0.5831838382901816\n",
      "epoch:1498, weight:[1.20204047 0.95730152], bias:-0.9910128708664583, loss:0.5831663803930371\n",
      "epoch:1499, weight:[1.20232547 0.95746949], bias:-0.9912679325613897, loss:0.5831489273971754\n",
      "epoch:1500, weight:[1.20261049 0.9576374 ], bias:-0.99152291817932, loss:0.5831314792990372\n",
      "epoch:1501, weight:[1.20289551 0.95780527], bias:-0.9917778278400106, loss:0.5831140360950696\n",
      "epoch:1502, weight:[1.20318054 0.95797308], bias:-0.9920326616628212, loss:0.5830965977817266\n",
      "epoch:1503, weight:[1.20346558 0.95814085], bias:-0.9922874197667122, loss:0.583079164355467\n",
      "epoch:1504, weight:[1.20375064 0.95830857], bias:-0.9925421022702454, loss:0.5830617358127568\n",
      "epoch:1505, weight:[1.2040357  0.95847624], bias:-0.992796709291586, loss:0.583044312150067\n",
      "epoch:1506, weight:[1.20432078 0.95864386], bias:-0.993051240948504, loss:0.5830268933638757\n",
      "epoch:1507, weight:[1.20460587 0.95881143], bias:-0.9933056973583758, loss:0.583009479450666\n",
      "epoch:1508, weight:[1.20489096 0.95897895], bias:-0.9935600786381853, loss:0.5829920704069272\n",
      "epoch:1509, weight:[1.20517607 0.95914643], bias:-0.993814384904526, loss:0.5829746662291548\n",
      "epoch:1510, weight:[1.20546119 0.95931385], bias:-0.9940686162736021, loss:0.5829572669138501\n",
      "epoch:1511, weight:[1.20574632 0.95948123], bias:-0.99432277286123, loss:0.5829398724575199\n",
      "epoch:1512, weight:[1.20603146 0.95964855], bias:-0.9945768547828402, loss:0.5829224828566771\n",
      "epoch:1513, weight:[1.20631661 0.95981583], bias:-0.994830862153478, loss:0.5829050981078404\n",
      "epoch:1514, weight:[1.20660177 0.95998305], bias:-0.995084795087806, loss:0.5828877182075342\n",
      "epoch:1515, weight:[1.20688694 0.96015023], bias:-0.9953386537001045, loss:0.5828703431522887\n",
      "epoch:1516, weight:[1.20717212 0.96031736], bias:-0.9955924381042738, loss:0.5828529729386396\n",
      "epoch:1517, weight:[1.20745731 0.96048444], bias:-0.9958461484138351, loss:0.5828356075631285\n",
      "epoch:1518, weight:[1.20774251 0.96065147], bias:-0.9960997847419323, loss:0.5828182470223026\n",
      "epoch:1519, weight:[1.20802772 0.96081845], bias:-0.9963533472013333, loss:0.5828008913127145\n",
      "epoch:1520, weight:[1.20831294 0.96098538], bias:-0.9966068359044314, loss:0.5827835404309227\n",
      "epoch:1521, weight:[1.20859817 0.96115226], bias:-0.996860250963247, loss:0.5827661943734914\n",
      "epoch:1522, weight:[1.20888341 0.96131909], bias:-0.9971135924894285, loss:0.5827488531369899\n",
      "epoch:1523, weight:[1.20916866 0.96148587], bias:-0.9973668605942543, loss:0.5827315167179932\n",
      "epoch:1524, weight:[1.20945392 0.9616526 ], bias:-0.9976200553886337, loss:0.5827141851130819\n",
      "epoch:1525, weight:[1.20973919 0.96181928], bias:-0.997873176983109, loss:0.5826968583188421\n",
      "epoch:1526, weight:[1.21002447 0.96198591], bias:-0.998126225487856, loss:0.582679536331865\n",
      "epoch:1527, weight:[1.21030975 0.96215249], bias:-0.9983792010126862, loss:0.5826622191487475\n",
      "epoch:1528, weight:[1.21059505 0.96231902], bias:-0.9986321036670476, loss:0.5826449067660918\n",
      "epoch:1529, weight:[1.21088036 0.9624855 ], bias:-0.9988849335600266, loss:0.5826275991805059\n",
      "epoch:1530, weight:[1.21116568 0.96265194], bias:-0.9991376908003491, loss:0.5826102963886022\n",
      "epoch:1531, weight:[1.21145101 0.96281832], bias:-0.9993903754963819, loss:0.5825929983869993\n",
      "epoch:1532, weight:[1.21173634 0.96298465], bias:-0.9996429877561339, loss:0.5825757051723205\n",
      "epoch:1533, weight:[1.21202169 0.96315093], bias:-0.9998955276872581, loss:0.582558416741195\n",
      "epoch:1534, weight:[1.21230705 0.96331716], bias:-1.000147995397052, loss:0.5825411330902566\n",
      "epoch:1535, weight:[1.21259241 0.96348334], bias:-1.00040039099246, loss:0.5825238542161444\n",
      "epoch:1536, weight:[1.21287779 0.96364947], bias:-1.0006527145800737, loss:0.5825065801155032\n",
      "epoch:1537, weight:[1.21316317 0.96381555], bias:-1.0009049662661342, loss:0.5824893107849825\n",
      "epoch:1538, weight:[1.21344856 0.96398158], bias:-1.001157146156533, loss:0.582472046221237\n",
      "epoch:1539, weight:[1.21373397 0.96414756], bias:-1.001409254356813, loss:0.5824547864209269\n",
      "epoch:1540, weight:[1.21401938 0.96431349], bias:-1.0016612909721705, loss:0.5824375313807169\n",
      "epoch:1541, weight:[1.2143048  0.96447937], bias:-1.0019132561074564, loss:0.5824202810972772\n",
      "epoch:1542, weight:[1.21459023 0.9646452 ], bias:-1.0021651498671769, loss:0.5824030355672829\n",
      "epoch:1543, weight:[1.21487567 0.96481097], bias:-1.0024169723554954, loss:0.5823857947874145\n",
      "epoch:1544, weight:[1.21516112 0.9649767 ], bias:-1.002668723676234, loss:0.5823685587543568\n",
      "epoch:1545, weight:[1.21544657 0.96514238], bias:-1.0029204039328736, loss:0.5823513274648001\n",
      "epoch:1546, weight:[1.21573204 0.965308  ], bias:-1.003172013228557, loss:0.5823341009154394\n",
      "epoch:1547, weight:[1.21601751 0.96547358], bias:-1.003423551666089, loss:0.582316879102975\n",
      "epoch:1548, weight:[1.216303  0.9656391], bias:-1.0036750193479376, loss:0.5822996620241118\n",
      "epoch:1549, weight:[1.21658849 0.96580458], bias:-1.003926416376236, loss:0.5822824496755596\n",
      "epoch:1550, weight:[1.21687399 0.96597   ], bias:-1.0041777428527834, loss:0.5822652420540336\n",
      "epoch:1551, weight:[1.2171595  0.96613537], bias:-1.0044289988790465, loss:0.5822480391562529\n",
      "epoch:1552, weight:[1.21744502 0.96630069], bias:-1.0046801845561604, loss:0.5822308409789422\n",
      "epoch:1553, weight:[1.21773055 0.96646596], bias:-1.0049312999849302, loss:0.5822136475188309\n",
      "epoch:1554, weight:[1.21801608 0.96663118], bias:-1.0051823452658326, loss:0.5821964587726529\n",
      "epoch:1555, weight:[1.21830163 0.96679635], bias:-1.0054333204990162, loss:0.5821792747371468\n",
      "epoch:1556, weight:[1.21858718 0.96696147], bias:-1.0056842257843035, loss:0.5821620954090567\n",
      "epoch:1557, weight:[1.21887274 0.96712654], bias:-1.005935061221192, loss:0.5821449207851308\n",
      "epoch:1558, weight:[1.21915831 0.96729155], bias:-1.0061858269088553, loss:0.5821277508621218\n",
      "epoch:1559, weight:[1.21944389 0.96745652], bias:-1.0064365229461443, loss:0.5821105856367877\n",
      "epoch:1560, weight:[1.21972948 0.96762143], bias:-1.0066871494315888, loss:0.5820934251058909\n",
      "epoch:1561, weight:[1.22001507 0.96778629], bias:-1.0069377064633984, loss:0.5820762692661985\n",
      "epoch:1562, weight:[1.22030068 0.96795111], bias:-1.0071881941394638, loss:0.582059118114482\n",
      "epoch:1563, weight:[1.22058629 0.96811587], bias:-1.0074386125573578, loss:0.5820419716475175\n",
      "epoch:1564, weight:[1.22087191 0.96828058], bias:-1.007688961814337, loss:0.5820248298620864\n",
      "epoch:1565, weight:[1.22115754 0.96844523], bias:-1.0079392420073423, loss:0.5820076927549739\n",
      "epoch:1566, weight:[1.22144318 0.96860984], bias:-1.0081894532330011, loss:0.5819905603229699\n",
      "epoch:1567, weight:[1.22172882 0.9687744 ], bias:-1.0084395955876277, loss:0.581973432562869\n",
      "epoch:1568, weight:[1.22201447 0.9689389 ], bias:-1.0086896691672247, loss:0.5819563094714701\n",
      "epoch:1569, weight:[1.22230013 0.96910335], bias:-1.0089396740674839, loss:0.5819391910455769\n",
      "epoch:1570, weight:[1.2225858  0.96926775], bias:-1.0091896103837883, loss:0.5819220772819974\n",
      "epoch:1571, weight:[1.22287148 0.9694321 ], bias:-1.0094394782112124, loss:0.5819049681775441\n",
      "epoch:1572, weight:[1.22315716 0.9695964 ], bias:-1.0096892776445239, loss:0.5818878637290339\n",
      "epoch:1573, weight:[1.22344286 0.96976065], bias:-1.0099390087781848, loss:0.5818707639332878\n",
      "epoch:1574, weight:[1.22372856 0.96992485], bias:-1.0101886717063524, loss:0.5818536687871322\n",
      "epoch:1575, weight:[1.22401427 0.97008899], bias:-1.0104382665228806, loss:0.5818365782873965\n",
      "epoch:1576, weight:[1.22429998 0.97025308], bias:-1.0106877933213207, loss:0.5818194924309157\n",
      "epoch:1577, weight:[1.22458571 0.97041712], bias:-1.0109372521949234, loss:0.5818024112145284\n",
      "epoch:1578, weight:[1.22487144 0.97058111], bias:-1.0111866432366388, loss:0.5817853346350778\n",
      "epoch:1579, weight:[1.22515718 0.97074505], bias:-1.0114359665391184, loss:0.5817682626894111\n",
      "epoch:1580, weight:[1.22544292 0.97090894], bias:-1.0116852221947161, loss:0.5817511953743806\n",
      "epoch:1581, weight:[1.22572868 0.97107277], bias:-1.0119344102954893, loss:0.581734132686842\n",
      "epoch:1582, weight:[1.22601444 0.97123655], bias:-1.0121835309331995, loss:0.5817170746236558\n",
      "epoch:1583, weight:[1.22630021 0.97140028], bias:-1.012432584199314, loss:0.5817000211816864\n",
      "epoch:1584, weight:[1.22658599 0.97156396], bias:-1.0126815701850074, loss:0.5816829723578025\n",
      "epoch:1585, weight:[1.22687177 0.97172759], bias:-1.0129304889811614, loss:0.5816659281488773\n",
      "epoch:1586, weight:[1.22715757 0.97189116], bias:-1.0131793406783673, loss:0.581648888551788\n",
      "epoch:1587, weight:[1.22744337 0.97205469], bias:-1.0134281253669264, loss:0.5816318535634157\n",
      "epoch:1588, weight:[1.22772917 0.97221816], bias:-1.013676843136851, loss:0.5816148231806462\n",
      "epoch:1589, weight:[1.22801499 0.97238158], bias:-1.0139254940778661, loss:0.5815977974003689\n",
      "epoch:1590, weight:[1.22830081 0.97254495], bias:-1.0141740782794098, loss:0.5815807762194777\n",
      "epoch:1591, weight:[1.22858664 0.97270826], bias:-1.0144225958306348, loss:0.5815637596348705\n",
      "epoch:1592, weight:[1.22887248 0.97287153], bias:-1.0146710468204094, loss:0.5815467476434494\n",
      "epoch:1593, weight:[1.22915832 0.97303474], bias:-1.0149194313373189, loss:0.5815297402421203\n",
      "epoch:1594, weight:[1.22944417 0.9731979 ], bias:-1.0151677494696656, loss:0.5815127374277934\n",
      "epoch:1595, weight:[1.22973003 0.97336101], bias:-1.0154160013054714, loss:0.5814957391973833\n",
      "epoch:1596, weight:[1.23001589 0.97352406], bias:-1.0156641869324776, loss:0.5814787455478073\n",
      "epoch:1597, weight:[1.23030177 0.97368707], bias:-1.0159123064381468, loss:0.5814617564759884\n",
      "epoch:1598, weight:[1.23058765 0.97385002], bias:-1.0161603599096634, loss:0.5814447719788526\n",
      "epoch:1599, weight:[1.23087353 0.97401292], bias:-1.016408347433935, loss:0.5814277920533301\n",
      "epoch:1600, weight:[1.23115942 0.97417576], bias:-1.0166562690975933, loss:0.5814108166963551\n",
      "epoch:1601, weight:[1.23144532 0.97433856], bias:-1.0169041249869952, loss:0.5813938459048656\n",
      "epoch:1602, weight:[1.23173123 0.9745013 ], bias:-1.0171519151882238, loss:0.5813768796758042\n",
      "epoch:1603, weight:[1.23201715 0.97466399], bias:-1.0173996397870892, loss:0.5813599180061164\n",
      "epoch:1604, weight:[1.23230307 0.97482663], bias:-1.0176472988691305, loss:0.5813429608927523\n",
      "epoch:1605, weight:[1.23258899 0.97498922], bias:-1.0178948925196156, loss:0.5813260083326657\n",
      "epoch:1606, weight:[1.23287493 0.97515175], bias:-1.0181424208235428, loss:0.5813090603228142\n",
      "epoch:1607, weight:[1.23316087 0.97531423], bias:-1.0183898838656418, loss:0.5812921168601594\n",
      "epoch:1608, weight:[1.23344682 0.97547666], bias:-1.0186372817303748, loss:0.5812751779416672\n",
      "epoch:1609, weight:[1.23373277 0.97563904], bias:-1.0188846145019377, loss:0.581258243564306\n",
      "epoch:1610, weight:[1.23401873 0.97580136], bias:-1.0191318822642603, loss:0.5812413137250494\n",
      "epoch:1611, weight:[1.2343047  0.97596363], bias:-1.0193790851010083, loss:0.5812243884208746\n",
      "epoch:1612, weight:[1.23459068 0.97612585], bias:-1.0196262230955833, loss:0.5812074676487616\n",
      "epoch:1613, weight:[1.23487666 0.97628802], bias:-1.019873296331125, loss:0.5811905514056955\n",
      "epoch:1614, weight:[1.23516265 0.97645013], bias:-1.0201203048905112, loss:0.581173639688664\n",
      "epoch:1615, weight:[1.23544864 0.9766122 ], bias:-1.020367248856359, loss:0.5811567324946595\n",
      "epoch:1616, weight:[1.23573464 0.97677421], bias:-1.0206141283110266, loss:0.5811398298206775\n",
      "epoch:1617, weight:[1.23602065 0.97693616], bias:-1.020860943336613, loss:0.5811229316637175\n",
      "epoch:1618, weight:[1.23630666 0.97709807], bias:-1.0211076940149593, loss:0.581106038020783\n",
      "epoch:1619, weight:[1.23659268 0.97725992], bias:-1.0213543804276508, loss:0.5810891488888802\n",
      "epoch:1620, weight:[1.23687871 0.97742172], bias:-1.021601002656017, loss:0.5810722642650202\n",
      "epoch:1621, weight:[1.23716474 0.97758346], bias:-1.021847560781132, loss:0.5810553841462173\n",
      "epoch:1622, weight:[1.23745078 0.97774516], bias:-1.0220940548838169, loss:0.5810385085294891\n",
      "epoch:1623, weight:[1.23773682 0.9779068 ], bias:-1.02234048504464, loss:0.5810216374118573\n",
      "epoch:1624, weight:[1.23802287 0.97806839], bias:-1.0225868513439174, loss:0.5810047707903472\n",
      "epoch:1625, weight:[1.23830893 0.97822992], bias:-1.0228331538617146, loss:0.5809879086619872\n",
      "epoch:1626, weight:[1.238595   0.97839141], bias:-1.0230793926778474, loss:0.5809710510238102\n",
      "epoch:1627, weight:[1.23888107 0.97855284], bias:-1.0233255678718824, loss:0.580954197872852\n",
      "epoch:1628, weight:[1.23916714 0.97871421], bias:-1.0235716795231382, loss:0.5809373492061521\n",
      "epoch:1629, weight:[1.23945322 0.97887554], bias:-1.0238177277106866, loss:0.5809205050207541\n",
      "epoch:1630, weight:[1.23973931 0.97903681], bias:-1.024063712513353, loss:0.580903665313704\n",
      "epoch:1631, weight:[1.24002541 0.97919803], bias:-1.0243096340097175, loss:0.5808868300820529\n",
      "epoch:1632, weight:[1.24031151 0.9793592 ], bias:-1.0245554922781164, loss:0.5808699993228539\n",
      "epoch:1633, weight:[1.24059761 0.97952031], bias:-1.0248012873966423, loss:0.5808531730331649\n",
      "epoch:1634, weight:[1.24088372 0.97968137], bias:-1.0250470194431456, loss:0.5808363512100466\n",
      "epoch:1635, weight:[1.24116984 0.97984238], bias:-1.0252926884952351, loss:0.5808195338505632\n",
      "epoch:1636, weight:[1.24145597 0.98000333], bias:-1.0255382946302791, loss:0.5808027209517825\n",
      "epoch:1637, weight:[1.24174209 0.98016423], bias:-1.025783837925406, loss:0.580785912510776\n",
      "epoch:1638, weight:[1.24202823 0.98032508], bias:-1.0260293184575058, loss:0.5807691085246186\n",
      "epoch:1639, weight:[1.24231437 0.98048588], bias:-1.0262747363032303, loss:0.580752308990388\n",
      "epoch:1640, weight:[1.24260052 0.98064662], bias:-1.0265200915389947, loss:0.5807355139051665\n",
      "epoch:1641, weight:[1.24288667 0.98080731], bias:-1.0267653842409779, loss:0.580718723266039\n",
      "epoch:1642, weight:[1.24317283 0.98096795], bias:-1.0270106144851234, loss:0.5807019370700938\n",
      "epoch:1643, weight:[1.24345899 0.98112853], bias:-1.027255782347141, loss:0.580685155314423\n",
      "epoch:1644, weight:[1.24374516 0.98128906], bias:-1.027500887902507, loss:0.5806683779961219\n",
      "epoch:1645, weight:[1.24403134 0.98144954], bias:-1.0277459312264645, loss:0.580651605112289\n",
      "epoch:1646, weight:[1.24431752 0.98160997], bias:-1.027990912394026, loss:0.5806348366600269\n",
      "epoch:1647, weight:[1.2446037  0.98177034], bias:-1.0282358314799727, loss:0.5806180726364405\n",
      "epoch:1648, weight:[1.2448899  0.98193066], bias:-1.0284806885588555, loss:0.580601313038639\n",
      "epoch:1649, weight:[1.24517609 0.98209092], bias:-1.0287254837049973, loss:0.5805845578637341\n",
      "epoch:1650, weight:[1.2454623  0.98225113], bias:-1.0289702169924921, loss:0.5805678071088417\n",
      "epoch:1651, weight:[1.24574851 0.98241129], bias:-1.0292148884952068, loss:0.5805510607710803\n",
      "epoch:1652, weight:[1.24603472 0.9825714 ], bias:-1.0294594982867822, loss:0.580534318847572\n",
      "epoch:1653, weight:[1.24632094 0.98273145], bias:-1.0297040464406328, loss:0.5805175813354423\n",
      "epoch:1654, weight:[1.24660716 0.98289145], bias:-1.0299485330299494, loss:0.5805008482318196\n",
      "epoch:1655, weight:[1.24689339 0.9830514 ], bias:-1.030192958127698, loss:0.5804841195338363\n",
      "epoch:1656, weight:[1.24717963 0.98321129], bias:-1.0304373218066223, loss:0.5804673952386273\n",
      "epoch:1657, weight:[1.24746587 0.98337113], bias:-1.0306816241392434, loss:0.5804506753433314\n",
      "epoch:1658, weight:[1.24775211 0.98353092], bias:-1.030925865197861, loss:0.5804339598450897\n",
      "epoch:1659, weight:[1.24803836 0.98369065], bias:-1.0311700450545547, loss:0.5804172487410476\n",
      "epoch:1660, weight:[1.24832462 0.98385033], bias:-1.0314141637811842, loss:0.580400542028353\n",
      "epoch:1661, weight:[1.24861088 0.98400996], bias:-1.0316582214493903, loss:0.5803838397041579\n",
      "epoch:1662, weight:[1.24889715 0.98416953], bias:-1.0319022181305961, loss:0.580367141765616\n",
      "epoch:1663, weight:[1.24918342 0.98432905], bias:-1.032146153896007, loss:0.5803504482098855\n",
      "epoch:1664, weight:[1.2494697  0.98448852], bias:-1.0323900288166126, loss:0.5803337590341276\n",
      "epoch:1665, weight:[1.24975598 0.98464793], bias:-1.0326338429631867, loss:0.5803170742355062\n",
      "epoch:1666, weight:[1.25004226 0.98480729], bias:-1.0328775964062882, loss:0.5803003938111885\n",
      "epoch:1667, weight:[1.25032856 0.9849666 ], bias:-1.0331212892162625, loss:0.5802837177583452\n",
      "epoch:1668, weight:[1.25061485 0.98512585], bias:-1.0333649214632412, loss:0.5802670460741497\n",
      "epoch:1669, weight:[1.25090115 0.98528505], bias:-1.0336084932171443, loss:0.5802503787557787\n",
      "epoch:1670, weight:[1.25118746 0.9854442 ], bias:-1.0338520045476802, loss:0.5802337158004126\n",
      "epoch:1671, weight:[1.25147377 0.98560329], bias:-1.034095455524346, loss:0.5802170572052338\n",
      "epoch:1672, weight:[1.25176009 0.98576233], bias:-1.0343388462164296, loss:0.5802004029674287\n",
      "epoch:1673, weight:[1.25204641 0.98592132], bias:-1.0345821766930092, loss:0.580183753084186\n",
      "epoch:1674, weight:[1.25233274 0.98608025], bias:-1.0348254470229552, loss:0.580167107552699\n",
      "epoch:1675, weight:[1.25261907 0.98623913], bias:-1.03506865727493, loss:0.5801504663701621\n",
      "epoch:1676, weight:[1.2529054  0.98639795], bias:-1.0353118075173893, loss:0.5801338295337738\n",
      "epoch:1677, weight:[1.25319174 0.98655673], bias:-1.035554897818583, loss:0.5801171970407364\n",
      "epoch:1678, weight:[1.25347809 0.98671545], bias:-1.0357979282465557, loss:0.5801005688882536\n",
      "epoch:1679, weight:[1.25376444 0.98687411], bias:-1.0360408988691476, loss:0.5800839450735334\n",
      "epoch:1680, weight:[1.25405079 0.98703272], bias:-1.0362838097539953, loss:0.5800673255937865\n",
      "epoch:1681, weight:[1.25433715 0.98719128], bias:-1.036526660968532, loss:0.5800507104462261\n",
      "epoch:1682, weight:[1.25462351 0.98734979], bias:-1.0367694525799893, loss:0.5800340996280694\n",
      "epoch:1683, weight:[1.25490988 0.98750824], bias:-1.0370121846553975, loss:0.5800174931365359\n",
      "epoch:1684, weight:[1.25519626 0.98766664], bias:-1.0372548572615858, loss:0.5800008909688482\n",
      "epoch:1685, weight:[1.25548263 0.98782498], bias:-1.037497470465184, loss:0.579984293122232\n",
      "epoch:1686, weight:[1.25576902 0.98798327], bias:-1.0377400243326225, loss:0.5799676995939159\n",
      "epoch:1687, weight:[1.2560554  0.98814151], bias:-1.0379825189301335, loss:0.5799511103811317\n",
      "epoch:1688, weight:[1.25634179 0.98829969], bias:-1.0382249543237514, loss:0.5799345254811138\n",
      "epoch:1689, weight:[1.25662819 0.98845782], bias:-1.0384673305793137, loss:0.5799179448910997\n",
      "epoch:1690, weight:[1.25691459 0.9886159 ], bias:-1.0387096477624622, loss:0.5799013686083302\n",
      "epoch:1691, weight:[1.25720099 0.98877392], bias:-1.038951905938643, loss:0.5798847966300484\n",
      "epoch:1692, weight:[1.2574874  0.98893189], bias:-1.0391941051731073, loss:0.5798682289535012\n",
      "epoch:1693, weight:[1.25777381 0.9890898 ], bias:-1.039436245530913, loss:0.5798516655759373\n",
      "epoch:1694, weight:[1.25806023 0.98924766], bias:-1.039678327076924, loss:0.5798351064946092\n",
      "epoch:1695, weight:[1.25834665 0.98940547], bias:-1.0399203498758127, loss:0.5798185517067721\n",
      "epoch:1696, weight:[1.25863308 0.98956323], bias:-1.040162313992059, loss:0.5798020012096837\n",
      "epoch:1697, weight:[1.25891951 0.98972093], bias:-1.040404219489952, loss:0.5797854550006053\n",
      "epoch:1698, weight:[1.25920594 0.98987857], bias:-1.0406460664335906, loss:0.5797689130768003\n",
      "epoch:1699, weight:[1.25949238 0.99003617], bias:-1.0408878548868838, loss:0.5797523754355359\n",
      "epoch:1700, weight:[1.25977883 0.9901937 ], bias:-1.0411295849135522, loss:0.5797358420740811\n",
      "epoch:1701, weight:[1.26006527 0.99035119], bias:-1.041371256577128, loss:0.5797193129897086\n",
      "epoch:1702, weight:[1.26035172 0.99050862], bias:-1.041612869940956, loss:0.5797027881796933\n",
      "epoch:1703, weight:[1.26063818 0.990666  ], bias:-1.0418544250681938, loss:0.579686267641314\n",
      "epoch:1704, weight:[1.26092464 0.99082332], bias:-1.0420959220218136, loss:0.579669751371851\n",
      "epoch:1705, weight:[1.2612111  0.99098059], bias:-1.0423373608646018, loss:0.5796532393685884\n",
      "epoch:1706, weight:[1.26149757 0.99113781], bias:-1.0425787416591605, loss:0.5796367316288125\n",
      "epoch:1707, weight:[1.26178404 0.99129497], bias:-1.0428200644679075, loss:0.579620228149813\n",
      "epoch:1708, weight:[1.26207052 0.99145208], bias:-1.0430613293530777, loss:0.5796037289288818\n",
      "epoch:1709, weight:[1.262357   0.99160914], bias:-1.043302536376723, loss:0.5795872339633142\n",
      "epoch:1710, weight:[1.26264348 0.99176614], bias:-1.0435436856007136, loss:0.579570743250408\n",
      "epoch:1711, weight:[1.26292997 0.99192309], bias:-1.0437847770867386, loss:0.5795542567874633\n",
      "epoch:1712, weight:[1.26321646 0.99207998], bias:-1.044025810896306, loss:0.579537774571784\n",
      "epoch:1713, weight:[1.26350295 0.99223682], bias:-1.044266787090745, loss:0.5795212966006761\n",
      "epoch:1714, weight:[1.26378945 0.99239361], bias:-1.0445077057312044, loss:0.5795048228714486\n",
      "epoch:1715, weight:[1.26407596 0.99255034], bias:-1.0447485668786554, loss:0.5794883533814129\n",
      "epoch:1716, weight:[1.26436246 0.99270702], bias:-1.0449893705938909, loss:0.5794718881278835\n",
      "epoch:1717, weight:[1.26464897 0.99286365], bias:-1.0452301169375267, loss:0.5794554271081774\n",
      "epoch:1718, weight:[1.26493549 0.99302022], bias:-1.0454708059700022, loss:0.5794389703196147\n",
      "epoch:1719, weight:[1.265222   0.99317673], bias:-1.0457114377515808, loss:0.579422517759518\n",
      "epoch:1720, weight:[1.26550853 0.9933332 ], bias:-1.045952012342351, loss:0.5794060694252124\n",
      "epoch:1721, weight:[1.26579505 0.99348961], bias:-1.0461925298022263, loss:0.5793896253140263\n",
      "epoch:1722, weight:[1.26608158 0.99364596], bias:-1.0464329901909468, loss:0.57937318542329\n",
      "epoch:1723, weight:[1.26636811 0.99380226], bias:-1.046673393568079, loss:0.5793567497503372\n",
      "epoch:1724, weight:[1.26665465 0.99395851], bias:-1.046913739993017, loss:0.5793403182925042\n",
      "epoch:1725, weight:[1.26694119 0.99411471], bias:-1.047154029524983, loss:0.5793238910471297\n",
      "epoch:1726, weight:[1.26722773 0.99427085], bias:-1.0473942622230277, loss:0.579307468011555\n",
      "epoch:1727, weight:[1.26751428 0.99442693], bias:-1.0476344381460312, loss:0.5792910491831244\n",
      "epoch:1728, weight:[1.26780083 0.99458297], bias:-1.047874557352704, loss:0.5792746345591847\n",
      "epoch:1729, weight:[1.26808739 0.99473894], bias:-1.0481146199015865, loss:0.5792582241370856\n",
      "epoch:1730, weight:[1.26837395 0.99489487], bias:-1.048354625851051, loss:0.5792418179141792\n",
      "epoch:1731, weight:[1.26866051 0.99505074], bias:-1.0485945752593016, loss:0.57922541588782\n",
      "epoch:1732, weight:[1.26894707 0.99520656], bias:-1.0488344681843744, loss:0.5792090180553658\n",
      "epoch:1733, weight:[1.26923364 0.99536232], bias:-1.0490743046841393, loss:0.5791926244141767\n",
      "epoch:1734, weight:[1.26952021 0.99551803], bias:-1.0493140848162994, loss:0.5791762349616152\n",
      "epoch:1735, weight:[1.26980679 0.99567368], bias:-1.0495538086383926, loss:0.5791598496950466\n",
      "epoch:1736, weight:[1.27009337 0.99582928], bias:-1.0497934762077918, loss:0.579143468611839\n",
      "epoch:1737, weight:[1.27037995 0.99598483], bias:-1.0500330875817054, loss:0.5791270917093633\n",
      "epoch:1738, weight:[1.27066653 0.99614032], bias:-1.050272642817178, loss:0.5791107189849919\n",
      "epoch:1739, weight:[1.27095312 0.99629576], bias:-1.0505121419710912, loss:0.5790943504361009\n",
      "epoch:1740, weight:[1.27123971 0.99645115], bias:-1.0507515851001639, loss:0.5790779860600686\n",
      "epoch:1741, weight:[1.27152631 0.99660648], bias:-1.0509909722609532, loss:0.579061625854276\n",
      "epoch:1742, weight:[1.27181291 0.99676175], bias:-1.0512303035098547, loss:0.5790452698161068\n",
      "epoch:1743, weight:[1.27209951 0.99691698], bias:-1.0514695789031034, loss:0.5790289179429468\n",
      "epoch:1744, weight:[1.27238611 0.99707215], bias:-1.0517087984967746, loss:0.5790125702321847\n",
      "epoch:1745, weight:[1.27267272 0.99722726], bias:-1.0519479623467831, loss:0.5789962266812118\n",
      "epoch:1746, weight:[1.27295933 0.99738232], bias:-1.0521870705088858, loss:0.5789798872874214\n",
      "epoch:1747, weight:[1.27324595 0.99753733], bias:-1.0524261230386807, loss:0.5789635520482106\n",
      "epoch:1748, weight:[1.27353257 0.99769228], bias:-1.052665119991608, loss:0.5789472209609776\n",
      "epoch:1749, weight:[1.27381919 0.99784718], bias:-1.0529040614229508, loss:0.578930894023124\n",
      "epoch:1750, weight:[1.27410581 0.99800203], bias:-1.053142947387836, loss:0.5789145712320537\n",
      "epoch:1751, weight:[1.27439244 0.99815682], bias:-1.0533817779412342, loss:0.5788982525851734\n",
      "epoch:1752, weight:[1.27467907 0.99831156], bias:-1.0536205531379608, loss:0.5788819380798916\n",
      "epoch:1753, weight:[1.2749657  0.99846624], bias:-1.0538592730326761, loss:0.57886562771362\n",
      "epoch:1754, weight:[1.27525234 0.99862087], bias:-1.0540979376798865, loss:0.5788493214837727\n",
      "epoch:1755, weight:[1.27553898 0.99877545], bias:-1.0543365471339443, loss:0.5788330193877659\n",
      "epoch:1756, weight:[1.27582562 0.99892997], bias:-1.054575101449049, loss:0.5788167214230189\n",
      "epoch:1757, weight:[1.27611226 0.99908443], bias:-1.0548136006792475, loss:0.5788004275869529\n",
      "epoch:1758, weight:[1.27639891 0.99923885], bias:-1.0550520448784346, loss:0.5787841378769919\n",
      "epoch:1759, weight:[1.27668556 0.99939321], bias:-1.0552904341003542, loss:0.5787678522905623\n",
      "epoch:1760, weight:[1.27697221 0.99954751], bias:-1.0555287683985988, loss:0.5787515708250932\n",
      "epoch:1761, weight:[1.27725887 0.99970176], bias:-1.055767047826611, loss:0.5787352934780158\n",
      "epoch:1762, weight:[1.27754553 0.99985596], bias:-1.0560052724376836, loss:0.5787190202467641\n",
      "epoch:1763, weight:[1.27783219 1.0000101 ], bias:-1.05624344228496, loss:0.5787027511287742\n",
      "epoch:1764, weight:[1.27811886 1.00016419], bias:-1.0564815574214355, loss:0.578686486121485\n",
      "epoch:1765, weight:[1.27840553 1.00031823], bias:-1.056719617899957, loss:0.5786702252223376\n",
      "epoch:1766, weight:[1.2786922  1.00047221], bias:-1.0569576237732239, loss:0.5786539684287758\n",
      "epoch:1767, weight:[1.27897887 1.00062614], bias:-1.057195575093789, loss:0.5786377157382453\n",
      "epoch:1768, weight:[1.27926555 1.00078001], bias:-1.0574334719140581, loss:0.578621467148195\n",
      "epoch:1769, weight:[1.27955223 1.00093383], bias:-1.057671314286292, loss:0.5786052226560755\n",
      "epoch:1770, weight:[1.27983891 1.00108759], bias:-1.0579091022626053, loss:0.5785889822593404\n",
      "epoch:1771, weight:[1.28012559 1.00124131], bias:-1.0581468358949684, loss:0.5785727459554457\n",
      "epoch:1772, weight:[1.28041228 1.00139496], bias:-1.0583845152352074, loss:0.5785565137418491\n",
      "epoch:1773, weight:[1.28069897 1.00154857], bias:-1.0586221403350047, loss:0.5785402856160111\n",
      "epoch:1774, weight:[1.28098566 1.00170212], bias:-1.0588597112458993, loss:0.5785240615753953\n",
      "epoch:1775, weight:[1.28127236 1.00185561], bias:-1.0590972280192879, loss:0.5785078416174666\n",
      "epoch:1776, weight:[1.28155905 1.00200905], bias:-1.0593346907064247, loss:0.5784916257396929\n",
      "epoch:1777, weight:[1.28184575 1.00216244], bias:-1.059572099358423, loss:0.5784754139395444\n",
      "epoch:1778, weight:[1.28213246 1.00231577], bias:-1.0598094540262544, loss:0.5784592062144935\n",
      "epoch:1779, weight:[1.28241916 1.00246905], bias:-1.0600467547607504, loss:0.5784430025620152\n",
      "epoch:1780, weight:[1.28270587 1.00262227], bias:-1.0602840016126023, loss:0.5784268029795869\n",
      "epoch:1781, weight:[1.28299258 1.00277545], bias:-1.0605211946323618, loss:0.578410607464688\n",
      "epoch:1782, weight:[1.28327929 1.00292856], bias:-1.060758333870442, loss:0.5783944160148007\n",
      "epoch:1783, weight:[1.28356601 1.00308162], bias:-1.0609954193771174, loss:0.5783782286274092\n",
      "epoch:1784, weight:[1.28385273 1.00323463], bias:-1.0612324512025244, loss:0.5783620453000005\n",
      "epoch:1785, weight:[1.28413945 1.00338759], bias:-1.0614694293966622, loss:0.5783458660300633\n",
      "epoch:1786, weight:[1.28442617 1.00354049], bias:-1.0617063540093932, loss:0.5783296908150891\n",
      "epoch:1787, weight:[1.2847129  1.00369334], bias:-1.0619432250904428, loss:0.578313519652572\n",
      "epoch:1788, weight:[1.28499962 1.00384613], bias:-1.0621800426894012, loss:0.5782973525400078\n",
      "epoch:1789, weight:[1.28528635 1.00399887], bias:-1.0624168068557232, loss:0.5782811894748946\n",
      "epoch:1790, weight:[1.28557308 1.00415155], bias:-1.062653517638728, loss:0.5782650304547334\n",
      "epoch:1791, weight:[1.28585982 1.00430418], bias:-1.0628901750876012, loss:0.5782488754770275\n",
      "epoch:1792, weight:[1.28614656 1.00445676], bias:-1.063126779251394, loss:0.578232724539282\n",
      "epoch:1793, weight:[1.28643329 1.00460928], bias:-1.0633633301790246, loss:0.5782165776390044\n",
      "epoch:1794, weight:[1.28672004 1.00476175], bias:-1.063599827919278, loss:0.578200434773705\n",
      "epoch:1795, weight:[1.28700678 1.00491416], bias:-1.0638362725208068, loss:0.5781842959408958\n",
      "epoch:1796, weight:[1.28729353 1.00506652], bias:-1.0640726640321319, loss:0.5781681611380914\n",
      "epoch:1797, weight:[1.28758027 1.00521883], bias:-1.0643090025016424, loss:0.5781520303628086\n",
      "epoch:1798, weight:[1.28786702 1.00537108], bias:-1.064545287977597, loss:0.5781359036125671\n",
      "epoch:1799, weight:[1.28815378 1.00552328], bias:-1.0647815205081235, loss:0.5781197808848876\n",
      "epoch:1800, weight:[1.28844053 1.00567543], bias:-1.0650177001412198, loss:0.578103662177294\n",
      "epoch:1801, weight:[1.28872729 1.00582752], bias:-1.0652538269247545, loss:0.5780875474873125\n",
      "epoch:1802, weight:[1.28901405 1.00597955], bias:-1.0654899009064671, loss:0.5780714368124712\n",
      "epoch:1803, weight:[1.28930081 1.00613153], bias:-1.0657259221339686, loss:0.5780553301503004\n",
      "epoch:1804, weight:[1.28958757 1.00628346], bias:-1.0659618906547417, loss:0.5780392274983331\n",
      "epoch:1805, weight:[1.28987434 1.00643534], bias:-1.0661978065161417, loss:0.5780231288541046\n",
      "epoch:1806, weight:[1.2901611  1.00658716], bias:-1.0664336697653967, loss:0.5780070342151515\n",
      "epoch:1807, weight:[1.29044787 1.00673892], bias:-1.0666694804496084, loss:0.5779909435790138\n",
      "epoch:1808, weight:[1.29073464 1.00689064], bias:-1.066905238615752, loss:0.5779748569432331\n",
      "epoch:1809, weight:[1.29102142 1.00704229], bias:-1.0671409443106772, loss:0.5779587743053535\n",
      "epoch:1810, weight:[1.29130819 1.0071939 ], bias:-1.0673765975811085, loss:0.5779426956629211\n",
      "epoch:1811, weight:[1.29159497 1.00734545], bias:-1.0676121984736453, loss:0.5779266210134846\n",
      "epoch:1812, weight:[1.29188175 1.00749695], bias:-1.067847747034763, loss:0.5779105503545944\n",
      "epoch:1813, weight:[1.29216853 1.00764839], bias:-1.0680832433108127, loss:0.5778944836838035\n",
      "epoch:1814, weight:[1.29245531 1.00779978], bias:-1.0683186873480228, loss:0.5778784209986673\n",
      "epoch:1815, weight:[1.2927421  1.00795111], bias:-1.0685540791924981, loss:0.5778623622967428\n",
      "epoch:1816, weight:[1.29302889 1.00810239], bias:-1.0687894188902212, loss:0.5778463075755899\n",
      "epoch:1817, weight:[1.29331568 1.00825362], bias:-1.0690247064870526, loss:0.5778302568327697\n",
      "epoch:1818, weight:[1.29360247 1.00840479], bias:-1.0692599420287312, loss:0.577814210065847\n",
      "epoch:1819, weight:[1.29388926 1.00855591], bias:-1.069495125560875, loss:0.5777981672723874\n",
      "epoch:1820, weight:[1.29417605 1.00870697], bias:-1.0697302571289806, loss:0.5777821284499596\n",
      "epoch:1821, weight:[1.29446285 1.00885798], bias:-1.069965336778425, loss:0.5777660935961338\n",
      "epoch:1822, weight:[1.29474965 1.00900894], bias:-1.070200364554465, loss:0.5777500627084832\n",
      "epoch:1823, weight:[1.29503645 1.00915984], bias:-1.0704353405022387, loss:0.5777340357845822\n",
      "epoch:1824, weight:[1.29532325 1.00931069], bias:-1.0706702646667643, loss:0.5777180128220084\n",
      "epoch:1825, weight:[1.29561005 1.00946149], bias:-1.070905137092942, loss:0.5777019938183406\n",
      "epoch:1826, weight:[1.29589686 1.00961223], bias:-1.0711399578255543, loss:0.5776859787711605\n",
      "epoch:1827, weight:[1.29618367 1.00976291], bias:-1.0713747269092653, loss:0.5776699676780517\n",
      "epoch:1828, weight:[1.29647047 1.00991355], bias:-1.0716094443886224, loss:0.5776539605365999\n",
      "epoch:1829, weight:[1.29675728 1.01006413], bias:-1.0718441103080563, loss:0.577637957344393\n",
      "epoch:1830, weight:[1.2970441  1.01021465], bias:-1.072078724711881, loss:0.5776219580990212\n",
      "epoch:1831, weight:[1.29733091 1.01036512], bias:-1.072313287644295, loss:0.5776059627980765\n",
      "epoch:1832, weight:[1.29761773 1.01051554], bias:-1.0725477991493808, loss:0.5775899714391536\n",
      "epoch:1833, weight:[1.29790454 1.0106659 ], bias:-1.0727822592711065, loss:0.5775739840198487\n",
      "epoch:1834, weight:[1.29819136 1.01081621], bias:-1.073016668053325, loss:0.5775580005377606\n",
      "epoch:1835, weight:[1.29847818 1.01096647], bias:-1.0732510255397756, loss:0.5775420209904902\n",
      "epoch:1836, weight:[1.298765   1.01111667], bias:-1.0734853317740831, loss:0.5775260453756406\n",
      "epoch:1837, weight:[1.29905183 1.01126682], bias:-1.0737195867997595, loss:0.5775100736908164\n",
      "epoch:1838, weight:[1.29933865 1.01141691], bias:-1.0739537906602037, loss:0.577494105933625\n",
      "epoch:1839, weight:[1.29962548 1.01156695], bias:-1.0741879433987018, loss:0.5774781421016756\n",
      "epoch:1840, weight:[1.29991231 1.01171694], bias:-1.074422045058428, loss:0.5774621821925802\n",
      "epoch:1841, weight:[1.30019914 1.01186687], bias:-1.074656095682445, loss:0.5774462262039515\n",
      "epoch:1842, weight:[1.30048597 1.01201675], bias:-1.0748900953137035, loss:0.5774302741334056\n",
      "epoch:1843, weight:[1.3007728  1.01216657], bias:-1.075124043995044, loss:0.5774143259785605\n",
      "epoch:1844, weight:[1.30105963 1.01231634], bias:-1.0753579417691965, loss:0.5773983817370354\n",
      "epoch:1845, weight:[1.30134647 1.01246606], bias:-1.0755917886787805, loss:0.5773824414064528\n",
      "epoch:1846, weight:[1.30163331 1.01261572], bias:-1.0758255847663059, loss:0.5773665049844365\n",
      "epoch:1847, weight:[1.30192014 1.01276533], bias:-1.0760593300741734, loss:0.577350572468613\n",
      "epoch:1848, weight:[1.30220698 1.01291488], bias:-1.0762930246446751, loss:0.5773346438566102\n",
      "epoch:1849, weight:[1.30249382 1.01306439], bias:-1.0765266685199943, loss:0.5773187191460585\n",
      "epoch:1850, weight:[1.30278067 1.01321383], bias:-1.0767602617422065, loss:0.5773027983345904\n",
      "epoch:1851, weight:[1.30306751 1.01336323], bias:-1.0769938043532792, loss:0.5772868814198402\n",
      "epoch:1852, weight:[1.30335436 1.01351257], bias:-1.0772272963950726, loss:0.5772709683994448\n",
      "epoch:1853, weight:[1.3036412  1.01366185], bias:-1.0774607379093402, loss:0.5772550592710426\n",
      "epoch:1854, weight:[1.30392805 1.01381108], bias:-1.0776941289377289, loss:0.5772391540322744\n",
      "epoch:1855, weight:[1.3042149  1.01396026], bias:-1.0779274695217795, loss:0.577223252680783\n",
      "epoch:1856, weight:[1.30450175 1.01410939], bias:-1.0781607597029275, loss:0.577207355214213\n",
      "epoch:1857, weight:[1.3047886  1.01425846], bias:-1.078393999522502, loss:0.5771914616302118\n",
      "epoch:1858, weight:[1.30507545 1.01440747], bias:-1.0786271890217283, loss:0.5771755719264277\n",
      "epoch:1859, weight:[1.30536231 1.01455644], bias:-1.0788603282417264, loss:0.5771596861005123\n",
      "epoch:1860, weight:[1.30564916 1.01470535], bias:-1.0790934172235125, loss:0.5771438041501183\n",
      "epoch:1861, weight:[1.30593602 1.0148542 ], bias:-1.079326456007999, loss:0.5771279260729011\n",
      "epoch:1862, weight:[1.30622288 1.015003  ], bias:-1.0795594446359942, loss:0.5771120518665177\n",
      "epoch:1863, weight:[1.30650974 1.01515175], bias:-1.0797923831482044, loss:0.5770961815286273\n",
      "epoch:1864, weight:[1.3067966  1.01530045], bias:-1.0800252715852323, loss:0.5770803150568908\n",
      "epoch:1865, weight:[1.30708346 1.01544909], bias:-1.080258109987579, loss:0.5770644524489719\n",
      "epoch:1866, weight:[1.30737032 1.01559767], bias:-1.0804908983956432, loss:0.5770485937025357\n",
      "epoch:1867, weight:[1.30765718 1.01574621], bias:-1.0807236368497222, loss:0.5770327388152495\n",
      "epoch:1868, weight:[1.30794405 1.01589469], bias:-1.080956325390012, loss:0.5770168877847829\n",
      "epoch:1869, weight:[1.30823091 1.01604311], bias:-1.0811889640566084, loss:0.577001040608807\n",
      "epoch:1870, weight:[1.30851778 1.01619148], bias:-1.081421552889506, loss:0.576985197284995\n",
      "epoch:1871, weight:[1.30880465 1.0163398 ], bias:-1.0816540919285993, loss:0.5769693578110228\n",
      "epoch:1872, weight:[1.30909152 1.01648807], bias:-1.081886581213684, loss:0.5769535221845673\n",
      "epoch:1873, weight:[1.30937839 1.01663628], bias:-1.0821190207844553, loss:0.5769376904033081\n",
      "epoch:1874, weight:[1.30966526 1.01678443], bias:-1.0823514106805103, loss:0.5769218624649267\n",
      "epoch:1875, weight:[1.30995213 1.01693254], bias:-1.0825837509413472, loss:0.5769060383671065\n",
      "epoch:1876, weight:[1.310239   1.01708059], bias:-1.0828160416063655, loss:0.5768902181075328\n",
      "epoch:1877, weight:[1.31052588 1.01722858], bias:-1.0830482827148673, loss:0.5768744016838933\n",
      "epoch:1878, weight:[1.31081275 1.01737653], bias:-1.0832804743060571, loss:0.5768585890938769\n",
      "epoch:1879, weight:[1.31109963 1.01752441], bias:-1.0835126164190423, loss:0.5768427803351753\n",
      "epoch:1880, weight:[1.31138651 1.01767225], bias:-1.083744709092833, loss:0.576826975405482\n",
      "epoch:1881, weight:[1.31167338 1.01782003], bias:-1.083976752366343, loss:0.5768111743024922\n",
      "epoch:1882, weight:[1.31196026 1.01796776], bias:-1.0842087462783903, loss:0.5767953770239032\n",
      "epoch:1883, weight:[1.31224714 1.01811543], bias:-1.0844406908676967, loss:0.5767795835674142\n",
      "epoch:1884, weight:[1.31253402 1.01826305], bias:-1.0846725861728888, loss:0.5767637939307267\n",
      "epoch:1885, weight:[1.31282091 1.01841062], bias:-1.0849044322324977, loss:0.5767480081115441\n",
      "epoch:1886, weight:[1.31310779 1.01855813], bias:-1.0851362290849604, loss:0.5767322261075714\n",
      "epoch:1887, weight:[1.31339467 1.01870559], bias:-1.085367976768619, loss:0.5767164479165158\n",
      "epoch:1888, weight:[1.31368156 1.018853  ], bias:-1.0855996753217219, loss:0.5767006735360868\n",
      "epoch:1889, weight:[1.31396844 1.01900035], bias:-1.0858313247824234, loss:0.5766849029639951\n",
      "epoch:1890, weight:[1.31425533 1.01914765], bias:-1.0860629251887846, loss:0.5766691361979537\n",
      "epoch:1891, weight:[1.31454221 1.01929489], bias:-1.0862944765787736, loss:0.5766533732356781\n",
      "epoch:1892, weight:[1.3148291  1.01944209], bias:-1.086525978990266, loss:0.5766376140748849\n",
      "epoch:1893, weight:[1.31511599 1.01958922], bias:-1.0867574324610443, loss:0.5766218587132934\n",
      "epoch:1894, weight:[1.31540288 1.01973631], bias:-1.0869888370288, loss:0.5766061071486243\n",
      "epoch:1895, weight:[1.31568977 1.01988334], bias:-1.0872201927311318, loss:0.5765903593786003\n",
      "epoch:1896, weight:[1.31597666 1.02003032], bias:-1.0874514996055482, loss:0.5765746154009462\n",
      "epoch:1897, weight:[1.31626355 1.02017724], bias:-1.0876827576894657, loss:0.5765588752133891\n",
      "epoch:1898, weight:[1.31655044 1.02032411], bias:-1.0879139670202105, loss:0.5765431388136568\n",
      "epoch:1899, weight:[1.31683733 1.02047093], bias:-1.0881451276350185, loss:0.5765274061994806\n",
      "epoch:1900, weight:[1.31712423 1.02061769], bias:-1.0883762395710355, loss:0.5765116773685928\n",
      "epoch:1901, weight:[1.31741112 1.0207644 ], bias:-1.0886073028653174, loss:0.5764959523187277\n",
      "epoch:1902, weight:[1.31769801 1.02091106], bias:-1.0888383175548308, loss:0.5764802310476218\n",
      "epoch:1903, weight:[1.31798491 1.02105766], bias:-1.0890692836764535, loss:0.5764645135530134\n",
      "epoch:1904, weight:[1.3182718  1.02120421], bias:-1.0893002012669741, loss:0.5764487998326424\n",
      "epoch:1905, weight:[1.3185587  1.02135071], bias:-1.0895310703630932, loss:0.5764330898842513\n",
      "epoch:1906, weight:[1.3188456  1.02149715], bias:-1.0897618910014228, loss:0.5764173837055837\n",
      "epoch:1907, weight:[1.3191325  1.02164354], bias:-1.0899926632184878, loss:0.5764016812943858\n",
      "epoch:1908, weight:[1.31941939 1.02178988], bias:-1.090223387050725, loss:0.5763859826484055\n",
      "epoch:1909, weight:[1.31970629 1.02193616], bias:-1.0904540625344843, loss:0.5763702877653922\n",
      "epoch:1910, weight:[1.31999319 1.02208239], bias:-1.0906846897060285, loss:0.5763545966430976\n",
      "epoch:1911, weight:[1.32028009 1.02222856], bias:-1.0909152686015344, loss:0.5763389092792757\n",
      "epoch:1912, weight:[1.32056699 1.02237468], bias:-1.0911457992570923, loss:0.5763232256716814\n",
      "epoch:1913, weight:[1.32085389 1.02252075], bias:-1.0913762817087063, loss:0.5763075458180721\n",
      "epoch:1914, weight:[1.32114079 1.02266677], bias:-1.0916067159922953, loss:0.5762918697162073\n",
      "epoch:1915, weight:[1.3214277  1.02281273], bias:-1.091837102143693, loss:0.576276197363848\n",
      "epoch:1916, weight:[1.3217146  1.02295864], bias:-1.0920674401986479, loss:0.576260528758757\n",
      "epoch:1917, weight:[1.3220015  1.02310449], bias:-1.0922977301928236, loss:0.5762448638986993\n",
      "epoch:1918, weight:[1.32228841 1.0232503 ], bias:-1.0925279721618, loss:0.5762292027814416\n",
      "epoch:1919, weight:[1.32257531 1.02339605], bias:-1.0927581661410721, loss:0.5762135454047529\n",
      "epoch:1920, weight:[1.32286221 1.02354174], bias:-1.092988312166052, loss:0.5761978917664032\n",
      "epoch:1921, weight:[1.32314912 1.02368738], bias:-1.0932184102720677, loss:0.5761822418641651\n",
      "epoch:1922, weight:[1.32343602 1.02383297], bias:-1.0934484604943644, loss:0.5761665956958127\n",
      "epoch:1923, weight:[1.32372293 1.02397851], bias:-1.0936784628681042, loss:0.5761509532591224\n",
      "epoch:1924, weight:[1.32400983 1.02412399], bias:-1.0939084174283669, loss:0.5761353145518722\n",
      "epoch:1925, weight:[1.32429674 1.02426942], bias:-1.09413832421015, loss:0.5761196795718416\n",
      "epoch:1926, weight:[1.32458365 1.02441479], bias:-1.0943681832483685, loss:0.5761040483168126\n",
      "epoch:1927, weight:[1.32487055 1.02456011], bias:-1.0945979945778568, loss:0.5760884207845687\n",
      "epoch:1928, weight:[1.32515746 1.02470538], bias:-1.094827758233367, loss:0.5760727969728953\n",
      "epoch:1929, weight:[1.32544437 1.0248506 ], bias:-1.0950574742495705, loss:0.5760571768795796\n",
      "epoch:1930, weight:[1.32573128 1.02499576], bias:-1.0952871426610575, loss:0.5760415605024108\n",
      "epoch:1931, weight:[1.32601819 1.02514087], bias:-1.0955167635023386, loss:0.5760259478391802\n",
      "epoch:1932, weight:[1.32630509 1.02528593], bias:-1.0957463368078433, loss:0.5760103388876802\n",
      "epoch:1933, weight:[1.326592   1.02543093], bias:-1.0959758626119216, loss:0.5759947336457054\n",
      "epoch:1934, weight:[1.32687891 1.02557588], bias:-1.096205340948844, loss:0.5759791321110524\n",
      "epoch:1935, weight:[1.32716582 1.02572078], bias:-1.096434771852801, loss:0.5759635342815201\n",
      "epoch:1936, weight:[1.32745273 1.02586562], bias:-1.0966641553579046, loss:0.5759479401549079\n",
      "epoch:1937, weight:[1.32773964 1.02601041], bias:-1.0968934914981883, loss:0.5759323497290182\n",
      "epoch:1938, weight:[1.32802655 1.02615515], bias:-1.0971227803076062, loss:0.575916763001655\n",
      "epoch:1939, weight:[1.32831346 1.02629983], bias:-1.097352021820035, loss:0.5759011799706234\n",
      "epoch:1940, weight:[1.32860037 1.02644446], bias:-1.097581216069273, loss:0.5758856006337315\n",
      "epoch:1941, weight:[1.32888728 1.02658904], bias:-1.0978103630890412, loss:0.5758700249887885\n",
      "epoch:1942, weight:[1.32917419 1.02673356], bias:-1.0980394629129828, loss:0.5758544530336053\n",
      "epoch:1943, weight:[1.32946111 1.02687803], bias:-1.098268515574664, loss:0.5758388847659949\n",
      "epoch:1944, weight:[1.32974802 1.02702245], bias:-1.0984975211075747, loss:0.5758233201837724\n",
      "epoch:1945, weight:[1.33003493 1.02716682], bias:-1.0987264795451275, loss:0.5758077592847541\n",
      "epoch:1946, weight:[1.33032184 1.02731113], bias:-1.0989553909206593, loss:0.5757922020667586\n",
      "epoch:1947, weight:[1.33060875 1.02745539], bias:-1.0991842552674307, loss:0.5757766485276059\n",
      "epoch:1948, weight:[1.33089566 1.02759959], bias:-1.0994130726186266, loss:0.5757610986651183\n",
      "epoch:1949, weight:[1.33118257 1.02774375], bias:-1.0996418430073565, loss:0.5757455524771194\n",
      "epoch:1950, weight:[1.33146949 1.02788785], bias:-1.0998705664666546, loss:0.5757300099614351\n",
      "epoch:1951, weight:[1.3317564  1.02803189], bias:-1.1000992430294805, loss:0.5757144711158925\n",
      "epoch:1952, weight:[1.33204331 1.02817589], bias:-1.100327872728719, loss:0.5756989359383211\n",
      "epoch:1953, weight:[1.33233022 1.02831983], bias:-1.10055645559718, loss:0.5756834044265519\n",
      "epoch:1954, weight:[1.33261713 1.02846372], bias:-1.1007849916676002, loss:0.5756678765784177\n",
      "epoch:1955, weight:[1.33290405 1.02860755], bias:-1.1010134809726417, loss:0.575652352391753\n",
      "epoch:1956, weight:[1.33319096 1.02875133], bias:-1.1012419235448936, loss:0.5756368318643946\n",
      "epoch:1957, weight:[1.33347787 1.02889506], bias:-1.101470319416871, loss:0.5756213149941802\n",
      "epoch:1958, weight:[1.33376478 1.02903874], bias:-1.1016986686210164, loss:0.5756058017789499\n",
      "epoch:1959, weight:[1.3340517  1.02918236], bias:-1.1019269711896995, loss:0.5755902922165459\n",
      "epoch:1960, weight:[1.33433861 1.02932593], bias:-1.1021552271552173, loss:0.5755747863048112\n",
      "epoch:1961, weight:[1.33462552 1.02946945], bias:-1.1023834365497944, loss:0.5755592840415914\n",
      "epoch:1962, weight:[1.33491243 1.02961291], bias:-1.1026115994055838, loss:0.5755437854247335\n",
      "epoch:1963, weight:[1.33519934 1.02975632], bias:-1.1028397157546663, loss:0.5755282904520865\n",
      "epoch:1964, weight:[1.33548626 1.02989968], bias:-1.1030677856290514, loss:0.5755127991215011\n",
      "epoch:1965, weight:[1.33577317 1.03004299], bias:-1.103295809060677, loss:0.5754973114308294\n",
      "epoch:1966, weight:[1.33606008 1.03018624], bias:-1.1035237860814107, loss:0.5754818273779259\n",
      "epoch:1967, weight:[1.33634699 1.03032944], bias:-1.1037517167230486, loss:0.5754663469606464\n",
      "epoch:1968, weight:[1.3366339  1.03047259], bias:-1.1039796010173166, loss:0.5754508701768487\n",
      "epoch:1969, weight:[1.33692082 1.03061568], bias:-1.1042074389958705, loss:0.5754353970243922\n",
      "epoch:1970, weight:[1.33720773 1.03075872], bias:-1.1044352306902958, loss:0.5754199275011382\n",
      "epoch:1971, weight:[1.33749464 1.03090171], bias:-1.1046629761321087, loss:0.5754044616049495\n",
      "epoch:1972, weight:[1.33778155 1.03104465], bias:-1.1048906753527554, loss:0.575388999333691\n",
      "epoch:1973, weight:[1.33806846 1.03118753], bias:-1.105118328383613, loss:0.5753735406852294\n",
      "epoch:1974, weight:[1.33835537 1.03133036], bias:-1.1053459352559896, loss:0.5753580856574327\n",
      "epoch:1975, weight:[1.33864228 1.03147314], bias:-1.1055734960011245, loss:0.5753426342481709\n",
      "epoch:1976, weight:[1.33892919 1.03161586], bias:-1.1058010106501888, loss:0.5753271864553159\n",
      "epoch:1977, weight:[1.3392161  1.03175853], bias:-1.1060284792342847, loss:0.5753117422767411\n",
      "epoch:1978, weight:[1.33950301 1.03190115], bias:-1.1062559017844469, loss:0.5752963017103215\n",
      "epoch:1979, weight:[1.33978992 1.03204372], bias:-1.106483278331642, loss:0.5752808647539345\n",
      "epoch:1980, weight:[1.34007683 1.03218623], bias:-1.1067106089067693, loss:0.5752654314054585\n",
      "epoch:1981, weight:[1.34036374 1.03232869], bias:-1.1069378935406606, loss:0.5752500016627741\n",
      "epoch:1982, weight:[1.34065065 1.0324711 ], bias:-1.1071651322640805, loss:0.5752345755237633\n",
      "epoch:1983, weight:[1.34093756 1.03261346], bias:-1.1073923251077271, loss:0.5752191529863101\n",
      "epoch:1984, weight:[1.34122447 1.03275576], bias:-1.1076194721022317, loss:0.5752037340483004\n",
      "epoch:1985, weight:[1.34151138 1.03289801], bias:-1.107846573278159, loss:0.5751883187076212\n",
      "epoch:1986, weight:[1.34179828 1.03304021], bias:-1.108073628666008, loss:0.5751729069621616\n",
      "epoch:1987, weight:[1.34208519 1.03318235], bias:-1.1083006382962115, loss:0.5751574988098127\n",
      "epoch:1988, weight:[1.3423721  1.03332445], bias:-1.1085276021991368, loss:0.575142094248467\n",
      "epoch:1989, weight:[1.34265901 1.03346649], bias:-1.1087545204050857, loss:0.5751266932760186\n",
      "epoch:1990, weight:[1.34294591 1.03360847], bias:-1.1089813929442949, loss:0.5751112958903634\n",
      "epoch:1991, weight:[1.34323282 1.03375041], bias:-1.1092082198469357, loss:0.5750959020893991\n",
      "epoch:1992, weight:[1.34351972 1.03389229], bias:-1.1094350011431153, loss:0.5750805118710253\n",
      "epoch:1993, weight:[1.34380663 1.03403412], bias:-1.109661736862876, loss:0.5750651252331431\n",
      "epoch:1994, weight:[1.34409353 1.0341759 ], bias:-1.109888427036196, loss:0.5750497421736552\n",
      "epoch:1995, weight:[1.34438044 1.03431762], bias:-1.1101150716929888, loss:0.5750343626904663\n",
      "epoch:1996, weight:[1.34466734 1.03445929], bias:-1.110341670863105, loss:0.5750189867814822\n",
      "epoch:1997, weight:[1.34495425 1.03460091], bias:-1.1105682245763313, loss:0.5750036144446115\n",
      "epoch:1998, weight:[1.34524115 1.03474248], bias:-1.1107947328623906, loss:0.5749882456777634\n",
      "epoch:1999, weight:[1.34552806 1.03488399], bias:-1.111021195750943, loss:0.5749728804788495\n",
      "epoch:2000, weight:[1.34581496 1.03502546], bias:-1.1112476132715856, loss:0.5749575188457826\n",
      "epoch:2001, weight:[1.34610186 1.03516686], bias:-1.1114739854538527, loss:0.5749421607764774\n",
      "epoch:2002, weight:[1.34638876 1.03530822], bias:-1.1117003123272162, loss:0.5749268062688505\n",
      "epoch:2003, weight:[1.34667566 1.03544953], bias:-1.1119265939210856, loss:0.5749114553208201\n",
      "epoch:2004, weight:[1.34696256 1.03559078], bias:-1.1121528302648087, loss:0.5748961079303059\n",
      "epoch:2005, weight:[1.34724946 1.03573198], bias:-1.112379021387671, loss:0.5748807640952293\n",
      "epoch:2006, weight:[1.34753636 1.03587313], bias:-1.1126051673188966, loss:0.5748654238135136\n",
      "epoch:2007, weight:[1.34782326 1.03601422], bias:-1.112831268087648, loss:0.5748500870830836\n",
      "epoch:2008, weight:[1.34811016 1.03615526], bias:-1.113057323723027, loss:0.5748347539018659\n",
      "epoch:2009, weight:[1.34839706 1.03629625], bias:-1.113283334254074, loss:0.5748194242677891\n",
      "epoch:2010, weight:[1.34868396 1.03643719], bias:-1.1135092997097686, loss:0.5748040981787823\n",
      "epoch:2011, weight:[1.34897086 1.03657808], bias:-1.11373522011903, loss:0.5747887756327779\n",
      "epoch:2012, weight:[1.34925775 1.03671891], bias:-1.1139610955107173, loss:0.5747734566277086\n",
      "epoch:2013, weight:[1.34954465 1.03685969], bias:-1.114186925913629, loss:0.5747581411615095\n",
      "epoch:2014, weight:[1.34983155 1.03700042], bias:-1.1144127113565039, loss:0.5747428292321173\n",
      "epoch:2015, weight:[1.35011844 1.0371411 ], bias:-1.1146384518680212, loss:0.5747275208374704\n",
      "epoch:2016, weight:[1.35040534 1.03728172], bias:-1.1148641474768006, loss:0.5747122159755084\n",
      "epoch:2017, weight:[1.35069223 1.03742229], bias:-1.1150897982114025, loss:0.5746969146441729\n",
      "epoch:2018, weight:[1.35097912 1.03756281], bias:-1.115315404100328, loss:0.5746816168414077\n",
      "epoch:2019, weight:[1.35126602 1.03770328], bias:-1.1155409651720194, loss:0.5746663225651572\n",
      "epoch:2020, weight:[1.35155291 1.0378437 ], bias:-1.1157664814548607, loss:0.5746510318133683\n",
      "epoch:2021, weight:[1.3518398  1.03798406], bias:-1.1159919529771771, loss:0.5746357445839889\n",
      "epoch:2022, weight:[1.35212669 1.03812437], bias:-1.1162173797672357, loss:0.5746204608749693\n",
      "epoch:2023, weight:[1.35241358 1.03826463], bias:-1.116442761853245, loss:0.5746051806842609\n",
      "epoch:2024, weight:[1.35270047 1.03840484], bias:-1.1166680992633569, loss:0.5745899040098169\n",
      "epoch:2025, weight:[1.35298736 1.03854499], bias:-1.116893392025664, loss:0.574574630849592\n",
      "epoch:2026, weight:[1.35327425 1.03868509], bias:-1.117118640168203, loss:0.5745593612015432\n",
      "epoch:2027, weight:[1.35356113 1.03882514], bias:-1.1173438437189525, loss:0.5745440950636282\n",
      "epoch:2028, weight:[1.35384802 1.03896514], bias:-1.117569002705834, loss:0.574528832433807\n",
      "epoch:2029, weight:[1.35413491 1.03910509], bias:-1.1177941171567127, loss:0.5745135733100409\n",
      "epoch:2030, weight:[1.35442179 1.03924498], bias:-1.1180191870993967, loss:0.5744983176902934\n",
      "epoch:2031, weight:[1.35470868 1.03938482], bias:-1.1182442125616379, loss:0.5744830655725286\n",
      "epoch:2032, weight:[1.35499556 1.03952461], bias:-1.1184691935711317, loss:0.5744678169547134\n",
      "epoch:2033, weight:[1.35528244 1.03966435], bias:-1.1186941301555178, loss:0.5744525718348155\n",
      "epoch:2034, weight:[1.35556933 1.03980403], bias:-1.1189190223423797, loss:0.5744373302108049\n",
      "epoch:2035, weight:[1.35585621 1.03994367], bias:-1.1191438701592453, loss:0.5744220920806522\n",
      "epoch:2036, weight:[1.35614309 1.04008325], bias:-1.1193686736335873, loss:0.5744068574423311\n",
      "epoch:2037, weight:[1.35642997 1.04022278], bias:-1.1195934327928228, loss:0.5743916262938156\n",
      "epoch:2038, weight:[1.35671685 1.04036226], bias:-1.1198181476643139, loss:0.5743763986330821\n",
      "epoch:2039, weight:[1.35700373 1.04050168], bias:-1.1200428182753677, loss:0.5743611744581083\n",
      "epoch:2040, weight:[1.3572906  1.04064105], bias:-1.1202674446532368, loss:0.5743459537668735\n",
      "epoch:2041, weight:[1.35757748 1.04078038], bias:-1.1204920268251195, loss:0.5743307365573589\n",
      "epoch:2042, weight:[1.35786436 1.04091965], bias:-1.1207165648181592, loss:0.574315522827547\n",
      "epoch:2043, weight:[1.35815123 1.04105886], bias:-1.1209410586594455, loss:0.5743003125754225\n",
      "epoch:2044, weight:[1.35843811 1.04119803], bias:-1.121165508376014, loss:0.5742851057989706\n",
      "epoch:2045, weight:[1.35872498 1.04133714], bias:-1.1213899139948464, loss:0.5742699024961795\n",
      "epoch:2046, weight:[1.35901185 1.04147621], bias:-1.121614275542871, loss:0.5742547026650379\n",
      "epoch:2047, weight:[1.35929872 1.04161522], bias:-1.121838593046963, loss:0.5742395063035364\n",
      "epoch:2048, weight:[1.3595856  1.04175417], bias:-1.1220628665339436, loss:0.5742243134096676\n",
      "epoch:2049, weight:[1.35987247 1.04189308], bias:-1.1222870960305815, loss:0.5742091239814257\n",
      "epoch:2050, weight:[1.36015933 1.04203193], bias:-1.1225112815635927, loss:0.5741939380168056\n",
      "epoch:2051, weight:[1.3604462  1.04217074], bias:-1.1227354231596403, loss:0.574178755513805\n",
      "epoch:2052, weight:[1.36073307 1.04230949], bias:-1.122959520845335, loss:0.5741635764704225\n",
      "epoch:2053, weight:[1.36101994 1.04244819], bias:-1.123183574647235, loss:0.5741484008846582\n",
      "epoch:2054, weight:[1.3613068  1.04258684], bias:-1.1234075845918468, loss:0.5741332287545147\n",
      "epoch:2055, weight:[1.36159367 1.04272543], bias:-1.1236315507056245, loss:0.5741180600779949\n",
      "epoch:2056, weight:[1.36188053 1.04286398], bias:-1.123855473014971, loss:0.5741028948531044\n",
      "epoch:2057, weight:[1.36216739 1.04300247], bias:-1.124079351546237, loss:0.5740877330778497\n",
      "epoch:2058, weight:[1.36245425 1.04314091], bias:-1.1243031863257225, loss:0.5740725747502392\n",
      "epoch:2059, weight:[1.36274112 1.0432793 ], bias:-1.1245269773796756, loss:0.5740574198682828\n",
      "epoch:2060, weight:[1.36302797 1.04341763], bias:-1.1247507247342936, loss:0.5740422684299923\n",
      "epoch:2061, weight:[1.36331483 1.04355592], bias:-1.1249744284157233, loss:0.5740271204333802\n",
      "epoch:2062, weight:[1.36360169 1.04369415], bias:-1.1251980884500603, loss:0.574011975876462\n",
      "epoch:2063, weight:[1.36388855 1.04383234], bias:-1.1254217048633501, loss:0.5739968347572536\n",
      "epoch:2064, weight:[1.3641754  1.04397047], bias:-1.1256452776815875, loss:0.5739816970737729\n",
      "epoch:2065, weight:[1.36446226 1.04410855], bias:-1.1258688069307174, loss:0.5739665628240392\n",
      "epoch:2066, weight:[1.36474911 1.04424657], bias:-1.1260922926366346, loss:0.5739514320060736\n",
      "epoch:2067, weight:[1.36503596 1.04438455], bias:-1.126315734825184, loss:0.5739363046178991\n",
      "epoch:2068, weight:[1.36532282 1.04452247], bias:-1.126539133522161, loss:0.573921180657539\n",
      "epoch:2069, weight:[1.36560967 1.04466035], bias:-1.1267624887533114, loss:0.5739060601230201\n",
      "epoch:2070, weight:[1.36589652 1.04479817], bias:-1.1269858005443318, loss:0.573890943012369\n",
      "epoch:2071, weight:[1.36618337 1.04493594], bias:-1.1272090689208696, loss:0.5738758293236151\n",
      "epoch:2072, weight:[1.36647021 1.04507365], bias:-1.127432293908523, loss:0.5738607190547885\n",
      "epoch:2073, weight:[1.36675706 1.04521132], bias:-1.127655475532842, loss:0.5738456122039215\n",
      "epoch:2074, weight:[1.3670439  1.04534894], bias:-1.1278786138193275, loss:0.5738305087690475\n",
      "epoch:2075, weight:[1.36733075 1.0454865 ], bias:-1.128101708793432, loss:0.5738154087482017\n",
      "epoch:2076, weight:[1.36761759 1.04562401], bias:-1.1283247604805595, loss:0.5738003121394212\n",
      "epoch:2077, weight:[1.36790443 1.04576147], bias:-1.1285477689060663, loss:0.5737852189407437\n",
      "epoch:2078, weight:[1.36819127 1.04589888], bias:-1.1287707340952606, loss:0.5737701291502098\n",
      "epoch:2079, weight:[1.36847811 1.04603624], bias:-1.1289936560734024, loss:0.57375504276586\n",
      "epoch:2080, weight:[1.36876495 1.04617355], bias:-1.1292165348657046, loss:0.5737399597857382\n",
      "epoch:2081, weight:[1.36905179 1.0463108 ], bias:-1.1294393704973322, loss:0.5737248802078886\n",
      "epoch:2082, weight:[1.36933862 1.046448  ], bias:-1.1296621629934032, loss:0.5737098040303571\n",
      "epoch:2083, weight:[1.36962546 1.04658516], bias:-1.1298849123789882, loss:0.5736947312511913\n",
      "epoch:2084, weight:[1.36991229 1.04672226], bias:-1.130107618679111, loss:0.5736796618684409\n",
      "epoch:2085, weight:[1.37019913 1.04685931], bias:-1.1303302819187484, loss:0.5736645958801562\n",
      "epoch:2086, weight:[1.37048596 1.0469963 ], bias:-1.1305529021228307, loss:0.5736495332843895\n",
      "epoch:2087, weight:[1.37077279 1.04713325], bias:-1.1307754793162414, loss:0.573634474079195\n",
      "epoch:2088, weight:[1.37105962 1.04727015], bias:-1.130998013523818, loss:0.5736194182626276\n",
      "epoch:2089, weight:[1.37134644 1.04740699], bias:-1.1312205047703514, loss:0.5736043658327447\n",
      "epoch:2090, weight:[1.37163327 1.04754378], bias:-1.1314429530805867, loss:0.5735893167876043\n",
      "epoch:2091, weight:[1.3719201  1.04768053], bias:-1.1316653584792233, loss:0.5735742711252668\n",
      "epoch:2092, weight:[1.37220692 1.04781722], bias:-1.1318877209909144, loss:0.5735592288437936\n",
      "epoch:2093, weight:[1.37249374 1.04795386], bias:-1.132110040640268, loss:0.5735441899412478\n",
      "epoch:2094, weight:[1.37278057 1.04809044], bias:-1.1323323174518465, loss:0.5735291544156939\n",
      "epoch:2095, weight:[1.37306739 1.04822698], bias:-1.1325545514501671, loss:0.5735141222651983\n",
      "epoch:2096, weight:[1.3733542  1.04836347], bias:-1.1327767426597022, loss:0.5734990934878283\n",
      "epoch:2097, weight:[1.37364102 1.0484999 ], bias:-1.1329988911048785, loss:0.5734840680816536\n",
      "epoch:2098, weight:[1.37392784 1.04863629], bias:-1.1332209968100786, loss:0.5734690460447447\n",
      "epoch:2099, weight:[1.37421465 1.04877262], bias:-1.13344305979964, loss:0.5734540273751738\n",
      "epoch:2100, weight:[1.37450147 1.0489089 ], bias:-1.1336650800978563, loss:0.5734390120710148\n",
      "epoch:2101, weight:[1.37478828 1.04904513], bias:-1.1338870577289757, loss:0.573424000130343\n",
      "epoch:2102, weight:[1.37507509 1.04918131], bias:-1.1341089927172032, loss:0.5734089915512353\n",
      "epoch:2103, weight:[1.3753619  1.04931744], bias:-1.1343308850866993, loss:0.5733939863317701\n",
      "epoch:2104, weight:[1.37564871 1.04945351], bias:-1.1345527348615807, loss:0.5733789844700271\n",
      "epoch:2105, weight:[1.37593552 1.04958954], bias:-1.1347745420659203, loss:0.5733639859640879\n",
      "epoch:2106, weight:[1.37622232 1.04972551], bias:-1.1349963067237474, loss:0.5733489908120353\n",
      "epoch:2107, weight:[1.37650913 1.04986144], bias:-1.1352180288590479, loss:0.5733339990119538\n",
      "epoch:2108, weight:[1.37679593 1.04999731], bias:-1.1354397084957644, loss:0.5733190105619294\n",
      "epoch:2109, weight:[1.37708273 1.05013313], bias:-1.1356613456577962, loss:0.5733040254600495\n",
      "epoch:2110, weight:[1.37736953 1.0502689 ], bias:-1.1358829403689998, loss:0.5732890437044031\n",
      "epoch:2111, weight:[1.37765633 1.05040462], bias:-1.1361044926531887, loss:0.5732740652930809\n",
      "epoch:2112, weight:[1.37794313 1.05054029], bias:-1.1363260025341335, loss:0.5732590902241744\n",
      "epoch:2113, weight:[1.37822993 1.05067591], bias:-1.1365474700355627, loss:0.5732441184957776\n",
      "epoch:2114, weight:[1.37851672 1.05081148], bias:-1.1367688951811619, loss:0.5732291501059854\n",
      "epoch:2115, weight:[1.37880352 1.05094699], bias:-1.1369902779945744, loss:0.5732141850528941\n",
      "epoch:2116, weight:[1.37909031 1.05108246], bias:-1.1372116184994019, loss:0.5731992233346017\n",
      "epoch:2117, weight:[1.3793771  1.05121787], bias:-1.1374329167192034, loss:0.5731842649492083\n",
      "epoch:2118, weight:[1.37966389 1.05135324], bias:-1.1376541726774965, loss:0.5731693098948143\n",
      "epoch:2119, weight:[1.37995068 1.05148855], bias:-1.1378753863977566, loss:0.5731543581695224\n",
      "epoch:2120, weight:[1.38023746 1.05162381], bias:-1.1380965579034183, loss:0.5731394097714366\n",
      "epoch:2121, weight:[1.38052425 1.05175902], bias:-1.138317687217874, loss:0.5731244646986624\n",
      "epoch:2122, weight:[1.38081103 1.05189418], bias:-1.138538774364475, loss:0.5731095229493071\n",
      "epoch:2123, weight:[1.38109781 1.05202929], bias:-1.1387598193665318, loss:0.5730945845214787\n",
      "epoch:2124, weight:[1.38138459 1.05216435], bias:-1.1389808222473132, loss:0.5730796494132874\n",
      "epoch:2125, weight:[1.38167137 1.05229936], bias:-1.1392017830300478, loss:0.5730647176228445\n",
      "epoch:2126, weight:[1.38195815 1.05243432], bias:-1.1394227017379228, loss:0.5730497891482635\n",
      "epoch:2127, weight:[1.38224492 1.05256922], bias:-1.1396435783940853, loss:0.5730348639876586\n",
      "epoch:2128, weight:[1.3825317  1.05270408], bias:-1.1398644130216415, loss:0.5730199421391451\n",
      "epoch:2129, weight:[1.38281847 1.05283888], bias:-1.140085205643658, loss:0.5730050236008415\n",
      "epoch:2130, weight:[1.38310524 1.05297364], bias:-1.14030595628316, loss:0.5729901083708658\n",
      "epoch:2131, weight:[1.38339201 1.05310834], bias:-1.1405266649631336, loss:0.5729751964473387\n",
      "epoch:2132, weight:[1.38367878 1.053243  ], bias:-1.1407473317065246, loss:0.5729602878283823\n",
      "epoch:2133, weight:[1.38396555 1.0533776 ], bias:-1.1409679565362392, loss:0.5729453825121197\n",
      "epoch:2134, weight:[1.38425231 1.05351215], bias:-1.1411885394751433, loss:0.5729304804966756\n",
      "epoch:2135, weight:[1.38453908 1.05364665], bias:-1.141409080546064, loss:0.5729155817801765\n",
      "epoch:2136, weight:[1.38482584 1.0537811 ], bias:-1.1416295797717886, loss:0.5729006863607502\n",
      "epoch:2137, weight:[1.3851126 1.0539155], bias:-1.1418500371750653, loss:0.5728857942365256\n",
      "epoch:2138, weight:[1.38539936 1.05404985], bias:-1.142070452778603, loss:0.5728709054056338\n",
      "epoch:2139, weight:[1.38568612 1.05418415], bias:-1.1422908266050715, loss:0.5728560198662067\n",
      "epoch:2140, weight:[1.38597287 1.0543184 ], bias:-1.142511158677102, loss:0.572841137616378\n",
      "epoch:2141, weight:[1.38625963 1.0544526 ], bias:-1.1427314490172866, loss:0.5728262586542829\n",
      "epoch:2142, weight:[1.38654638 1.05458675], bias:-1.1429516976481793, loss:0.572811382978058\n",
      "epoch:2143, weight:[1.38683313 1.05472085], bias:-1.143171904592295, loss:0.5727965105858411\n",
      "epoch:2144, weight:[1.38711988 1.05485489], bias:-1.1433920698721105, loss:0.5727816414757719\n",
      "epoch:2145, weight:[1.38740663 1.05498889], bias:-1.1436121935100643, loss:0.5727667756459914\n",
      "epoch:2146, weight:[1.38769337 1.05512283], bias:-1.1438322755285568, loss:0.5727519130946419\n",
      "epoch:2147, weight:[1.38798012 1.05525673], bias:-1.1440523159499507, loss:0.5727370538198673\n",
      "epoch:2148, weight:[1.38826686 1.05539058], bias:-1.1442723147965703, loss:0.5727221978198128\n",
      "epoch:2149, weight:[1.3885536  1.05552437], bias:-1.1444922720907025, loss:0.5727073450926257\n",
      "epoch:2150, weight:[1.38884034 1.05565811], bias:-1.1447121878545963, loss:0.5726924956364535\n",
      "epoch:2151, weight:[1.38912708 1.05579181], bias:-1.1449320621104635, loss:0.5726776494494463\n",
      "epoch:2152, weight:[1.38941382 1.05592545], bias:-1.1451518948804786, loss:0.5726628065297555\n",
      "epoch:2153, weight:[1.38970055 1.05605905], bias:-1.1453716861867786, loss:0.5726479668755331\n",
      "epoch:2154, weight:[1.38998728 1.05619259], bias:-1.1455914360514636, loss:0.5726331304849336\n",
      "epoch:2155, weight:[1.39027401 1.05632608], bias:-1.1458111444965964, loss:0.5726182973561124\n",
      "epoch:2156, weight:[1.39056074 1.05645952], bias:-1.146030811544203, loss:0.5726034674872262\n",
      "epoch:2157, weight:[1.39084747 1.05659292], bias:-1.1462504372162732, loss:0.5725886408764338\n",
      "epoch:2158, weight:[1.3911342  1.05672626], bias:-1.1464700215347592, loss:0.5725738175218947\n",
      "epoch:2159, weight:[1.39142092 1.05685955], bias:-1.1466895645215776, loss:0.5725589974217703\n",
      "epoch:2160, weight:[1.39170764 1.05699279], bias:-1.146909066198608, loss:0.5725441805742233\n",
      "epoch:2161, weight:[1.39199436 1.05712598], bias:-1.1471285265876943, loss:0.5725293669774177\n",
      "epoch:2162, weight:[1.39228108 1.05725912], bias:-1.1473479457106435, loss:0.5725145566295192\n",
      "epoch:2163, weight:[1.3925678  1.05739222], bias:-1.1475673235892272, loss:0.5724997495286952\n",
      "epoch:2164, weight:[1.39285452 1.05752526], bias:-1.1477866602451807, loss:0.5724849456731134\n",
      "epoch:2165, weight:[1.39314123 1.05765825], bias:-1.1480059557002038, loss:0.5724701450609443\n",
      "epoch:2166, weight:[1.39342794 1.05779119], bias:-1.1482252099759604, loss:0.5724553476903588\n",
      "epoch:2167, weight:[1.39371465 1.05792408], bias:-1.1484444230940791, loss:0.5724405535595299\n",
      "epoch:2168, weight:[1.39400136 1.05805692], bias:-1.1486635950761528, loss:0.5724257626666317\n",
      "epoch:2169, weight:[1.39428807 1.05818971], bias:-1.1488827259437393, loss:0.57241097500984\n",
      "epoch:2170, weight:[1.39457477 1.05832245], bias:-1.149101815718361, loss:0.5723961905873315\n",
      "epoch:2171, weight:[1.39486147 1.05845514], bias:-1.1493208644215052, loss:0.5723814093972847\n",
      "epoch:2172, weight:[1.39514818 1.05858778], bias:-1.1495398720746242, loss:0.5723666314378801\n",
      "epoch:2173, weight:[1.39543488 1.05872037], bias:-1.1497588386991358, loss:0.5723518567072982\n",
      "epoch:2174, weight:[1.39572157 1.05885291], bias:-1.1499777643164226, loss:0.572337085203722\n",
      "epoch:2175, weight:[1.39600827 1.0589854 ], bias:-1.1501966489478328, loss:0.5723223169253356\n",
      "epoch:2176, weight:[1.39629496 1.05911784], bias:-1.1504154926146801, loss:0.572307551870325\n",
      "epoch:2177, weight:[1.39658165 1.05925023], bias:-1.1506342953382436, loss:0.5722927900368769\n",
      "epoch:2178, weight:[1.39686834 1.05938257], bias:-1.1508530571397682, loss:0.5722780314231793\n",
      "epoch:2179, weight:[1.39715503 1.05951486], bias:-1.1510717780404647, loss:0.5722632760274227\n",
      "epoch:2180, weight:[1.39744172 1.0596471 ], bias:-1.1512904580615098, loss:0.572248523847798\n",
      "epoch:2181, weight:[1.3977284  1.05977929], bias:-1.151509097224046, loss:0.5722337748824977\n",
      "epoch:2182, weight:[1.39801509 1.05991144], bias:-1.1517276955491824, loss:0.5722190291297161\n",
      "epoch:2183, weight:[1.39830177 1.06004353], bias:-1.1519462530579943, loss:0.5722042865876487\n",
      "epoch:2184, weight:[1.39858845 1.06017557], bias:-1.1521647697715227, loss:0.5721895472544921\n",
      "epoch:2185, weight:[1.39887512 1.06030756], bias:-1.1523832457107759, loss:0.5721748111284449\n",
      "epoch:2186, weight:[1.3991618 1.0604395], bias:-1.1526016808967283, loss:0.5721600782077064\n",
      "epoch:2187, weight:[1.39944847 1.06057139], bias:-1.1528200753503213, loss:0.5721453484904782\n",
      "epoch:2188, weight:[1.39973514 1.06070324], bias:-1.1530384290924627, loss:0.5721306219749622\n",
      "epoch:2189, weight:[1.40002181 1.06083503], bias:-1.1532567421440276, loss:0.5721158986593629\n",
      "epoch:2190, weight:[1.40030848 1.06096677], bias:-1.153475014525858, loss:0.5721011785418852\n",
      "epoch:2191, weight:[1.40059515 1.06109846], bias:-1.1536932462587632, loss:0.5720864616207358\n",
      "epoch:2192, weight:[1.40088181 1.06123011], bias:-1.1539114373635195, loss:0.572071747894123\n",
      "epoch:2193, weight:[1.40116847 1.0613617 ], bias:-1.1541295878608704, loss:0.5720570373602563\n",
      "epoch:2194, weight:[1.40145513 1.06149324], bias:-1.1543476977715272, loss:0.5720423300173463\n",
      "epoch:2195, weight:[1.40174179 1.06162474], bias:-1.1545657671161687, loss:0.5720276258636052\n",
      "epoch:2196, weight:[1.40202844 1.06175618], bias:-1.154783795915441, loss:0.5720129248972473\n",
      "epoch:2197, weight:[1.4023151  1.06188758], bias:-1.1550017841899582, loss:0.5719982271164871\n",
      "epoch:2198, weight:[1.40260175 1.06201892], bias:-1.1552197319603026, loss:0.5719835325195413\n",
      "epoch:2199, weight:[1.4028884  1.06215022], bias:-1.155437639247024, loss:0.5719688411046278\n",
      "epoch:2200, weight:[1.40317505 1.06228147], bias:-1.1556555060706404, loss:0.5719541528699655\n",
      "epoch:2201, weight:[1.40346169 1.06241266], bias:-1.1558733324516381, loss:0.5719394678137754\n",
      "epoch:2202, weight:[1.40374834 1.06254381], bias:-1.1560911184104716, loss:0.5719247859342793\n",
      "epoch:2203, weight:[1.40403498 1.06267491], bias:-1.1563088639675636, loss:0.5719101072297007\n",
      "epoch:2204, weight:[1.40432162 1.06280595], bias:-1.1565265691433058, loss:0.5718954316982642\n",
      "epoch:2205, weight:[1.40460826 1.06293695], bias:-1.1567442339580578, loss:0.5718807593381962\n",
      "epoch:2206, weight:[1.40489489 1.0630679 ], bias:-1.1569618584321484, loss:0.5718660901477239\n",
      "epoch:2207, weight:[1.40518153 1.0631988 ], bias:-1.157179442585875, loss:0.5718514241250765\n",
      "epoch:2208, weight:[1.40546816 1.06332965], bias:-1.157396986439504, loss:0.5718367612684842\n",
      "epoch:2209, weight:[1.40575479 1.06346045], bias:-1.1576144900132705, loss:0.5718221015761785\n",
      "epoch:2210, weight:[1.40604141 1.0635912 ], bias:-1.1578319533273793, loss:0.5718074450463928\n",
      "epoch:2211, weight:[1.40632804 1.06372191], bias:-1.1580493764020037, loss:0.5717927916773611\n",
      "epoch:2212, weight:[1.40661466 1.06385256], bias:-1.1582667592572866, loss:0.5717781414673194\n",
      "epoch:2213, weight:[1.40690129 1.06398316], bias:-1.1584841019133403, loss:0.5717634944145051\n",
      "epoch:2214, weight:[1.4071879  1.06411372], bias:-1.1587014043902466, loss:0.5717488505171562\n",
      "epoch:2215, weight:[1.40747452 1.06424422], bias:-1.1589186667080567, loss:0.571734209773513\n",
      "epoch:2216, weight:[1.40776114 1.06437468], bias:-1.1591358888867915, loss:0.5717195721818166\n",
      "epoch:2217, weight:[1.40804775 1.06450508], bias:-1.1593530709464421, loss:0.5717049377403097\n",
      "epoch:2218, weight:[1.40833436 1.06463544], bias:-1.159570212906969, loss:0.5716903064472363\n",
      "epoch:2219, weight:[1.40862097 1.06476575], bias:-1.1597873147883027, loss:0.5716756783008416\n",
      "epoch:2220, weight:[1.40890758 1.064896  ], bias:-1.160004376610344, loss:0.5716610532993728\n",
      "epoch:2221, weight:[1.40919418 1.06502621], bias:-1.160221398392964, loss:0.5716464314410772\n",
      "epoch:2222, weight:[1.40948078 1.06515637], bias:-1.1604383801560034, loss:0.571631812724205\n",
      "epoch:2223, weight:[1.40976738 1.06528648], bias:-1.160655321919274, loss:0.5716171971470065\n",
      "epoch:2224, weight:[1.41005398 1.06541654], bias:-1.1608722237025573, loss:0.5716025847077343\n",
      "epoch:2225, weight:[1.41034058 1.06554656], bias:-1.161089085525606, loss:0.5715879754046415\n",
      "epoch:2226, weight:[1.41062717 1.06567652], bias:-1.161305907408143, loss:0.5715733692359832\n",
      "epoch:2227, weight:[1.41091376 1.06580643], bias:-1.1615226893698625, loss:0.5715587662000156\n",
      "epoch:2228, weight:[1.41120035 1.0659363 ], bias:-1.1617394314304288, loss:0.5715441662949963\n",
      "epoch:2229, weight:[1.41148694 1.06606611], bias:-1.1619561336094775, loss:0.5715295695191841\n",
      "epoch:2230, weight:[1.41177353 1.06619588], bias:-1.162172795926615, loss:0.5715149758708394\n",
      "epoch:2231, weight:[1.41206011 1.0663256 ], bias:-1.1623894184014194, loss:0.5715003853482238\n",
      "epoch:2232, weight:[1.41234669 1.06645526], bias:-1.1626060010534391, loss:0.5714857979496002\n",
      "epoch:2233, weight:[1.41263327 1.06658488], bias:-1.1628225439021944, loss:0.5714712136732334\n",
      "epoch:2234, weight:[1.41291985 1.06671445], bias:-1.1630390469671767, loss:0.5714566325173882\n",
      "epoch:2235, weight:[1.41320642 1.06684398], bias:-1.163255510267849, loss:0.5714420544803325\n",
      "epoch:2236, weight:[1.41349299 1.06697345], bias:-1.1634719338236457, loss:0.5714274795603341\n",
      "epoch:2237, weight:[1.41377956 1.06710287], bias:-1.163688317653973, loss:0.571412907755663\n",
      "epoch:2238, weight:[1.41406613 1.06723225], bias:-1.1639046617782087, loss:0.5713983390645901\n",
      "epoch:2239, weight:[1.4143527  1.06736157], bias:-1.1641209662157026, loss:0.5713837734853878\n",
      "epoch:2240, weight:[1.41463926 1.06749085], bias:-1.1643372309857762, loss:0.5713692110163298\n",
      "epoch:2241, weight:[1.41492582 1.06762007], bias:-1.1645534561077233, loss:0.5713546516556911\n",
      "epoch:2242, weight:[1.41521238 1.06774925], bias:-1.1647696416008095, loss:0.5713400954017485\n",
      "epoch:2243, weight:[1.41549894 1.06787838], bias:-1.1649857874842726, loss:0.571325542252779\n",
      "epoch:2244, weight:[1.41578549 1.06800746], bias:-1.1652018937773228, loss:0.5713109922070626\n",
      "epoch:2245, weight:[1.41607204 1.0681365 ], bias:-1.1654179604991424, loss:0.5712964452628788\n",
      "epoch:2246, weight:[1.41635859 1.06826548], bias:-1.1656339876688866, loss:0.57128190141851\n",
      "epoch:2247, weight:[1.41664514 1.06839441], bias:-1.1658499753056826, loss:0.5712673606722387\n",
      "epoch:2248, weight:[1.41693168 1.0685233 ], bias:-1.1660659234286306, loss:0.5712528230223498\n",
      "epoch:2249, weight:[1.41721823 1.06865214], bias:-1.1662818320568034, loss:0.5712382884671287\n",
      "epoch:2250, weight:[1.41750477 1.06878092], bias:-1.1664977012092463, loss:0.5712237570048625\n",
      "epoch:2251, weight:[1.41779131 1.06890966], bias:-1.1667135309049779, loss:0.5712092286338396\n",
      "epoch:2252, weight:[1.41807784 1.06903835], bias:-1.1669293211629894, loss:0.5711947033523497\n",
      "epoch:2253, weight:[1.41836438 1.069167  ], bias:-1.1671450720022454, loss:0.5711801811586837\n",
      "epoch:2254, weight:[1.41865091 1.06929559], bias:-1.1673607834416833, loss:0.5711656620511344\n",
      "epoch:2255, weight:[1.41893744 1.06942413], bias:-1.1675764555002137, loss:0.5711511460279947\n",
      "epoch:2256, weight:[1.41922396 1.06955263], bias:-1.1677920881967208, loss:0.57113663308756\n",
      "epoch:2257, weight:[1.41951049 1.06968108], bias:-1.168007681550062, loss:0.5711221232281267\n",
      "epoch:2258, weight:[1.41979701 1.06980948], bias:-1.1682232355790678, loss:0.5711076164479922\n",
      "epoch:2259, weight:[1.42008353 1.06993783], bias:-1.168438750302543, loss:0.5710931127454558\n",
      "epoch:2260, weight:[1.42037005 1.07006613], bias:-1.1686542257392654, loss:0.571078612118817\n",
      "epoch:2261, weight:[1.42065656 1.07019438], bias:-1.1688696619079866, loss:0.5710641145663781\n",
      "epoch:2262, weight:[1.42094308 1.07032258], bias:-1.1690850588274322, loss:0.5710496200864416\n",
      "epoch:2263, weight:[1.42122959 1.07045074], bias:-1.1693004165163017, loss:0.5710351286773118\n",
      "epoch:2264, weight:[1.4215161  1.07057885], bias:-1.169515734993268, loss:0.571020640337294\n",
      "epoch:2265, weight:[1.4218026  1.07070691], bias:-1.169731014276979, loss:0.5710061550646953\n",
      "epoch:2266, weight:[1.4220891  1.07083492], bias:-1.1699462543860557, loss:0.5709916728578237\n",
      "epoch:2267, weight:[1.42237561 1.07096288], bias:-1.170161455339094, loss:0.5709771937149883\n",
      "epoch:2268, weight:[1.4226621  1.07109079], bias:-1.1703766171546637, loss:0.5709627176345003\n",
      "epoch:2269, weight:[1.4229486  1.07121866], bias:-1.1705917398513088, loss:0.5709482446146716\n",
      "epoch:2270, weight:[1.42323509 1.07134647], bias:-1.1708068234475484, loss:0.5709337746538156\n",
      "epoch:2271, weight:[1.42352159 1.07147424], bias:-1.1710218679618754, loss:0.5709193077502464\n",
      "epoch:2272, weight:[1.42380807 1.07160196], bias:-1.1712368734127576, loss:0.5709048439022802\n",
      "epoch:2273, weight:[1.42409456 1.07172963], bias:-1.1714518398186375, loss:0.5708903831082348\n",
      "epoch:2274, weight:[1.42438104 1.07185725], bias:-1.1716667671979324, loss:0.570875925366428\n",
      "epoch:2275, weight:[1.42466753 1.07198483], bias:-1.1718816555690343, loss:0.57086147067518\n",
      "epoch:2276, weight:[1.42495401 1.07211235], bias:-1.17209650495031, loss:0.5708470190328117\n",
      "epoch:2277, weight:[1.42524048 1.07223983], bias:-1.1723113153601015, loss:0.5708325704376458\n",
      "epoch:2278, weight:[1.42552696 1.07236726], bias:-1.1725260868167255, loss:0.5708181248880058\n",
      "epoch:2279, weight:[1.42581343 1.07249464], bias:-1.1727408193384745, loss:0.5708036823822163\n",
      "epoch:2280, weight:[1.4260999  1.07262198], bias:-1.1729555129436156, loss:0.5707892429186047\n",
      "epoch:2281, weight:[1.42638637 1.07274926], bias:-1.1731701676503912, loss:0.5707748064954977\n",
      "epoch:2282, weight:[1.42667283 1.0728765 ], bias:-1.1733847834770195, loss:0.5707603731112244\n",
      "epoch:2283, weight:[1.42695929 1.07300369], bias:-1.1735993604416937, loss:0.570745942764115\n",
      "epoch:2284, weight:[1.42724575 1.07313083], bias:-1.1738138985625826, loss:0.5707315154525009\n",
      "epoch:2285, weight:[1.42753221 1.07325792], bias:-1.1740283978578308, loss:0.5707170911747148\n",
      "epoch:2286, weight:[1.42781866 1.07338496], bias:-1.1742428583455584, loss:0.570702669929091\n",
      "epoch:2287, weight:[1.42810512 1.07351196], bias:-1.1744572800438615, loss:0.5706882517139644\n",
      "epoch:2288, weight:[1.42839157 1.0736389 ], bias:-1.1746716629708114, loss:0.5706738365276721\n",
      "epoch:2289, weight:[1.42867801 1.0737658 ], bias:-1.1748860071444558, loss:0.5706594243685514\n",
      "epoch:2290, weight:[1.42896446 1.07389265], bias:-1.1751003125828183, loss:0.5706450152349416\n",
      "epoch:2291, weight:[1.4292509  1.07401946], bias:-1.1753145793038984, loss:0.5706306091251836\n",
      "epoch:2292, weight:[1.42953734 1.07414621], bias:-1.1755288073256718, loss:0.5706162060376186\n",
      "epoch:2293, weight:[1.42982378 1.07427292], bias:-1.1757429966660902, loss:0.5706018059705898\n",
      "epoch:2294, weight:[1.43011021 1.07439958], bias:-1.1759571473430819, loss:0.5705874089224413\n",
      "epoch:2295, weight:[1.43039664 1.07452619], bias:-1.176171259374551, loss:0.570573014891519\n",
      "epoch:2296, weight:[1.43068307 1.07465275], bias:-1.1763853327783786, loss:0.5705586238761692\n",
      "epoch:2297, weight:[1.4309695  1.07477927], bias:-1.1765993675724218, loss:0.5705442358747403\n",
      "epoch:2298, weight:[1.43125593 1.07490574], bias:-1.1768133637745144, loss:0.5705298508855818\n",
      "epoch:2299, weight:[1.43154235 1.07503215], bias:-1.177027321402467, loss:0.5705154689070441\n",
      "epoch:2300, weight:[1.43182877 1.07515853], bias:-1.1772412404740664, loss:0.5705010899374791\n",
      "epoch:2301, weight:[1.43211518 1.07528485], bias:-1.1774551210070767, loss:0.5704867139752398\n",
      "epoch:2302, weight:[1.4324016  1.07541112], bias:-1.1776689630192385, loss:0.5704723410186813\n",
      "epoch:2303, weight:[1.43268801 1.07553735], bias:-1.1778827665282692, loss:0.5704579710661583\n",
      "epoch:2304, weight:[1.43297442 1.07566353], bias:-1.1780965315518634, loss:0.5704436041160286\n",
      "epoch:2305, weight:[1.43326083 1.07578966], bias:-1.1783102581076927, loss:0.5704292401666501\n",
      "epoch:2306, weight:[1.43354723 1.07591575], bias:-1.1785239462134058, loss:0.5704148792163821\n",
      "epoch:2307, weight:[1.43383363 1.07604178], bias:-1.1787375958866284, loss:0.5704005212635858\n",
      "epoch:2308, weight:[1.43412003 1.07616777], bias:-1.1789512071449637, loss:0.5703861663066229\n",
      "epoch:2309, weight:[1.43440643 1.07629371], bias:-1.179164780005992, loss:0.5703718143438566\n",
      "epoch:2310, weight:[1.43469282 1.07641961], bias:-1.1793783144872707, loss:0.5703574653736517\n",
      "epoch:2311, weight:[1.43497921 1.07654545], bias:-1.1795918106063354, loss:0.570343119394374\n",
      "epoch:2312, weight:[1.4352656  1.07667125], bias:-1.1798052683806988, loss:0.5703287764043904\n",
      "epoch:2313, weight:[1.43555198 1.076797  ], bias:-1.180018687827851, loss:0.570314436402069\n",
      "epoch:2314, weight:[1.43583837 1.0769227 ], bias:-1.18023206896526, loss:0.5703000993857796\n",
      "epoch:2315, weight:[1.43612475 1.07704835], bias:-1.1804454118103713, loss:0.5702857653538929\n",
      "epoch:2316, weight:[1.43641113 1.07717396], bias:-1.1806587163806086, loss:0.5702714343047813\n",
      "epoch:2317, weight:[1.4366975  1.07729952], bias:-1.1808719826933731, loss:0.5702571062368176\n",
      "epoch:2318, weight:[1.43698387 1.07742503], bias:-1.181085210766044, loss:0.5702427811483767\n",
      "epoch:2319, weight:[1.43727024 1.07755049], bias:-1.1812984006159781, loss:0.5702284590378341\n",
      "epoch:2320, weight:[1.43755661 1.07767591], bias:-1.1815115522605109, loss:0.5702141399035672\n",
      "epoch:2321, weight:[1.43784298 1.07780128], bias:-1.1817246657169556, loss:0.5701998237439543\n",
      "epoch:2322, weight:[1.43812934 1.0779266 ], bias:-1.1819377410026037, loss:0.5701855105573744\n",
      "epoch:2323, weight:[1.4384157  1.07805187], bias:-1.1821507781347251, loss:0.5701712003422089\n",
      "epoch:2324, weight:[1.43870205 1.0781771 ], bias:-1.1823637771305677, loss:0.5701568930968395\n",
      "epoch:2325, weight:[1.43898841 1.07830228], bias:-1.182576738007358, loss:0.5701425888196497\n",
      "epoch:2326, weight:[1.43927476 1.07842741], bias:-1.1827896607823007, loss:0.5701282875090239\n",
      "epoch:2327, weight:[1.43956111 1.07855249], bias:-1.1830025454725792, loss:0.5701139891633479\n",
      "epoch:2328, weight:[1.43984745 1.07867753], bias:-1.1832153920953554, loss:0.5700996937810084\n",
      "epoch:2329, weight:[1.4401338  1.07880252], bias:-1.1834282006677699, loss:0.5700854013603941\n",
      "epoch:2330, weight:[1.44042014 1.07892746], bias:-1.183640971206942, loss:0.5700711118998941\n",
      "epoch:2331, weight:[1.44070647 1.07905235], bias:-1.1838537037299695, loss:0.5700568253978994\n",
      "epoch:2332, weight:[1.44099281 1.0791772 ], bias:-1.1840663982539292, loss:0.5700425418528017\n",
      "epoch:2333, weight:[1.44127914 1.079302  ], bias:-1.184279054795877, loss:0.5700282612629942\n",
      "epoch:2334, weight:[1.44156547 1.07942675], bias:-1.1844916733728472, loss:0.5700139836268714\n",
      "epoch:2335, weight:[1.4418518  1.07955145], bias:-1.1847042540018538, loss:0.5699997089428289\n",
      "epoch:2336, weight:[1.44213812 1.07967611], bias:-1.1849167966998893, loss:0.5699854372092635\n",
      "epoch:2337, weight:[1.44242444 1.07980072], bias:-1.1851293014839253, loss:0.5699711684245736\n",
      "epoch:2338, weight:[1.44271076 1.07992528], bias:-1.185341768370913, loss:0.5699569025871581\n",
      "epoch:2339, weight:[1.44299708 1.0800498 ], bias:-1.185554197377783, loss:0.5699426396954179\n",
      "epoch:2340, weight:[1.44328339 1.08017426], bias:-1.1857665885214443, loss:0.5699283797477543\n",
      "epoch:2341, weight:[1.4435697  1.08029868], bias:-1.1859789418187863, loss:0.5699141227425709\n",
      "epoch:2342, weight:[1.44385601 1.08042306], bias:-1.186191257286677, loss:0.5698998686782715\n",
      "epoch:2343, weight:[1.44414231 1.08054738], bias:-1.1864035349419646, loss:0.5698856175532617\n",
      "epoch:2344, weight:[1.44442862 1.08067166], bias:-1.1866157748014763, loss:0.5698713693659483\n",
      "epoch:2345, weight:[1.44471491 1.08079589], bias:-1.1868279768820194, loss:0.5698571241147389\n",
      "epoch:2346, weight:[1.44500121 1.08092008], bias:-1.1870401412003804, loss:0.5698428817980425\n",
      "epoch:2347, weight:[1.4452875  1.08104422], bias:-1.1872522677733257, loss:0.5698286424142702\n",
      "epoch:2348, weight:[1.4455738  1.08116831], bias:-1.1874643566176017, loss:0.5698144059618329\n",
      "epoch:2349, weight:[1.44586008 1.08129235], bias:-1.1876764077499344, loss:0.5698001724391433\n",
      "epoch:2350, weight:[1.44614637 1.08141635], bias:-1.18788842118703, loss:0.569785941844616\n",
      "epoch:2351, weight:[1.44643265 1.0815403 ], bias:-1.1881003969455743, loss:0.5697717141766653\n",
      "epoch:2352, weight:[1.44671893 1.0816642 ], bias:-1.1883123350422335, loss:0.5697574894337083\n",
      "epoch:2353, weight:[1.44700521 1.08178805], bias:-1.1885242354936536, loss:0.5697432676141623\n",
      "epoch:2354, weight:[1.44729148 1.08191186], bias:-1.1887360983164608, loss:0.5697290487164464\n",
      "epoch:2355, weight:[1.44757775 1.08203562], bias:-1.1889479235272615, loss:0.5697148327389803\n",
      "epoch:2356, weight:[1.44786402 1.08215933], bias:-1.1891597111426424, loss:0.5697006196801856\n",
      "epoch:2357, weight:[1.44815029 1.082283  ], bias:-1.1893714611791706, loss:0.5696864095384844\n",
      "epoch:2358, weight:[1.44843655 1.08240662], bias:-1.1895831736533935, loss:0.5696722023123008\n",
      "epoch:2359, weight:[1.44872281 1.0825302 ], bias:-1.189794848581839, loss:0.5696579980000591\n",
      "epoch:2360, weight:[1.44900907 1.08265372], bias:-1.1900064859810153, loss:0.5696437966001859\n",
      "epoch:2361, weight:[1.44929532 1.0827772 ], bias:-1.1902180858674114, loss:0.5696295981111082\n",
      "epoch:2362, weight:[1.44958157 1.08290063], bias:-1.1904296482574965, loss:0.5696154025312546\n",
      "epoch:2363, weight:[1.44986782 1.08302402], bias:-1.1906411731677211, loss:0.5696012098590549\n",
      "epoch:2364, weight:[1.45015407 1.08314736], bias:-1.1908526606145158, loss:0.5695870200929397\n",
      "epoch:2365, weight:[1.45044031 1.08327065], bias:-1.191064110614292, loss:0.569572833231341\n",
      "epoch:2366, weight:[1.45072655 1.08339389], bias:-1.1912755231834427, loss:0.5695586492726927\n",
      "epoch:2367, weight:[1.45101278 1.08351709], bias:-1.1914868983383406, loss:0.5695444682154288\n",
      "epoch:2368, weight:[1.45129902 1.08364024], bias:-1.1916982360953405, loss:0.5695302900579851\n",
      "epoch:2369, weight:[1.45158525 1.08376335], bias:-1.1919095364707772, loss:0.5695161147987984\n",
      "epoch:2370, weight:[1.45187148 1.08388641], bias:-1.1921207994809673, loss:0.5695019424363067\n",
      "epoch:2371, weight:[1.4521577  1.08400942], bias:-1.1923320251422078, loss:0.5694877729689496\n",
      "epoch:2372, weight:[1.45244393 1.08413238], bias:-1.1925432134707776, loss:0.5694736063951673\n",
      "epoch:2373, weight:[1.45273015 1.0842553 ], bias:-1.1927543644829364, loss:0.5694594427134017\n",
      "epoch:2374, weight:[1.45301636 1.08437817], bias:-1.1929654781949248, loss:0.5694452819220953\n",
      "epoch:2375, weight:[1.45330258 1.084501  ], bias:-1.1931765546229656, loss:0.5694311240196922\n",
      "epoch:2376, weight:[1.45358879 1.08462377], bias:-1.193387593783262, loss:0.5694169690046377\n",
      "epoch:2377, weight:[1.45387499 1.0847465 ], bias:-1.1935985956919997, loss:0.5694028168753783\n",
      "epoch:2378, weight:[1.4541612  1.08486919], bias:-1.193809560365345, loss:0.5693886676303616\n",
      "epoch:2379, weight:[1.4544474  1.08499183], bias:-1.1940204878194458, loss:0.569374521268036\n",
      "epoch:2380, weight:[1.4547336  1.08511442], bias:-1.1942313780704321, loss:0.569360377786852\n",
      "epoch:2381, weight:[1.4550198  1.08523696], bias:-1.194442231134415, loss:0.5693462371852603\n",
      "epoch:2382, weight:[1.45530599 1.08535946], bias:-1.1946530470274874, loss:0.5693320994617136\n",
      "epoch:2383, weight:[1.45559218 1.08548191], bias:-1.1948638257657245, loss:0.5693179646146651\n",
      "epoch:2384, weight:[1.45587837 1.08560432], bias:-1.1950745673651824, loss:0.5693038326425699\n",
      "epoch:2385, weight:[1.45616455 1.08572668], bias:-1.1952852718418996, loss:0.5692897035438833\n",
      "epoch:2386, weight:[1.45645073 1.08584899], bias:-1.1954959392118965, loss:0.5692755773170629\n",
      "epoch:2387, weight:[1.45673691 1.08597126], bias:-1.195706569491175, loss:0.5692614539605668\n",
      "epoch:2388, weight:[1.45702309 1.08609347], bias:-1.1959171626957197, loss:0.5692473334728541\n",
      "epoch:2389, weight:[1.45730926 1.08621565], bias:-1.1961277188414967, loss:0.5692332158523855\n",
      "epoch:2390, weight:[1.45759543 1.08633777], bias:-1.1963382379444543, loss:0.569219101097623\n",
      "epoch:2391, weight:[1.45788159 1.08645985], bias:-1.196548720020523, loss:0.5692049892070292\n",
      "epoch:2392, weight:[1.45816776 1.08658189], bias:-1.1967591650856153, loss:0.5691908801790685\n",
      "epoch:2393, weight:[1.45845392 1.08670388], bias:-1.1969695731556265, loss:0.5691767740122061\n",
      "epoch:2394, weight:[1.45874007 1.08682582], bias:-1.1971799442464335, loss:0.5691626707049081\n",
      "epoch:2395, weight:[1.45902623 1.08694771], bias:-1.197390278373896, loss:0.5691485702556427\n",
      "epoch:2396, weight:[1.45931238 1.08706956], bias:-1.1976005755538561, loss:0.5691344726628784\n",
      "epoch:2397, weight:[1.45959853 1.08719136], bias:-1.197810835802138, loss:0.569120377925085\n",
      "epoch:2398, weight:[1.45988467 1.08731312], bias:-1.1980210591345488, loss:0.5691062860407338\n",
      "epoch:2399, weight:[1.46017082 1.08743483], bias:-1.198231245566878, loss:0.5690921970082969\n",
      "epoch:2400, weight:[1.46045696 1.08755649], bias:-1.1984413951148976, loss:0.5690781108262483\n",
      "epoch:2401, weight:[1.46074309 1.08767811], bias:-1.198651507794362, loss:0.5690640274930618\n",
      "epoch:2402, weight:[1.46102922 1.08779968], bias:-1.198861583621009, loss:0.5690499470072138\n",
      "epoch:2403, weight:[1.46131535 1.0879212 ], bias:-1.1990716226105587, loss:0.5690358693671809\n",
      "epoch:2404, weight:[1.46160148 1.08804268], bias:-1.1992816247787137, loss:0.5690217945714413\n",
      "epoch:2405, weight:[1.46188761 1.08816411], bias:-1.19949159014116, loss:0.5690077226184744\n",
      "epoch:2406, weight:[1.46217373 1.0882855 ], bias:-1.1997015187135662, loss:0.5689936535067606\n",
      "epoch:2407, weight:[1.46245984 1.08840684], bias:-1.199911410511584, loss:0.5689795872347809\n",
      "epoch:2408, weight:[1.46274596 1.08852813], bias:-1.2001212655508477, loss:0.5689655238010187\n",
      "epoch:2409, weight:[1.46303207 1.08864938], bias:-1.2003310838469752, loss:0.5689514632039577\n",
      "epoch:2410, weight:[1.46331818 1.08877058], bias:-1.2005408654155667, loss:0.568937405442083\n",
      "epoch:2411, weight:[1.46360429 1.08889174], bias:-1.2007506102722063, loss:0.5689233505138805\n",
      "epoch:2412, weight:[1.46389039 1.08901285], bias:-1.2009603184324609, loss:0.5689092984178381\n",
      "epoch:2413, weight:[1.46417649 1.08913391], bias:-1.2011699899118806, loss:0.5688952491524437\n",
      "epoch:2414, weight:[1.46446258 1.08925493], bias:-1.201379624725999, loss:0.568881202716187\n",
      "epoch:2415, weight:[1.46474868 1.0893759 ], bias:-1.2015892228903324, loss:0.5688671591075593\n",
      "epoch:2416, weight:[1.46503477 1.08949683], bias:-1.2017987844203812, loss:0.5688531183250523\n",
      "epoch:2417, weight:[1.46532085 1.08961771], bias:-1.2020083093316287, loss:0.5688390803671589\n",
      "epoch:2418, weight:[1.46560694 1.08973854], bias:-1.2022177976395418, loss:0.5688250452323735\n",
      "epoch:2419, weight:[1.46589302 1.08985933], bias:-1.2024272493595711, loss:0.5688110129191914\n",
      "epoch:2420, weight:[1.4661791  1.08998007], bias:-1.2026366645071505, loss:0.5687969834261092\n",
      "epoch:2421, weight:[1.46646517 1.09010077], bias:-1.2028460430976973, loss:0.5687829567516247\n",
      "epoch:2422, weight:[1.46675124 1.09022142], bias:-1.2030553851466128, loss:0.5687689328942367\n",
      "epoch:2423, weight:[1.46703731 1.09034202], bias:-1.2032646906692817, loss:0.5687549118524449\n",
      "epoch:2424, weight:[1.46732338 1.09046258], bias:-1.2034739596810726, loss:0.568740893624751\n",
      "epoch:2425, weight:[1.46760944 1.09058309], bias:-1.2036831921973379, loss:0.5687268782096563\n",
      "epoch:2426, weight:[1.4678955  1.09070356], bias:-1.2038923882334136, loss:0.5687128656056648\n",
      "epoch:2427, weight:[1.46818155 1.09082398], bias:-1.2041015478046195, loss:0.568698855811281\n",
      "epoch:2428, weight:[1.46846761 1.09094436], bias:-1.2043106709262597, loss:0.5686848488250107\n",
      "epoch:2429, weight:[1.46875365 1.09106469], bias:-1.2045197576136217, loss:0.5686708446453603\n",
      "epoch:2430, weight:[1.4690397  1.09118497], bias:-1.2047288078819776, loss:0.5686568432708382\n",
      "epoch:2431, weight:[1.46932574 1.09130521], bias:-1.204937821746583, loss:0.5686428446999529\n",
      "epoch:2432, weight:[1.46961178 1.0914254 ], bias:-1.2051467992226776, loss:0.568628848931215\n",
      "epoch:2433, weight:[1.46989782 1.09154555], bias:-1.2053557403254855, loss:0.5686148559631357\n",
      "epoch:2434, weight:[1.47018385 1.09166565], bias:-1.2055646450702149, loss:0.5686008657942274\n",
      "epoch:2435, weight:[1.47046988 1.09178571], bias:-1.205773513472058, loss:0.568586878423004\n",
      "epoch:2436, weight:[1.47075591 1.09190572], bias:-1.205982345546191, loss:0.5685728938479799\n",
      "epoch:2437, weight:[1.47104194 1.09202568], bias:-1.2061911413077755, loss:0.5685589120676711\n",
      "epoch:2438, weight:[1.47132796 1.0921456 ], bias:-1.206399900771956, loss:0.5685449330805945\n",
      "epoch:2439, weight:[1.47161397 1.09226547], bias:-1.2066086239538623, loss:0.5685309568852684\n",
      "epoch:2440, weight:[1.47189999 1.0923853 ], bias:-1.2068173108686082, loss:0.5685169834802118\n",
      "epoch:2441, weight:[1.472186   1.09250508], bias:-1.2070259615312922, loss:0.5685030128639451\n",
      "epoch:2442, weight:[1.47247201 1.09262482], bias:-1.2072345759569971, loss:0.5684890450349899\n",
      "epoch:2443, weight:[1.47275801 1.09274451], bias:-1.2074431541607904, loss:0.5684750799918686\n",
      "epoch:2444, weight:[1.47304401 1.09286416], bias:-1.2076516961577242, loss:0.5684611177331051\n",
      "epoch:2445, weight:[1.47333001 1.09298376], bias:-1.2078602019628348, loss:0.5684471582572244\n",
      "epoch:2446, weight:[1.47361601 1.09310331], bias:-1.2080686715911437, loss:0.5684332015627521\n",
      "epoch:2447, weight:[1.473902   1.09322282], bias:-1.2082771050576568, loss:0.5684192476482156\n",
      "epoch:2448, weight:[1.47418799 1.09334228], bias:-1.2084855023773649, loss:0.568405296512143\n",
      "epoch:2449, weight:[1.47447397 1.0934617 ], bias:-1.2086938635652433, loss:0.5683913481530636\n",
      "epoch:2450, weight:[1.47475996 1.09358108], bias:-1.2089021886362525, loss:0.5683774025695075\n",
      "epoch:2451, weight:[1.47504593 1.0937004 ], bias:-1.2091104776053379, loss:0.5683634597600071\n",
      "epoch:2452, weight:[1.47533191 1.09381968], bias:-1.209318730487429, loss:0.5683495197230941\n",
      "epoch:2453, weight:[1.47561788 1.09393892], bias:-1.2095269472974415, loss:0.568335582457303\n",
      "epoch:2454, weight:[1.47590385 1.09405811], bias:-1.2097351280502748, loss:0.5683216479611685\n",
      "epoch:2455, weight:[1.47618982 1.09417726], bias:-1.2099432727608144, loss:0.5683077162332265\n",
      "epoch:2456, weight:[1.47647578 1.09429636], bias:-1.2101513814439302, loss:0.5682937872720141\n",
      "epoch:2457, weight:[1.47676174 1.09441542], bias:-1.2103594541144775, loss:0.5682798610760698\n",
      "epoch:2458, weight:[1.4770477  1.09453443], bias:-1.2105674907872965, loss:0.5682659376439325\n",
      "epoch:2459, weight:[1.47733365 1.09465339], bias:-1.2107754914772129, loss:0.5682520169741431\n",
      "epoch:2460, weight:[1.4776196  1.09477231], bias:-1.2109834561990374, loss:0.5682380990652427\n",
      "epoch:2461, weight:[1.47790554 1.09489119], bias:-1.2111913849675662, loss:0.5682241839157745\n",
      "epoch:2462, weight:[1.47819149 1.09501002], bias:-1.2113992777975804, loss:0.5682102715242817\n",
      "epoch:2463, weight:[1.47847743 1.0951288 ], bias:-1.2116071347038468, loss:0.5681963618893096\n",
      "epoch:2464, weight:[1.47876336 1.09524754], bias:-1.2118149557011175, loss:0.568182455009404\n",
      "epoch:2465, weight:[1.4790493  1.09536623], bias:-1.2120227408041298, loss:0.5681685508831119\n",
      "epoch:2466, weight:[1.47933523 1.09548488], bias:-1.2122304900276066, loss:0.5681546495089815\n",
      "epoch:2467, weight:[1.47962115 1.09560349], bias:-1.2124382033862564, loss:0.5681407508855623\n",
      "epoch:2468, weight:[1.47990707 1.09572205], bias:-1.212645880894773, loss:0.5681268550114044\n",
      "epoch:2469, weight:[1.48019299 1.09584056], bias:-1.2128535225678363, loss:0.5681129618850593\n",
      "epoch:2470, weight:[1.48047891 1.09595903], bias:-1.2130611284201112, loss:0.5680990715050798\n",
      "epoch:2471, weight:[1.48076482 1.09607745], bias:-1.2132686984662484, loss:0.5680851838700194\n",
      "epoch:2472, weight:[1.48105073 1.09619583], bias:-1.2134762327208843, loss:0.5680712989784328\n",
      "epoch:2473, weight:[1.48133664 1.09631416], bias:-1.2136837311986413, loss:0.5680574168288759\n",
      "epoch:2474, weight:[1.48162254 1.09643245], bias:-1.213891193914127, loss:0.5680435374199058\n",
      "epoch:2475, weight:[1.48190844 1.0965507 ], bias:-1.2140986208819355, loss:0.5680296607500807\n",
      "epoch:2476, weight:[1.48219434 1.09666889], bias:-1.214306012116646, loss:0.5680157868179591\n",
      "epoch:2477, weight:[1.48248023 1.09678705], bias:-1.2145133676328241, loss:0.5680019156221017\n",
      "epoch:2478, weight:[1.48276612 1.09690516], bias:-1.2147206874450212, loss:0.5679880471610695\n",
      "epoch:2479, weight:[1.48305201 1.09702322], bias:-1.2149279715677743, loss:0.5679741814334256\n",
      "epoch:2480, weight:[1.48333789 1.09714124], bias:-1.215135220015607, loss:0.5679603184377329\n",
      "epoch:2481, weight:[1.48362377 1.09725921], bias:-1.2153424328030282, loss:0.5679464581725561\n",
      "epoch:2482, weight:[1.48390965 1.09737714], bias:-1.2155496099445335, loss:0.5679326006364609\n",
      "epoch:2483, weight:[1.48419552 1.09749503], bias:-1.2157567514546044, loss:0.5679187458280142\n",
      "epoch:2484, weight:[1.48448139 1.09761287], bias:-1.215963857347708, loss:0.5679048937457835\n",
      "epoch:2485, weight:[1.48476726 1.09773066], bias:-1.2161709276382984, loss:0.5678910443883379\n",
      "epoch:2486, weight:[1.48505312 1.09784841], bias:-1.216377962340815, loss:0.5678771977542475\n",
      "epoch:2487, weight:[1.48533898 1.09796612], bias:-1.2165849614696844, loss:0.5678633538420834\n",
      "epoch:2488, weight:[1.48562483 1.09808378], bias:-1.2167919250393187, loss:0.5678495126504178\n",
      "epoch:2489, weight:[1.48591069 1.09820139], bias:-1.2169988530641165, loss:0.5678356741778238\n",
      "epoch:2490, weight:[1.48619653 1.09831897], bias:-1.217205745558463, loss:0.5678218384228756\n",
      "epoch:2491, weight:[1.48648238 1.09843649], bias:-1.2174126025367296, loss:0.567808005384149\n",
      "epoch:2492, weight:[1.48676822 1.09855397], bias:-1.2176194240132738, loss:0.5677941750602203\n",
      "epoch:2493, weight:[1.48705406 1.09867141], bias:-1.2178262100024402, loss:0.5677803474496671\n",
      "epoch:2494, weight:[1.4873399 1.0987888], bias:-1.2180329605185594, loss:0.567766522551068\n",
      "epoch:2495, weight:[1.48762573 1.09890615], bias:-1.2182396755759484, loss:0.5677527003630027\n",
      "epoch:2496, weight:[1.48791156 1.09902345], bias:-1.218446355188911, loss:0.5677388808840522\n",
      "epoch:2497, weight:[1.48819738 1.09914071], bias:-1.2186529993717379, loss:0.5677250641127979\n",
      "epoch:2498, weight:[1.4884832  1.09925793], bias:-1.2188596081387055, loss:0.5677112500478232\n",
      "epoch:2499, weight:[1.48876902 1.0993751 ], bias:-1.2190661815040778, loss:0.5676974386877118\n",
      "epoch:2500, weight:[1.48905484 1.09949222], bias:-1.2192727194821047, loss:0.5676836300310492\n",
      "epoch:2501, weight:[1.48934065 1.0996093 ], bias:-1.2194792220870236, loss:0.5676698240764211\n",
      "epoch:2502, weight:[1.48962646 1.09972634], bias:-1.219685689333058, loss:0.5676560208224148\n",
      "epoch:2503, weight:[1.48991226 1.09984333], bias:-1.2198921212344185, loss:0.5676422202676187\n",
      "epoch:2504, weight:[1.49019806 1.09996028], bias:-1.2200985178053023, loss:0.5676284224106222\n",
      "epoch:2505, weight:[1.49048386 1.10007718], bias:-1.2203048790598938, loss:0.5676146272500158\n",
      "epoch:2506, weight:[1.49076965 1.10019404], bias:-1.2205112050123639, loss:0.5676008347843905\n",
      "epoch:2507, weight:[1.49105544 1.10031085], bias:-1.2207174956768707, loss:0.5675870450123394\n",
      "epoch:2508, weight:[1.49134123 1.10042762], bias:-1.220923751067559, loss:0.5675732579324557\n",
      "epoch:2509, weight:[1.49162702 1.10054434], bias:-1.2211299711985608, loss:0.5675594735433344\n",
      "epoch:2510, weight:[1.4919128  1.10066103], bias:-1.221336156083995, loss:0.5675456918435713\n",
      "epoch:2511, weight:[1.49219857 1.10077766], bias:-1.2215423057379675, loss:0.5675319128317627\n",
      "epoch:2512, weight:[1.49248435 1.10089425], bias:-1.2217484201745714, loss:0.5675181365065067\n",
      "epoch:2513, weight:[1.49277012 1.1010108 ], bias:-1.2219544994078868, loss:0.5675043628664024\n",
      "epoch:2514, weight:[1.49305588 1.1011273 ], bias:-1.222160543451981, loss:0.5674905919100497\n",
      "epoch:2515, weight:[1.49334164 1.10124376], bias:-1.2223665523209086, loss:0.5674768236360495\n",
      "epoch:2516, weight:[1.4936274  1.10136018], bias:-1.2225725260287112, loss:0.5674630580430038\n",
      "epoch:2517, weight:[1.49391316 1.10147655], bias:-1.2227784645894177, loss:0.567449295129516\n",
      "epoch:2518, weight:[1.49419891 1.10159287], bias:-1.2229843680170445, loss:0.5674355348941902\n",
      "epoch:2519, weight:[1.49448466 1.10170915], bias:-1.2231902363255949, loss:0.5674217773356317\n",
      "epoch:2520, weight:[1.49477041 1.10182539], bias:-1.2233960695290595, loss:0.5674080224524466\n",
      "epoch:2521, weight:[1.49505615 1.10194159], bias:-1.2236018676414169, loss:0.5673942702432424\n",
      "epoch:2522, weight:[1.49534188 1.10205773], bias:-1.2238076306766326, loss:0.5673805207066276\n",
      "epoch:2523, weight:[1.49562762 1.10217384], bias:-1.2240133586486595, loss:0.5673667738412115\n",
      "epoch:2524, weight:[1.49591335 1.1022899 ], bias:-1.2242190515714382, loss:0.5673530296456045\n",
      "epoch:2525, weight:[1.49619908 1.10240592], bias:-1.2244247094588965, loss:0.5673392881184185\n",
      "epoch:2526, weight:[1.4964848  1.10252189], bias:-1.22463033232495, loss:0.567325549258266\n",
      "epoch:2527, weight:[1.49677052 1.10263782], bias:-1.224835920183502, loss:0.5673118130637602\n",
      "epoch:2528, weight:[1.49705624 1.1027537 ], bias:-1.2250414730484427, loss:0.5672980795335166\n",
      "epoch:2529, weight:[1.49734195 1.10286954], bias:-1.2252469909336505, loss:0.56728434866615\n",
      "epoch:2530, weight:[1.49762766 1.10298534], bias:-1.2254524738529913, loss:0.5672706204602778\n",
      "epoch:2531, weight:[1.49791337 1.10310109], bias:-1.2256579218203185, loss:0.5672568949145177\n",
      "epoch:2532, weight:[1.49819907 1.1032168 ], bias:-1.2258633348494736, loss:0.5672431720274888\n",
      "epoch:2533, weight:[1.49848477 1.10333247], bias:-1.2260687129542855, loss:0.5672294517978106\n",
      "epoch:2534, weight:[1.49877047 1.10344809], bias:-1.226274056148571, loss:0.567215734224104\n",
      "epoch:2535, weight:[1.49905616 1.10356366], bias:-1.2264793644461347, loss:0.5672020193049915\n",
      "epoch:2536, weight:[1.49934185 1.10367919], bias:-1.2266846378607688, loss:0.5671883070390956\n",
      "epoch:2537, weight:[1.49962753 1.10379468], bias:-1.2268898764062537, loss:0.5671745974250407\n",
      "epoch:2538, weight:[1.49991321 1.10391013], bias:-1.2270950800963574, loss:0.5671608904614517\n",
      "epoch:2539, weight:[1.50019889 1.10402553], bias:-1.227300248944836, loss:0.5671471861469549\n",
      "epoch:2540, weight:[1.50048456 1.10414089], bias:-1.2275053829654334, loss:0.5671334844801772\n",
      "epoch:2541, weight:[1.50077023 1.1042562 ], bias:-1.2277104821718816, loss:0.567119785459747\n",
      "epoch:2542, weight:[1.5010559  1.10437147], bias:-1.2279155465779006, loss:0.5671060890842938\n",
      "epoch:2543, weight:[1.50134156 1.10448669], bias:-1.2281205761971983, loss:0.5670923953524476\n",
      "epoch:2544, weight:[1.50162722 1.10460187], bias:-1.2283255710434706, loss:0.5670787042628395\n",
      "epoch:2545, weight:[1.50191288 1.10471701], bias:-1.228530531130402, loss:0.5670650158141022\n",
      "epoch:2546, weight:[1.50219853 1.10483211], bias:-1.2287354564716644, loss:0.567051330004869\n",
      "epoch:2547, weight:[1.50248418 1.10494716], bias:-1.2289403470809181, loss:0.567037646833774\n",
      "epoch:2548, weight:[1.50276983 1.10506216], bias:-1.229145202971812, loss:0.5670239662994528\n",
      "epoch:2549, weight:[1.50305547 1.10517713], bias:-1.2293500241579827, loss:0.567010288400542\n",
      "epoch:2550, weight:[1.50334111 1.10529205], bias:-1.2295548106530552, loss:0.5669966131356791\n",
      "epoch:2551, weight:[1.50362674 1.10540692], bias:-1.2297595624706428, loss:0.5669829405035023\n",
      "epoch:2552, weight:[1.50391237 1.10552175], bias:-1.2299642796243468, loss:0.5669692705026513\n",
      "epoch:2553, weight:[1.504198   1.10563654], bias:-1.2301689621277574, loss:0.5669556031317667\n",
      "epoch:2554, weight:[1.50448362 1.10575129], bias:-1.2303736099944524, loss:0.5669419383894899\n",
      "epoch:2555, weight:[1.50476924 1.10586599], bias:-1.2305782232379987, loss:0.5669282762744637\n",
      "epoch:2556, weight:[1.50505486 1.10598064], bias:-1.230782801871951, loss:0.5669146167853317\n",
      "epoch:2557, weight:[1.50534047 1.10609526], bias:-1.2309873459098528, loss:0.5669009599207384\n",
      "epoch:2558, weight:[1.50562608 1.10620983], bias:-1.231191855365236, loss:0.5668873056793298\n",
      "epoch:2559, weight:[1.50591168 1.10632435], bias:-1.2313963302516207, loss:0.5668736540597519\n",
      "epoch:2560, weight:[1.50619728 1.10643884], bias:-1.2316007705825158, loss:0.5668600050606529\n",
      "epoch:2561, weight:[1.50648288 1.10655328], bias:-1.2318051763714188, loss:0.5668463586806818\n",
      "epoch:2562, weight:[1.50676848 1.10666767], bias:-1.2320095476318156, loss:0.5668327149184877\n",
      "epoch:2563, weight:[1.50705407 1.10678202], bias:-1.2322138843771806, loss:0.5668190737727216\n",
      "epoch:2564, weight:[1.50733965 1.10689633], bias:-1.2324181866209771, loss:0.5668054352420353\n",
      "epoch:2565, weight:[1.50762524 1.1070106 ], bias:-1.2326224543766569, loss:0.5667917993250817\n",
      "epoch:2566, weight:[1.50791081 1.10712482], bias:-1.2328266876576601, loss:0.5667781660205142\n",
      "epoch:2567, weight:[1.50819639 1.107239  ], bias:-1.2330308864774162, loss:0.566764535326988\n",
      "epoch:2568, weight:[1.50848196 1.10735314], bias:-1.2332350508493428, loss:0.5667509072431587\n",
      "epoch:2569, weight:[1.50876753 1.10746723], bias:-1.2334391807868468, loss:0.5667372817676831\n",
      "epoch:2570, weight:[1.50905309 1.10758128], bias:-1.2336432763033232, loss:0.5667236588992193\n",
      "epoch:2571, weight:[1.50933866 1.10769528], bias:-1.2338473374121564, loss:0.5667100386364257\n",
      "epoch:2572, weight:[1.50962421 1.10780924], bias:-1.2340513641267195, loss:0.5666964209779626\n",
      "epoch:2573, weight:[1.50990977 1.10792316], bias:-1.2342553564603742, loss:0.5666828059224905\n",
      "epoch:2574, weight:[1.51019532 1.10803704], bias:-1.2344593144264715, loss:0.5666691934686715\n",
      "epoch:2575, weight:[1.51048086 1.10815087], bias:-1.2346632380383509, loss:0.5666555836151685\n",
      "epoch:2576, weight:[1.5107664  1.10826466], bias:-1.234867127309341, loss:0.5666419763606452\n",
      "epoch:2577, weight:[1.51105194 1.1083784 ], bias:-1.2350709822527595, loss:0.5666283717037665\n",
      "epoch:2578, weight:[1.51133748 1.1084921 ], bias:-1.2352748028819127, loss:0.5666147696431982\n",
      "epoch:2579, weight:[1.51162301 1.10860576], bias:-1.2354785892100963, loss:0.5666011701776076\n",
      "epoch:2580, weight:[1.51190854 1.10871938], bias:-1.235682341250595, loss:0.5665875733056619\n",
      "epoch:2581, weight:[1.51219406 1.10883295], bias:-1.2358860590166822, loss:0.5665739790260307\n",
      "epoch:2582, weight:[1.51247958 1.10894648], bias:-1.2360897425216208, loss:0.5665603873373835\n",
      "epoch:2583, weight:[1.51276509 1.10905997], bias:-1.2362933917786625, loss:0.5665467982383912\n",
      "epoch:2584, weight:[1.51305061 1.10917341], bias:-1.2364970068010483, loss:0.5665332117277256\n",
      "epoch:2585, weight:[1.51333612 1.10928681], bias:-1.2367005876020085, loss:0.5665196278040597\n",
      "epoch:2586, weight:[1.51362162 1.10940017], bias:-1.2369041341947622, loss:0.5665060464660677\n",
      "epoch:2587, weight:[1.51390712 1.10951348], bias:-1.2371076465925182, loss:0.5664924677124239\n",
      "epoch:2588, weight:[1.51419262 1.10962675], bias:-1.237311124808474, loss:0.5664788915418044\n",
      "epoch:2589, weight:[1.51447811 1.10973998], bias:-1.237514568855817, loss:0.566465317952886\n",
      "epoch:2590, weight:[1.5147636  1.10985316], bias:-1.237717978747723, loss:0.5664517469443466\n",
      "epoch:2591, weight:[1.51504909 1.10996631], bias:-1.237921354497358, loss:0.5664381785148653\n",
      "epoch:2592, weight:[1.51533457 1.11007941], bias:-1.2381246961178767, loss:0.5664246126631215\n",
      "epoch:2593, weight:[1.51562005 1.11019246], bias:-1.2383280036224236, loss:0.5664110493877963\n",
      "epoch:2594, weight:[1.51590552 1.11030547], bias:-1.2385312770241323, loss:0.5663974886875714\n",
      "epoch:2595, weight:[1.51619099 1.11041844], bias:-1.238734516336126, loss:0.5663839305611298\n",
      "epoch:2596, weight:[1.51647646 1.11053137], bias:-1.2389377215715174, loss:0.5663703750071549\n",
      "epoch:2597, weight:[1.51676192 1.11064425], bias:-1.2391408927434082, loss:0.5663568220243319\n",
      "epoch:2598, weight:[1.51704738 1.11075709], bias:-1.23934402986489, loss:0.5663432716113461\n",
      "epoch:2599, weight:[1.51733284 1.11086989], bias:-1.2395471329490435, loss:0.5663297237668851\n",
      "epoch:2600, weight:[1.51761829 1.11098265], bias:-1.2397502020089397, loss:0.5663161784896356\n",
      "epoch:2601, weight:[1.51790374 1.11109536], bias:-1.2399532370576383, loss:0.5663026357782869\n",
      "epoch:2602, weight:[1.51818918 1.11120803], bias:-1.240156238108189, loss:0.5662890956315288\n",
      "epoch:2603, weight:[1.51847462 1.11132066], bias:-1.240359205173631, loss:0.5662755580480516\n",
      "epoch:2604, weight:[1.51876006 1.11143324], bias:-1.2405621382669931, loss:0.5662620230265473\n",
      "epoch:2605, weight:[1.51904549 1.11154578], bias:-1.240765037401294, loss:0.5662484905657083\n",
      "epoch:2606, weight:[1.51933092 1.11165828], bias:-1.2409679025895415, loss:0.5662349606642283\n",
      "epoch:2607, weight:[1.51961635 1.11177074], bias:-1.2411707338447338, loss:0.566221433320802\n",
      "epoch:2608, weight:[1.51990177 1.11188315], bias:-1.2413735311798582, loss:0.5662079085341252\n",
      "epoch:2609, weight:[1.52018719 1.11199552], bias:-1.241576294607892, loss:0.5661943863028939\n",
      "epoch:2610, weight:[1.5204726  1.11210785], bias:-1.2417790241418025, loss:0.5661808666258058\n",
      "epoch:2611, weight:[1.52075801 1.11222013], bias:-1.2419817197945462, loss:0.5661673495015599\n",
      "epoch:2612, weight:[1.52104342 1.11233237], bias:-1.2421843815790699, loss:0.5661538349288553\n",
      "epoch:2613, weight:[1.52132882 1.11244457], bias:-1.2423870095083098, loss:0.5661403229063924\n",
      "epoch:2614, weight:[1.52161422 1.11255673], bias:-1.2425896035951924, loss:0.5661268134328726\n",
      "epoch:2615, weight:[1.52189961 1.11266884], bias:-1.242792163852634, loss:0.5661133065069989\n",
      "epoch:2616, weight:[1.522185   1.11278091], bias:-1.2429946902935405, loss:0.5660998021274742\n",
      "epoch:2617, weight:[1.52247039 1.11289294], bias:-1.243197182930808, loss:0.5660863002930027\n",
      "epoch:2618, weight:[1.52275577 1.11300493], bias:-1.2433996417773223, loss:0.56607280100229\n",
      "epoch:2619, weight:[1.52304115 1.11311687], bias:-1.2436020668459595, loss:0.5660593042540424\n",
      "epoch:2620, weight:[1.52332652 1.11322877], bias:-1.2438044581495853, loss:0.5660458100469669\n",
      "epoch:2621, weight:[1.52361189 1.11334063], bias:-1.2440068157010555, loss:0.5660323183797721\n",
      "epoch:2622, weight:[1.52389726 1.11345245], bias:-1.2442091395132162, loss:0.5660188292511671\n",
      "epoch:2623, weight:[1.52418262 1.11356422], bias:-1.2444114295989033, loss:0.566005342659862\n",
      "epoch:2624, weight:[1.52446798 1.11367595], bias:-1.2446136859709427, loss:0.5659918586045679\n",
      "epoch:2625, weight:[1.52475334 1.11378764], bias:-1.2448159086421506, loss:0.5659783770839968\n",
      "epoch:2626, weight:[1.52503869 1.11389929], bias:-1.2450180976253333, loss:0.5659648980968621\n",
      "epoch:2627, weight:[1.52532404 1.11401089], bias:-1.2452202529332872, loss:0.5659514216418775\n",
      "epoch:2628, weight:[1.52560938 1.11412246], bias:-1.2454223745787987, loss:0.5659379477177582\n",
      "epoch:2629, weight:[1.52589472 1.11423397], bias:-1.2456244625746444, loss:0.56592447632322\n",
      "epoch:2630, weight:[1.52618006 1.11434545], bias:-1.2458265169335916, loss:0.5659110074569798\n",
      "epoch:2631, weight:[1.52646539 1.11445689], bias:-1.246028537668397, loss:0.5658975411177556\n",
      "epoch:2632, weight:[1.52675072 1.11456828], bias:-1.2462305247918082, loss:0.5658840773042662\n",
      "epoch:2633, weight:[1.52703604 1.11467963], bias:-1.2464324783165628, loss:0.5658706160152313\n",
      "epoch:2634, weight:[1.52732136 1.11479094], bias:-1.2466343982553887, loss:0.5658571572493715\n",
      "epoch:2635, weight:[1.52760668 1.1149022 ], bias:-1.2468362846210042, loss:0.5658437010054088\n",
      "epoch:2636, weight:[1.52789199 1.11501342], bias:-1.2470381374261177, loss:0.5658302472820658\n",
      "epoch:2637, weight:[1.5281773 1.1151246], bias:-1.247239956683428, loss:0.5658167960780659\n",
      "epoch:2638, weight:[1.52846261 1.11523574], bias:-1.2474417424056246, loss:0.565803347392134\n",
      "epoch:2639, weight:[1.52874791 1.11534684], bias:-1.2476434946053871, loss:0.5657899012229954\n",
      "epoch:2640, weight:[1.5290332  1.11545789], bias:-1.2478452132953857, loss:0.5657764575693766\n",
      "epoch:2641, weight:[1.5293185 1.1155689], bias:-1.2480468984882807, loss:0.5657630164300048\n",
      "epoch:2642, weight:[1.52960379 1.11567987], bias:-1.2482485501967229, loss:0.5657495778036087\n",
      "epoch:2643, weight:[1.52988907 1.1157908 ], bias:-1.248450168433354, loss:0.5657361416889175\n",
      "epoch:2644, weight:[1.53017435 1.11590169], bias:-1.248651753210806, loss:0.5657227080846616\n",
      "epoch:2645, weight:[1.53045963 1.11601253], bias:-1.248853304541701, loss:0.5657092769895721\n",
      "epoch:2646, weight:[1.5307449  1.11612333], bias:-1.249054822438652, loss:0.5656958484023812\n",
      "epoch:2647, weight:[1.53103017 1.11623409], bias:-1.2492563069142626, loss:0.5656824223218219\n",
      "epoch:2648, weight:[1.53131544 1.11634481], bias:-1.249457757981127, loss:0.5656689987466285\n",
      "epoch:2649, weight:[1.5316007  1.11645548], bias:-1.2496591756518298, loss:0.5656555776755358\n",
      "epoch:2650, weight:[1.53188595 1.11656611], bias:-1.2498605599389463, loss:0.5656421591072798\n",
      "epoch:2651, weight:[1.53217121 1.1166767 ], bias:-1.2500619108550421, loss:0.5656287430405975\n",
      "epoch:2652, weight:[1.53245646 1.11678725], bias:-1.2502632284126742, loss:0.5656153294742269\n",
      "epoch:2653, weight:[1.5327417  1.11689776], bias:-1.2504645126243896, loss:0.5656019184069062\n",
      "epoch:2654, weight:[1.53302694 1.11700822], bias:-1.2506657635027263, loss:0.5655885098373759\n",
      "epoch:2655, weight:[1.53331218 1.11711865], bias:-1.2508669810602129, loss:0.5655751037643758\n",
      "epoch:2656, weight:[1.53359741 1.11722903], bias:-1.2510681653093687, loss:0.5655617001866482\n",
      "epoch:2657, weight:[1.53388264 1.11733937], bias:-1.251269316262704, loss:0.5655482991029355\n",
      "epoch:2658, weight:[1.53416787 1.11744966], bias:-1.2514704339327196, loss:0.5655349005119811\n",
      "epoch:2659, weight:[1.53445309 1.11755992], bias:-1.2516715183319072, loss:0.5655215044125292\n",
      "epoch:2660, weight:[1.53473831 1.11767013], bias:-1.251872569472749, loss:0.5655081108033256\n",
      "epoch:2661, weight:[1.53502352 1.1177803 ], bias:-1.252073587367719, loss:0.5654947196831164\n",
      "epoch:2662, weight:[1.53530873 1.11789043], bias:-1.2522745720292805, loss:0.5654813310506488\n",
      "epoch:2663, weight:[1.53559394 1.11800052], bias:-1.252475523469889, loss:0.5654679449046709\n",
      "epoch:2664, weight:[1.53587914 1.11811057], bias:-1.2526764417019904, loss:0.565454561243932\n",
      "epoch:2665, weight:[1.53616433 1.11822057], bias:-1.2528773267380215, loss:0.565441180067182\n",
      "epoch:2666, weight:[1.53644953 1.11833053], bias:-1.25307817859041, loss:0.565427801373172\n",
      "epoch:2667, weight:[1.53673472 1.11844045], bias:-1.2532789972715743, loss:0.5654144251606538\n",
      "epoch:2668, weight:[1.5370199  1.11855033], bias:-1.2534797827939246, loss:0.5654010514283802\n",
      "epoch:2669, weight:[1.53730508 1.11866017], bias:-1.253680535169861, loss:0.565387680175105\n",
      "epoch:2670, weight:[1.53759026 1.11876996], bias:-1.2538812544117752, loss:0.5653743113995829\n",
      "epoch:2671, weight:[1.53787543 1.11887972], bias:-1.25408194053205, loss:0.5653609451005696\n",
      "epoch:2672, weight:[1.5381606  1.11898943], bias:-1.254282593543059, loss:0.5653475812768215\n",
      "epoch:2673, weight:[1.53844577 1.1190991 ], bias:-1.2544832134571668, loss:0.5653342199270961\n",
      "epoch:2674, weight:[1.53873093 1.11920873], bias:-1.2546838002867293, loss:0.5653208610501518\n",
      "epoch:2675, weight:[1.53901608 1.11931832], bias:-1.2548843540440933, loss:0.5653075046447481\n",
      "epoch:2676, weight:[1.53930124 1.11942786], bias:-1.2550848747415966, loss:0.565294150709645\n",
      "epoch:2677, weight:[1.53958639 1.11953737], bias:-1.2552853623915685, loss:0.5652807992436037\n",
      "epoch:2678, weight:[1.53987153 1.11964683], bias:-1.2554858170063292, loss:0.5652674502453867\n",
      "epoch:2679, weight:[1.54015667 1.11975625], bias:-1.25568623859819, loss:0.5652541037137564\n",
      "epoch:2680, weight:[1.54044181 1.11986563], bias:-1.2558866271794535, loss:0.5652407596474774\n",
      "epoch:2681, weight:[1.54072694 1.11997496], bias:-1.2560869827624135, loss:0.565227418045314\n",
      "epoch:2682, weight:[1.54101207 1.12008426], bias:-1.256287305359355, loss:0.5652140789060323\n",
      "epoch:2683, weight:[1.54129719 1.12019351], bias:-1.2564875949825542, loss:0.5652007422283989\n",
      "epoch:2684, weight:[1.54158231 1.12030273], bias:-1.2566878516442785, loss:0.5651874080111813\n",
      "epoch:2685, weight:[1.54186743 1.1204119 ], bias:-1.2568880753567868, loss:0.5651740762531484\n",
      "epoch:2686, weight:[1.54215254 1.12052103], bias:-1.257088266132329, loss:0.5651607469530693\n",
      "epoch:2687, weight:[1.54243765 1.12063012], bias:-1.2572884239831466, loss:0.5651474201097145\n",
      "epoch:2688, weight:[1.54272275 1.12073916], bias:-1.257488548921472, loss:0.5651340957218555\n",
      "epoch:2689, weight:[1.54300785 1.12084817], bias:-1.2576886409595291, loss:0.5651207737882642\n",
      "epoch:2690, weight:[1.54329295 1.12095713], bias:-1.2578887001095336, loss:0.5651074543077138\n",
      "epoch:2691, weight:[1.54357804 1.12106606], bias:-1.258088726383692, loss:0.5650941372789785\n",
      "epoch:2692, weight:[1.54386313 1.12117494], bias:-1.2582887197942023, loss:0.5650808227008329\n",
      "epoch:2693, weight:[1.54414821 1.12128378], bias:-1.258488680353254, loss:0.5650675105720532\n",
      "epoch:2694, weight:[1.54443329 1.12139258], bias:-1.2586886080730282, loss:0.5650542008914161\n",
      "epoch:2695, weight:[1.54471836 1.12150134], bias:-1.258888502965697, loss:0.5650408936576992\n",
      "epoch:2696, weight:[1.54500344 1.12161005], bias:-1.2590883650434248, loss:0.5650275888696812\n",
      "epoch:2697, weight:[1.5452885  1.12171873], bias:-1.2592881943183662, loss:0.5650142865261413\n",
      "epoch:2698, weight:[1.54557357 1.12182736], bias:-1.2594879908026684, loss:0.5650009866258603\n",
      "epoch:2699, weight:[1.54585862 1.12193595], bias:-1.2596877545084697, loss:0.5649876891676192\n",
      "epoch:2700, weight:[1.54614368 1.12204451], bias:-1.2598874854478999, loss:0.5649743941502003\n",
      "epoch:2701, weight:[1.54642873 1.12215302], bias:-1.26008718363308, loss:0.5649611015723871\n",
      "epoch:2702, weight:[1.54671377 1.12226148], bias:-1.2602868490761234, loss:0.5649478114329631\n",
      "epoch:2703, weight:[1.54699882 1.12236991], bias:-1.2604864817891344, loss:0.5649345237307133\n",
      "epoch:2704, weight:[1.54728385 1.1224783 ], bias:-1.260686081784209, loss:0.5649212384644242\n",
      "epoch:2705, weight:[1.54756889 1.12258664], bias:-1.260885649073435, loss:0.5649079556328818\n",
      "epoch:2706, weight:[1.54785392 1.12269495], bias:-1.2610851836688919, loss:0.5648946752348739\n",
      "epoch:2707, weight:[1.54813894 1.12280321], bias:-1.2612846855826503, loss:0.564881397269189\n",
      "epoch:2708, weight:[1.54842396 1.12291143], bias:-1.261484154826773, loss:0.5648681217346169\n",
      "epoch:2709, weight:[1.54870898 1.12301961], bias:-1.2616835914133144, loss:0.5648548486299477\n",
      "epoch:2710, weight:[1.54899399 1.12312775], bias:-1.2618829953543205, loss:0.5648415779539726\n",
      "epoch:2711, weight:[1.549279   1.12323585], bias:-1.2620823666618288, loss:0.5648283097054839\n",
      "epoch:2712, weight:[1.54956401 1.12334391], bias:-1.2622817053478688, loss:0.5648150438832746\n",
      "epoch:2713, weight:[1.54984901 1.12345193], bias:-1.2624810114244616, loss:0.5648017804861388\n",
      "epoch:2714, weight:[1.550134  1.1235599], bias:-1.26268028490362, loss:0.5647885195128709\n",
      "epoch:2715, weight:[1.550419   1.12366784], bias:-1.262879525797349, loss:0.5647752609622669\n",
      "epoch:2716, weight:[1.55070398 1.12377573], bias:-1.263078734117645, loss:0.5647620048331237\n",
      "epoch:2717, weight:[1.55098897 1.12388359], bias:-1.2632779098764961, loss:0.5647487511242383\n",
      "epoch:2718, weight:[1.55127395 1.1239914 ], bias:-1.2634770530858823, loss:0.5647354998344092\n",
      "epoch:2719, weight:[1.55155892 1.12409917], bias:-1.2636761637577758, loss:0.564722250962436\n",
      "epoch:2720, weight:[1.55184389 1.1242069 ], bias:-1.2638752419041401, loss:0.5647090045071189\n",
      "epoch:2721, weight:[1.55212886 1.12431459], bias:-1.264074287536931, loss:0.5646957604672588\n",
      "epoch:2722, weight:[1.55241382 1.12442224], bias:-1.264273300668096, loss:0.5646825188416575\n",
      "epoch:2723, weight:[1.55269878 1.12452984], bias:-1.2644722813095743, loss:0.5646692796291185\n",
      "epoch:2724, weight:[1.55298374 1.12463741], bias:-1.2646712294732976, loss:0.5646560428284452\n",
      "epoch:2725, weight:[1.55326869 1.12474494], bias:-1.2648701451711888, loss:0.5646428084384417\n",
      "epoch:2726, weight:[1.55355363 1.12485242], bias:-1.265069028415163, loss:0.5646295764579146\n",
      "epoch:2727, weight:[1.55383857 1.12495987], bias:-1.2652678792171277, loss:0.5646163468856696\n",
      "epoch:2728, weight:[1.55412351 1.12506727], bias:-1.2654666975889817, loss:0.564603119720514\n",
      "epoch:2729, weight:[1.55440845 1.12517463], bias:-1.2656654835426162, loss:0.5645898949612563\n",
      "epoch:2730, weight:[1.55469337 1.12528195], bias:-1.2658642370899145, loss:0.5645766726067056\n",
      "epoch:2731, weight:[1.5549783  1.12538923], bias:-1.2660629582427514, loss:0.5645634526556716\n",
      "epoch:2732, weight:[1.55526322 1.12549647], bias:-1.2662616470129944, loss:0.5645502351069653\n",
      "epoch:2733, weight:[1.55554814 1.12560367], bias:-1.2664603034125024, loss:0.5645370199593984\n",
      "epoch:2734, weight:[1.55583305 1.12571083], bias:-1.2666589274531268, loss:0.5645238072117836\n",
      "epoch:2735, weight:[1.55611796 1.12581795], bias:-1.2668575191467109, loss:0.5645105968629344\n",
      "epoch:2736, weight:[1.55640286 1.12592503], bias:-1.2670560785050902, loss:0.564497388911665\n",
      "epoch:2737, weight:[1.55668776 1.12603207], bias:-1.2672546055400922, loss:0.5644841833567905\n",
      "epoch:2738, weight:[1.55697265 1.12613906], bias:-1.2674531002635365, loss:0.5644709801971276\n",
      "epoch:2739, weight:[1.55725755 1.12624602], bias:-1.267651562687235, loss:0.5644577794314927\n",
      "epoch:2740, weight:[1.55754243 1.12635293], bias:-1.2678499928229914, loss:0.5644445810587041\n",
      "epoch:2741, weight:[1.55782731 1.12645981], bias:-1.2680483906826021, loss:0.5644313850775805\n",
      "epoch:2742, weight:[1.55811219 1.12656664], bias:-1.2682467562778552, loss:0.5644181914869413\n",
      "epoch:2743, weight:[1.55839707 1.12667344], bias:-1.2684450896205315, loss:0.5644050002856074\n",
      "epoch:2744, weight:[1.55868194 1.12678019], bias:-1.2686433907224033, loss:0.5643918114723998\n",
      "epoch:2745, weight:[1.5589668 1.1268869], bias:-1.2688416595952359, loss:0.5643786250461408\n",
      "epoch:2746, weight:[1.55925166 1.12699358], bias:-1.2690398962507863, loss:0.564365441005654\n",
      "epoch:2747, weight:[1.55953652 1.12710021], bias:-1.2692381007008038, loss:0.5643522593497629\n",
      "epoch:2748, weight:[1.55982137 1.1272068 ], bias:-1.26943627295703, loss:0.5643390800772924\n",
      "epoch:2749, weight:[1.56010622 1.12731335], bias:-1.2696344130311994, loss:0.5643259031870687\n",
      "epoch:2750, weight:[1.56039106 1.12741986], bias:-1.2698325209350378, loss:0.5643127286779178\n",
      "epoch:2751, weight:[1.5606759  1.12752633], bias:-1.2700305966802639, loss:0.5642995565486678\n",
      "epoch:2752, weight:[1.56096074 1.12763276], bias:-1.2702286402785885, loss:0.5642863867981465\n",
      "epoch:2753, weight:[1.56124557 1.12773915], bias:-1.2704266517417149, loss:0.5642732194251835\n",
      "epoch:2754, weight:[1.5615304 1.1278455], bias:-1.2706246310813387, loss:0.5642600544286089\n",
      "epoch:2755, weight:[1.56181522 1.1279518 ], bias:-1.2708225783091478, loss:0.5642468918072534\n",
      "epoch:2756, weight:[1.56210004 1.12805807], bias:-1.2710204934368226, loss:0.5642337315599492\n",
      "epoch:2757, weight:[1.56238485 1.1281643 ], bias:-1.2712183764760356, loss:0.5642205736855285\n",
      "epoch:2758, weight:[1.56266966 1.12827049], bias:-1.2714162274384524, loss:0.5642074181828253\n",
      "epoch:2759, weight:[1.56295447 1.12837664], bias:-1.2716140463357302, loss:0.5641942650506737\n",
      "epoch:2760, weight:[1.56323927 1.12848274], bias:-1.271811833179519, loss:0.5641811142879092\n",
      "epoch:2761, weight:[1.56352406 1.12858881], bias:-1.2720095879814612, loss:0.5641679658933679\n",
      "epoch:2762, weight:[1.56380885 1.12869484], bias:-1.2722073107531917, loss:0.5641548198658868\n",
      "epoch:2763, weight:[1.56409364 1.12880082], bias:-1.272405001506338, loss:0.5641416762043038\n",
      "epoch:2764, weight:[1.56437843 1.12890677], bias:-1.2726026602525198, loss:0.5641285349074575\n",
      "epoch:2765, weight:[1.56466321 1.12901267], bias:-1.2728002870033495, loss:0.5641153959741877\n",
      "epoch:2766, weight:[1.56494798 1.12911854], bias:-1.272997881770432, loss:0.5641022594033344\n",
      "epoch:2767, weight:[1.56523275 1.12922437], bias:-1.2731954445653646, loss:0.5640891251937394\n",
      "epoch:2768, weight:[1.56551752 1.12933015], bias:-1.2733929753997375, loss:0.5640759933442449\n",
      "epoch:2769, weight:[1.56580228 1.1294359 ], bias:-1.273590474285133, loss:0.5640628638536934\n",
      "epoch:2770, weight:[1.56608704 1.1295416 ], bias:-1.273787941233126, loss:0.5640497367209291\n",
      "epoch:2771, weight:[1.56637179 1.12964727], bias:-1.2739853762552846, loss:0.5640366119447967\n",
      "epoch:2772, weight:[1.56665654 1.12975289], bias:-1.2741827793631688, loss:0.564023489524142\n",
      "epoch:2773, weight:[1.56694128 1.12985848], bias:-1.2743801505683314, loss:0.5640103694578111\n",
      "epoch:2774, weight:[1.56722602 1.12996402], bias:-1.274577489882318, loss:0.5639972517446513\n",
      "epoch:2775, weight:[1.56751076 1.13006953], bias:-1.2747747973166663, loss:0.5639841363835111\n",
      "epoch:2776, weight:[1.56779549 1.13017499], bias:-1.2749720728829077, loss:0.563971023373239\n",
      "epoch:2777, weight:[1.56808022 1.13028042], bias:-1.2751693165925653, loss:0.5639579127126854\n",
      "epoch:2778, weight:[1.56836494 1.1303858 ], bias:-1.2753665284571551, loss:0.5639448044007004\n",
      "epoch:2779, weight:[1.56864966 1.13049114], bias:-1.275563708488186, loss:0.5639316984361362\n",
      "epoch:2780, weight:[1.56893437 1.13059645], bias:-1.2757608566971592, loss:0.5639185948178448\n",
      "epoch:2781, weight:[1.56921908 1.13070171], bias:-1.2759579730955692, loss:0.5639054935446793\n",
      "epoch:2782, weight:[1.56950379 1.13080694], bias:-1.276155057694903, loss:0.563892394615494\n",
      "epoch:2783, weight:[1.56978849 1.13091212], bias:-1.27635211050664, loss:0.5638792980291439\n",
      "epoch:2784, weight:[1.57007319 1.13101727], bias:-1.2765491315422528, loss:0.5638662037844847\n",
      "epoch:2785, weight:[1.57035788 1.13112238], bias:-1.2767461208132065, loss:0.5638531118803731\n",
      "epoch:2786, weight:[1.57064257 1.13122744], bias:-1.276943078330959, loss:0.5638400223156665\n",
      "epoch:2787, weight:[1.57092725 1.13133247], bias:-1.277140004106961, loss:0.5638269350892234\n",
      "epoch:2788, weight:[1.57121193 1.13143745], bias:-1.2773368981526558, loss:0.5638138501999026\n",
      "epoch:2789, weight:[1.5714966 1.1315424], bias:-1.27753376047948, loss:0.5638007676465645\n",
      "epoch:2790, weight:[1.57178127 1.13164731], bias:-1.277730591098863, loss:0.5637876874280696\n",
      "epoch:2791, weight:[1.57206594 1.13175217], bias:-1.2779273900222263, loss:0.5637746095432798\n",
      "epoch:2792, weight:[1.5723506 1.131857 ], bias:-1.2781241572609852, loss:0.5637615339910578\n",
      "epoch:2793, weight:[1.57263526 1.13196179], bias:-1.278320892826547, loss:0.5637484607702663\n",
      "epoch:2794, weight:[1.57291991 1.13206653], bias:-1.2785175967303126, loss:0.5637353898797702\n",
      "epoch:2795, weight:[1.57320456 1.13217124], bias:-1.2787142689836755, loss:0.5637223213184345\n",
      "epoch:2796, weight:[1.5734892  1.13227591], bias:-1.2789109095980218, loss:0.5637092550851248\n",
      "epoch:2797, weight:[1.57377384 1.13238054], bias:-1.279107518584731, loss:0.5636961911787081\n",
      "epoch:2798, weight:[1.57405847 1.13248512], bias:-1.2793040959551751, loss:0.5636831295980514\n",
      "epoch:2799, weight:[1.5743431  1.13258967], bias:-1.2795006417207195, loss:0.5636700703420238\n",
      "epoch:2800, weight:[1.57462773 1.13269418], bias:-1.2796971558927221, loss:0.563657013409494\n",
      "epoch:2801, weight:[1.57491235 1.13279865], bias:-1.279893638482534, loss:0.5636439587993325\n",
      "epoch:2802, weight:[1.57519697 1.13290308], bias:-1.280090089501499, loss:0.5636309065104099\n",
      "epoch:2803, weight:[1.57548158 1.13300747], bias:-1.2802865089609545, loss:0.563617856541598\n",
      "epoch:2804, weight:[1.57576619 1.13311182], bias:-1.2804828968722304, loss:0.5636048088917693\n",
      "epoch:2805, weight:[1.57605079 1.13321614], bias:-1.2806792532466493, loss:0.5635917635597976\n",
      "epoch:2806, weight:[1.57633539 1.13332041], bias:-1.2808755780955277, loss:0.5635787205445568\n",
      "epoch:2807, weight:[1.57661999 1.13342464], bias:-1.2810718714301743, loss:0.5635656798449216\n",
      "epoch:2808, weight:[1.57690458 1.13352883], bias:-1.2812681332618916, loss:0.5635526414597686\n",
      "epoch:2809, weight:[1.57718916 1.13363298], bias:-1.2814643636019745, loss:0.5635396053879741\n",
      "epoch:2810, weight:[1.57747374 1.1337371 ], bias:-1.281660562461711, loss:0.5635265716284157\n",
      "epoch:2811, weight:[1.57775832 1.13384117], bias:-1.2818567298523826, loss:0.5635135401799717\n",
      "epoch:2812, weight:[1.57804289 1.13394521], bias:-1.282052865785264, loss:0.5635005110415215\n",
      "epoch:2813, weight:[1.57832746 1.1340492 ], bias:-1.282248970271622, loss:0.5634874842119451\n",
      "epoch:2814, weight:[1.57861203 1.13415316], bias:-1.2824450433227177, loss:0.5634744596901233\n",
      "epoch:2815, weight:[1.57889658 1.13425708], bias:-1.2826410849498044, loss:0.5634614374749376\n",
      "epoch:2816, weight:[1.57918114 1.13436095], bias:-1.2828370951641292, loss:0.5634484175652709\n",
      "epoch:2817, weight:[1.57946569 1.13446479], bias:-1.2830330739769322, loss:0.5634353999600061\n",
      "epoch:2818, weight:[1.57975024 1.13456859], bias:-1.2832290213994464, loss:0.5634223846580276\n",
      "epoch:2819, weight:[1.58003478 1.13467235], bias:-1.283424937442898, loss:0.5634093716582205\n",
      "epoch:2820, weight:[1.58031931 1.13477607], bias:-1.2836208221185068, loss:0.5633963609594702\n",
      "epoch:2821, weight:[1.58060385 1.13487975], bias:-1.2838166754374851, loss:0.5633833525606636\n",
      "epoch:2822, weight:[1.58088837 1.13498339], bias:-1.284012497411039, loss:0.5633703464606881\n",
      "epoch:2823, weight:[1.5811729  1.13508699], bias:-1.2842082880503676, loss:0.5633573426584321\n",
      "epoch:2824, weight:[1.58145742 1.13519055], bias:-1.2844040473666631, loss:0.5633443411527841\n",
      "epoch:2825, weight:[1.58174193 1.13529408], bias:-1.2845997753711111, loss:0.5633313419426347\n",
      "epoch:2826, weight:[1.58202644 1.13539756], bias:-1.2847954720748904, loss:0.5633183450268742\n",
      "epoch:2827, weight:[1.58231094 1.13550101], bias:-1.2849911374891732, loss:0.5633053504043942\n",
      "epoch:2828, weight:[1.58259545 1.13560441], bias:-1.2851867716251244, loss:0.563292358074087\n",
      "epoch:2829, weight:[1.58287994 1.13570778], bias:-1.285382374493903, loss:0.5632793680348459\n",
      "epoch:2830, weight:[1.58316443 1.13581111], bias:-1.2855779461066608, loss:0.5632663802855647\n",
      "epoch:2831, weight:[1.58344892 1.1359144 ], bias:-1.285773486474543, loss:0.5632533948251384\n",
      "epoch:2832, weight:[1.5837334  1.13601764], bias:-1.285968995608688, loss:0.5632404116524625\n",
      "epoch:2833, weight:[1.58401788 1.13612085], bias:-1.2861644735202278, loss:0.5632274307664334\n",
      "epoch:2834, weight:[1.58430235 1.13622403], bias:-1.2863599202202876, loss:0.5632144521659483\n",
      "epoch:2835, weight:[1.58458682 1.13632716], bias:-1.2865553357199857, loss:0.5632014758499053\n",
      "epoch:2836, weight:[1.58487129 1.13643025], bias:-1.286750720030434, loss:0.5631885018172031\n",
      "epoch:2837, weight:[1.58515575 1.1365333 ], bias:-1.2869460731627378, loss:0.5631755300667417\n",
      "epoch:2838, weight:[1.5854402  1.13663632], bias:-1.2871413951279955, loss:0.5631625605974211\n",
      "epoch:2839, weight:[1.58572465 1.13673929], bias:-1.2873366859372992, loss:0.5631495934081431\n",
      "epoch:2840, weight:[1.5860091  1.13684223], bias:-1.2875319456017345, loss:0.5631366284978092\n",
      "epoch:2841, weight:[1.58629354 1.13694513], bias:-1.28772717413238, loss:0.5631236658653228\n",
      "epoch:2842, weight:[1.58657798 1.13704799], bias:-1.2879223715403079, loss:0.5631107055095872\n",
      "epoch:2843, weight:[1.58686241 1.13715081], bias:-1.2881175378365837, loss:0.5630977474295072\n",
      "epoch:2844, weight:[1.58714684 1.13725359], bias:-1.2883126730322667, loss:0.5630847916239882\n",
      "epoch:2845, weight:[1.58743126 1.13735633], bias:-1.2885077771384095, loss:0.5630718380919361\n",
      "epoch:2846, weight:[1.58771568 1.13745903], bias:-1.2887028501660578, loss:0.5630588868322577\n",
      "epoch:2847, weight:[1.5880001 1.1375617], bias:-1.288897892126251, loss:0.5630459378438609\n",
      "epoch:2848, weight:[1.58828451 1.13766432], bias:-1.2890929030300224, loss:0.5630329911256544\n",
      "epoch:2849, weight:[1.58856891 1.13776691], bias:-1.2892878828883982, loss:0.5630200466765474\n",
      "epoch:2850, weight:[1.58885331 1.13786945], bias:-1.2894828317123985, loss:0.5630071044954496\n",
      "epoch:2851, weight:[1.58913771 1.13797196], bias:-1.2896777495130365, loss:0.5629941645812727\n",
      "epoch:2852, weight:[1.5894221  1.13807443], bias:-1.2898726363013193, loss:0.5629812269329278\n",
      "epoch:2853, weight:[1.58970649 1.13817686], bias:-1.2900674920882473, loss:0.5629682915493279\n",
      "epoch:2854, weight:[1.58999087 1.13827926], bias:-1.2902623168848146, loss:0.5629553584293859\n",
      "epoch:2855, weight:[1.59027525 1.13838161], bias:-1.2904571107020089, loss:0.5629424275720164\n",
      "epoch:2856, weight:[1.59055962 1.13848392], bias:-1.290651873550811, loss:0.5629294989761341\n",
      "epoch:2857, weight:[1.59084399 1.1385862 ], bias:-1.2908466054421959, loss:0.5629165726406545\n",
      "epoch:2858, weight:[1.59112836 1.13868844], bias:-1.2910413063871318, loss:0.5629036485644943\n",
      "epoch:2859, weight:[1.59141271 1.13879063], bias:-1.2912359763965804, loss:0.562890726746571\n",
      "epoch:2860, weight:[1.59169707 1.13889279], bias:-1.2914306154814974, loss:0.5628778071858026\n",
      "epoch:2861, weight:[1.59198142 1.13899492], bias:-1.291625223652832, loss:0.5628648898811078\n",
      "epoch:2862, weight:[1.59226577 1.139097  ], bias:-1.2918198009215267, loss:0.5628519748314068\n",
      "epoch:2863, weight:[1.59255011 1.13919904], bias:-1.292014347298518, loss:0.5628390620356196\n",
      "epoch:2864, weight:[1.59283444 1.13930105], bias:-1.2922088627947357, loss:0.5628261514926676\n",
      "epoch:2865, weight:[1.59311878 1.13940301], bias:-1.2924033474211036, loss:0.562813243201473\n",
      "epoch:2866, weight:[1.5934031  1.13950494], bias:-1.292597801188539, loss:0.5628003371609587\n",
      "epoch:2867, weight:[1.59368742 1.13960683], bias:-1.292792224107953, loss:0.5627874333700483\n",
      "epoch:2868, weight:[1.59397174 1.13970868], bias:-1.2929866161902501, loss:0.562774531827666\n",
      "epoch:2869, weight:[1.59425606 1.13981049], bias:-1.2931809774463285, loss:0.5627616325327376\n",
      "epoch:2870, weight:[1.59454037 1.13991227], bias:-1.2933753078870804, loss:0.5627487354841887\n",
      "epoch:2871, weight:[1.59482467 1.140014  ], bias:-1.2935696075233916, loss:0.5627358406809461\n",
      "epoch:2872, weight:[1.59510897 1.1401157 ], bias:-1.2937638763661414, loss:0.5627229481219376\n",
      "epoch:2873, weight:[1.59539326 1.14021735], bias:-1.2939581144262031, loss:0.5627100578060916\n",
      "epoch:2874, weight:[1.59567755 1.14031897], bias:-1.2941523217144435, loss:0.5626971697323373\n",
      "epoch:2875, weight:[1.59596184 1.14042056], bias:-1.2943464982417234, loss:0.5626842838996043\n",
      "epoch:2876, weight:[1.59624612 1.1405221 ], bias:-1.2945406440188973, loss:0.5626714003068239\n",
      "epoch:2877, weight:[1.5965304 1.1406236], bias:-1.2947347590568132, loss:0.5626585189529273\n",
      "epoch:2878, weight:[1.59681467 1.14072507], bias:-1.2949288433663133, loss:0.5626456398368469\n",
      "epoch:2879, weight:[1.59709894 1.14082649], bias:-1.2951228969582331, loss:0.5626327629575157\n",
      "epoch:2880, weight:[1.5973832  1.14092788], bias:-1.2953169198434022, loss:0.5626198883138677\n",
      "epoch:2881, weight:[1.59766746 1.14102923], bias:-1.295510912032644, loss:0.5626070159048374\n",
      "epoch:2882, weight:[1.59795171 1.14113055], bias:-1.2957048735367758, loss:0.5625941457293605\n",
      "epoch:2883, weight:[1.59823596 1.14123182], bias:-1.2958988043666084, loss:0.5625812777863731\n",
      "epoch:2884, weight:[1.5985202  1.14133305], bias:-1.2960927045329467, loss:0.5625684120748122\n",
      "epoch:2885, weight:[1.59880444 1.14143425], bias:-1.2962865740465892, loss:0.5625555485936158\n",
      "epoch:2886, weight:[1.59908867 1.14153541], bias:-1.2964804129183285, loss:0.562542687341722\n",
      "epoch:2887, weight:[1.5993729  1.14163653], bias:-1.296674221158951, loss:0.5625298283180705\n",
      "epoch:2888, weight:[1.59965713 1.14173761], bias:-1.2968679987792369, loss:0.5625169715216013\n",
      "epoch:2889, weight:[1.59994135 1.14183866], bias:-1.2970617457899603, loss:0.5625041169512554\n",
      "epoch:2890, weight:[1.60022557 1.14193966], bias:-1.297255462201889, loss:0.5624912646059742\n",
      "epoch:2891, weight:[1.60050978 1.14204063], bias:-1.297449148025785, loss:0.5624784144847004\n",
      "epoch:2892, weight:[1.60079398 1.14214156], bias:-1.2976428032724043, loss:0.5624655665863773\n",
      "epoch:2893, weight:[1.60107818 1.14224245], bias:-1.2978364279524963, loss:0.5624527209099486\n",
      "epoch:2894, weight:[1.60136238 1.1423433 ], bias:-1.2980300220768046, loss:0.5624398774543591\n",
      "epoch:2895, weight:[1.60164657 1.14244412], bias:-1.2982235856560669, loss:0.5624270362185547\n",
      "epoch:2896, weight:[1.60193076 1.14254489], bias:-1.2984171187010147, loss:0.5624141972014812\n",
      "epoch:2897, weight:[1.60221494 1.14264563], bias:-1.2986106212223734, loss:0.5624013604020863\n",
      "epoch:2898, weight:[1.60249912 1.14274633], bias:-1.2988040932308622, loss:0.5623885258193174\n",
      "epoch:2899, weight:[1.6027833 1.142847 ], bias:-1.2989975347371945, loss:0.5623756934521233\n",
      "epoch:2900, weight:[1.60306746 1.14294762], bias:-1.2991909457520776, loss:0.5623628632994532\n",
      "epoch:2901, weight:[1.60335163 1.14304821], bias:-1.299384326286213, loss:0.5623500353602576\n",
      "epoch:2902, weight:[1.60363579 1.14314875], bias:-1.299577676350296, loss:0.562337209633487\n",
      "epoch:2903, weight:[1.60391994 1.14324926], bias:-1.2997709959550157, loss:0.5623243861180935\n",
      "epoch:2904, weight:[1.60420409 1.14334974], bias:-1.2999642851110553, loss:0.5623115648130292\n",
      "epoch:2905, weight:[1.60448824 1.14345017], bias:-1.3001575438290924, loss:0.562298745717248\n",
      "epoch:2906, weight:[1.60477238 1.14355057], bias:-1.3003507721197982, loss:0.5622859288297031\n",
      "epoch:2907, weight:[1.60505651 1.14365092], bias:-1.300543969993838, loss:0.5622731141493498\n",
      "epoch:2908, weight:[1.60534065 1.14375124], bias:-1.3007371374618713, loss:0.5622603016751432\n",
      "epoch:2909, weight:[1.60562477 1.14385153], bias:-1.3009302745345515, loss:0.56224749140604\n",
      "epoch:2910, weight:[1.60590889 1.14395177], bias:-1.3011233812225262, loss:0.5622346833409971\n",
      "epoch:2911, weight:[1.60619301 1.14405198], bias:-1.301316457536437, loss:0.5622218774789723\n",
      "epoch:2912, weight:[1.60647712 1.14415214], bias:-1.3015095034869197, loss:0.5622090738189243\n",
      "epoch:2913, weight:[1.60676123 1.14425227], bias:-1.3017025190846037, loss:0.5621962723598123\n",
      "epoch:2914, weight:[1.60704533 1.14435237], bias:-1.301895504340113, loss:0.5621834731005964\n",
      "epoch:2915, weight:[1.60732943 1.14445242], bias:-1.3020884592640656, loss:0.5621706760402374\n",
      "epoch:2916, weight:[1.60761352 1.14455244], bias:-1.3022813838670735, loss:0.5621578811776974\n",
      "epoch:2917, weight:[1.60789761 1.14465242], bias:-1.302474278159743, loss:0.5621450885119381\n",
      "epoch:2918, weight:[1.6081817  1.14475236], bias:-1.3026671421526743, loss:0.5621322980419232\n",
      "epoch:2919, weight:[1.60846577 1.14485226], bias:-1.3028599758564618, loss:0.5621195097666162\n",
      "epoch:2920, weight:[1.60874985 1.14495213], bias:-1.3030527792816942, loss:0.5621067236849822\n",
      "epoch:2921, weight:[1.60903392 1.14505195], bias:-1.3032455524389541, loss:0.5620939397959861\n",
      "epoch:2922, weight:[1.60931798 1.14515174], bias:-1.3034382953388186, loss:0.5620811580985943\n",
      "epoch:2923, weight:[1.60960204 1.1452515 ], bias:-1.3036310079918585, loss:0.562068378591774\n",
      "epoch:2924, weight:[1.6098861  1.14535121], bias:-1.303823690408639, loss:0.5620556012744925\n",
      "epoch:2925, weight:[1.61017015 1.14545089], bias:-1.30401634259972, loss:0.5620428261457183\n",
      "epoch:2926, weight:[1.61045419 1.14555053], bias:-1.3042089645756545, loss:0.5620300532044209\n",
      "epoch:2927, weight:[1.61073823 1.14565013], bias:-1.3044015563469906, loss:0.5620172824495698\n",
      "epoch:2928, weight:[1.61102227 1.14574969], bias:-1.3045941179242704, loss:0.5620045138801358\n",
      "epoch:2929, weight:[1.6113063  1.14584922], bias:-1.30478664931803, loss:0.5619917474950908\n",
      "epoch:2930, weight:[1.61159033 1.14594871], bias:-1.3049791505387998, loss:0.5619789832934063\n",
      "epoch:2931, weight:[1.61187435 1.14604816], bias:-1.3051716215971045, loss:0.5619662212740558\n",
      "epoch:2932, weight:[1.61215837 1.14614757], bias:-1.305364062503463, loss:0.5619534614360128\n",
      "epoch:2933, weight:[1.61244238 1.14624694], bias:-1.3055564732683886, loss:0.5619407037782516\n",
      "epoch:2934, weight:[1.61272638 1.14634628], bias:-1.3057488539023887, loss:0.5619279482997475\n",
      "epoch:2935, weight:[1.61301039 1.14644558], bias:-1.305941204415965, loss:0.5619151949994766\n",
      "epoch:2936, weight:[1.61329438 1.14654485], bias:-1.3061335248196135, loss:0.5619024438764154\n",
      "epoch:2937, weight:[1.61357838 1.14664407], bias:-1.3063258151238244, loss:0.5618896949295414\n",
      "epoch:2938, weight:[1.61386237 1.14674326], bias:-1.3065180753390822, loss:0.5618769481578328\n",
      "epoch:2939, weight:[1.61414635 1.14684241], bias:-1.3067103054758655, loss:0.5618642035602686\n",
      "epoch:2940, weight:[1.61443033 1.14694152], bias:-1.3069025055446477, loss:0.5618514611358282\n",
      "epoch:2941, weight:[1.6147143 1.1470406], bias:-1.307094675555896, loss:0.5618387208834922\n",
      "epoch:2942, weight:[1.61499827 1.14713964], bias:-1.3072868155200725, loss:0.5618259828022419\n",
      "epoch:2943, weight:[1.61528223 1.14723864], bias:-1.3074789254476331, loss:0.5618132468910592\n",
      "epoch:2944, weight:[1.61556619 1.1473376 ], bias:-1.3076710053490281, loss:0.5618005131489263\n",
      "epoch:2945, weight:[1.61585015 1.14743652], bias:-1.3078630552347026, loss:0.561787781574827\n",
      "epoch:2946, weight:[1.6161341  1.14753541], bias:-1.3080550751150952, loss:0.5617750521677455\n",
      "epoch:2947, weight:[1.61641804 1.14763426], bias:-1.3082470650006397, loss:0.5617623249266663\n",
      "epoch:2948, weight:[1.61670198 1.14773308], bias:-1.308439024901764, loss:0.5617495998505755\n",
      "epoch:2949, weight:[1.61698592 1.14783185], bias:-1.30863095482889, loss:0.5617368769384589\n",
      "epoch:2950, weight:[1.61726985 1.14793059], bias:-1.3088228547924343, loss:0.561724156189304\n",
      "epoch:2951, weight:[1.61755377 1.14802929], bias:-1.3090147248028081, loss:0.5617114376020984\n",
      "epoch:2952, weight:[1.61783769 1.14812796], bias:-1.3092065648704165, loss:0.561698721175831\n",
      "epoch:2953, weight:[1.61812161 1.14822658], bias:-1.3093983750056593, loss:0.5616860069094908\n",
      "epoch:2954, weight:[1.61840552 1.14832517], bias:-1.3095901552189306, loss:0.5616732948020676\n",
      "epoch:2955, weight:[1.61868942 1.14842373], bias:-1.3097819055206192, loss:0.5616605848525529\n",
      "epoch:2956, weight:[1.61897333 1.14852224], bias:-1.3099736259211079, loss:0.5616478770599375\n",
      "epoch:2957, weight:[1.61925722 1.14862072], bias:-1.3101653164307743, loss:0.5616351714232142\n",
      "epoch:2958, weight:[1.61954111 1.14871916], bias:-1.31035697705999, loss:0.5616224679413756\n",
      "epoch:2959, weight:[1.619825   1.14881756], bias:-1.3105486078191217, loss:0.5616097666134156\n",
      "epoch:2960, weight:[1.62010888 1.14891593], bias:-1.3107402087185298, loss:0.5615970674383283\n",
      "epoch:2961, weight:[1.62039276 1.14901426], bias:-1.3109317797685696, loss:0.5615843704151096\n",
      "epoch:2962, weight:[1.62067663 1.14911255], bias:-1.3111233209795907, loss:0.5615716755427548\n",
      "epoch:2963, weight:[1.6209605 1.1492108], bias:-1.3113148323619375, loss:0.5615589828202606\n",
      "epoch:2964, weight:[1.62124436 1.14930902], bias:-1.3115063139259486, loss:0.5615462922466248\n",
      "epoch:2965, weight:[1.62152822 1.1494072 ], bias:-1.311697765681957, loss:0.5615336038208449\n",
      "epoch:2966, weight:[1.62181207 1.14950535], bias:-1.3118891876402905, loss:0.5615209175419201\n",
      "epoch:2967, weight:[1.62209592 1.14960345], bias:-1.3120805798112711, loss:0.56150823340885\n",
      "epoch:2968, weight:[1.62237976 1.14970152], bias:-1.3122719422052154, loss:0.5614955514206347\n",
      "epoch:2969, weight:[1.6226636  1.14979955], bias:-1.3124632748324347, loss:0.5614828715762752\n",
      "epoch:2970, weight:[1.62294743 1.14989755], bias:-1.3126545777032346, loss:0.5614701938747736\n",
      "epoch:2971, weight:[1.62323126 1.14999551], bias:-1.3128458508279153, loss:0.5614575183151319\n",
      "epoch:2972, weight:[1.62351508 1.15009343], bias:-1.3130370942167715, loss:0.5614448448963537\n",
      "epoch:2973, weight:[1.6237989  1.15019131], bias:-1.3132283078800926, loss:0.5614321736174427\n",
      "epoch:2974, weight:[1.62408271 1.15028916], bias:-1.3134194918281625, loss:0.5614195044774033\n",
      "epoch:2975, weight:[1.62436652 1.15038697], bias:-1.3136106460712595, loss:0.5614068374752416\n",
      "epoch:2976, weight:[1.62465032 1.15048474], bias:-1.3138017706196568, loss:0.5613941726099627\n",
      "epoch:2977, weight:[1.62493412 1.15058248], bias:-1.3139928654836215, loss:0.5613815098805743\n",
      "epoch:2978, weight:[1.62521792 1.15068018], bias:-1.3141839306734162, loss:0.5613688492860835\n",
      "epoch:2979, weight:[1.62550171 1.15077784], bias:-1.3143749661992974, loss:0.5613561908254989\n",
      "epoch:2980, weight:[1.62578549 1.15087547], bias:-1.3145659720715164, loss:0.561343534497829\n",
      "epoch:2981, weight:[1.62606927 1.15097305], bias:-1.3147569483003192, loss:0.5613308803020838\n",
      "epoch:2982, weight:[1.62635304 1.15107061], bias:-1.314947894895946, loss:0.5613182282372736\n",
      "epoch:2983, weight:[1.62663681 1.15116812], bias:-1.3151388118686325, loss:0.5613055783024099\n",
      "epoch:2984, weight:[1.62692058 1.1512656 ], bias:-1.315329699228608, loss:0.561292930496504\n",
      "epoch:2985, weight:[1.62720434 1.15136304], bias:-1.3155205569860973, loss:0.5612802848185687\n",
      "epoch:2986, weight:[1.62748809 1.15146044], bias:-1.315711385151319, loss:0.5612676412676176\n",
      "epoch:2987, weight:[1.62777184 1.15155781], bias:-1.3159021837344869, loss:0.5612549998426644\n",
      "epoch:2988, weight:[1.62805558 1.15165514], bias:-1.3160929527458094, loss:0.5612423605427238\n",
      "epoch:2989, weight:[1.62833932 1.15175244], bias:-1.3162836921954892, loss:0.5612297233668113\n",
      "epoch:2990, weight:[1.62862306 1.15184969], bias:-1.3164744020937242, loss:0.5612170883139432\n",
      "epoch:2991, weight:[1.62890679 1.15194691], bias:-1.3166650824507067, loss:0.5612044553831361\n",
      "epoch:2992, weight:[1.62919051 1.1520441 ], bias:-1.3168557332766235, loss:0.561191824573408\n",
      "epoch:2993, weight:[1.62947423 1.15214125], bias:-1.3170463545816564, loss:0.561179195883777\n",
      "epoch:2994, weight:[1.62975795 1.15223836], bias:-1.3172369463759819, loss:0.5611665693132619\n",
      "epoch:2995, weight:[1.63004166 1.15233543], bias:-1.3174275086697707, loss:0.5611539448608824\n",
      "epoch:2996, weight:[1.63032536 1.15243247], bias:-1.3176180414731886, loss:0.5611413225256595\n",
      "epoch:2997, weight:[1.63060906 1.15252947], bias:-1.3178085447963963, loss:0.561128702306614\n",
      "epoch:2998, weight:[1.63089276 1.15262643], bias:-1.3179990186495487, loss:0.5611160842027677\n",
      "epoch:2999, weight:[1.63117645 1.15272336], bias:-1.3181894630427957, loss:0.5611034682131432\n",
      "epoch:3000, weight:[1.63146013 1.15282025], bias:-1.318379877986282, loss:0.561090854336764\n",
      "epoch:3001, weight:[1.63174381 1.1529171 ], bias:-1.318570263490147, loss:0.5610782425726536\n",
      "epoch:3002, weight:[1.63202749 1.15301392], bias:-1.3187606195645247, loss:0.5610656329198374\n",
      "epoch:3003, weight:[1.63231116 1.1531107 ], bias:-1.318950946219544, loss:0.56105302537734\n",
      "epoch:3004, weight:[1.63259482 1.15320745], bias:-1.3191412434653282, loss:0.5610404199441882\n",
      "epoch:3005, weight:[1.63287848 1.15330415], bias:-1.319331511311996, loss:0.5610278166194086\n",
      "epoch:3006, weight:[1.63316214 1.15340083], bias:-1.3195217497696605, loss:0.5610152154020285\n",
      "epoch:3007, weight:[1.63344579 1.15349746], bias:-1.3197119588484294, loss:0.5610026162910766\n",
      "epoch:3008, weight:[1.63372944 1.15359406], bias:-1.3199021385584053, loss:0.5609900192855815\n",
      "epoch:3009, weight:[1.63401308 1.15369062], bias:-1.3200922889096858, loss:0.5609774243845727\n",
      "epoch:3010, weight:[1.63429671 1.15378715], bias:-1.3202824099123631, loss:0.5609648315870808\n",
      "epoch:3011, weight:[1.63458034 1.15388364], bias:-1.3204725015765244, loss:0.5609522408921367\n",
      "epoch:3012, weight:[1.63486397 1.15398009], bias:-1.3206625639122513, loss:0.5609396522987725\n",
      "epoch:3013, weight:[1.63514759 1.1540765 ], bias:-1.3208525969296208, loss:0.5609270658060201\n",
      "epoch:3014, weight:[1.6354312  1.15417288], bias:-1.321042600638704, loss:0.5609144814129132\n",
      "epoch:3015, weight:[1.63571481 1.15426923], bias:-1.3212325750495673, loss:0.5609018991184855\n",
      "epoch:3016, weight:[1.63599842 1.15436553], bias:-1.3214225201722718, loss:0.5608893189217713\n",
      "epoch:3017, weight:[1.63628202 1.15446181], bias:-1.3216124360168735, loss:0.560876740821806\n",
      "epoch:3018, weight:[1.63656561 1.15455804], bias:-1.3218023225934235, loss:0.5608641648176257\n",
      "epoch:3019, weight:[1.6368492  1.15465424], bias:-1.321992179911967, loss:0.5608515909082669\n",
      "epoch:3020, weight:[1.63713279 1.1547504 ], bias:-1.3221820079825446, loss:0.5608390190927668\n",
      "epoch:3021, weight:[1.63741637 1.15484652], bias:-1.3223718068151917, loss:0.5608264493701639\n",
      "epoch:3022, weight:[1.63769995 1.15494261], bias:-1.3225615764199388, loss:0.5608138817394965\n",
      "epoch:3023, weight:[1.63798352 1.15503867], bias:-1.3227513168068106, loss:0.5608013161998043\n",
      "epoch:3024, weight:[1.63826708 1.15513468], bias:-1.3229410279858274, loss:0.5607887527501275\n",
      "epoch:3025, weight:[1.63855064 1.15523066], bias:-1.3231307099670038, loss:0.5607761913895066\n",
      "epoch:3026, weight:[1.6388342  1.15532661], bias:-1.3233203627603498, loss:0.5607636321169835\n",
      "epoch:3027, weight:[1.63911775 1.15542252], bias:-1.32350998637587, loss:0.5607510749316001\n",
      "epoch:3028, weight:[1.63940129 1.15551839], bias:-1.3236995808235636, loss:0.5607385198323998\n",
      "epoch:3029, weight:[1.63968483 1.15561422], bias:-1.3238891461134257, loss:0.5607259668184255\n",
      "epoch:3030, weight:[1.63996837 1.15571002], bias:-1.3240786822554451, loss:0.5607134158887219\n",
      "epoch:3031, weight:[1.6402519  1.15580579], bias:-1.3242681892596064, loss:0.5607008670423342\n",
      "epoch:3032, weight:[1.64053542 1.15590151], bias:-1.3244576671358887, loss:0.5606883202783078\n",
      "epoch:3033, weight:[1.64081894 1.1559972 ], bias:-1.3246471158942663, loss:0.5606757755956893\n",
      "epoch:3034, weight:[1.64110246 1.15609286], bias:-1.3248365355447083, loss:0.5606632329935253\n",
      "epoch:3035, weight:[1.64138597 1.15618848], bias:-1.3250259260971784, loss:0.560650692470864\n",
      "epoch:3036, weight:[1.64166947 1.15628406], bias:-1.3252152875616359, loss:0.5606381540267537\n",
      "epoch:3037, weight:[1.64195297 1.15637961], bias:-1.3254046199480347, loss:0.5606256176602435\n",
      "epoch:3038, weight:[1.64223647 1.15647512], bias:-1.3255939232663236, loss:0.5606130833703834\n",
      "epoch:3039, weight:[1.64251996 1.15657059], bias:-1.3257831975264467, loss:0.5606005511562236\n",
      "epoch:3040, weight:[1.64280344 1.15666603], bias:-1.3259724427383426, loss:0.5605880210168156\n",
      "epoch:3041, weight:[1.64308692 1.15676143], bias:-1.3261616589119454, loss:0.5605754929512112\n",
      "epoch:3042, weight:[1.6433704 1.1568568], bias:-1.3263508460571836, loss:0.5605629669584627\n",
      "epoch:3043, weight:[1.64365387 1.15695213], bias:-1.3265400041839812, loss:0.5605504430376237\n",
      "epoch:3044, weight:[1.64393733 1.15704742], bias:-1.326729133302257, loss:0.560537921187748\n",
      "epoch:3045, weight:[1.64422079 1.15714268], bias:-1.3269182334219247, loss:0.5605254014078903\n",
      "epoch:3046, weight:[1.64450424 1.15723791], bias:-1.3271073045528932, loss:0.560512883697106\n",
      "epoch:3047, weight:[1.64478769 1.15733309], bias:-1.3272963467050662, loss:0.5605003680544507\n",
      "epoch:3048, weight:[1.64507114 1.15742824], bias:-1.3274853598883427, loss:0.5604878544789813\n",
      "epoch:3049, weight:[1.64535458 1.15752336], bias:-1.3276743441126164, loss:0.5604753429697552\n",
      "epoch:3050, weight:[1.64563801 1.15761844], bias:-1.3278632993877764, loss:0.5604628335258304\n",
      "epoch:3051, weight:[1.64592144 1.15771348], bias:-1.3280522257237064, loss:0.5604503261462657\n",
      "epoch:3052, weight:[1.64620486 1.15780849], bias:-1.3282411231302855, loss:0.5604378208301202\n",
      "epoch:3053, weight:[1.64648828 1.15790346], bias:-1.3284299916173878, loss:0.5604253175764543\n",
      "epoch:3054, weight:[1.6467717 1.1579984], bias:-1.3286188311948823, loss:0.5604128163843285\n",
      "epoch:3055, weight:[1.6470551 1.1580933], bias:-1.3288076418726331, loss:0.5604003172528045\n",
      "epoch:3056, weight:[1.64733851 1.15818816], bias:-1.3289964236604994, loss:0.5603878201809442\n",
      "epoch:3057, weight:[1.64762191 1.15828299], bias:-1.3291851765683356, loss:0.5603753251678105\n",
      "epoch:3058, weight:[1.6479053  1.15837778], bias:-1.3293739006059908, loss:0.560362832212467\n",
      "epoch:3059, weight:[1.64818869 1.15847254], bias:-1.3295625957833097, loss:0.5603503413139772\n",
      "epoch:3060, weight:[1.64847207 1.15856726], bias:-1.3297512621101317, loss:0.5603378524714068\n",
      "epoch:3061, weight:[1.64875545 1.15866194], bias:-1.3299398995962912, loss:0.5603253656838207\n",
      "epoch:3062, weight:[1.64903882 1.15875659], bias:-1.330128508251618, loss:0.5603128809502853\n",
      "epoch:3063, weight:[1.64932219 1.15885121], bias:-1.3303170880859372, loss:0.5603003982698674\n",
      "epoch:3064, weight:[1.64960555 1.15894579], bias:-1.3305056391090684, loss:0.5602879176416345\n",
      "epoch:3065, weight:[1.64988891 1.15904033], bias:-1.3306941613308267, loss:0.5602754390646547\n",
      "epoch:3066, weight:[1.65017226 1.15913484], bias:-1.3308826547610224, loss:0.5602629625379971\n",
      "epoch:3067, weight:[1.65045561 1.15922931], bias:-1.3310711194094604, loss:0.5602504880607311\n",
      "epoch:3068, weight:[1.65073895 1.15932374], bias:-1.3312595552859414, loss:0.5602380156319265\n",
      "epoch:3069, weight:[1.65102229 1.15941814], bias:-1.3314479624002609, loss:0.5602255452506549\n",
      "epoch:3070, weight:[1.65130562 1.15951251], bias:-1.3316363407622094, loss:0.5602130769159875\n",
      "epoch:3071, weight:[1.65158895 1.15960684], bias:-1.331824690381573, loss:0.5602006106269966\n",
      "epoch:3072, weight:[1.65187227 1.15970113], bias:-1.3320130112681323, loss:0.5601881463827548\n",
      "epoch:3073, weight:[1.65215558 1.15979539], bias:-1.3322013034316638, loss:0.5601756841823359\n",
      "epoch:3074, weight:[1.6524389  1.15988961], bias:-1.3323895668819385, loss:0.5601632240248141\n",
      "epoch:3075, weight:[1.6527222 1.1599838], bias:-1.332577801628723, loss:0.5601507659092644\n",
      "epoch:3076, weight:[1.6530055  1.16007795], bias:-1.332766007681779, loss:0.5601383098347621\n",
      "epoch:3077, weight:[1.6532888  1.16017207], bias:-1.3329541850508633, loss:0.5601258558003835\n",
      "epoch:3078, weight:[1.65357209 1.16026615], bias:-1.3331423337457278, loss:0.5601134038052057\n",
      "epoch:3079, weight:[1.65385537 1.16036019], bias:-1.3333304537761195, loss:0.5601009538483058\n",
      "epoch:3080, weight:[1.65413865 1.1604542 ], bias:-1.333518545151781, loss:0.5600885059287627\n",
      "epoch:3081, weight:[1.65442193 1.16054817], bias:-1.3337066078824498, loss:0.5600760600456546\n",
      "epoch:3082, weight:[1.6547052  1.16064211], bias:-1.3338946419778586, loss:0.5600636161980616\n",
      "epoch:3083, weight:[1.65498846 1.16073602], bias:-1.3340826474477354, loss:0.5600511743850634\n",
      "epoch:3084, weight:[1.65527172 1.16082988], bias:-1.3342706243018037, loss:0.5600387346057413\n",
      "epoch:3085, weight:[1.65555498 1.16092372], bias:-1.3344585725497815, loss:0.5600262968591765\n",
      "epoch:3086, weight:[1.65583823 1.16101751], bias:-1.3346464922013825, loss:0.5600138611444515\n",
      "epoch:3087, weight:[1.65612147 1.16111128], bias:-1.3348343832663159, loss:0.5600014274606491\n",
      "epoch:3088, weight:[1.65640471 1.161205  ], bias:-1.3350222457542853, loss:0.5599889958068526\n",
      "epoch:3089, weight:[1.65668795 1.16129869], bias:-1.3352100796749904, loss:0.5599765661821464\n",
      "epoch:3090, weight:[1.65697117 1.16139235], bias:-1.3353978850381256, loss:0.5599641385856151\n",
      "epoch:3091, weight:[1.6572544  1.16148597], bias:-1.335585661853381, loss:0.5599517130163445\n",
      "epoch:3092, weight:[1.65753762 1.16157955], bias:-1.3357734101304415, loss:0.5599392894734206\n",
      "epoch:3093, weight:[1.65782083 1.1616731 ], bias:-1.3359611298789873, loss:0.55992686795593\n",
      "epoch:3094, weight:[1.65810404 1.16176662], bias:-1.3361488211086943, loss:0.5599144484629609\n",
      "epoch:3095, weight:[1.65838724 1.1618601 ], bias:-1.336336483829233, loss:0.5599020309936008\n",
      "epoch:3096, weight:[1.65867044 1.16195354], bias:-1.33652411805027, loss:0.5598896155469385\n",
      "epoch:3097, weight:[1.65895363 1.16204695], bias:-1.3367117237814665, loss:0.5598772021220635\n",
      "epoch:3098, weight:[1.65923682 1.16214033], bias:-1.3368993010324792, loss:0.559864790718066\n",
      "epoch:3099, weight:[1.65952    1.16223366], bias:-1.3370868498129602, loss:0.5598523813340368\n",
      "epoch:3100, weight:[1.65980318 1.16232697], bias:-1.3372743701325567, loss:0.5598399739690673\n",
      "epoch:3101, weight:[1.66008635 1.16242024], bias:-1.3374618620009113, loss:0.5598275686222492\n",
      "epoch:3102, weight:[1.66036951 1.16251347], bias:-1.3376493254276622, loss:0.5598151652926758\n",
      "epoch:3103, weight:[1.66065268 1.16260667], bias:-1.3378367604224424, loss:0.55980276397944\n",
      "epoch:3104, weight:[1.66093583 1.16269983], bias:-1.3380241669948802, loss:0.559790364681636\n",
      "epoch:3105, weight:[1.66121898 1.16279296], bias:-1.3382115451546, loss:0.5597779673983585\n",
      "epoch:3106, weight:[1.66150213 1.16288605], bias:-1.3383988949112204, loss:0.5597655721287027\n",
      "epoch:3107, weight:[1.66178527 1.16297911], bias:-1.3385862162743563, loss:0.5597531788717647\n",
      "epoch:3108, weight:[1.6620684  1.16307213], bias:-1.3387735092536173, loss:0.559740787626641\n",
      "epoch:3109, weight:[1.66235153 1.16316512], bias:-1.3389607738586087, loss:0.5597283983924292\n",
      "epoch:3110, weight:[1.66263466 1.16325807], bias:-1.339148010098931, loss:0.5597160111682267\n",
      "epoch:3111, weight:[1.66291778 1.16335099], bias:-1.3393352179841802, loss:0.5597036259531323\n",
      "epoch:3112, weight:[1.66320089 1.16344387], bias:-1.3395223975239474, loss:0.5596912427462455\n",
      "epoch:3113, weight:[1.663484   1.16353672], bias:-1.339709548727819, loss:0.5596788615466657\n",
      "epoch:3114, weight:[1.6637671  1.16362953], bias:-1.3398966716053773, loss:0.5596664823534936\n",
      "epoch:3115, weight:[1.6640502  1.16372231], bias:-1.3400837661661993, loss:0.5596541051658305\n",
      "epoch:3116, weight:[1.6643333  1.16381505], bias:-1.3402708324198578, loss:0.5596417299827782\n",
      "epoch:3117, weight:[1.66461638 1.16390776], bias:-1.340457870375921, loss:0.5596293568034386\n",
      "epoch:3118, weight:[1.66489947 1.16400043], bias:-1.3406448800439519, loss:0.5596169856269156\n",
      "epoch:3119, weight:[1.66518254 1.16409307], bias:-1.3408318614335097, loss:0.5596046164523126\n",
      "epoch:3120, weight:[1.66546562 1.16418567], bias:-1.3410188145541486, loss:0.5595922492787339\n",
      "epoch:3121, weight:[1.66574868 1.16427824], bias:-1.3412057394154182, loss:0.5595798841052844\n",
      "epoch:3122, weight:[1.66603175 1.16437078], bias:-1.3413926360268635, loss:0.5595675209310701\n",
      "epoch:3123, weight:[1.6663148  1.16446328], bias:-1.3415795043980248, loss:0.559555159755197\n",
      "epoch:3124, weight:[1.66659785 1.16455574], bias:-1.341766344538438, loss:0.5595428005767723\n",
      "epoch:3125, weight:[1.6668809  1.16464817], bias:-1.3419531564576344, loss:0.5595304433949035\n",
      "epoch:3126, weight:[1.66716394 1.16474056], bias:-1.3421399401651406, loss:0.5595180882086989\n",
      "epoch:3127, weight:[1.66744698 1.16483292], bias:-1.3423266956704787, loss:0.5595057350172673\n",
      "epoch:3128, weight:[1.66773001 1.16492525], bias:-1.3425134229831661, loss:0.5594933838197181\n",
      "epoch:3129, weight:[1.66801303 1.16501754], bias:-1.342700122112716, loss:0.5594810346151616\n",
      "epoch:3130, weight:[1.66829605 1.16510979], bias:-1.3428867930686363, loss:0.5594686874027087\n",
      "epoch:3131, weight:[1.66857906 1.16520201], bias:-1.3430734358604315, loss:0.5594563421814707\n",
      "epoch:3132, weight:[1.66886207 1.1652942 ], bias:-1.3432600504976004, loss:0.5594439989505595\n",
      "epoch:3133, weight:[1.66914508 1.16538635], bias:-1.3434466369896378, loss:0.5594316577090882\n",
      "epoch:3134, weight:[1.66942808 1.16547846], bias:-1.3436331953460339, loss:0.5594193184561698\n",
      "epoch:3135, weight:[1.66971107 1.16557055], bias:-1.3438197255762743, loss:0.5594069811909184\n",
      "epoch:3136, weight:[1.66999406 1.16566259], bias:-1.3440062276898401, loss:0.5593946459124486\n",
      "epoch:3137, weight:[1.67027704 1.1657546 ], bias:-1.3441927016962079, loss:0.5593823126198756\n",
      "epoch:3138, weight:[1.67056002 1.16584658], bias:-1.3443791476048497, loss:0.5593699813123153\n",
      "epoch:3139, weight:[1.67084299 1.16593852], bias:-1.344565565425233, loss:0.5593576519888844\n",
      "epoch:3140, weight:[1.67112596 1.16603043], bias:-1.344751955166821, loss:0.5593453246486998\n",
      "epoch:3141, weight:[1.67140892 1.16612231], bias:-1.344938316839072, loss:0.5593329992908793\n",
      "epoch:3142, weight:[1.67169187 1.16621415], bias:-1.34512465045144, loss:0.5593206759145416\n",
      "epoch:3143, weight:[1.67197483 1.16630595], bias:-1.3453109560133745, loss:0.5593083545188053\n",
      "epoch:3144, weight:[1.67225777 1.16639772], bias:-1.3454972335343205, loss:0.5592960351027906\n",
      "epoch:3145, weight:[1.67254071 1.16648946], bias:-1.3456834830237185, loss:0.5592837176656175\n",
      "epoch:3146, weight:[1.67282365 1.16658116], bias:-1.3458697044910044, loss:0.5592714022064068\n",
      "epoch:3147, weight:[1.67310658 1.16667282], bias:-1.3460558979456096, loss:0.5592590887242805\n",
      "epoch:3148, weight:[1.6733895  1.16676446], bias:-1.3462420633969614, loss:0.5592467772183605\n",
      "epoch:3149, weight:[1.67367242 1.16685605], bias:-1.3464282008544821, loss:0.5592344676877694\n",
      "epoch:3150, weight:[1.67395533 1.16694762], bias:-1.34661431032759, loss:0.5592221601316312\n",
      "epoch:3151, weight:[1.67423824 1.16703914], bias:-1.3468003918256986, loss:0.5592098545490695\n",
      "epoch:3152, weight:[1.67452115 1.16713064], bias:-1.3469864453582168, loss:0.5591975509392095\n",
      "epoch:3153, weight:[1.67480404 1.1672221 ], bias:-1.3471724709345494, loss:0.5591852493011761\n",
      "epoch:3154, weight:[1.67508694 1.16731352], bias:-1.3473584685640967, loss:0.5591729496340955\n",
      "epoch:3155, weight:[1.67536982 1.16740491], bias:-1.3475444382562545, loss:0.5591606519370941\n",
      "epoch:3156, weight:[1.67565271 1.16749627], bias:-1.3477303800204141, loss:0.5591483562092994\n",
      "epoch:3157, weight:[1.67593558 1.16758759], bias:-1.3479162938659623, loss:0.559136062449839\n",
      "epoch:3158, weight:[1.67621845 1.16767888], bias:-1.3481021798022816, loss:0.5591237706578416\n",
      "epoch:3159, weight:[1.67650132 1.16777013], bias:-1.3482880378387498, loss:0.5591114808324359\n",
      "epoch:3160, weight:[1.67678418 1.16786135], bias:-1.3484738679847408, loss:0.5590991929727521\n",
      "epoch:3161, weight:[1.67706703 1.16795254], bias:-1.3486596702496234, loss:0.5590869070779202\n",
      "epoch:3162, weight:[1.67734988 1.16804369], bias:-1.3488454446427625, loss:0.5590746231470712\n",
      "epoch:3163, weight:[1.67763273 1.16813481], bias:-1.3490311911735184, loss:0.5590623411793366\n",
      "epoch:3164, weight:[1.67791557 1.16822589], bias:-1.349216909851247, loss:0.559050061173849\n",
      "epoch:3165, weight:[1.6781984  1.16831693], bias:-1.3494026006852997, loss:0.5590377831297411\n",
      "epoch:3166, weight:[1.67848123 1.16840795], bias:-1.3495882636850236, loss:0.5590255070461458\n",
      "epoch:3167, weight:[1.67876405 1.16849893], bias:-1.3497738988597614, loss:0.5590132329221978\n",
      "epoch:3168, weight:[1.67904687 1.16858987], bias:-1.3499595062188512, loss:0.5590009607570315\n",
      "epoch:3169, weight:[1.67932968 1.16868078], bias:-1.350145085771627, loss:0.5589886905497823\n",
      "epoch:3170, weight:[1.67961249 1.16877166], bias:-1.3503306375274184, loss:0.558976422299586\n",
      "epoch:3171, weight:[1.67989529 1.1688625 ], bias:-1.3505161614955505, loss:0.5589641560055791\n",
      "epoch:3172, weight:[1.68017809 1.16895331], bias:-1.350701657685344, loss:0.5589518916668991\n",
      "epoch:3173, weight:[1.68046088 1.16904408], bias:-1.3508871261061148, loss:0.5589396292826835\n",
      "epoch:3174, weight:[1.68074367 1.16913482], bias:-1.3510725667671755, loss:0.5589273688520705\n",
      "epoch:3175, weight:[1.68102645 1.16922553], bias:-1.3512579796778335, loss:0.5589151103741993\n",
      "epoch:3176, weight:[1.68130922 1.1693162 ], bias:-1.351443364847392, loss:0.5589028538482099\n",
      "epoch:3177, weight:[1.68159199 1.16940684], bias:-1.35162872228515, loss:0.5588905992732419\n",
      "epoch:3178, weight:[1.68187475 1.16949744], bias:-1.3518140520004018, loss:0.5588783466484366\n",
      "epoch:3179, weight:[1.68215751 1.16958801], bias:-1.3519993540024378, loss:0.5588660959729351\n",
      "epoch:3180, weight:[1.68244027 1.16967855], bias:-1.3521846283005436, loss:0.5588538472458798\n",
      "epoch:3181, weight:[1.68272301 1.16976905], bias:-1.3523698749040007, loss:0.5588416004664132\n",
      "epoch:3182, weight:[1.68300576 1.16985952], bias:-1.3525550938220865, loss:0.5588293556336789\n",
      "epoch:3183, weight:[1.68328849 1.16994995], bias:-1.3527402850640735, loss:0.5588171127468202\n",
      "epoch:3184, weight:[1.68357123 1.17004035], bias:-1.3529254486392304, loss:0.5588048718049822\n",
      "epoch:3185, weight:[1.68385395 1.17013071], bias:-1.3531105845568212, loss:0.5587926328073097\n",
      "epoch:3186, weight:[1.68413667 1.17022105], bias:-1.353295692826106, loss:0.5587803957529487\n",
      "epoch:3187, weight:[1.68441939 1.17031134], bias:-1.3534807734563399, loss:0.5587681606410454\n",
      "epoch:3188, weight:[1.6847021  1.17040161], bias:-1.3536658264567742, loss:0.5587559274707468\n",
      "epoch:3189, weight:[1.6849848  1.17049184], bias:-1.353850851836656, loss:0.5587436962412003\n",
      "epoch:3190, weight:[1.6852675  1.17058203], bias:-1.3540358496052278, loss:0.5587314669515545\n",
      "epoch:3191, weight:[1.6855502  1.17067219], bias:-1.3542208197717278, loss:0.5587192396009578\n",
      "epoch:3192, weight:[1.68583289 1.17076232], bias:-1.35440576234539, loss:0.5587070141885598\n",
      "epoch:3193, weight:[1.68611557 1.17085241], bias:-1.354590677335444, loss:0.5586947907135106\n",
      "epoch:3194, weight:[1.68639825 1.17094247], bias:-1.354775564751115, loss:0.5586825691749605\n",
      "epoch:3195, weight:[1.68668092 1.1710325 ], bias:-1.3549604246016245, loss:0.558670349572061\n",
      "epoch:3196, weight:[1.68696359 1.17112249], bias:-1.355145256896189, loss:0.5586581319039635\n",
      "epoch:3197, weight:[1.68724625 1.17121245], bias:-1.3553300616440211, loss:0.5586459161698211\n",
      "epoch:3198, weight:[1.6875289  1.17130238], bias:-1.355514838854329, loss:0.5586337023687862\n",
      "epoch:3199, weight:[1.68781155 1.17139227], bias:-1.3556995885363168, loss:0.5586214905000129\n",
      "epoch:3200, weight:[1.6880942  1.17148212], bias:-1.355884310699184, loss:0.5586092805626552\n",
      "epoch:3201, weight:[1.68837684 1.17157195], bias:-1.3560690053521263, loss:0.5585970725558679\n",
      "epoch:3202, weight:[1.68865947 1.17166174], bias:-1.3562536725043346, loss:0.5585848664788066\n",
      "epoch:3203, weight:[1.6889421  1.17175149], bias:-1.356438312164996, loss:0.5585726623306272\n",
      "epoch:3204, weight:[1.68922473 1.17184121], bias:-1.3566229243432932, loss:0.5585604601104864\n",
      "epoch:3205, weight:[1.68950734 1.1719309 ], bias:-1.3568075090484046, loss:0.5585482598175416\n",
      "epoch:3206, weight:[1.68978996 1.17202056], bias:-1.3569920662895043, loss:0.5585360614509505\n",
      "epoch:3207, weight:[1.69007256 1.17211018], bias:-1.3571765960757622, loss:0.5585238650098717\n",
      "epoch:3208, weight:[1.69035517 1.17219977], bias:-1.357361098416344, loss:0.5585116704934641\n",
      "epoch:3209, weight:[1.69063776 1.17228932], bias:-1.3575455733204111, loss:0.5584994779008873\n",
      "epoch:3210, weight:[1.69092035 1.17237884], bias:-1.3577300207971208, loss:0.5584872872313016\n",
      "epoch:3211, weight:[1.69120294 1.17246833], bias:-1.357914440855626, loss:0.5584750984838681\n",
      "epoch:3212, weight:[1.69148552 1.17255778], bias:-1.3580988335050757, loss:0.5584629116577479\n",
      "epoch:3213, weight:[1.69176809 1.1726472 ], bias:-1.3582831987546142, loss:0.558450726752103\n",
      "epoch:3214, weight:[1.69205066 1.17273658], bias:-1.358467536613382, loss:0.5584385437660966\n",
      "epoch:3215, weight:[1.69233322 1.17282594], bias:-1.3586518470905151, loss:0.5584263626988913\n",
      "epoch:3216, weight:[1.69261578 1.17291525], bias:-1.3588361301951455, loss:0.5584141835496514\n",
      "epoch:3217, weight:[1.69289834 1.17300454], bias:-1.359020385936401, loss:0.558402006317541\n",
      "epoch:3218, weight:[1.69318088 1.17309379], bias:-1.359204614323405, loss:0.5583898310017253\n",
      "epoch:3219, weight:[1.69346342 1.17318301], bias:-1.3593888153652767, loss:0.5583776576013698\n",
      "epoch:3220, weight:[1.69374596 1.17327219], bias:-1.3595729890711314, loss:0.5583654861156409\n",
      "epoch:3221, weight:[1.69402849 1.17336134], bias:-1.35975713545008, loss:0.5583533165437052\n",
      "epoch:3222, weight:[1.69431102 1.17345046], bias:-1.359941254511229, loss:0.5583411488847301\n",
      "epoch:3223, weight:[1.69459354 1.17353954], bias:-1.3601253462636813, loss:0.5583289831378838\n",
      "epoch:3224, weight:[1.69487605 1.17362859], bias:-1.3603094107165352, loss:0.5583168193023347\n",
      "epoch:3225, weight:[1.69515856 1.17371761], bias:-1.3604934478788848, loss:0.558304657377252\n",
      "epoch:3226, weight:[1.69544106 1.17380659], bias:-1.3606774577598202, loss:0.5582924973618053\n",
      "epoch:3227, weight:[1.69572356 1.17389554], bias:-1.3608614403684272, loss:0.5582803392551655\n",
      "epoch:3228, weight:[1.69600605 1.17398446], bias:-1.3610453957137876, loss:0.558268183056503\n",
      "epoch:3229, weight:[1.69628854 1.17407334], bias:-1.3612293238049789, loss:0.5582560287649896\n",
      "epoch:3230, weight:[1.69657102 1.17416219], bias:-1.3614132246510744, loss:0.5582438763797973\n",
      "epoch:3231, weight:[1.6968535  1.17425101], bias:-1.3615970982611434, loss:0.5582317259000991\n",
      "epoch:3232, weight:[1.69713597 1.17433979], bias:-1.3617809446442508, loss:0.5582195773250677\n",
      "epoch:3233, weight:[1.69741843 1.17442854], bias:-1.3619647638094579, loss:0.5582074306538775\n",
      "epoch:3234, weight:[1.69770089 1.17451726], bias:-1.362148555765821, loss:0.5581952858857029\n",
      "epoch:3235, weight:[1.69798335 1.17460594], bias:-1.3623323205223932, loss:0.5581831430197188\n",
      "epoch:3236, weight:[1.69826579 1.17469459], bias:-1.3625160580882227, loss:0.5581710020551012\n",
      "epoch:3237, weight:[1.69854824 1.17478321], bias:-1.362699768472354, loss:0.5581588629910258\n",
      "epoch:3238, weight:[1.69883067 1.17487179], bias:-1.3628834516838275, loss:0.5581467258266698\n",
      "epoch:3239, weight:[1.69911311 1.17496034], bias:-1.3630671077316792, loss:0.5581345905612104\n",
      "epoch:3240, weight:[1.69939553 1.17504886], bias:-1.3632507366249411, loss:0.5581224571938258\n",
      "epoch:3241, weight:[1.69967795 1.17513734], bias:-1.363434338372641, loss:0.5581103257236947\n",
      "epoch:3242, weight:[1.69996037 1.17522579], bias:-1.3636179129838029, loss:0.5580981961499959\n",
      "epoch:3243, weight:[1.70024278 1.17531421], bias:-1.3638014604674462, loss:0.5580860684719092\n",
      "epoch:3244, weight:[1.70052518 1.17540259], bias:-1.3639849808325866, loss:0.558073942688615\n",
      "epoch:3245, weight:[1.70080758 1.17549094], bias:-1.3641684740882354, loss:0.5580618187992944\n",
      "epoch:3246, weight:[1.70108998 1.17557926], bias:-1.3643519402434001, loss:0.5580496968031287\n",
      "epoch:3247, weight:[1.70137236 1.17566755], bias:-1.364535379307084, loss:0.5580375766992997\n",
      "epoch:3248, weight:[1.70165475 1.1757558 ], bias:-1.364718791288286, loss:0.5580254584869905\n",
      "epoch:3249, weight:[1.70193712 1.17584401], bias:-1.3649021761960016, loss:0.5580133421653841\n",
      "epoch:3250, weight:[1.70221949 1.1759322 ], bias:-1.3650855340392214, loss:0.5580012277336643\n",
      "epoch:3251, weight:[1.70250186 1.17602035], bias:-1.3652688648269322, loss:0.5579891151910158\n",
      "epoch:3252, weight:[1.70278422 1.17610847], bias:-1.3654521685681171, loss:0.5579770045366232\n",
      "epoch:3253, weight:[1.70306657 1.17619656], bias:-1.3656354452717547, loss:0.557964895769672\n",
      "epoch:3254, weight:[1.70334892 1.17628461], bias:-1.3658186949468198, loss:0.557952788889349\n",
      "epoch:3255, weight:[1.70363127 1.17637263], bias:-1.3660019176022828, loss:0.5579406838948399\n",
      "epoch:3256, weight:[1.7039136  1.17646061], bias:-1.3661851132471103, loss:0.5579285807853327\n",
      "epoch:3257, weight:[1.70419594 1.17654857], bias:-1.366368281890265, loss:0.557916479560015\n",
      "epoch:3258, weight:[1.70447826 1.17663649], bias:-1.3665514235407048, loss:0.5579043802180753\n",
      "epoch:3259, weight:[1.70476058 1.17672438], bias:-1.3667345382073846, loss:0.5578922827587024\n",
      "epoch:3260, weight:[1.7050429  1.17681223], bias:-1.3669176258992544, loss:0.5578801871810862\n",
      "epoch:3261, weight:[1.70532521 1.17690005], bias:-1.3671006866252604, loss:0.5578680934844168\n",
      "epoch:3262, weight:[1.70560751 1.17698784], bias:-1.3672837203943449, loss:0.5578560016678846\n",
      "epoch:3263, weight:[1.70588981 1.1770756 ], bias:-1.367466727215446, loss:0.5578439117306814\n",
      "epoch:3264, weight:[1.70617211 1.17716332], bias:-1.3676497070974978, loss:0.5578318236719987\n",
      "epoch:3265, weight:[1.7064544  1.17725101], bias:-1.3678326600494306, loss:0.5578197374910293\n",
      "epoch:3266, weight:[1.70673668 1.17733867], bias:-1.3680155860801702, loss:0.5578076531869657\n",
      "epoch:3267, weight:[1.70701895 1.17742629], bias:-1.3681984851986386, loss:0.557795570759002\n",
      "epoch:3268, weight:[1.70730123 1.17751388], bias:-1.368381357413754, loss:0.5577834902063322\n",
      "epoch:3269, weight:[1.70758349 1.17760144], bias:-1.3685642027344302, loss:0.5577714115281508\n",
      "epoch:3270, weight:[1.70786575 1.17768896], bias:-1.3687470211695774, loss:0.5577593347236536\n",
      "epoch:3271, weight:[1.70814801 1.17777646], bias:-1.368929812728101, loss:0.5577472597920361\n",
      "epoch:3272, weight:[1.70843025 1.17786392], bias:-1.3691125774189035, loss:0.5577351867324948\n",
      "epoch:3273, weight:[1.7087125  1.17795134], bias:-1.3692953152508824, loss:0.5577231155442267\n",
      "epoch:3274, weight:[1.70899474 1.17803874], bias:-1.3694780262329318, loss:0.5577110462264295\n",
      "epoch:3275, weight:[1.70927697 1.1781261 ], bias:-1.3696607103739415, loss:0.5576989787783014\n",
      "epoch:3276, weight:[1.70955919 1.17821343], bias:-1.3698433676827977, loss:0.5576869131990411\n",
      "epoch:3277, weight:[1.70984141 1.17830072], bias:-1.3700259981683818, loss:0.5576748494878477\n",
      "epoch:3278, weight:[1.71012363 1.17838799], bias:-1.370208601839572, loss:0.5576627876439214\n",
      "epoch:3279, weight:[1.71040584 1.17847522], bias:-1.3703911787052423, loss:0.5576507276664623\n",
      "epoch:3280, weight:[1.71068804 1.17856242], bias:-1.3705737287742625, loss:0.5576386695546713\n",
      "epoch:3281, weight:[1.71097024 1.17864958], bias:-1.3707562520554986, loss:0.5576266133077505\n",
      "epoch:3282, weight:[1.71125244 1.17873671], bias:-1.3709387485578124, loss:0.5576145589249016\n",
      "epoch:3283, weight:[1.71153462 1.17882381], bias:-1.371121218290062, loss:0.5576025064053272\n",
      "epoch:3284, weight:[1.7118168  1.17891088], bias:-1.3713036612611016, loss:0.5575904557482306\n",
      "epoch:3285, weight:[1.71209898 1.17899791], bias:-1.371486077479781, loss:0.5575784069528162\n",
      "epoch:3286, weight:[1.71238115 1.17908491], bias:-1.3716684669549464, loss:0.5575663600182875\n",
      "epoch:3287, weight:[1.71266332 1.17917188], bias:-1.3718508296954397, loss:0.5575543149438502\n",
      "epoch:3288, weight:[1.71294548 1.17925882], bias:-1.3720331657100993, loss:0.5575422717287092\n",
      "epoch:3289, weight:[1.71322763 1.17934572], bias:-1.372215475007759, loss:0.5575302303720707\n",
      "epoch:3290, weight:[1.71350978 1.17943259], bias:-1.3723977575972497, loss:0.5575181908731418\n",
      "epoch:3291, weight:[1.71379192 1.17951943], bias:-1.372580013487397, loss:0.5575061532311292\n",
      "epoch:3292, weight:[1.71407406 1.17960624], bias:-1.3727622426870238, loss:0.5574941174452408\n",
      "epoch:3293, weight:[1.71435619 1.17969301], bias:-1.3729444452049482, loss:0.5574820835146848\n",
      "epoch:3294, weight:[1.71463831 1.17977975], bias:-1.3731266210499846, loss:0.5574700514386702\n",
      "epoch:3295, weight:[1.71492043 1.17986646], bias:-1.3733087702309437, loss:0.5574580212164063\n",
      "epoch:3296, weight:[1.71520255 1.17995314], bias:-1.3734908927566318, loss:0.5574459928471032\n",
      "epoch:3297, weight:[1.71548466 1.18003978], bias:-1.3736729886358516, loss:0.5574339663299713\n",
      "epoch:3298, weight:[1.71576676 1.18012639], bias:-1.373855057877402, loss:0.5574219416642221\n",
      "epoch:3299, weight:[1.71604886 1.18021297], bias:-1.3740371004900778, loss:0.5574099188490669\n",
      "epoch:3300, weight:[1.71633095 1.18029952], bias:-1.3742191164826696, loss:0.5573978978837179\n",
      "epoch:3301, weight:[1.71661303 1.18038603], bias:-1.3744011058639645, loss:0.5573858787673879\n",
      "epoch:3302, weight:[1.71689511 1.18047251], bias:-1.3745830686427454, loss:0.5573738614992905\n",
      "epoch:3303, weight:[1.71717719 1.18055896], bias:-1.3747650048277915, loss:0.5573618460786391\n",
      "epoch:3304, weight:[1.71745926 1.18064538], bias:-1.3749469144278779, loss:0.5573498325046486\n",
      "epoch:3305, weight:[1.71774132 1.18073176], bias:-1.3751287974517759, loss:0.5573378207765338\n",
      "epoch:3306, weight:[1.71802338 1.18081811], bias:-1.375310653908253, loss:0.5573258108935103\n",
      "epoch:3307, weight:[1.71830543 1.18090443], bias:-1.3754924838060725, loss:0.557313802854794\n",
      "epoch:3308, weight:[1.71858748 1.18099072], bias:-1.375674287153994, loss:0.5573017966596019\n",
      "epoch:3309, weight:[1.71886952 1.18107697], bias:-1.3758560639607733, loss:0.5572897923071509\n",
      "epoch:3310, weight:[1.71915155 1.18116319], bias:-1.3760378142351621, loss:0.557277789796659\n",
      "epoch:3311, weight:[1.71943358 1.18124938], bias:-1.3762195379859083, loss:0.5572657891273444\n",
      "epoch:3312, weight:[1.71971561 1.18133554], bias:-1.3764012352217558, loss:0.5572537902984259\n",
      "epoch:3313, weight:[1.71999763 1.18142167], bias:-1.376582905951445, loss:0.5572417933091229\n",
      "epoch:3314, weight:[1.72027964 1.18150776], bias:-1.3767645501837118, loss:0.5572297981586556\n",
      "epoch:3315, weight:[1.72056165 1.18159382], bias:-1.3769461679272887, loss:0.5572178048462443\n",
      "epoch:3316, weight:[1.72084365 1.18167985], bias:-1.3771277591909044, loss:0.5572058133711102\n",
      "epoch:3317, weight:[1.72112564 1.18176584], bias:-1.3773093239832832, loss:0.5571938237324748\n",
      "epoch:3318, weight:[1.72140763 1.18185181], bias:-1.3774908623131459, loss:0.5571818359295605\n",
      "epoch:3319, weight:[1.72168962 1.18193774], bias:-1.3776723741892094, loss:0.5571698499615898\n",
      "epoch:3320, weight:[1.7219716  1.18202364], bias:-1.3778538596201868, loss:0.5571578658277859\n",
      "epoch:3321, weight:[1.72225357 1.18210951], bias:-1.3780353186147871, loss:0.5571458835273727\n",
      "epoch:3322, weight:[1.72253554 1.18219534], bias:-1.3782167511817158, loss:0.5571339030595746\n",
      "epoch:3323, weight:[1.7228175  1.18228115], bias:-1.3783981573296742, loss:0.5571219244236166\n",
      "epoch:3324, weight:[1.72309945 1.18236692], bias:-1.37857953706736, loss:0.557109947618724\n",
      "epoch:3325, weight:[1.7233814  1.18245265], bias:-1.3787608904034667, loss:0.5570979726441229\n",
      "epoch:3326, weight:[1.72366335 1.18253836], bias:-1.3789422173466845, loss:0.5570859994990396\n",
      "epoch:3327, weight:[1.72394529 1.18262404], bias:-1.3791235179056993, loss:0.5570740281827012\n",
      "epoch:3328, weight:[1.72422722 1.18270968], bias:-1.3793047920891932, loss:0.5570620586943359\n",
      "epoch:3329, weight:[1.72450915 1.18279529], bias:-1.3794860399058448, loss:0.5570500910331713\n",
      "epoch:3330, weight:[1.72479107 1.18288087], bias:-1.3796672613643286, loss:0.5570381251984364\n",
      "epoch:3331, weight:[1.72507298 1.18296641], bias:-1.379848456473315, loss:0.5570261611893603\n",
      "epoch:3332, weight:[1.72535489 1.18305193], bias:-1.3800296252414712, loss:0.5570141990051728\n",
      "epoch:3333, weight:[1.7256368  1.18313741], bias:-1.3802107676774602, loss:0.5570022386451045\n",
      "epoch:3334, weight:[1.7259187  1.18322286], bias:-1.3803918837899412, loss:0.5569902801083859\n",
      "epoch:3335, weight:[1.72620059 1.18330828], bias:-1.3805729735875696, loss:0.5569783233942488\n",
      "epoch:3336, weight:[1.72648248 1.18339366], bias:-1.380754037078997, loss:0.5569663685019252\n",
      "epoch:3337, weight:[1.72676436 1.18347902], bias:-1.3809350742728712, loss:0.5569544154306472\n",
      "epoch:3338, weight:[1.72704624 1.18356434], bias:-1.3811160851778361, loss:0.5569424641796478\n",
      "epoch:3339, weight:[1.72732811 1.18364963], bias:-1.381297069802532, loss:0.5569305147481614\n",
      "epoch:3340, weight:[1.72760997 1.18373489], bias:-1.381478028155595, loss:0.5569185671354214\n",
      "epoch:3341, weight:[1.72789183 1.18382011], bias:-1.381658960245658, loss:0.5569066213406627\n",
      "epoch:3342, weight:[1.72817368 1.18390531], bias:-1.3818398660813493, loss:0.5568946773631205\n",
      "epoch:3343, weight:[1.72845553 1.18399047], bias:-1.3820207456712943, loss:0.5568827352020306\n",
      "epoch:3344, weight:[1.72873737 1.1840756 ], bias:-1.3822015990241139, loss:0.5568707948566295\n",
      "epoch:3345, weight:[1.72901921 1.1841607 ], bias:-1.3823824261484257, loss:0.5568588563261535\n",
      "epoch:3346, weight:[1.72930104 1.18424577], bias:-1.3825632270528432, loss:0.5568469196098403\n",
      "epoch:3347, weight:[1.72958286 1.1843308 ], bias:-1.382744001745976, loss:0.5568349847069279\n",
      "epoch:3348, weight:[1.72986468 1.18441581], bias:-1.3829247502364304, loss:0.5568230516166545\n",
      "epoch:3349, weight:[1.73014649 1.18450078], bias:-1.3831054725328085, loss:0.556811120338259\n",
      "epoch:3350, weight:[1.7304283  1.18458572], bias:-1.3832861686437086, loss:0.5567991908709813\n",
      "epoch:3351, weight:[1.7307101  1.18467062], bias:-1.3834668385777256, loss:0.556787263214061\n",
      "epoch:3352, weight:[1.7309919 1.1847555], bias:-1.3836474823434504, loss:0.556775337366739\n",
      "epoch:3353, weight:[1.73127369 1.18484034], bias:-1.38382809994947, loss:0.5567634133282565\n",
      "epoch:3354, weight:[1.73155547 1.18492516], bias:-1.384008691404368, loss:0.5567514910978546\n",
      "epoch:3355, weight:[1.73183725 1.18500994], bias:-1.384189256716724, loss:0.556739570674776\n",
      "epoch:3356, weight:[1.73211902 1.18509469], bias:-1.3843697958951136, loss:0.556727652058263\n",
      "epoch:3357, weight:[1.73240079 1.1851794 ], bias:-1.384550308948109, loss:0.5567157352475594\n",
      "epoch:3358, weight:[1.73268255 1.18526409], bias:-1.3847307958842787, loss:0.5567038202419083\n",
      "epoch:3359, weight:[1.73296431 1.18534874], bias:-1.384911256712187, loss:0.5566919070405545\n",
      "epoch:3360, weight:[1.73324606 1.18543336], bias:-1.385091691440395, loss:0.5566799956427426\n",
      "epoch:3361, weight:[1.7335278  1.18551795], bias:-1.3852721000774597, loss:0.556668086047718\n",
      "epoch:3362, weight:[1.73380954 1.18560251], bias:-1.3854524826319345, loss:0.5566561782547269\n",
      "epoch:3363, weight:[1.73409127 1.18568704], bias:-1.3856328391123691, loss:0.5566442722630153\n",
      "epoch:3364, weight:[1.734373   1.18577154], bias:-1.385813169527309, loss:0.5566323680718303\n",
      "epoch:3365, weight:[1.73465472 1.185856  ], bias:-1.3859934738852968, loss:0.5566204656804193\n",
      "epoch:3366, weight:[1.73493643 1.18594043], bias:-1.3861737521948705, loss:0.5566085650880302\n",
      "epoch:3367, weight:[1.73521814 1.18602483], bias:-1.386354004464565, loss:0.5565966662939124\n",
      "epoch:3368, weight:[1.73549985 1.1861092 ], bias:-1.3865342307029112, loss:0.5565847692973139\n",
      "epoch:3369, weight:[1.73578154 1.18619354], bias:-1.3867144309184363, loss:0.5565728740974847\n",
      "epoch:3370, weight:[1.73606324 1.18627784], bias:-1.3868946051196638, loss:0.5565609806936751\n",
      "epoch:3371, weight:[1.73634492 1.18636212], bias:-1.3870747533151135, loss:0.5565490890851353\n",
      "epoch:3372, weight:[1.7366266  1.18644636], bias:-1.3872548755133014, loss:0.5565371992711171\n",
      "epoch:3373, weight:[1.73690828 1.18653057], bias:-1.3874349717227399, loss:0.5565253112508717\n",
      "epoch:3374, weight:[1.73718995 1.18661475], bias:-1.3876150419519375, loss:0.5565134250236515\n",
      "epoch:3375, weight:[1.73747161 1.1866989 ], bias:-1.3877950862093993, loss:0.556501540588709\n",
      "epoch:3376, weight:[1.73775327 1.18678302], bias:-1.3879751045036264, loss:0.556489657945298\n",
      "epoch:3377, weight:[1.73803492 1.1868671 ], bias:-1.3881550968431164, loss:0.5564777770926719\n",
      "epoch:3378, weight:[1.73831656 1.18695116], bias:-1.3883350632363631, loss:0.5564658980300851\n",
      "epoch:3379, weight:[1.7385982  1.18703518], bias:-1.3885150036918565, loss:0.5564540207567924\n",
      "epoch:3380, weight:[1.73887984 1.18711917], bias:-1.3886949182180832, loss:0.5564421452720492\n",
      "epoch:3381, weight:[1.73916146 1.18720313], bias:-1.388874806823526, loss:0.5564302715751115\n",
      "epoch:3382, weight:[1.73944309 1.18728706], bias:-1.3890546695166635, loss:0.5564183996652355\n",
      "epoch:3383, weight:[1.7397247  1.18737095], bias:-1.3892345063059715, loss:0.5564065295416782\n",
      "epoch:3384, weight:[1.74000631 1.18745482], bias:-1.3894143171999214, loss:0.5563946612036974\n",
      "epoch:3385, weight:[1.74028792 1.18753865], bias:-1.3895941022069813, loss:0.5563827946505504\n",
      "epoch:3386, weight:[1.74056952 1.18762246], bias:-1.3897738613356154, loss:0.5563709298814964\n",
      "epoch:3387, weight:[1.74085111 1.18770623], bias:-1.3899535945942845, loss:0.5563590668957938\n",
      "epoch:3388, weight:[1.7411327  1.18778997], bias:-1.3901333019914455, loss:0.5563472056927024\n",
      "epoch:3389, weight:[1.74141428 1.18787368], bias:-1.3903129835355514, loss:0.5563353462714824\n",
      "epoch:3390, weight:[1.74169586 1.18795735], bias:-1.3904926392350523, loss:0.5563234886313941\n",
      "epoch:3391, weight:[1.74197743 1.188041  ], bias:-1.3906722690983937, loss:0.5563116327716987\n",
      "epoch:3392, weight:[1.74225899 1.18812461], bias:-1.390851873134018, loss:0.5562997786916579\n",
      "epoch:3393, weight:[1.74254055 1.1882082 ], bias:-1.3910314513503639, loss:0.5562879263905336\n",
      "epoch:3394, weight:[1.7428221  1.18829175], bias:-1.3912110037558663, loss:0.5562760758675889\n",
      "epoch:3395, weight:[1.74310365 1.18837527], bias:-1.3913905303589564, loss:0.5562642271220862\n",
      "epoch:3396, weight:[1.74338519 1.18845876], bias:-1.391570031168062, loss:0.5562523801532896\n",
      "epoch:3397, weight:[1.74366673 1.18854222], bias:-1.3917495061916072, loss:0.5562405349604634\n",
      "epoch:3398, weight:[1.74394826 1.18862564], bias:-1.391928955438012, loss:0.5562286915428721\n",
      "epoch:3399, weight:[1.74422978 1.18870904], bias:-1.3921083789156936, loss:0.5562168498997812\n",
      "epoch:3400, weight:[1.7445113  1.18879241], bias:-1.3922877766330646, loss:0.5562050100304559\n",
      "epoch:3401, weight:[1.74479281 1.18887574], bias:-1.3924671485985347, loss:0.5561931719341627\n",
      "epoch:3402, weight:[1.74507431 1.18895904], bias:-1.3926464948205095, loss:0.5561813356101685\n",
      "epoch:3403, weight:[1.74535581 1.18904231], bias:-1.3928258153073911, loss:0.5561695010577405\n",
      "epoch:3404, weight:[1.74563731 1.18912555], bias:-1.3930051100675782, loss:0.5561576682761465\n",
      "epoch:3405, weight:[1.7459188  1.18920876], bias:-1.3931843791094656, loss:0.5561458372646547\n",
      "epoch:3406, weight:[1.74620028 1.18929194], bias:-1.3933636224414443, loss:0.5561340080225339\n",
      "epoch:3407, weight:[1.74648176 1.18937509], bias:-1.3935428400719023, loss:0.5561221805490535\n",
      "epoch:3408, weight:[1.74676323 1.1894582 ], bias:-1.3937220320092234, loss:0.5561103548434833\n",
      "epoch:3409, weight:[1.74704469 1.18954129], bias:-1.393901198261788, loss:0.5560985309050935\n",
      "epoch:3410, weight:[1.74732615 1.18962434], bias:-1.3940803388379728, loss:0.5560867087331552\n",
      "epoch:3411, weight:[1.7476076  1.18970736], bias:-1.394259453746151, loss:0.5560748883269393\n",
      "epoch:3412, weight:[1.74788905 1.18979036], bias:-1.3944385429946922, loss:0.5560630696857185\n",
      "epoch:3413, weight:[1.74817049 1.18987332], bias:-1.3946176065919622, loss:0.5560512528087644\n",
      "epoch:3414, weight:[1.74845193 1.18995625], bias:-1.3947966445463233, loss:0.5560394376953501\n",
      "epoch:3415, weight:[1.74873336 1.19003914], bias:-1.3949756568661345, loss:0.5560276243447494\n",
      "epoch:3416, weight:[1.74901478 1.19012201], bias:-1.3951546435597504, loss:0.5560158127562356\n",
      "epoch:3417, weight:[1.7492962  1.19020485], bias:-1.3953336046355227, loss:0.5560040029290833\n",
      "epoch:3418, weight:[1.74957761 1.19028765], bias:-1.3955125401017994, loss:0.5559921948625676\n",
      "epoch:3419, weight:[1.74985902 1.19037043], bias:-1.3956914499669248, loss:0.5559803885559638\n",
      "epoch:3420, weight:[1.75014042 1.19045317], bias:-1.3958703342392396, loss:0.5559685840085474\n",
      "epoch:3421, weight:[1.75042181 1.19053589], bias:-1.3960491929270809, loss:0.5559567812195957\n",
      "epoch:3422, weight:[1.7507032  1.19061857], bias:-1.396228026038782, loss:0.555944980188385\n",
      "epoch:3423, weight:[1.75098458 1.19070122], bias:-1.3964068335826731, loss:0.555933180914193\n",
      "epoch:3424, weight:[1.75126596 1.19078384], bias:-1.3965856155670806, loss:0.5559213833962975\n",
      "epoch:3425, weight:[1.75154733 1.19086643], bias:-1.396764372000327, loss:0.5559095876339771\n",
      "epoch:3426, weight:[1.7518287  1.19094899], bias:-1.396943102890732, loss:0.5558977936265106\n",
      "epoch:3427, weight:[1.75211006 1.19103151], bias:-1.3971218082466108, loss:0.5558860013731778\n",
      "epoch:3428, weight:[1.75239141 1.19111401], bias:-1.3973004880762754, loss:0.5558742108732582\n",
      "epoch:3429, weight:[1.75267276 1.19119648], bias:-1.3974791423880344, loss:0.5558624221260323\n",
      "epoch:3430, weight:[1.7529541  1.19127891], bias:-1.3976577711901927, loss:0.5558506351307814\n",
      "epoch:3431, weight:[1.75323543 1.19136132], bias:-1.3978363744910518, loss:0.5558388498867868\n",
      "epoch:3432, weight:[1.75351676 1.19144369], bias:-1.3980149522989094, loss:0.5558270663933306\n",
      "epoch:3433, weight:[1.75379809 1.19152603], bias:-1.3981935046220595, loss:0.5558152846496949\n",
      "epoch:3434, weight:[1.75407941 1.19160834], bias:-1.3983720314687929, loss:0.5558035046551629\n",
      "epoch:3435, weight:[1.75436072 1.19169062], bias:-1.3985505328473966, loss:0.5557917264090183\n",
      "epoch:3436, weight:[1.75464202 1.19177288], bias:-1.3987290087661544, loss:0.5557799499105447\n",
      "epoch:3437, weight:[1.75492332 1.1918551 ], bias:-1.3989074592333461, loss:0.5557681751590265\n",
      "epoch:3438, weight:[1.75520462 1.19193728], bias:-1.3990858842572482, loss:0.5557564021537493\n",
      "epoch:3439, weight:[1.75548591 1.19201944], bias:-1.3992642838461335, loss:0.5557446308939977\n",
      "epoch:3440, weight:[1.75576719 1.19210157], bias:-1.3994426580082715, loss:0.5557328613790585\n",
      "epoch:3441, weight:[1.75604847 1.19218367], bias:-1.399621006751928, loss:0.5557210936082175\n",
      "epoch:3442, weight:[1.75632974 1.19226573], bias:-1.3997993300853648, loss:0.5557093275807622\n",
      "epoch:3443, weight:[1.756611   1.19234777], bias:-1.3999776280168412, loss:0.5556975632959795\n",
      "epoch:3444, weight:[1.75689226 1.19242977], bias:-1.400155900554612, loss:0.555685800753158\n",
      "epoch:3445, weight:[1.75717351 1.19251175], bias:-1.400334147706929, loss:0.5556740399515854\n",
      "epoch:3446, weight:[1.75745476 1.19259369], bias:-1.4005123694820405, loss:0.5556622808905514\n",
      "epoch:3447, weight:[1.757736  1.1926756], bias:-1.400690565888191, loss:0.5556505235693447\n",
      "epoch:3448, weight:[1.75801723 1.19275749], bias:-1.4008687369336215, loss:0.5556387679872556\n",
      "epoch:3449, weight:[1.75829846 1.19283934], bias:-1.4010468826265694, loss:0.5556270141435748\n",
      "epoch:3450, weight:[1.75857969 1.19292116], bias:-1.4012250029752689, loss:0.5556152620375929\n",
      "epoch:3451, weight:[1.7588609  1.19300295], bias:-1.4014030979879504, loss:0.5556035116686012\n",
      "epoch:3452, weight:[1.75914211 1.19308471], bias:-1.401581167672841, loss:0.5555917630358923\n",
      "epoch:3453, weight:[1.75942332 1.19316644], bias:-1.4017592120381641, loss:0.5555800161387577\n",
      "epoch:3454, weight:[1.75970452 1.19324814], bias:-1.4019372310921396, loss:0.5555682709764906\n",
      "epoch:3455, weight:[1.75998571 1.19332981], bias:-1.402115224842984, loss:0.5555565275483847\n",
      "epoch:3456, weight:[1.7602669  1.19341145], bias:-1.4022931932989102, loss:0.5555447858537335\n",
      "epoch:3457, weight:[1.76054808 1.19349306], bias:-1.402471136468128, loss:0.5555330458918316\n",
      "epoch:3458, weight:[1.76082926 1.19357463], bias:-1.4026490543588428, loss:0.5555213076619738\n",
      "epoch:3459, weight:[1.76111043 1.19365618], bias:-1.4028269469792571, loss:0.5555095711634555\n",
      "epoch:3460, weight:[1.76139159 1.1937377 ], bias:-1.4030048143375702, loss:0.5554978363955723\n",
      "epoch:3461, weight:[1.76167275 1.19381918], bias:-1.4031826564419771, loss:0.5554861033576208\n",
      "epoch:3462, weight:[1.7619539  1.19390064], bias:-1.4033604733006702, loss:0.5554743720488978\n",
      "epoch:3463, weight:[1.76223505 1.19398206], bias:-1.4035382649218375, loss:0.5554626424687007\n",
      "epoch:3464, weight:[1.76251619 1.19406346], bias:-1.4037160313136643, loss:0.555450914616327\n",
      "epoch:3465, weight:[1.76279732 1.19414482], bias:-1.4038937724843317, loss:0.5554391884910751\n",
      "epoch:3466, weight:[1.76307845 1.19422616], bias:-1.404071488442018, loss:0.5554274640922438\n",
      "epoch:3467, weight:[1.76335957 1.19430746], bias:-1.4042491791948977, loss:0.5554157414191324\n",
      "epoch:3468, weight:[1.76364069 1.19438873], bias:-1.4044268447511414, loss:0.5554040204710406\n",
      "epoch:3469, weight:[1.7639218  1.19446997], bias:-1.4046044851189172, loss:0.5553923012472688\n",
      "epoch:3470, weight:[1.7642029  1.19455119], bias:-1.404782100306389, loss:0.5553805837471177\n",
      "epoch:3471, weight:[1.764484   1.19463237], bias:-1.4049596903217172, loss:0.5553688679698882\n",
      "epoch:3472, weight:[1.76476509 1.19471352], bias:-1.405137255173059, loss:0.5553571539148822\n",
      "epoch:3473, weight:[1.76504618 1.19479464], bias:-1.405314794868568, loss:0.5553454415814019\n",
      "epoch:3474, weight:[1.76532726 1.19487573], bias:-1.4054923094163947, loss:0.55533373096875\n",
      "epoch:3475, weight:[1.76560833 1.1949568 ], bias:-1.4056697988246856, loss:0.5553220220762297\n",
      "epoch:3476, weight:[1.7658894  1.19503783], bias:-1.405847263101584, loss:0.5553103149031444\n",
      "epoch:3477, weight:[1.76617046 1.19511883], bias:-1.4060247022552295, loss:0.5552986094487985\n",
      "epoch:3478, weight:[1.76645152 1.1951998 ], bias:-1.4062021162937586, loss:0.5552869057124962\n",
      "epoch:3479, weight:[1.76673257 1.19528074], bias:-1.406379505225304, loss:0.555275203693543\n",
      "epoch:3480, weight:[1.76701361 1.19536165], bias:-1.4065568690579957, loss:0.5552635033912443\n",
      "epoch:3481, weight:[1.76729465 1.19544253], bias:-1.4067342077999592, loss:0.5552518048049062\n",
      "epoch:3482, weight:[1.76757568 1.19552338], bias:-1.406911521459317, loss:0.5552401079338349\n",
      "epoch:3483, weight:[1.76785671 1.1956042 ], bias:-1.4070888100441885, loss:0.555228412777338\n",
      "epoch:3484, weight:[1.76813773 1.19568499], bias:-1.407266073562689, loss:0.5552167193347226\n",
      "epoch:3485, weight:[1.76841874 1.19576575], bias:-1.4074433120229308, loss:0.5552050276052968\n",
      "epoch:3486, weight:[1.76869975 1.19584647], bias:-1.4076205254330227, loss:0.5551933375883691\n",
      "epoch:3487, weight:[1.76898075 1.19592717], bias:-1.4077977138010702, loss:0.555181649283248\n",
      "epoch:3488, weight:[1.76926175 1.19600784], bias:-1.407974877135175, loss:0.5551699626892435\n",
      "epoch:3489, weight:[1.76954274 1.19608848], bias:-1.4081520154434355, loss:0.5551582778056652\n",
      "epoch:3490, weight:[1.76982372 1.19616909], bias:-1.4083291287339468, loss:0.5551465946318236\n",
      "epoch:3491, weight:[1.7701047  1.19624967], bias:-1.4085062170148004, loss:0.5551349131670293\n",
      "epoch:3492, weight:[1.77038567 1.19633022], bias:-1.4086832802940845, loss:0.555123233410594\n",
      "epoch:3493, weight:[1.77066664 1.19641073], bias:-1.4088603185798838, loss:0.5551115553618293\n",
      "epoch:3494, weight:[1.7709476  1.19649122], bias:-1.4090373318802798, loss:0.5550998790200474\n",
      "epoch:3495, weight:[1.77122855 1.19657168], bias:-1.4092143202033502, loss:0.5550882043845612\n",
      "epoch:3496, weight:[1.7715095  1.19665211], bias:-1.4093912835571696, loss:0.5550765314546838\n",
      "epoch:3497, weight:[1.77179044 1.19673251], bias:-1.409568221949809, loss:0.5550648602297289\n",
      "epoch:3498, weight:[1.77207138 1.19681288], bias:-1.409745135389336, loss:0.5550531907090109\n",
      "epoch:3499, weight:[1.77235231 1.19689322], bias:-1.4099220238838148, loss:0.5550415228918443\n",
      "epoch:3500, weight:[1.77263323 1.19697352], bias:-1.4100988874413063, loss:0.5550298567775444\n",
      "epoch:3501, weight:[1.77291415 1.1970538 ], bias:-1.410275726069868, loss:0.5550181923654264\n",
      "epoch:3502, weight:[1.77319506 1.19713405], bias:-1.4104525397775538, loss:0.5550065296548068\n",
      "epoch:3503, weight:[1.77347597 1.19721427], bias:-1.4106293285724143, loss:0.554994868645002\n",
      "epoch:3504, weight:[1.77375687 1.19729446], bias:-1.4108060924624968, loss:0.5549832093353292\n",
      "epoch:3505, weight:[1.77403776 1.19737462], bias:-1.410982831455845, loss:0.5549715517251056\n",
      "epoch:3506, weight:[1.77431865 1.19745475], bias:-1.4111595455604993, loss:0.5549598958136494\n",
      "epoch:3507, weight:[1.77459953 1.19753484], bias:-1.4113362347844967, loss:0.554948241600279\n",
      "epoch:3508, weight:[1.7748804  1.19761491], bias:-1.411512899135871, loss:0.5549365890843133\n",
      "epoch:3509, weight:[1.77516127 1.19769495], bias:-1.4116895386226522, loss:0.5549249382650716\n",
      "epoch:3510, weight:[1.77544214 1.19777496], bias:-1.4118661532528674, loss:0.5549132891418739\n",
      "epoch:3511, weight:[1.77572299 1.19785494], bias:-1.41204274303454, loss:0.5549016417140407\n",
      "epoch:3512, weight:[1.77600385 1.19793489], bias:-1.4122193079756897, loss:0.5548899959808923\n",
      "epoch:3513, weight:[1.77628469 1.19801481], bias:-1.4123958480843337, loss:0.5548783519417506\n",
      "epoch:3514, weight:[1.77656553 1.1980947 ], bias:-1.412572363368485, loss:0.5548667095959368\n",
      "epoch:3515, weight:[1.77684636 1.19817456], bias:-1.4127488538361537, loss:0.5548550689427735\n",
      "epoch:3516, weight:[1.77712719 1.19825439], bias:-1.4129253194953462, loss:0.5548434299815829\n",
      "epoch:3517, weight:[1.77740801 1.19833419], bias:-1.4131017603540657, loss:0.5548317927116888\n",
      "epoch:3518, weight:[1.77768883 1.19841397], bias:-1.4132781764203122, loss:0.5548201571324144\n",
      "epoch:3519, weight:[1.77796964 1.19849371], bias:-1.413454567702082, loss:0.5548085232430839\n",
      "epoch:3520, weight:[1.77825044 1.19857342], bias:-1.413630934207368, loss:0.5547968910430219\n",
      "epoch:3521, weight:[1.77853123 1.1986531 ], bias:-1.4138072759441602, loss:0.5547852605315531\n",
      "epoch:3522, weight:[1.77881203 1.19873275], bias:-1.413983592920445, loss:0.5547736317080035\n",
      "epoch:3523, weight:[1.77909281 1.19881238], bias:-1.414159885144205, loss:0.5547620045716989\n",
      "epoch:3524, weight:[1.77937359 1.19889197], bias:-1.4143361526234202, loss:0.5547503791219653\n",
      "epoch:3525, weight:[1.77965436 1.19897153], bias:-1.4145123953660665, loss:0.5547387553581301\n",
      "epoch:3526, weight:[1.77993513 1.19905107], bias:-1.4146886133801173, loss:0.5547271332795206\n",
      "epoch:3527, weight:[1.78021589 1.19913057], bias:-1.4148648066735419, loss:0.5547155128854642\n",
      "epoch:3528, weight:[1.78049664 1.19921004], bias:-1.4150409752543063, loss:0.5547038941752895\n",
      "epoch:3529, weight:[1.78077739 1.19928949], bias:-1.4152171191303735, loss:0.5546922771483255\n",
      "epoch:3530, weight:[1.78105813 1.1993689 ], bias:-1.4153932383097032, loss:0.5546806618039007\n",
      "epoch:3531, weight:[1.78133887 1.19944829], bias:-1.4155693328002514, loss:0.5546690481413455\n",
      "epoch:3532, weight:[1.7816196  1.19952765], bias:-1.4157454026099712, loss:0.5546574361599896\n",
      "epoch:3533, weight:[1.78190032 1.19960697], bias:-1.4159214477468116, loss:0.5546458258591638\n",
      "epoch:3534, weight:[1.78218104 1.19968627], bias:-1.416097468218719, loss:0.5546342172381992\n",
      "epoch:3535, weight:[1.78246175 1.19976554], bias:-1.4162734640336365, loss:0.5546226102964269\n",
      "epoch:3536, weight:[1.78274246 1.19984477], bias:-1.4164494351995032, loss:0.5546110050331793\n",
      "epoch:3537, weight:[1.78302316 1.19992398], bias:-1.4166253817242553, loss:0.5545994014477887\n",
      "epoch:3538, weight:[1.78330385 1.20000316], bias:-1.4168013036158258, loss:0.5545877995395881\n",
      "epoch:3539, weight:[1.78358454 1.20008231], bias:-1.416977200882144, loss:0.5545761993079108\n",
      "epoch:3540, weight:[1.78386522 1.20016143], bias:-1.417153073531136, loss:0.5545646007520906\n",
      "epoch:3541, weight:[1.78414589 1.20024052], bias:-1.4173289215707248, loss:0.5545530038714618\n",
      "epoch:3542, weight:[1.78442656 1.20031958], bias:-1.4175047450088298, loss:0.5545414086653593\n",
      "epoch:3543, weight:[1.78470722 1.20039861], bias:-1.4176805438533675, loss:0.554529815133118\n",
      "epoch:3544, weight:[1.78498788 1.20047761], bias:-1.4178563181122503, loss:0.5545182232740739\n",
      "epoch:3545, weight:[1.78526853 1.20055659], bias:-1.4180320677933882, loss:0.5545066330875628\n",
      "epoch:3546, weight:[1.78554918 1.20063553], bias:-1.4182077929046872, loss:0.5544950445729214\n",
      "epoch:3547, weight:[1.78582981 1.20071444], bias:-1.4183834934540502, loss:0.5544834577294868\n",
      "epoch:3548, weight:[1.78611045 1.20079333], bias:-1.418559169449377, loss:0.5544718725565965\n",
      "epoch:3549, weight:[1.78639107 1.20087218], bias:-1.418734820898564, loss:0.5544602890535884\n",
      "epoch:3550, weight:[1.78667169 1.20095101], bias:-1.4189104478095038, loss:0.5544487072198008\n",
      "epoch:3551, weight:[1.78695231 1.2010298 ], bias:-1.4190860501900864, loss:0.5544371270545726\n",
      "epoch:3552, weight:[1.78723291 1.20110857], bias:-1.4192616280481982, loss:0.5544255485572435\n",
      "epoch:3553, weight:[1.78751352 1.20118731], bias:-1.4194371813917221, loss:0.5544139717271528\n",
      "epoch:3554, weight:[1.78779411 1.20126602], bias:-1.4196127102285383, loss:0.5544023965636408\n",
      "epoch:3555, weight:[1.7880747  1.20134469], bias:-1.419788214566523, loss:0.5543908230660484\n",
      "epoch:3556, weight:[1.78835528 1.20142334], bias:-1.4199636944135494, loss:0.5543792512337166\n",
      "epoch:3557, weight:[1.78863586 1.20150196], bias:-1.4201391497774876, loss:0.5543676810659869\n",
      "epoch:3558, weight:[1.78891643 1.20158055], bias:-1.420314580666204, loss:0.5543561125622015\n",
      "epoch:3559, weight:[1.789197   1.20165912], bias:-1.4204899870875622, loss:0.5543445457217029\n",
      "epoch:3560, weight:[1.78947756 1.20173765], bias:-1.4206653690494222, loss:0.554332980543834\n",
      "epoch:3561, weight:[1.78975811 1.20181615], bias:-1.4208407265596408, loss:0.554321417027938\n",
      "epoch:3562, weight:[1.79003865 1.20189463], bias:-1.4210160596260712, loss:0.5543098551733591\n",
      "epoch:3563, weight:[1.79031919 1.20197307], bias:-1.421191368256564, loss:0.5542982949794415\n",
      "epoch:3564, weight:[1.79059973 1.20205149], bias:-1.4213666524589659, loss:0.55428673644553\n",
      "epoch:3565, weight:[1.79088026 1.20212987], bias:-1.4215419122411206, loss:0.5542751795709696\n",
      "epoch:3566, weight:[1.79116078 1.20220823], bias:-1.4217171476108685, loss:0.5542636243551059\n",
      "epoch:3567, weight:[1.79144129 1.20228656], bias:-1.4218923585760468, loss:0.5542520707972854\n",
      "epoch:3568, weight:[1.7917218  1.20236486], bias:-1.422067545144489, loss:0.5542405188968546\n",
      "epoch:3569, weight:[1.79200231 1.20244313], bias:-1.4222427073240262, loss:0.5542289686531601\n",
      "epoch:3570, weight:[1.7922828  1.20252137], bias:-1.4224178451224854, loss:0.5542174200655497\n",
      "epoch:3571, weight:[1.79256329 1.20259958], bias:-1.4225929585476906, loss:0.5542058731333713\n",
      "epoch:3572, weight:[1.79284378 1.20267776], bias:-1.4227680476074627, loss:0.5541943278559733\n",
      "epoch:3573, weight:[1.79312426 1.20275591], bias:-1.4229431123096192, loss:0.5541827842327042\n",
      "epoch:3574, weight:[1.79340473 1.20283404], bias:-1.4231181526619743, loss:0.5541712422629135\n",
      "epoch:3575, weight:[1.7936852  1.20291213], bias:-1.423293168672339, loss:0.554159701945951\n",
      "epoch:3576, weight:[1.79396566 1.2029902 ], bias:-1.423468160348521, loss:0.5541481632811665\n",
      "epoch:3577, weight:[1.79424611 1.20306824], bias:-1.423643127698325, loss:0.5541366262679109\n",
      "epoch:3578, weight:[1.79452656 1.20314624], bias:-1.423818070729552, loss:0.554125090905535\n",
      "epoch:3579, weight:[1.794807   1.20322422], bias:-1.42399298945, loss:0.5541135571933905\n",
      "epoch:3580, weight:[1.79508744 1.20330217], bias:-1.424167883867464, loss:0.5541020251308292\n",
      "epoch:3581, weight:[1.79536786 1.20338009], bias:-1.4243427539897355, loss:0.5540904947172035\n",
      "epoch:3582, weight:[1.79564829 1.20345798], bias:-1.4245175998246025, loss:0.5540789659518663\n",
      "epoch:3583, weight:[1.7959287  1.20353585], bias:-1.42469242137985, loss:0.554067438834171\n",
      "epoch:3584, weight:[1.79620912 1.20361368], bias:-1.4248672186632598, loss:0.5540559133634708\n",
      "epoch:3585, weight:[1.79648952 1.20369149], bias:-1.4250419916826107, loss:0.5540443895391204\n",
      "epoch:3586, weight:[1.79676992 1.20376926], bias:-1.425216740445678, loss:0.554032867360474\n",
      "epoch:3587, weight:[1.79705031 1.20384701], bias:-1.4253914649602333, loss:0.554021346826887\n",
      "epoch:3588, weight:[1.7973307  1.20392473], bias:-1.425566165234046, loss:0.5540098279377147\n",
      "epoch:3589, weight:[1.79761108 1.20400242], bias:-1.425740841274881, loss:0.5539983106923129\n",
      "epoch:3590, weight:[1.79789145 1.20408008], bias:-1.4259154930905016, loss:0.5539867950900383\n",
      "epoch:3591, weight:[1.79817182 1.20415771], bias:-1.4260901206886663, loss:0.5539752811302473\n",
      "epoch:3592, weight:[1.79845218 1.20423531], bias:-1.4262647240771311, loss:0.5539637688122975\n",
      "epoch:3593, weight:[1.79873253 1.20431288], bias:-1.4264393032636489, loss:0.5539522581355464\n",
      "epoch:3594, weight:[1.79901288 1.20439043], bias:-1.4266138582559689, loss:0.5539407490993522\n",
      "epoch:3595, weight:[1.79929322 1.20446794], bias:-1.4267883890618376, loss:0.5539292417030736\n",
      "epoch:3596, weight:[1.79957356 1.20454543], bias:-1.426962895688998, loss:0.5539177359460692\n",
      "epoch:3597, weight:[1.79985389 1.20462289], bias:-1.4271373781451897, loss:0.5539062318276989\n",
      "epoch:3598, weight:[1.80013421 1.20470032], bias:-1.4273118364381496, loss:0.5538947293473226\n",
      "epoch:3599, weight:[1.80041453 1.20477772], bias:-1.4274862705756113, loss:0.5538832285043005\n",
      "epoch:3600, weight:[1.80069484 1.20485509], bias:-1.4276606805653045, loss:0.5538717292979931\n",
      "epoch:3601, weight:[1.80097515 1.20493243], bias:-1.4278350664149564, loss:0.5538602317277619\n",
      "epoch:3602, weight:[1.80125545 1.20500975], bias:-1.4280094281322908, loss:0.5538487357929687\n",
      "epoch:3603, weight:[1.80153574 1.20508703], bias:-1.4281837657250285, loss:0.5538372414929752\n",
      "epoch:3604, weight:[1.80181603 1.20516429], bias:-1.4283580792008865, loss:0.5538257488271441\n",
      "epoch:3605, weight:[1.80209631 1.20524152], bias:-1.4285323685675793, loss:0.5538142577948384\n",
      "epoch:3606, weight:[1.80237658 1.20531872], bias:-1.4287066338328176, loss:0.5538027683954216\n",
      "epoch:3607, weight:[1.80265685 1.20539589], bias:-1.4288808750043092, loss:0.5537912806282571\n",
      "epoch:3608, weight:[1.80293711 1.20547303], bias:-1.429055092089759, loss:0.5537797944927098\n",
      "epoch:3609, weight:[1.80321737 1.20555014], bias:-1.429229285096868, loss:0.5537683099881439\n",
      "epoch:3610, weight:[1.80349762 1.20562723], bias:-1.4294034540333345, loss:0.553756827113925\n",
      "epoch:3611, weight:[1.80377786 1.20570428], bias:-1.4295775989068535, loss:0.553745345869418\n",
      "epoch:3612, weight:[1.8040581  1.20578131], bias:-1.429751719725117, loss:0.5537338662539896\n",
      "epoch:3613, weight:[1.80433833 1.20585831], bias:-1.4299258164958137, loss:0.5537223882670058\n",
      "epoch:3614, weight:[1.80461855 1.20593528], bias:-1.4300998892266288, loss:0.5537109119078338\n",
      "epoch:3615, weight:[1.80489877 1.20601222], bias:-1.4302739379252447, loss:0.5536994371758406\n",
      "epoch:3616, weight:[1.80517898 1.20608913], bias:-1.4304479625993405, loss:0.5536879640703941\n",
      "epoch:3617, weight:[1.80545919 1.20616602], bias:-1.4306219632565922, loss:0.5536764925908625\n",
      "epoch:3618, weight:[1.80573939 1.20624287], bias:-1.4307959399046724, loss:0.5536650227366143\n",
      "epoch:3619, weight:[1.80601958 1.2063197 ], bias:-1.4309698925512506, loss:0.5536535545070186\n",
      "epoch:3620, weight:[1.80629977 1.2063965 ], bias:-1.4311438212039933, loss:0.5536420879014451\n",
      "epoch:3621, weight:[1.80657995 1.20647327], bias:-1.4313177258705638, loss:0.5536306229192632\n",
      "epoch:3622, weight:[1.80686012 1.20655001], bias:-1.431491606558622, loss:0.5536191595598436\n",
      "epoch:3623, weight:[1.80714029 1.20662672], bias:-1.431665463275825, loss:0.5536076978225574\n",
      "epoch:3624, weight:[1.80742045 1.20670341], bias:-1.4318392960298263, loss:0.5535962377067748\n",
      "epoch:3625, weight:[1.80770061 1.20678006], bias:-1.4320131048282765, loss:0.5535847792118684\n",
      "epoch:3626, weight:[1.80798076 1.20685669], bias:-1.432186889678823, loss:0.5535733223372097\n",
      "epoch:3627, weight:[1.8082609  1.20693329], bias:-1.4323606505891102, loss:0.5535618670821715\n",
      "epoch:3628, weight:[1.80854104 1.20700986], bias:-1.432534387566779, loss:0.5535504134461265\n",
      "epoch:3629, weight:[1.80882117 1.2070864 ], bias:-1.4327081006194675, loss:0.5535389614284484\n",
      "epoch:3630, weight:[1.80910129 1.20716292], bias:-1.4328817897548103, loss:0.5535275110285104\n",
      "epoch:3631, weight:[1.80938141 1.2072394 ], bias:-1.433055454980439, loss:0.5535160622456872\n",
      "epoch:3632, weight:[1.80966152 1.20731586], bias:-1.4332290963039822, loss:0.553504615079353\n",
      "epoch:3633, weight:[1.80994163 1.20739228], bias:-1.433402713733065, loss:0.5534931695288833\n",
      "epoch:3634, weight:[1.81022173 1.20746868], bias:-1.4335763072753096, loss:0.5534817255936533\n",
      "epoch:3635, weight:[1.81050182 1.20754506], bias:-1.4337498769383352, loss:0.5534702832730389\n",
      "epoch:3636, weight:[1.81078191 1.2076214 ], bias:-1.4339234227297577, loss:0.5534588425664168\n",
      "epoch:3637, weight:[1.81106199 1.20769771], bias:-1.4340969446571896, loss:0.5534474034731632\n",
      "epoch:3638, weight:[1.81134206 1.207774  ], bias:-1.4342704427282407, loss:0.5534359659926558\n",
      "epoch:3639, weight:[1.81162213 1.20785026], bias:-1.4344439169505172, loss:0.5534245301242717\n",
      "epoch:3640, weight:[1.81190219 1.20792649], bias:-1.4346173673316227, loss:0.5534130958673896\n",
      "epoch:3641, weight:[1.81218225 1.20800269], bias:-1.4347907938791573, loss:0.5534016632213874\n",
      "epoch:3642, weight:[1.8124623  1.20807886], bias:-1.4349641966007178, loss:0.5533902321856441\n",
      "epoch:3643, weight:[1.81274234 1.20815501], bias:-1.4351375755038984, loss:0.5533788027595393\n",
      "epoch:3644, weight:[1.81302237 1.20823112], bias:-1.43531093059629, loss:0.5533673749424525\n",
      "epoch:3645, weight:[1.8133024  1.20830721], bias:-1.4354842618854797, loss:0.5533559487337637\n",
      "epoch:3646, weight:[1.81358243 1.20838327], bias:-1.4356575693790528, loss:0.5533445241328541\n",
      "epoch:3647, weight:[1.81386245 1.2084593 ], bias:-1.43583085308459, loss:0.5533331011391038\n",
      "epoch:3648, weight:[1.81414246 1.20853531], bias:-1.4360041130096701, loss:0.5533216797518951\n",
      "epoch:3649, weight:[1.81442246 1.20861128], bias:-1.4361773491618681, loss:0.5533102599706091\n",
      "epoch:3650, weight:[1.81470246 1.20868723], bias:-1.436350561548756, loss:0.5532988417946287\n",
      "epoch:3651, weight:[1.81498245 1.20876315], bias:-1.4365237501779027, loss:0.5532874252233362\n",
      "epoch:3652, weight:[1.81526244 1.20883904], bias:-1.436696915056874, loss:0.553276010256115\n",
      "epoch:3653, weight:[1.81554242 1.2089149 ], bias:-1.4368700561932326, loss:0.5532645968923482\n",
      "epoch:3654, weight:[1.81582239 1.20899073], bias:-1.4370431735945381, loss:0.5532531851314202\n",
      "epoch:3655, weight:[1.81610236 1.20906654], bias:-1.437216267268347, loss:0.5532417749727151\n",
      "epoch:3656, weight:[1.81638232 1.20914232], bias:-1.4373893372222128, loss:0.5532303664156181\n",
      "epoch:3657, weight:[1.81666228 1.20921807], bias:-1.4375623834636857, loss:0.5532189594595137\n",
      "epoch:3658, weight:[1.81694222 1.20929379], bias:-1.4377354060003127, loss:0.5532075541037883\n",
      "epoch:3659, weight:[1.81722217 1.20936948], bias:-1.437908404839638, loss:0.5531961503478277\n",
      "epoch:3660, weight:[1.8175021  1.20944515], bias:-1.4380813799892025, loss:0.5531847481910179\n",
      "epoch:3661, weight:[1.81778203 1.20952078], bias:-1.438254331456544, loss:0.5531733476327463\n",
      "epoch:3662, weight:[1.81806195 1.20959639], bias:-1.4384272592491971, loss:0.5531619486724\n",
      "epoch:3663, weight:[1.81834187 1.20967197], bias:-1.4386001633746939, loss:0.5531505513093666\n",
      "epoch:3664, weight:[1.81862178 1.20974753], bias:-1.4387730438405626, loss:0.5531391555430349\n",
      "epoch:3665, weight:[1.81890168 1.20982305], bias:-1.4389459006543288, loss:0.5531277613727928\n",
      "epoch:3666, weight:[1.81918158 1.20989855], bias:-1.4391187338235147, loss:0.5531163687980294\n",
      "epoch:3667, weight:[1.81946147 1.20997402], bias:-1.43929154335564, loss:0.5531049778181344\n",
      "epoch:3668, weight:[1.81974136 1.21004946], bias:-1.4394643292582203, loss:0.5530935884324969\n",
      "epoch:3669, weight:[1.82002124 1.21012487], bias:-1.4396370915387693, loss:0.553082200640508\n",
      "epoch:3670, weight:[1.82030111 1.21020026], bias:-1.4398098302047966, loss:0.5530708144415576\n",
      "epoch:3671, weight:[1.82058098 1.21027561], bias:-1.4399825452638093, loss:0.5530594298350374\n",
      "epoch:3672, weight:[1.82086083 1.21035094], bias:-1.4401552367233112, loss:0.5530480468203381\n",
      "epoch:3673, weight:[1.82114069 1.21042624], bias:-1.4403279045908033, loss:0.5530366653968524\n",
      "epoch:3674, weight:[1.82142054 1.21050151], bias:-1.440500548873783, loss:0.5530252855639721\n",
      "epoch:3675, weight:[1.82170038 1.21057676], bias:-1.4406731695797452, loss:0.55301390732109\n",
      "epoch:3676, weight:[1.82198021 1.21065198], bias:-1.4408457667161814, loss:0.5530025306675991\n",
      "epoch:3677, weight:[1.82226004 1.21072717], bias:-1.4410183402905798, loss:0.5529911556028936\n",
      "epoch:3678, weight:[1.82253986 1.21080233], bias:-1.441190890310426, loss:0.5529797821263664\n",
      "epoch:3679, weight:[1.82281968 1.21087746], bias:-1.4413634167832023, loss:0.5529684102374125\n",
      "epoch:3680, weight:[1.82309948 1.21095257], bias:-1.4415359197163882, loss:0.5529570399354266\n",
      "epoch:3681, weight:[1.82337929 1.21102764], bias:-1.4417083991174597, loss:0.5529456712198038\n",
      "epoch:3682, weight:[1.82365908 1.21110269], bias:-1.44188085499389, loss:0.5529343040899396\n",
      "epoch:3683, weight:[1.82393887 1.21117772], bias:-1.442053287353149, loss:0.5529229385452302\n",
      "epoch:3684, weight:[1.82421866 1.21125271], bias:-1.442225696202704, loss:0.552911574585072\n",
      "epoch:3685, weight:[1.82449843 1.21132768], bias:-1.4423980815500188, loss:0.5529002122088615\n",
      "epoch:3686, weight:[1.8247782  1.21140261], bias:-1.4425704434025544, loss:0.5528888514159968\n",
      "epoch:3687, weight:[1.82505797 1.21147752], bias:-1.4427427817677685, loss:0.5528774922058745\n",
      "epoch:3688, weight:[1.82533773 1.21155241], bias:-1.442915096653116, loss:0.5528661345778931\n",
      "epoch:3689, weight:[1.82561748 1.21162726], bias:-1.4430873880660484, loss:0.5528547785314512\n",
      "epoch:3690, weight:[1.82589722 1.21170209], bias:-1.4432596560140147, loss:0.5528434240659473\n",
      "epoch:3691, weight:[1.82617696 1.21177689], bias:-1.4434319005044605, loss:0.5528320711807813\n",
      "epoch:3692, weight:[1.8264567  1.21185166], bias:-1.443604121544828, loss:0.552820719875352\n",
      "epoch:3693, weight:[1.82673642 1.2119264 ], bias:-1.4437763191425572, loss:0.5528093701490605\n",
      "epoch:3694, weight:[1.82701614 1.21200112], bias:-1.4439484933050846, loss:0.5527980220013065\n",
      "epoch:3695, weight:[1.82729585 1.21207581], bias:-1.4441206440398433, loss:0.5527866754314911\n",
      "epoch:3696, weight:[1.82757556 1.21215047], bias:-1.444292771354264, loss:0.5527753304390159\n",
      "epoch:3697, weight:[1.82785526 1.2122251 ], bias:-1.4444648752557738, loss:0.5527639870232822\n",
      "epoch:3698, weight:[1.82813496 1.21229971], bias:-1.4446369557517975, loss:0.5527526451836926\n",
      "epoch:3699, weight:[1.82841464 1.21237429], bias:-1.4448090128497562, loss:0.5527413049196493\n",
      "epoch:3700, weight:[1.82869433 1.21244884], bias:-1.4449810465570678, loss:0.5527299662305555\n",
      "epoch:3701, weight:[1.828974   1.21252336], bias:-1.4451530568811481, loss:0.5527186291158142\n",
      "epoch:3702, weight:[1.82925367 1.21259785], bias:-1.445325043829409, loss:0.5527072935748294\n",
      "epoch:3703, weight:[1.82953333 1.21267232], bias:-1.4454970074092597, loss:0.5526959596070052\n",
      "epoch:3704, weight:[1.82981299 1.21274676], bias:-1.4456689476281064, loss:0.5526846272117462\n",
      "epoch:3705, weight:[1.83009264 1.21282117], bias:-1.445840864493352, loss:0.5526732963884572\n",
      "epoch:3706, weight:[1.83037228 1.21289556], bias:-1.446012758012397, loss:0.5526619671365439\n",
      "epoch:3707, weight:[1.83065192 1.21296991], bias:-1.446184628192638, loss:0.5526506394554115\n",
      "epoch:3708, weight:[1.83093155 1.21304424], bias:-1.4463564750414695, loss:0.5526393133444667\n",
      "epoch:3709, weight:[1.83121117 1.21311854], bias:-1.4465282985662824, loss:0.5526279888031159\n",
      "epoch:3710, weight:[1.83149079 1.21319282], bias:-1.4467000987744647, loss:0.552616665830766\n",
      "epoch:3711, weight:[1.8317704  1.21326706], bias:-1.4468718756734014, loss:0.5526053444268245\n",
      "epoch:3712, weight:[1.83205001 1.21334128], bias:-1.4470436292704743, loss:0.552594024590699\n",
      "epoch:3713, weight:[1.8323296  1.21341547], bias:-1.4472153595730626, loss:0.5525827063217981\n",
      "epoch:3714, weight:[1.8326092  1.21348964], bias:-1.4473870665885422, loss:0.5525713896195297\n",
      "epoch:3715, weight:[1.83288878 1.21356377], bias:-1.447558750324286, loss:0.5525600744833034\n",
      "epoch:3716, weight:[1.83316836 1.21363788], bias:-1.4477304107876638, loss:0.5525487609125281\n",
      "epoch:3717, weight:[1.83344793 1.21371196], bias:-1.447902047986043, loss:0.5525374489066142\n",
      "epoch:3718, weight:[1.8337275  1.21378602], bias:-1.448073661926787, loss:0.5525261384649713\n",
      "epoch:3719, weight:[1.83400706 1.21386005], bias:-1.4482452526172571, loss:0.5525148295870103\n",
      "epoch:3720, weight:[1.83428661 1.21393404], bias:-1.448416820064811, loss:0.552503522272142\n",
      "epoch:3721, weight:[1.83456616 1.21400802], bias:-1.4485883642768038, loss:0.552492216519778\n",
      "epoch:3722, weight:[1.8348457  1.21408196], bias:-1.4487598852605872, loss:0.5524809123293296\n",
      "epoch:3723, weight:[1.83512524 1.21415588], bias:-1.4489313830235102, loss:0.5524696097002098\n",
      "epoch:3724, weight:[1.83540476 1.21422977], bias:-1.449102857572919, loss:0.5524583086318304\n",
      "epoch:3725, weight:[1.83568429 1.21430363], bias:-1.4492743089161562, loss:0.5524470091236047\n",
      "epoch:3726, weight:[1.8359638  1.21437746], bias:-1.449445737060562, loss:0.5524357111749459\n",
      "epoch:3727, weight:[1.83624331 1.21445127], bias:-1.4496171420134731, loss:0.5524244147852682\n",
      "epoch:3728, weight:[1.83652281 1.21452505], bias:-1.4497885237822237, loss:0.5524131199539853\n",
      "epoch:3729, weight:[1.83680231 1.2145988 ], bias:-1.4499598823741446, loss:0.552401826680512\n",
      "epoch:3730, weight:[1.8370818  1.21467253], bias:-1.450131217796564, loss:0.5523905349642632\n",
      "epoch:3731, weight:[1.83736128 1.21474623], bias:-1.4503025300568066, loss:0.552379244804654\n",
      "epoch:3732, weight:[1.83764076 1.2148199 ], bias:-1.4504738191621949, loss:0.5523679562011005\n",
      "epoch:3733, weight:[1.83792023 1.21489354], bias:-1.4506450851200476, loss:0.5523566691530187\n",
      "epoch:3734, weight:[1.83819969 1.21496716], bias:-1.450816327937681, loss:0.5523453836598254\n",
      "epoch:3735, weight:[1.83847915 1.21504074], bias:-1.450987547622408, loss:0.5523340997209368\n",
      "epoch:3736, weight:[1.8387586  1.21511431], bias:-1.4511587441815386, loss:0.5523228173357712\n",
      "epoch:3737, weight:[1.83903804 1.21518784], bias:-1.4513299176223802, loss:0.5523115365037456\n",
      "epoch:3738, weight:[1.83931748 1.21526135], bias:-1.4515010679522367, loss:0.5523002572242784\n",
      "epoch:3739, weight:[1.83959691 1.21533483], bias:-1.4516721951784095, loss:0.552288979496788\n",
      "epoch:3740, weight:[1.83987633 1.21540828], bias:-1.4518432993081969, loss:0.5522777033206933\n",
      "epoch:3741, weight:[1.84015575 1.2154817 ], bias:-1.4520143803488939, loss:0.5522664286954136\n",
      "epoch:3742, weight:[1.84043517 1.2155551 ], bias:-1.452185438307793, loss:0.5522551556203688\n",
      "epoch:3743, weight:[1.84071457 1.21562847], bias:-1.4523564731921834, loss:0.5522438840949785\n",
      "epoch:3744, weight:[1.84099397 1.21570182], bias:-1.4525274850093515, loss:0.5522326141186636\n",
      "epoch:3745, weight:[1.84127336 1.21577513], bias:-1.4526984737665807, loss:0.552221345690845\n",
      "epoch:3746, weight:[1.84155275 1.21584842], bias:-1.4528694394711514, loss:0.5522100788109436\n",
      "epoch:3747, weight:[1.84183213 1.21592169], bias:-1.4530403821303413, loss:0.5521988134783814\n",
      "epoch:3748, weight:[1.8421115  1.21599492], bias:-1.4532113017514248, loss:0.5521875496925798\n",
      "epoch:3749, weight:[1.84239087 1.21606813], bias:-1.4533821983416733, loss:0.5521762874529621\n",
      "epoch:3750, weight:[1.84267023 1.21614131], bias:-1.4535530719083556, loss:0.5521650267589503\n",
      "epoch:3751, weight:[1.84294958 1.21621446], bias:-1.4537239224587373, loss:0.5521537676099683\n",
      "epoch:3752, weight:[1.84322893 1.21628759], bias:-1.4538947500000812, loss:0.5521425100054392\n",
      "epoch:3753, weight:[1.84350827 1.21636069], bias:-1.4540655545396468, loss:0.5521312539447872\n",
      "epoch:3754, weight:[1.8437876  1.21643376], bias:-1.454236336084691, loss:0.5521199994274364\n",
      "epoch:3755, weight:[1.84406693 1.21650681], bias:-1.4544070946424679, loss:0.5521087464528119\n",
      "epoch:3756, weight:[1.84434625 1.21657983], bias:-1.4545778302202281, loss:0.5520974950203386\n",
      "epoch:3757, weight:[1.84462557 1.21665282], bias:-1.45474854282522, loss:0.5520862451294422\n",
      "epoch:3758, weight:[1.84490488 1.21672578], bias:-1.4549192324646882, loss:0.5520749967795486\n",
      "epoch:3759, weight:[1.84518418 1.21679872], bias:-1.4550898991458752, loss:0.5520637499700838\n",
      "epoch:3760, weight:[1.84546347 1.21687163], bias:-1.4552605428760197, loss:0.5520525047004751\n",
      "epoch:3761, weight:[1.84574276 1.21694451], bias:-1.4554311636623583, loss:0.5520412609701488\n",
      "epoch:3762, weight:[1.84602205 1.21701737], bias:-1.455601761512124, loss:0.5520300187785332\n",
      "epoch:3763, weight:[1.84630132 1.2170902 ], bias:-1.4557723364325472, loss:0.5520187781250553\n",
      "epoch:3764, weight:[1.84658059 1.217163  ], bias:-1.4559428884308556, loss:0.5520075390091441\n",
      "epoch:3765, weight:[1.84685985 1.21723577], bias:-1.4561134175142734, loss:0.5519963014302277\n",
      "epoch:3766, weight:[1.84713911 1.21730852], bias:-1.4562839236900222, loss:0.5519850653877354\n",
      "epoch:3767, weight:[1.84741836 1.21738124], bias:-1.456454406965321, loss:0.5519738308810964\n",
      "epoch:3768, weight:[1.8476976  1.21745394], bias:-1.456624867347385, loss:0.5519625979097406\n",
      "epoch:3769, weight:[1.84797684 1.21752661], bias:-1.456795304843427, loss:0.5519513664730981\n",
      "epoch:3770, weight:[1.84825607 1.21759925], bias:-1.4569657194606571, loss:0.5519401365705994\n",
      "epoch:3771, weight:[1.8485353  1.21767186], bias:-1.4571361112062822, loss:0.5519289082016756\n",
      "epoch:3772, weight:[1.84881451 1.21774445], bias:-1.4573064800875062, loss:0.5519176813657577\n",
      "epoch:3773, weight:[1.84909373 1.21781701], bias:-1.4574768261115303, loss:0.5519064560622776\n",
      "epoch:3774, weight:[1.84937293 1.21788954], bias:-1.4576471492855525, loss:0.5518952322906676\n",
      "epoch:3775, weight:[1.84965213 1.21796205], bias:-1.4578174496167684, loss:0.5518840100503597\n",
      "epoch:3776, weight:[1.84993132 1.21803453], bias:-1.45798772711237, loss:0.551872789340787\n",
      "epoch:3777, weight:[1.8502105  1.21810698], bias:-1.458157981779547, loss:0.5518615701613826\n",
      "epoch:3778, weight:[1.85048968 1.21817941], bias:-1.4583282136254856, loss:0.5518503525115802\n",
      "epoch:3779, weight:[1.85076885 1.2182518 ], bias:-1.4584984226573696, loss:0.5518391363908136\n",
      "epoch:3780, weight:[1.85104802 1.21832418], bias:-1.45866860888238, loss:0.5518279217985176\n",
      "epoch:3781, weight:[1.85132718 1.21839652], bias:-1.458838772307694, loss:0.5518167087341266\n",
      "epoch:3782, weight:[1.85160633 1.21846884], bias:-1.459008912940487, loss:0.5518054971970756\n",
      "epoch:3783, weight:[1.85188548 1.21854113], bias:-1.4591790307879309, loss:0.5517942871868005\n",
      "epoch:3784, weight:[1.85216462 1.2186134 ], bias:-1.4593491258571945, loss:0.5517830787027367\n",
      "epoch:3785, weight:[1.85244375 1.21868564], bias:-1.459519198155444, loss:0.5517718717443209\n",
      "epoch:3786, weight:[1.85272288 1.21875785], bias:-1.459689247689843, loss:0.5517606663109895\n",
      "epoch:3787, weight:[1.853002   1.21883003], bias:-1.4598592744675518, loss:0.5517494624021796\n",
      "epoch:3788, weight:[1.85328111 1.21890219], bias:-1.4600292784957278, loss:0.5517382600173287\n",
      "epoch:3789, weight:[1.85356022 1.21897432], bias:-1.4601992597815256, loss:0.5517270591558744\n",
      "epoch:3790, weight:[1.85383932 1.21904643], bias:-1.460369218332097, loss:0.5517158598172549\n",
      "epoch:3791, weight:[1.85411841 1.21911851], bias:-1.460539154154591, loss:0.5517046620009087\n",
      "epoch:3792, weight:[1.8543975  1.21919056], bias:-1.460709067256153, loss:0.5516934657062748\n",
      "epoch:3793, weight:[1.85467658 1.21926258], bias:-1.4608789576439263, loss:0.5516822709327925\n",
      "epoch:3794, weight:[1.85495565 1.21933458], bias:-1.461048825325051, loss:0.5516710776799012\n",
      "epoch:3795, weight:[1.85523472 1.21940655], bias:-1.4612186703066647, loss:0.5516598859470414\n",
      "epoch:3796, weight:[1.85551378 1.2194785 ], bias:-1.4613884925959015, loss:0.551648695733653\n",
      "epoch:3797, weight:[1.85579284 1.21955041], bias:-1.4615582921998929, loss:0.5516375070391774\n",
      "epoch:3798, weight:[1.85607188 1.21962231], bias:-1.4617280691257675, loss:0.551626319863055\n",
      "epoch:3799, weight:[1.85635092 1.21969417], bias:-1.461897823380651, loss:0.551615134204728\n",
      "epoch:3800, weight:[1.85662996 1.21976601], bias:-1.4620675549716664, loss:0.5516039500636379\n",
      "epoch:3801, weight:[1.85690899 1.21983782], bias:-1.4622372639059336, loss:0.5515927674392271\n",
      "epoch:3802, weight:[1.85718801 1.21990961], bias:-1.4624069501905697, loss:0.5515815863309386\n",
      "epoch:3803, weight:[1.85746702 1.21998137], bias:-1.462576613832689, loss:0.5515704067382151\n",
      "epoch:3804, weight:[1.85774603 1.2200531 ], bias:-1.4627462548394028, loss:0.5515592286605\n",
      "epoch:3805, weight:[1.85802504 1.2201248 ], bias:-1.4629158732178196, loss:0.5515480520972371\n",
      "epoch:3806, weight:[1.85830403 1.22019648], bias:-1.463085468975045, loss:0.5515368770478707\n",
      "epoch:3807, weight:[1.85858302 1.22026814], bias:-1.4632550421181818, loss:0.5515257035118453\n",
      "epoch:3808, weight:[1.858862   1.22033976], bias:-1.46342459265433, loss:0.5515145314886054\n",
      "epoch:3809, weight:[1.85914098 1.22041136], bias:-1.4635941205905862, loss:0.551503360977597\n",
      "epoch:3810, weight:[1.85941995 1.22048294], bias:-1.4637636259340452, loss:0.5514921919782653\n",
      "epoch:3811, weight:[1.85969891 1.22055448], bias:-1.4639331086917977, loss:0.5514810244900562\n",
      "epoch:3812, weight:[1.85997787 1.220626  ], bias:-1.4641025688709324, loss:0.5514698585124164\n",
      "epoch:3813, weight:[1.86025682 1.2206975 ], bias:-1.4642720064785348, loss:0.5514586940447926\n",
      "epoch:3814, weight:[1.86053576 1.22076896], bias:-1.4644414215216879, loss:0.5514475310866318\n",
      "epoch:3815, weight:[1.8608147  1.22084041], bias:-1.4646108140074712, loss:0.5514363696373816\n",
      "epoch:3816, weight:[1.86109363 1.22091182], bias:-1.4647801839429617, loss:0.5514252096964899\n",
      "epoch:3817, weight:[1.86137255 1.22098321], bias:-1.4649495313352339, loss:0.5514140512634047\n",
      "epoch:3818, weight:[1.86165147 1.22105457], bias:-1.4651188561913588, loss:0.551402894337575\n",
      "epoch:3819, weight:[1.86193038 1.22112591], bias:-1.465288158518405, loss:0.5513917389184494\n",
      "epoch:3820, weight:[1.86220928 1.22119721], bias:-1.465457438323438, loss:0.5513805850054777\n",
      "epoch:3821, weight:[1.86248818 1.2212685 ], bias:-1.4656266956135207, loss:0.5513694325981091\n",
      "epoch:3822, weight:[1.86276707 1.22133975], bias:-1.4657959303957129, loss:0.551358281695794\n",
      "epoch:3823, weight:[1.86304595 1.22141098], bias:-1.4659651426770717, loss:0.5513471322979828\n",
      "epoch:3824, weight:[1.86332483 1.22148219], bias:-1.4661343324646514, loss:0.5513359844041262\n",
      "epoch:3825, weight:[1.8636037  1.22155336], bias:-1.4663034997655033, loss:0.5513248380136758\n",
      "epoch:3826, weight:[1.86388256 1.22162452], bias:-1.4664726445866758, loss:0.5513136931260826\n",
      "epoch:3827, weight:[1.86416142 1.22169564], bias:-1.4666417669352148, loss:0.5513025497407988\n",
      "epoch:3828, weight:[1.86444027 1.22176674], bias:-1.466810866818163, loss:0.5512914078572767\n",
      "epoch:3829, weight:[1.86471911 1.22183781], bias:-1.4669799442425606, loss:0.5512802674749692\n",
      "epoch:3830, weight:[1.86499795 1.22190886], bias:-1.4671489992154447, loss:0.5512691285933289\n",
      "epoch:3831, weight:[1.86527678 1.22197988], bias:-1.46731803174385, loss:0.5512579912118093\n",
      "epoch:3832, weight:[1.86555561 1.22205087], bias:-1.4674870418348074, loss:0.5512468553298642\n",
      "epoch:3833, weight:[1.86583443 1.22212184], bias:-1.467656029495346, loss:0.5512357209469476\n",
      "epoch:3834, weight:[1.86611324 1.22219278], bias:-1.4678249947324917, loss:0.5512245880625144\n",
      "epoch:3835, weight:[1.86639204 1.22226369], bias:-1.4679939375532676, loss:0.551213456676019\n",
      "epoch:3836, weight:[1.86667084 1.22233458], bias:-1.4681628579646935, loss:0.5512023267869167\n",
      "epoch:3837, weight:[1.86694963 1.22240544], bias:-1.4683317559737872, loss:0.5511911983946634\n",
      "epoch:3838, weight:[1.86722842 1.22247628], bias:-1.468500631587563, loss:0.5511800714987148\n",
      "epoch:3839, weight:[1.86750719 1.22254709], bias:-1.468669484813033, loss:0.5511689460985271\n",
      "epoch:3840, weight:[1.86778597 1.22261787], bias:-1.4688383156572058, loss:0.551157822193557\n",
      "epoch:3841, weight:[1.86806473 1.22268863], bias:-1.4690071241270877, loss:0.5511466997832616\n",
      "epoch:3842, weight:[1.86834349 1.22275936], bias:-1.469175910229682, loss:0.5511355788670985\n",
      "epoch:3843, weight:[1.86862224 1.22283007], bias:-1.469344673971989, loss:0.551124459444525\n",
      "epoch:3844, weight:[1.86890099 1.22290075], bias:-1.4695134153610065, loss:0.5511133415149998\n",
      "epoch:3845, weight:[1.86917973 1.2229714 ], bias:-1.4696821344037294, loss:0.5511022250779809\n",
      "epoch:3846, weight:[1.86945846 1.22304203], bias:-1.4698508311071496, loss:0.5510911101329273\n",
      "epoch:3847, weight:[1.86973718 1.22311263], bias:-1.4700195054782565, loss:0.5510799966792981\n",
      "epoch:3848, weight:[1.8700159 1.2231832], bias:-1.4701881575240363, loss:0.5510688847165531\n",
      "epoch:3849, weight:[1.87029461 1.22325375], bias:-1.470356787251473, loss:0.5510577742441521\n",
      "epoch:3850, weight:[1.87057332 1.22332427], bias:-1.4705253946675467, loss:0.5510466652615554\n",
      "epoch:3851, weight:[1.87085202 1.22339477], bias:-1.4706939797792362, loss:0.5510355577682237\n",
      "epoch:3852, weight:[1.87113071 1.22346524], bias:-1.4708625425935162, loss:0.551024451763618\n",
      "epoch:3853, weight:[1.8714094  1.22353569], bias:-1.4710310831173594, loss:0.5510133472471995\n",
      "epoch:3854, weight:[1.87168807 1.2236061 ], bias:-1.471199601357735, loss:0.55100224421843\n",
      "epoch:3855, weight:[1.87196675 1.2236765 ], bias:-1.4713680973216103, loss:0.5509911426767717\n",
      "epoch:3856, weight:[1.87224541 1.22374686], bias:-1.4715365710159491, loss:0.5509800426216869\n",
      "epoch:3857, weight:[1.87252407 1.2238172 ], bias:-1.4717050224477126, loss:0.5509689440526385\n",
      "epoch:3858, weight:[1.87280272 1.22388752], bias:-1.4718734516238592, loss:0.5509578469690898\n",
      "epoch:3859, weight:[1.87308137 1.22395781], bias:-1.4720418585513444, loss:0.5509467513705039\n",
      "epoch:3860, weight:[1.87336001 1.22402807], bias:-1.4722102432371211, loss:0.550935657256345\n",
      "epoch:3861, weight:[1.87363864 1.22409831], bias:-1.4723786056881394, loss:0.5509245646260772\n",
      "epoch:3862, weight:[1.87391727 1.22416852], bias:-1.4725469459113465, loss:0.5509134734791653\n",
      "epoch:3863, weight:[1.87419589 1.2242387 ], bias:-1.472715263913687, loss:0.5509023838150738\n",
      "epoch:3864, weight:[1.8744745  1.22430886], bias:-1.4728835597021024, loss:0.5508912956332686\n",
      "epoch:3865, weight:[1.87475311 1.22437899], bias:-1.4730518332835316, loss:0.5508802089332149\n",
      "epoch:3866, weight:[1.8750317 1.2244491], bias:-1.4732200846649108, loss:0.5508691237143789\n",
      "epoch:3867, weight:[1.8753103  1.22451918], bias:-1.4733883138531734, loss:0.550858039976227\n",
      "epoch:3868, weight:[1.87558888 1.22458924], bias:-1.4735565208552497, loss:0.5508469577182258\n",
      "epoch:3869, weight:[1.87586746 1.22465927], bias:-1.4737247056780676, loss:0.5508358769398425\n",
      "epoch:3870, weight:[1.87614603 1.22472927], bias:-1.4738928683285522, loss:0.5508247976405444\n",
      "epoch:3871, weight:[1.8764246  1.22479925], bias:-1.4740610088136255, loss:0.5508137198197993\n",
      "epoch:3872, weight:[1.87670316 1.2248692 ], bias:-1.474229127140207, loss:0.5508026434770756\n",
      "epoch:3873, weight:[1.87698171 1.22493913], bias:-1.4743972233152134, loss:0.5507915686118415\n",
      "epoch:3874, weight:[1.87726026 1.22500903], bias:-1.4745652973455587, loss:0.5507804952235661\n",
      "epoch:3875, weight:[1.8775388 1.2250789], bias:-1.4747333492381538, loss:0.5507694233117184\n",
      "epoch:3876, weight:[1.87781733 1.22514875], bias:-1.4749013789999073, loss:0.5507583528757682\n",
      "epoch:3877, weight:[1.87809586 1.22521857], bias:-1.4750693866377245, loss:0.5507472839151851\n",
      "epoch:3878, weight:[1.87837438 1.22528837], bias:-1.4752373721585084, loss:0.5507362164294395\n",
      "epoch:3879, weight:[1.87865289 1.22535814], bias:-1.475405335569159, loss:0.5507251504180021\n",
      "epoch:3880, weight:[1.87893139 1.22542789], bias:-1.4755732768765737, loss:0.5507140858803437\n",
      "epoch:3881, weight:[1.87920989 1.22549761], bias:-1.4757411960876468, loss:0.5507030228159359\n",
      "epoch:3882, weight:[1.87948839 1.2255673 ], bias:-1.4759090932092702, loss:0.55069196122425\n",
      "epoch:3883, weight:[1.87976687 1.22563697], bias:-1.476076968248333, loss:0.5506809011047584\n",
      "epoch:3884, weight:[1.88004535 1.22570661], bias:-1.4762448212117212, loss:0.5506698424569332\n",
      "epoch:3885, weight:[1.88032382 1.22577623], bias:-1.4764126521063183, loss:0.5506587852802474\n",
      "epoch:3886, weight:[1.88060229 1.22584582], bias:-1.4765804609390054, loss:0.5506477295741736\n",
      "epoch:3887, weight:[1.88088075 1.22591539], bias:-1.4767482477166602, loss:0.5506366753381857\n",
      "epoch:3888, weight:[1.8811592  1.22598493], bias:-1.476916012446158, loss:0.5506256225717574\n",
      "epoch:3889, weight:[1.88143765 1.22605444], bias:-1.4770837551343712, loss:0.5506145712743625\n",
      "epoch:3890, weight:[1.88171609 1.22612393], bias:-1.4772514757881694, loss:0.5506035214454758\n",
      "epoch:3891, weight:[1.88199452 1.22619339], bias:-1.4774191744144198, loss:0.550592473084572\n",
      "epoch:3892, weight:[1.88227295 1.22626283], bias:-1.4775868510199865, loss:0.5505814261911266\n",
      "epoch:3893, weight:[1.88255136 1.22633224], bias:-1.4777545056117312, loss:0.5505703807646145\n",
      "epoch:3894, weight:[1.88282978 1.22640163], bias:-1.4779221381965122, loss:0.5505593368045119\n",
      "epoch:3895, weight:[1.88310818 1.22647099], bias:-1.4780897487811857, loss:0.5505482943102952\n",
      "epoch:3896, weight:[1.88338658 1.22654033], bias:-1.4782573373726051, loss:0.5505372532814407\n",
      "epoch:3897, weight:[1.88366497 1.22660963], bias:-1.4784249039776207, loss:0.5505262137174253\n",
      "epoch:3898, weight:[1.88394336 1.22667892], bias:-1.4785924486030804, loss:0.5505151756177263\n",
      "epoch:3899, weight:[1.88422174 1.22674818], bias:-1.4787599712558293, loss:0.5505041389818216\n",
      "epoch:3900, weight:[1.88450011 1.22681741], bias:-1.4789274719427095, loss:0.5504931038091887\n",
      "epoch:3901, weight:[1.88477848 1.22688662], bias:-1.4790949506705606, loss:0.5504820700993064\n",
      "epoch:3902, weight:[1.88505684 1.2269558 ], bias:-1.4792624074462195, loss:0.5504710378516529\n",
      "epoch:3903, weight:[1.88533519 1.22702495], bias:-1.4794298422765204, loss:0.5504600070657074\n",
      "epoch:3904, weight:[1.88561353 1.22709409], bias:-1.4795972551682945, loss:0.550448977740949\n",
      "epoch:3905, weight:[1.88589187 1.22716319], bias:-1.4797646461283704, loss:0.5504379498768578\n",
      "epoch:3906, weight:[1.8861702  1.22723227], bias:-1.4799320151635742, loss:0.5504269234729136\n",
      "epoch:3907, weight:[1.88644853 1.22730132], bias:-1.4800993622807288, loss:0.5504158985285965\n",
      "epoch:3908, weight:[1.88672685 1.22737035], bias:-1.4802666874866548, loss:0.5504048750433879\n",
      "epoch:3909, weight:[1.88700516 1.22743936], bias:-1.4804339907881698, loss:0.5503938530167682\n",
      "epoch:3910, weight:[1.88728346 1.22750833], bias:-1.480601272192089, loss:0.550382832448219\n",
      "epoch:3911, weight:[1.88756176 1.22757729], bias:-1.4807685317052244, loss:0.5503718133372225\n",
      "epoch:3912, weight:[1.88784005 1.22764621], bias:-1.4809357693343859, loss:0.5503607956832599\n",
      "epoch:3913, weight:[1.88811834 1.22771512], bias:-1.4811029850863802, loss:0.5503497794858144\n",
      "epoch:3914, weight:[1.88839662 1.22778399], bias:-1.4812701789680114, loss:0.5503387647443684\n",
      "epoch:3915, weight:[1.88867489 1.22785284], bias:-1.4814373509860808, loss:0.5503277514584053\n",
      "epoch:3916, weight:[1.88895315 1.22792167], bias:-1.4816045011473873, loss:0.5503167396274082\n",
      "epoch:3917, weight:[1.88923141 1.22799047], bias:-1.4817716294587266, loss:0.5503057292508614\n",
      "epoch:3918, weight:[1.88950966 1.22805924], bias:-1.4819387359268923, loss:0.5502947203282486\n",
      "epoch:3919, weight:[1.88978791 1.22812799], bias:-1.4821058205586746, loss:0.5502837128590545\n",
      "epoch:3920, weight:[1.89006615 1.22819672], bias:-1.4822728833608616, loss:0.5502727068427637\n",
      "epoch:3921, weight:[1.89034438 1.22826541], bias:-1.4824399243402384, loss:0.5502617022788617\n",
      "epoch:3922, weight:[1.8906226  1.22833409], bias:-1.4826069435035873, loss:0.5502506991668338\n",
      "epoch:3923, weight:[1.89090082 1.22840274], bias:-1.482773940857688, loss:0.550239697506166\n",
      "epoch:3924, weight:[1.89117903 1.22847136], bias:-1.482940916409318, loss:0.5502286972963443\n",
      "epoch:3925, weight:[1.89145723 1.22853996], bias:-1.483107870165251, loss:0.5502176985368553\n",
      "epoch:3926, weight:[1.89173543 1.22860853], bias:-1.4832748021322586, loss:0.550206701227186\n",
      "epoch:3927, weight:[1.89201362 1.22867707], bias:-1.4834417123171102, loss:0.5501957053668235\n",
      "epoch:3928, weight:[1.89229181 1.2287456 ], bias:-1.4836086007265716, loss:0.5501847109552553\n",
      "epoch:3929, weight:[1.89256998 1.22881409], bias:-1.4837754673674066, loss:0.5501737179919696\n",
      "epoch:3930, weight:[1.89284815 1.22888256], bias:-1.4839423122463757, loss:0.5501627264764541\n",
      "epoch:3931, weight:[1.89312632 1.22895101], bias:-1.4841091353702374, loss:0.5501517364081977\n",
      "epoch:3932, weight:[1.89340447 1.22901943], bias:-1.4842759367457468, loss:0.5501407477866894\n",
      "epoch:3933, weight:[1.89368262 1.22908782], bias:-1.4844427163796567, loss:0.5501297606114183\n",
      "epoch:3934, weight:[1.89396077 1.2291562 ], bias:-1.4846094742787173, loss:0.5501187748818738\n",
      "epoch:3935, weight:[1.89423891 1.22922454], bias:-1.4847762104496758, loss:0.5501077905975462\n",
      "epoch:3936, weight:[1.89451703 1.22929286], bias:-1.484942924899277, loss:0.5500968077579255\n",
      "epoch:3937, weight:[1.89479516 1.22936115], bias:-1.4851096176342626, loss:0.5500858263625021\n",
      "epoch:3938, weight:[1.89507327 1.22942942], bias:-1.4852762886613722, loss:0.5500748464107676\n",
      "epoch:3939, weight:[1.89535138 1.22949767], bias:-1.4854429379873422, loss:0.5500638679022126\n",
      "epoch:3940, weight:[1.89562949 1.22956589], bias:-1.4856095656189066, loss:0.5500528908363289\n",
      "epoch:3941, weight:[1.89590758 1.22963408], bias:-1.4857761715627964, loss:0.5500419152126086\n",
      "epoch:3942, weight:[1.89618567 1.22970225], bias:-1.4859427558257405, loss:0.5500309410305437\n",
      "epoch:3943, weight:[1.89646376 1.22977039], bias:-1.4861093184144647, loss:0.5500199682896272\n",
      "epoch:3944, weight:[1.89674183 1.22983851], bias:-1.4862758593356922, loss:0.5500089969893516\n",
      "epoch:3945, weight:[1.8970199  1.22990661], bias:-1.4864423785961434, loss:0.5499980271292103\n",
      "epoch:3946, weight:[1.89729796 1.22997467], bias:-1.4866088762025362, loss:0.5499870587086972\n",
      "epoch:3947, weight:[1.89757602 1.23004272], bias:-1.4867753521615859, loss:0.5499760917273059\n",
      "epoch:3948, weight:[1.89785407 1.23011074], bias:-1.4869418064800048, loss:0.5499651261845308\n",
      "epoch:3949, weight:[1.89813211 1.23017873], bias:-1.4871082391645027, loss:0.5499541620798666\n",
      "epoch:3950, weight:[1.89841014 1.2302467 ], bias:-1.487274650221787, loss:0.549943199412808\n",
      "epoch:3951, weight:[1.89868817 1.23031464], bias:-1.487441039658562, loss:0.5499322381828505\n",
      "epoch:3952, weight:[1.89896619 1.23038256], bias:-1.4876074074815295, loss:0.5499212783894898\n",
      "epoch:3953, weight:[1.89924421 1.23045045], bias:-1.487773753697389, loss:0.5499103200322216\n",
      "epoch:3954, weight:[1.89952222 1.23051832], bias:-1.4879400783128365, loss:0.5498993631105423\n",
      "epoch:3955, weight:[1.89980022 1.23058616], bias:-1.488106381334566, loss:0.5498884076239483\n",
      "epoch:3956, weight:[1.90007821 1.23065398], bias:-1.4882726627692688, loss:0.549877453571937\n",
      "epoch:3957, weight:[1.9003562  1.23072177], bias:-1.4884389226236332, loss:0.5498665009540052\n",
      "epoch:3958, weight:[1.90063418 1.23078954], bias:-1.4886051609043451, loss:0.5498555497696507\n",
      "epoch:3959, weight:[1.90091216 1.23085729], bias:-1.4887713776180878, loss:0.5498446000183717\n",
      "epoch:3960, weight:[1.90119012 1.230925  ], bias:-1.4889375727715417, loss:0.5498336516996658\n",
      "epoch:3961, weight:[1.90146808 1.2309927 ], bias:-1.4891037463713848, loss:0.5498227048130324\n",
      "epoch:3962, weight:[1.90174604 1.23106037], bias:-1.489269898424292, loss:0.5498117593579698\n",
      "epoch:3963, weight:[1.90202398 1.23112801], bias:-1.4894360289369362, loss:0.5498008153339774\n",
      "epoch:3964, weight:[1.90230192 1.23119563], bias:-1.4896021379159872, loss:0.5497898727405551\n",
      "epoch:3965, weight:[1.90257986 1.23126322], bias:-1.4897682253681122, loss:0.5497789315772024\n",
      "epoch:3966, weight:[1.90285778 1.23133079], bias:-1.4899342912999756, loss:0.5497679918434198\n",
      "epoch:3967, weight:[1.9031357  1.23139833], bias:-1.4901003357182396, loss:0.5497570535387077\n",
      "epoch:3968, weight:[1.90341362 1.23146585], bias:-1.4902663586295635, loss:0.5497461166625672\n",
      "epoch:3969, weight:[1.90369152 1.23153335], bias:-1.490432360040604, loss:0.5497351812144994\n",
      "epoch:3970, weight:[1.90396942 1.23160082], bias:-1.490598339958015, loss:0.5497242471940059\n",
      "epoch:3971, weight:[1.90424732 1.23166826], bias:-1.490764298388448, loss:0.5497133146005887\n",
      "epoch:3972, weight:[1.9045252  1.23173568], bias:-1.4909302353385514, loss:0.5497023834337498\n",
      "epoch:3973, weight:[1.90480308 1.23180308], bias:-1.4910961508149716, loss:0.5496914536929917\n",
      "epoch:3974, weight:[1.90508095 1.23187045], bias:-1.491262044824352, loss:0.5496805253778176\n",
      "epoch:3975, weight:[1.90535882 1.23193779], bias:-1.4914279173733336, loss:0.5496695984877304\n",
      "epoch:3976, weight:[1.90563668 1.23200511], bias:-1.4915937684685543, loss:0.5496586730222337\n",
      "epoch:3977, weight:[1.90591453 1.23207241], bias:-1.4917595981166496, loss:0.5496477489808315\n",
      "epoch:3978, weight:[1.90619237 1.23213968], bias:-1.4919254063242524, loss:0.5496368263630278\n",
      "epoch:3979, weight:[1.90647021 1.23220693], bias:-1.4920911930979932, loss:0.5496259051683271\n",
      "epoch:3980, weight:[1.90674804 1.23227415], bias:-1.4922569584444996, loss:0.5496149853962343\n",
      "epoch:3981, weight:[1.90702587 1.23234134], bias:-1.4924227023703964, loss:0.5496040670462548\n",
      "epoch:3982, weight:[1.90730368 1.23240852], bias:-1.492588424882306, loss:0.5495931501178934\n",
      "epoch:3983, weight:[1.90758149 1.23247566], bias:-1.4927541259868482, loss:0.5495822346106567\n",
      "epoch:3984, weight:[1.9078593  1.23254279], bias:-1.49291980569064, loss:0.5495713205240501\n",
      "epoch:3985, weight:[1.9081371  1.23260988], bias:-1.4930854640002964, loss:0.5495604078575805\n",
      "epoch:3986, weight:[1.90841489 1.23267696], bias:-1.4932511009224287, loss:0.5495494966107546\n",
      "epoch:3987, weight:[1.90869267 1.232744  ], bias:-1.4934167164636465, loss:0.5495385867830795\n",
      "epoch:3988, weight:[1.90897045 1.23281103], bias:-1.4935823106305561, loss:0.5495276783740629\n",
      "epoch:3989, weight:[1.90924822 1.23287803], bias:-1.4937478834297617, loss:0.5495167713832119\n",
      "epoch:3990, weight:[1.90952598 1.232945  ], bias:-1.4939134348678647, loss:0.5495058658100349\n",
      "epoch:3991, weight:[1.90980373 1.23301195], bias:-1.4940789649514639, loss:0.5494949616540405\n",
      "epoch:3992, weight:[1.91008148 1.23307888], bias:-1.4942444736871552, loss:0.5494840589147372\n",
      "epoch:3993, weight:[1.91035923 1.23314578], bias:-1.4944099610815325, loss:0.549473157591634\n",
      "epoch:3994, weight:[1.91063696 1.23321265], bias:-1.4945754271411864, loss:0.5494622576842404\n",
      "epoch:3995, weight:[1.91091469 1.2332795 ], bias:-1.4947408718727053, loss:0.5494513591920659\n",
      "epoch:3996, weight:[1.91119241 1.23334633], bias:-1.494906295282675, loss:0.5494404621146206\n",
      "epoch:3997, weight:[1.91147013 1.23341313], bias:-1.4950716973776785, loss:0.549429566451415\n",
      "epoch:3998, weight:[1.91174784 1.23347991], bias:-1.4952370781642963, loss:0.5494186722019596\n",
      "epoch:3999, weight:[1.91202554 1.23354666], bias:-1.4954024376491062, loss:0.5494077793657651\n",
      "epoch:4000, weight:[1.91230323 1.23361339], bias:-1.4955677758386834, loss:0.5493968879423434\n",
      "epoch:4001, weight:[1.91258092 1.2336801 ], bias:-1.4957330927396006, loss:0.5493859979312057\n",
      "epoch:4002, weight:[1.9128586  1.23374678], bias:-1.495898388358428, loss:0.5493751093318638\n",
      "epoch:4003, weight:[1.91313627 1.23381343], bias:-1.496063662701733, loss:0.5493642221438303\n",
      "epoch:4004, weight:[1.91341394 1.23388006], bias:-1.4962289157760804, loss:0.5493533363666178\n",
      "epoch:4005, weight:[1.9136916  1.23394667], bias:-1.4963941475880325, loss:0.5493424519997385\n",
      "epoch:4006, weight:[1.91396925 1.23401325], bias:-1.4965593581441488, loss:0.5493315690427065\n",
      "epoch:4007, weight:[1.9142469  1.23407981], bias:-1.4967245474509863, loss:0.5493206874950348\n",
      "epoch:4008, weight:[1.91452454 1.23414634], bias:-1.4968897155150995, loss:0.5493098073562375\n",
      "epoch:4009, weight:[1.91480217 1.23421285], bias:-1.4970548623430404, loss:0.5492989286258285\n",
      "epoch:4010, weight:[1.9150798  1.23427933], bias:-1.4972199879413581, loss:0.5492880513033225\n",
      "epoch:4011, weight:[1.91535742 1.23434579], bias:-1.4973850923165992, loss:0.5492771753882343\n",
      "epoch:4012, weight:[1.91563503 1.23441222], bias:-1.497550175475308, loss:0.5492663008800788\n",
      "epoch:4013, weight:[1.91591264 1.23447863], bias:-1.497715237424026, loss:0.5492554277783716\n",
      "epoch:4014, weight:[1.91619023 1.23454502], bias:-1.4978802781692917, loss:0.5492445560826287\n",
      "epoch:4015, weight:[1.91646783 1.23461138], bias:-1.4980452977176417, loss:0.5492336857923656\n",
      "epoch:4016, weight:[1.91674541 1.23467772], bias:-1.4982102960756096, loss:0.549222816907099\n",
      "epoch:4017, weight:[1.91702299 1.23474403], bias:-1.4983752732497266, loss:0.5492119494263457\n",
      "epoch:4018, weight:[1.91730056 1.23481032], bias:-1.4985402292465213, loss:0.5492010833496226\n",
      "epoch:4019, weight:[1.91757812 1.23487658], bias:-1.4987051640725195, loss:0.5491902186764471\n",
      "epoch:4020, weight:[1.91785568 1.23494282], bias:-1.4988700777342447, loss:0.5491793554063367\n",
      "epoch:4021, weight:[1.91813323 1.23500904], bias:-1.4990349702382175, loss:0.5491684935388096\n",
      "epoch:4022, weight:[1.91841077 1.23507523], bias:-1.4991998415909564, loss:0.5491576330733839\n",
      "epoch:4023, weight:[1.91868831 1.23514139], bias:-1.499364691798977, loss:0.5491467740095781\n",
      "epoch:4024, weight:[1.91896584 1.23520754], bias:-1.499529520868792, loss:0.5491359163469114\n",
      "epoch:4025, weight:[1.91924336 1.23527365], bias:-1.4996943288069122, loss:0.5491250600849029\n",
      "epoch:4026, weight:[1.91952088 1.23533975], bias:-1.4998591156198455, loss:0.5491142052230721\n",
      "epoch:4027, weight:[1.91979839 1.23540582], bias:-1.5000238813140971, loss:0.5491033517609387\n",
      "epoch:4028, weight:[1.92007589 1.23547186], bias:-1.5001886258961699, loss:0.5490924996980233\n",
      "epoch:4029, weight:[1.92035339 1.23553788], bias:-1.500353349372564, loss:0.549081649033846\n",
      "epoch:4030, weight:[1.92063087 1.23560388], bias:-1.5005180517497771, loss:0.5490707997679279\n",
      "epoch:4031, weight:[1.92090836 1.23566985], bias:-1.5006827330343042, loss:0.5490599518997898\n",
      "epoch:4032, weight:[1.92118583 1.2357358 ], bias:-1.5008473932326376, loss:0.5490491054289532\n",
      "epoch:4033, weight:[1.9214633  1.23580172], bias:-1.5010120323512675, loss:0.54903826035494\n",
      "epoch:4034, weight:[1.92174076 1.23586762], bias:-1.501176650396681, loss:0.5490274166772721\n",
      "epoch:4035, weight:[1.92201821 1.2359335 ], bias:-1.5013412473753631, loss:0.5490165743954719\n",
      "epoch:4036, weight:[1.92229566 1.23599935], bias:-1.5015058232937961, loss:0.5490057335090619\n",
      "epoch:4037, weight:[1.9225731  1.23606517], bias:-1.5016703781584595, loss:0.5489948940175655\n",
      "epoch:4038, weight:[1.92285053 1.23613098], bias:-1.5018349119758303, loss:0.5489840559205056\n",
      "epoch:4039, weight:[1.92312796 1.23619676], bias:-1.5019994247523831, loss:0.5489732192174059\n",
      "epoch:4040, weight:[1.92340538 1.23626251], bias:-1.5021639164945901, loss:0.5489623839077905\n",
      "epoch:4041, weight:[1.92368279 1.23632824], bias:-1.5023283872089206, loss:0.5489515499911833\n",
      "epoch:4042, weight:[1.9239602  1.23639395], bias:-1.5024928369018413, loss:0.5489407174671092\n",
      "epoch:4043, weight:[1.92423759 1.23645963], bias:-1.5026572655798167, loss:0.5489298863350928\n",
      "epoch:4044, weight:[1.92451499 1.23652529], bias:-1.5028216732493085, loss:0.5489190565946592\n",
      "epoch:4045, weight:[1.92479237 1.23659092], bias:-1.502986059916776, loss:0.5489082282453341\n",
      "epoch:4046, weight:[1.92506975 1.23665653], bias:-1.5031504255886756, loss:0.5488974012866431\n",
      "epoch:4047, weight:[1.92534712 1.23672211], bias:-1.5033147702714618, loss:0.5488865757181123\n",
      "epoch:4048, weight:[1.92562448 1.23678767], bias:-1.5034790939715859, loss:0.5488757515392683\n",
      "epoch:4049, weight:[1.92590184 1.23685321], bias:-1.503643396695497, loss:0.5488649287496374\n",
      "epoch:4050, weight:[1.92617919 1.23691873], bias:-1.5038076784496415, loss:0.5488541073487472\n",
      "epoch:4051, weight:[1.92645653 1.23698421], bias:-1.5039719392404636, loss:0.5488432873361243\n",
      "epoch:4052, weight:[1.92673387 1.23704968], bias:-1.5041361790744043, loss:0.5488324687112969\n",
      "epoch:4053, weight:[1.9270112  1.23711512], bias:-1.5043003979579028, loss:0.5488216514737928\n",
      "epoch:4054, weight:[1.92728852 1.23718054], bias:-1.5044645958973952, loss:0.5488108356231401\n",
      "epoch:4055, weight:[1.92756584 1.23724593], bias:-1.5046287728993153, loss:0.5488000211588674\n",
      "epoch:4056, weight:[1.92784315 1.2373113 ], bias:-1.504792928970094, loss:0.5487892080805035\n",
      "epoch:4057, weight:[1.92812045 1.23737664], bias:-1.5049570641161605, loss:0.5487783963875776\n",
      "epoch:4058, weight:[1.92839774 1.23744196], bias:-1.5051211783439407, loss:0.5487675860796194\n",
      "epoch:4059, weight:[1.92867503 1.23750726], bias:-1.5052852716598581, loss:0.5487567771561582\n",
      "epoch:4060, weight:[1.92895231 1.23757253], bias:-1.505449344070334, loss:0.5487459696167246\n",
      "epoch:4061, weight:[1.92922959 1.23763778], bias:-1.505613395581787, loss:0.5487351634608489\n",
      "epoch:4062, weight:[1.92950685 1.23770301], bias:-1.5057774262006327, loss:0.5487243586880614\n",
      "epoch:4063, weight:[1.92978411 1.23776821], bias:-1.505941435933285, loss:0.5487135552978936\n",
      "epoch:4064, weight:[1.93006137 1.23783339], bias:-1.5061054247861547, loss:0.5487027532898763\n",
      "epoch:4065, weight:[1.93033861 1.23789854], bias:-1.5062693927656503, loss:0.5486919526635416\n",
      "epoch:4066, weight:[1.93061585 1.23796367], bias:-1.5064333398781775, loss:0.5486811534184209\n",
      "epoch:4067, weight:[1.93089308 1.23802877], bias:-1.50659726613014, loss:0.548670355554047\n",
      "epoch:4068, weight:[1.93117031 1.23809386], bias:-1.506761171527938, loss:0.548659559069952\n",
      "epoch:4069, weight:[1.93144753 1.23815891], bias:-1.5069250560779706, loss:0.5486487639656686\n",
      "epoch:4070, weight:[1.93172474 1.23822395], bias:-1.507088919786633, loss:0.5486379702407305\n",
      "epoch:4071, weight:[1.93200194 1.23828896], bias:-1.507252762660319, loss:0.5486271778946706\n",
      "epoch:4072, weight:[1.93227914 1.23835394], bias:-1.507416584705419, loss:0.5486163869270231\n",
      "epoch:4073, weight:[1.93255633 1.2384189 ], bias:-1.5075803859283214, loss:0.5486055973373216\n",
      "epoch:4074, weight:[1.93283352 1.23848384], bias:-1.5077441663354119, loss:0.5485948091251007\n",
      "epoch:4075, weight:[1.93311069 1.23854876], bias:-1.5079079259330737, loss:0.548584022289895\n",
      "epoch:4076, weight:[1.93338786 1.23861365], bias:-1.5080716647276875, loss:0.5485732368312395\n",
      "epoch:4077, weight:[1.93366503 1.23867851], bias:-1.5082353827256314, loss:0.5485624527486692\n",
      "epoch:4078, weight:[1.93394218 1.23874336], bias:-1.5083990799332812, loss:0.5485516700417201\n",
      "epoch:4079, weight:[1.93421933 1.23880818], bias:-1.5085627563570099, loss:0.5485408887099275\n",
      "epoch:4080, weight:[1.93449647 1.23887297], bias:-1.5087264120031882, loss:0.5485301087528277\n",
      "epoch:4081, weight:[1.93477361 1.23893774], bias:-1.5088900468781845, loss:0.5485193301699577\n",
      "epoch:4082, weight:[1.93505074 1.23900249], bias:-1.509053660988364, loss:0.5485085529608539\n",
      "epoch:4083, weight:[1.93532786 1.23906722], bias:-1.5092172543400901, loss:0.548497777125053\n",
      "epoch:4084, weight:[1.93560497 1.23913192], bias:-1.5093808269397233, loss:0.5484870026620926\n",
      "epoch:4085, weight:[1.93588208 1.23919659], bias:-1.5095443787936218, loss:0.5484762295715108\n",
      "epoch:4086, weight:[1.93615918 1.23926125], bias:-1.5097079099081412, loss:0.5484654578528448\n",
      "epoch:4087, weight:[1.93643627 1.23932587], bias:-1.5098714202896346, loss:0.5484546875056335\n",
      "epoch:4088, weight:[1.93671336 1.23939048], bias:-1.5100349099444526, loss:0.5484439185294152\n",
      "epoch:4089, weight:[1.93699044 1.23945506], bias:-1.510198378878943, loss:0.5484331509237287\n",
      "epoch:4090, weight:[1.93726751 1.23951962], bias:-1.5103618270994519, loss:0.5484223846881133\n",
      "epoch:4091, weight:[1.93754457 1.23958415], bias:-1.5105252546123222, loss:0.5484116198221083\n",
      "epoch:4092, weight:[1.93782163 1.23964866], bias:-1.5106886614238946, loss:0.5484008563252536\n",
      "epoch:4093, weight:[1.93809868 1.23971315], bias:-1.510852047540507, loss:0.5483900941970892\n",
      "epoch:4094, weight:[1.93837573 1.23977761], bias:-1.5110154129684952, loss:0.5483793334371554\n",
      "epoch:4095, weight:[1.93865276 1.23984205], bias:-1.5111787577141922, loss:0.5483685740449928\n",
      "epoch:4096, weight:[1.9389298  1.23990647], bias:-1.5113420817839287, loss:0.5483578160201424\n",
      "epoch:4097, weight:[1.93920682 1.23997086], bias:-1.511505385184033, loss:0.5483470593621456\n",
      "epoch:4098, weight:[1.93948384 1.24003523], bias:-1.5116686679208304, loss:0.5483363040705438\n",
      "epoch:4099, weight:[1.93976084 1.24009958], bias:-1.5118319300006444, loss:0.5483255501448789\n",
      "epoch:4100, weight:[1.94003785 1.2401639 ], bias:-1.5119951714297957, loss:0.5483147975846928\n",
      "epoch:4101, weight:[1.94031484 1.2402282 ], bias:-1.5121583922146022, loss:0.5483040463895281\n",
      "epoch:4102, weight:[1.94059183 1.24029247], bias:-1.51232159236138, loss:0.5482932965589279\n",
      "epoch:4103, weight:[1.94086881 1.24035672], bias:-1.512484771876442, loss:0.5482825480924345\n",
      "epoch:4104, weight:[1.94114579 1.24042095], bias:-1.5126479307660992, loss:0.5482718009895917\n",
      "epoch:4105, weight:[1.94142275 1.24048515], bias:-1.5128110690366596, loss:0.548261055249943\n",
      "epoch:4106, weight:[1.94169971 1.24054933], bias:-1.512974186694429, loss:0.5482503108730324\n",
      "epoch:4107, weight:[1.94197667 1.24061349], bias:-1.513137283745711, loss:0.548239567858404\n",
      "epoch:4108, weight:[1.94225361 1.24067762], bias:-1.5133003601968062, loss:0.5482288262056024\n",
      "epoch:4109, weight:[1.94253055 1.24074173], bias:-1.513463416054013, loss:0.5482180859141722\n",
      "epoch:4110, weight:[1.94280749 1.24080582], bias:-1.5136264513236273, loss:0.5482073469836586\n",
      "epoch:4111, weight:[1.94308441 1.24086988], bias:-1.5137894660119424, loss:0.548196609413607\n",
      "epoch:4112, weight:[1.94336133 1.24093392], bias:-1.5139524601252494, loss:0.548185873203563\n",
      "epoch:4113, weight:[1.94363824 1.24099794], bias:-1.5141154336698366, loss:0.548175138353073\n",
      "epoch:4114, weight:[1.94391515 1.24106193], bias:-1.5142783866519902, loss:0.5481644048616826\n",
      "epoch:4115, weight:[1.94419204 1.2411259 ], bias:-1.5144413190779935, loss:0.5481536727289386\n",
      "epoch:4116, weight:[1.94446893 1.24118984], bias:-1.5146042309541277, loss:0.548142941954388\n",
      "epoch:4117, weight:[1.94474582 1.24125376], bias:-1.5147671222866712, loss:0.548132212537578\n",
      "epoch:4118, weight:[1.94502269 1.24131766], bias:-1.5149299930819002, loss:0.5481214844780559\n",
      "epoch:4119, weight:[1.94529956 1.24138154], bias:-1.5150928433460884, loss:0.5481107577753693\n",
      "epoch:4120, weight:[1.94557643 1.24144539], bias:-1.515255673085507, loss:0.5481000324290665\n",
      "epoch:4121, weight:[1.94585328 1.24150922], bias:-1.5154184823064245, loss:0.5480893084386956\n",
      "epoch:4122, weight:[1.94613013 1.24157302], bias:-1.5155812710151075, loss:0.5480785858038053\n",
      "epoch:4123, weight:[1.94640697 1.2416368 ], bias:-1.5157440392178196, loss:0.5480678645239444\n",
      "epoch:4124, weight:[1.9466838  1.24170056], bias:-1.5159067869208223, loss:0.5480571445986623\n",
      "epoch:4125, weight:[1.94696063 1.24176429], bias:-1.5160695141303742, loss:0.5480464260275083\n",
      "epoch:4126, weight:[1.94723745 1.24182801], bias:-1.516232220852732, loss:0.5480357088100323\n",
      "epoch:4127, weight:[1.94751426 1.24189169], bias:-1.5163949070941494, loss:0.5480249929457841\n",
      "epoch:4128, weight:[1.94779107 1.24195536], bias:-1.5165575728608782, loss:0.5480142784343144\n",
      "epoch:4129, weight:[1.94806787 1.242019  ], bias:-1.5167202181591675, loss:0.5480035652751737\n",
      "epoch:4130, weight:[1.94834466 1.24208262], bias:-1.5168828429952637, loss:0.5479928534679126\n",
      "epoch:4131, weight:[1.94862145 1.24214621], bias:-1.517045447375411, loss:0.5479821430120829\n",
      "epoch:4132, weight:[1.94889823 1.24220978], bias:-1.517208031305851, loss:0.547971433907236\n",
      "epoch:4133, weight:[1.949175   1.24227333], bias:-1.5173705947928229, loss:0.5479607261529233\n",
      "epoch:4134, weight:[1.94945176 1.24233686], bias:-1.5175331378425638, loss:0.5479500197486971\n",
      "epoch:4135, weight:[1.94972852 1.24240036], bias:-1.5176956604613079, loss:0.5479393146941098\n",
      "epoch:4136, weight:[1.95000527 1.24246384], bias:-1.5178581626552872, loss:0.5479286109887144\n",
      "epoch:4137, weight:[1.95028201 1.24252729], bias:-1.518020644430731, loss:0.5479179086320634\n",
      "epoch:4138, weight:[1.95055875 1.24259072], bias:-1.5181831057938664, loss:0.5479072076237101\n",
      "epoch:4139, weight:[1.95083547 1.24265413], bias:-1.5183455467509182, loss:0.5478965079632082\n",
      "epoch:4140, weight:[1.9511122  1.24271752], bias:-1.518507967308108, loss:0.5478858096501115\n",
      "epoch:4141, weight:[1.95138891 1.24278088], bias:-1.5186703674716562, loss:0.5478751126839739\n",
      "epoch:4142, weight:[1.95166562 1.24284422], bias:-1.5188327472477796, loss:0.54786441706435\n",
      "epoch:4143, weight:[1.95194232 1.24290753], bias:-1.5189951066426932, loss:0.5478537227907946\n",
      "epoch:4144, weight:[1.95221901 1.24297082], bias:-1.5191574456626094, loss:0.5478430298628623\n",
      "epoch:4145, weight:[1.9524957  1.24303409], bias:-1.519319764313738, loss:0.5478323382801086\n",
      "epoch:4146, weight:[1.95277238 1.24309734], bias:-1.5194820626022867, loss:0.5478216480420891\n",
      "epoch:4147, weight:[1.95304905 1.24316056], bias:-1.5196443405344604, loss:0.5478109591483594\n",
      "epoch:4148, weight:[1.95332572 1.24322376], bias:-1.519806598116462, loss:0.5478002715984759\n",
      "epoch:4149, weight:[1.95360237 1.24328694], bias:-1.5199688353544913, loss:0.5477895853919947\n",
      "epoch:4150, weight:[1.95387903 1.24335009], bias:-1.5201310522547467, loss:0.5477789005284728\n",
      "epoch:4151, weight:[1.95415567 1.24341322], bias:-1.520293248823423, loss:0.5477682170074667\n",
      "epoch:4152, weight:[1.95443231 1.24347633], bias:-1.5204554250667135, loss:0.5477575348285342\n",
      "epoch:4153, weight:[1.95470894 1.24353941], bias:-1.5206175809908085, loss:0.5477468539912325\n",
      "epoch:4154, weight:[1.95498556 1.24360247], bias:-1.5207797166018961, loss:0.5477361744951197\n",
      "epoch:4155, weight:[1.95526218 1.24366551], bias:-1.520941831906162, loss:0.5477254963397534\n",
      "epoch:4156, weight:[1.95553878 1.24372853], bias:-1.5211039269097895, loss:0.5477148195246925\n",
      "epoch:4157, weight:[1.95581539 1.24379152], bias:-1.5212660016189592, loss:0.5477041440494956\n",
      "epoch:4158, weight:[1.95609198 1.24385449], bias:-1.5214280560398497, loss:0.5476934699137216\n",
      "epoch:4159, weight:[1.95636857 1.24391743], bias:-1.5215900901786368, loss:0.5476827971169296\n",
      "epoch:4160, weight:[1.95664515 1.24398036], bias:-1.5217521040414943, loss:0.5476721256586793\n",
      "epoch:4161, weight:[1.95692172 1.24404326], bias:-1.521914097634593, loss:0.5476614555385303\n",
      "epoch:4162, weight:[1.95719829 1.24410613], bias:-1.5220760709641021, loss:0.5476507867560432\n",
      "epoch:4163, weight:[1.95747485 1.24416899], bias:-1.5222380240361875, loss:0.5476401193107777\n",
      "epoch:4164, weight:[1.9577514  1.24423182], bias:-1.5223999568570132, loss:0.5476294532022951\n",
      "epoch:4165, weight:[1.95802795 1.24429462], bias:-1.5225618694327407, loss:0.5476187884301558\n",
      "epoch:4166, weight:[1.95830448 1.24435741], bias:-1.522723761769529, loss:0.5476081249939214\n",
      "epoch:4167, weight:[1.95858102 1.24442017], bias:-1.5228856338735348, loss:0.5475974628931534\n",
      "epoch:4168, weight:[1.95885754 1.24448291], bias:-1.5230474857509122, loss:0.5475868021274132\n",
      "epoch:4169, weight:[1.95913406 1.24454562], bias:-1.5232093174078132, loss:0.5475761426962632\n",
      "epoch:4170, weight:[1.95941057 1.24460832], bias:-1.523371128850387, loss:0.5475654845992657\n",
      "epoch:4171, weight:[1.95968707 1.24467098], bias:-1.523532920084781, loss:0.5475548278359833\n",
      "epoch:4172, weight:[1.95996356 1.24473363], bias:-1.5236946911171394, loss:0.5475441724059791\n",
      "epoch:4173, weight:[1.96024005 1.24479626], bias:-1.5238564419536047, loss:0.5475335183088158\n",
      "epoch:4174, weight:[1.96051653 1.24485886], bias:-1.5240181726003166, loss:0.5475228655440575\n",
      "epoch:4175, weight:[1.96079301 1.24492143], bias:-1.5241798830634123, loss:0.5475122141112674\n",
      "epoch:4176, weight:[1.96106948 1.24498399], bias:-1.5243415733490273, loss:0.5475015640100102\n",
      "epoch:4177, weight:[1.96134594 1.24504652], bias:-1.5245032434632937, loss:0.5474909152398494\n",
      "epoch:4178, weight:[1.96162239 1.24510903], bias:-1.524664893412342, loss:0.5474802678003501\n",
      "epoch:4179, weight:[1.96189884 1.24517152], bias:-1.5248265232022997, loss:0.5474696216910772\n",
      "epoch:4180, weight:[1.96217527 1.24523398], bias:-1.5249881328392925, loss:0.5474589769115954\n",
      "epoch:4181, weight:[1.96245171 1.24529642], bias:-1.5251497223294432, loss:0.5474483334614706\n",
      "epoch:4182, weight:[1.96272813 1.24535884], bias:-1.5253112916788727, loss:0.5474376913402685\n",
      "epoch:4183, weight:[1.96300455 1.24542123], bias:-1.5254728408936988, loss:0.5474270505475549\n",
      "epoch:4184, weight:[1.96328096 1.24548361], bias:-1.5256343699800377, loss:0.5474164110828961\n",
      "epoch:4185, weight:[1.96355736 1.24554596], bias:-1.5257958789440027, loss:0.5474057729458586\n",
      "epoch:4186, weight:[1.96383376 1.24560828], bias:-1.5259573677917049, loss:0.5473951361360093\n",
      "epoch:4187, weight:[1.96411015 1.24567059], bias:-1.5261188365292528, loss:0.5473845006529154\n",
      "epoch:4188, weight:[1.96438653 1.24573287], bias:-1.5262802851627528, loss:0.5473738664961441\n",
      "epoch:4189, weight:[1.9646629  1.24579512], bias:-1.5264417136983086, loss:0.547363233665263\n",
      "epoch:4190, weight:[1.96493927 1.24585736], bias:-1.526603122142022, loss:0.5473526021598402\n",
      "epoch:4191, weight:[1.96521563 1.24591957], bias:-1.5267645104999918, loss:0.5473419719794437\n",
      "epoch:4192, weight:[1.96549199 1.24598176], bias:-1.5269258787783149, loss:0.5473313431236421\n",
      "epoch:4193, weight:[1.96576833 1.24604393], bias:-1.5270872269830855, loss:0.5473207155920043\n",
      "epoch:4194, weight:[1.96604467 1.24610607], bias:-1.5272485551203958, loss:0.5473100893840993\n",
      "epoch:4195, weight:[1.966321  1.2461682], bias:-1.5274098631963353, loss:0.5472994644994962\n",
      "epoch:4196, weight:[1.96659733 1.24623029], bias:-1.5275711512169912, loss:0.5472888409377649\n",
      "epoch:4197, weight:[1.96687365 1.24629237], bias:-1.527732419188448, loss:0.5472782186984749\n",
      "epoch:4198, weight:[1.96714996 1.24635442], bias:-1.5278936671167886, loss:0.5472675977811966\n",
      "epoch:4199, weight:[1.96742626 1.24641645], bias:-1.5280548950080928, loss:0.5472569781855005\n",
      "epoch:4200, weight:[1.96770256 1.24647846], bias:-1.5282161028684385, loss:0.5472463599109567\n",
      "epoch:4201, weight:[1.96797885 1.24654045], bias:-1.5283772907039008, loss:0.5472357429571368\n",
      "epoch:4202, weight:[1.96825513 1.24660241], bias:-1.5285384585205528, loss:0.5472251273236118\n",
      "epoch:4203, weight:[1.96853141 1.24666435], bias:-1.5286996063244649, loss:0.5472145130099535\n",
      "epoch:4204, weight:[1.96880768 1.24672627], bias:-1.5288607341217055, loss:0.547203900015733\n",
      "epoch:4205, weight:[1.96908394 1.24678816], bias:-1.5290218419183403, loss:0.5471932883405229\n",
      "epoch:4206, weight:[1.96936019 1.24685004], bias:-1.529182929720433, loss:0.5471826779838955\n",
      "epoch:4207, weight:[1.96963644 1.24691189], bias:-1.5293439975340444, loss:0.5471720689454233\n",
      "epoch:4208, weight:[1.96991268 1.24697371], bias:-1.5295050453652335, loss:0.547161461224679\n",
      "epoch:4209, weight:[1.97018891 1.24703552], bias:-1.5296660732200564, loss:0.5471508548212362\n",
      "epoch:4210, weight:[1.97046513 1.2470973 ], bias:-1.5298270811045673, loss:0.5471402497346679\n",
      "epoch:4211, weight:[1.97074135 1.24715906], bias:-1.5299880690248178, loss:0.5471296459645479\n",
      "epoch:4212, weight:[1.97101756 1.24722079], bias:-1.5301490369868571, loss:0.5471190435104504\n",
      "epoch:4213, weight:[1.97129377 1.24728251], bias:-1.530309984996732, loss:0.5471084423719493\n",
      "epoch:4214, weight:[1.97156996 1.2473442 ], bias:-1.5304709130604874, loss:0.5470978425486194\n",
      "epoch:4215, weight:[1.97184615 1.24740587], bias:-1.5306318211841652, loss:0.5470872440400355\n",
      "epoch:4216, weight:[1.97212234 1.24746751], bias:-1.5307927093738054, loss:0.5470766468457722\n",
      "epoch:4217, weight:[1.97239851 1.24752914], bias:-1.5309535776354455, loss:0.5470660509654052\n",
      "epoch:4218, weight:[1.97267468 1.24759074], bias:-1.5311144259751204, loss:0.5470554563985102\n",
      "epoch:4219, weight:[1.97295084 1.24765232], bias:-1.531275254398863, loss:0.5470448631446628\n",
      "epoch:4220, weight:[1.973227   1.24771387], bias:-1.531436062912704, loss:0.5470342712034393\n",
      "epoch:4221, weight:[1.97350314 1.24777541], bias:-1.531596851522671, loss:0.547023680574416\n",
      "epoch:4222, weight:[1.97377928 1.24783692], bias:-1.53175762023479, loss:0.5470130912571696\n",
      "epoch:4223, weight:[1.97405541 1.24789841], bias:-1.5319183690550844, loss:0.5470025032512772\n",
      "epoch:4224, weight:[1.97433154 1.24795988], bias:-1.532079097989575, loss:0.5469919165563158\n",
      "epoch:4225, weight:[1.97460766 1.24802132], bias:-1.5322398070442806, loss:0.5469813311718631\n",
      "epoch:4226, weight:[1.97488377 1.24808274], bias:-1.5324004962252176, loss:0.5469707470974967\n",
      "epoch:4227, weight:[1.97515987 1.24814414], bias:-1.5325611655383997, loss:0.5469601643327947\n",
      "epoch:4228, weight:[1.97543597 1.24820552], bias:-1.5327218149898387, loss:0.5469495828773354\n",
      "epoch:4229, weight:[1.97571206 1.24826687], bias:-1.532882444585544, loss:0.5469390027306972\n",
      "epoch:4230, weight:[1.97598814 1.2483282 ], bias:-1.5330430543315223, loss:0.5469284238924591\n",
      "epoch:4231, weight:[1.97626422 1.24838951], bias:-1.5332036442337784, loss:0.5469178463622003\n",
      "epoch:4232, weight:[1.97654029 1.2484508 ], bias:-1.5333642142983146, loss:0.5469072701395\n",
      "epoch:4233, weight:[1.97681635 1.24851206], bias:-1.5335247645311305, loss:0.5468966952239379\n",
      "epoch:4234, weight:[1.9770924 1.2485733], bias:-1.533685294938224, loss:0.5468861216150939\n",
      "epoch:4235, weight:[1.97736845 1.24863452], bias:-1.5338458055255901, loss:0.5468755493125481\n",
      "epoch:4236, weight:[1.97764449 1.24869572], bias:-1.534006296299222, loss:0.5468649783158811\n",
      "epoch:4237, weight:[1.97792052 1.2487569 ], bias:-1.53416676726511, loss:0.5468544086246733\n",
      "epoch:4238, weight:[1.97819654 1.24881805], bias:-1.5343272184292425, loss:0.5468438402385059\n",
      "epoch:4239, weight:[1.97847256 1.24887918], bias:-1.5344876497976052, loss:0.5468332731569604\n",
      "epoch:4240, weight:[1.97874857 1.24894029], bias:-1.534648061376182, loss:0.5468227073796178\n",
      "epoch:4241, weight:[1.97902458 1.24900137], bias:-1.5348084531709538, loss:0.5468121429060603\n",
      "epoch:4242, weight:[1.97930057 1.24906244], bias:-1.5349688251878997, loss:0.5468015797358695\n",
      "epoch:4243, weight:[1.97957656 1.24912348], bias:-1.5351291774329963, loss:0.546791017868628\n",
      "epoch:4244, weight:[1.97985254 1.2491845 ], bias:-1.5352895099122177, loss:0.5467804573039184\n",
      "epoch:4245, weight:[1.98012852 1.24924549], bias:-1.5354498226315358, loss:0.5467698980413235\n",
      "epoch:4246, weight:[1.98040449 1.24930647], bias:-1.5356101155969204, loss:0.5467593400804264\n",
      "epoch:4247, weight:[1.98068045 1.24936742], bias:-1.5357703888143386, loss:0.5467487834208102\n",
      "epoch:4248, weight:[1.9809564  1.24942835], bias:-1.5359306422897554, loss:0.546738228062059\n",
      "epoch:4249, weight:[1.98123235 1.24948926], bias:-1.5360908760291336, loss:0.5467276740037563\n",
      "epoch:4250, weight:[1.98150828 1.24955014], bias:-1.5362510900384334, loss:0.5467171212454863\n",
      "epoch:4251, weight:[1.98178422 1.249611  ], bias:-1.5364112843236126, loss:0.5467065697868339\n",
      "epoch:4252, weight:[1.98206014 1.24967185], bias:-1.536571458890627, loss:0.5466960196273832\n",
      "epoch:4253, weight:[1.98233606 1.24973266], bias:-1.5367316137454299, loss:0.5466854707667194\n",
      "epoch:4254, weight:[1.98261197 1.24979346], bias:-1.5368917488939724, loss:0.5466749232044276\n",
      "epoch:4255, weight:[1.98288787 1.24985423], bias:-1.5370518643422033, loss:0.5466643769400934\n",
      "epoch:4256, weight:[1.98316377 1.24991499], bias:-1.5372119600960688, loss:0.5466538319733026\n",
      "epoch:4257, weight:[1.98343966 1.24997572], bias:-1.537372036161513, loss:0.5466432883036411\n",
      "epoch:4258, weight:[1.98371554 1.25003642], bias:-1.537532092544478, loss:0.5466327459306952\n",
      "epoch:4259, weight:[1.98399141 1.25009711], bias:-1.5376921292509027, loss:0.5466222048540517\n",
      "epoch:4260, weight:[1.98426728 1.25015777], bias:-1.5378521462867247, loss:0.5466116650732967\n",
      "epoch:4261, weight:[1.98454314 1.25021841], bias:-1.5380121436578786, loss:0.5466011265880178\n",
      "epoch:4262, weight:[1.98481899 1.25027903], bias:-1.538172121370297, loss:0.5465905893978019\n",
      "epoch:4263, weight:[1.98509484 1.25033963], bias:-1.53833207942991, loss:0.5465800535022375\n",
      "epoch:4264, weight:[1.98537067 1.2504002 ], bias:-1.5384920178426458, loss:0.5465695189009115\n",
      "epoch:4265, weight:[1.98564651 1.25046076], bias:-1.5386519366144298, loss:0.5465589855934123\n",
      "epoch:4266, weight:[1.98592233 1.25052129], bias:-1.5388118357511853, loss:0.5465484535793285\n",
      "epoch:4267, weight:[1.98619815 1.2505818 ], bias:-1.5389717152588331, loss:0.5465379228582482\n",
      "epoch:4268, weight:[1.98647396 1.25064228], bias:-1.5391315751432924, loss:0.5465273934297605\n",
      "epoch:4269, weight:[1.98674976 1.25070275], bias:-1.539291415410479, loss:0.546516865293455\n",
      "epoch:4270, weight:[1.98702555 1.25076319], bias:-1.5394512360663075, loss:0.5465063384489206\n",
      "epoch:4271, weight:[1.98730134 1.25082361], bias:-1.5396110371166893, loss:0.5464958128957472\n",
      "epoch:4272, weight:[1.98757712 1.25088401], bias:-1.539770818567534, loss:0.5464852886335246\n",
      "epoch:4273, weight:[1.98785289 1.25094438], bias:-1.539930580424749, loss:0.5464747656618429\n",
      "epoch:4274, weight:[1.98812866 1.25100474], bias:-1.5400903226942388, loss:0.5464642439802928\n",
      "epoch:4275, weight:[1.98840442 1.25106507], bias:-1.5402500453819064, loss:0.5464537235884649\n",
      "epoch:4276, weight:[1.98868017 1.25112538], bias:-1.5404097484936519, loss:0.5464432044859502\n",
      "epoch:4277, weight:[1.98895591 1.25118567], bias:-1.5405694320353733, loss:0.5464326866723397\n",
      "epoch:4278, weight:[1.98923165 1.25124593], bias:-1.5407290960129665, loss:0.546422170147225\n",
      "epoch:4279, weight:[1.98950738 1.25130618], bias:-1.5408887404323248, loss:0.5464116549101979\n",
      "epoch:4280, weight:[1.9897831 1.2513664], bias:-1.5410483652993392, loss:0.5464011409608506\n",
      "epoch:4281, weight:[1.99005882 1.2514266 ], bias:-1.5412079706198987, loss:0.5463906282987752\n",
      "epoch:4282, weight:[1.99033453 1.25148678], bias:-1.5413675563998899, loss:0.546380116923564\n",
      "epoch:4283, weight:[1.99061023 1.25154693], bias:-1.541527122645197, loss:0.54636960683481\n",
      "epoch:4284, weight:[1.99088592 1.25160707], bias:-1.541686669361702, loss:0.5463590980321059\n",
      "epoch:4285, weight:[1.99116161 1.25166718], bias:-1.5418461965552845, loss:0.5463485905150457\n",
      "epoch:4286, weight:[1.99143729 1.25172727], bias:-1.542005704231822, loss:0.5463380842832223\n",
      "epoch:4287, weight:[1.99171296 1.25178734], bias:-1.5421651923971895, loss:0.5463275793362298\n",
      "epoch:4288, weight:[1.99198863 1.25184739], bias:-1.54232466105726, loss:0.5463170756736622\n",
      "epoch:4289, weight:[1.99226428 1.25190741], bias:-1.542484110217904, loss:0.5463065732951133\n",
      "epoch:4290, weight:[1.99253993 1.25196741], bias:-1.54264353988499, loss:0.5462960722001786\n",
      "epoch:4291, weight:[1.99281558 1.25202739], bias:-1.5428029500643838, loss:0.5462855723884527\n",
      "epoch:4292, weight:[1.99309121 1.25208735], bias:-1.542962340761949, loss:0.5462750738595301\n",
      "epoch:4293, weight:[1.99336684 1.25214729], bias:-1.5431217119835472, loss:0.5462645766130065\n",
      "epoch:4294, weight:[1.99364246 1.25220721], bias:-1.5432810637350376, loss:0.5462540806484778\n",
      "epoch:4295, weight:[1.99391808 1.2522671 ], bias:-1.5434403960222771, loss:0.5462435859655393\n",
      "epoch:4296, weight:[1.99419369 1.25232697], bias:-1.5435997088511202, loss:0.5462330925637876\n",
      "epoch:4297, weight:[1.99446929 1.25238682], bias:-1.5437590022274195, loss:0.5462226004428188\n",
      "epoch:4298, weight:[1.99474488 1.25244665], bias:-1.5439182761570247, loss:0.5462121096022294\n",
      "epoch:4299, weight:[1.99502046 1.25250645], bias:-1.544077530645784, loss:0.5462016200416168\n",
      "epoch:4300, weight:[1.99529604 1.25256624], bias:-1.5442367656995426, loss:0.5461911317605774\n",
      "epoch:4301, weight:[1.99557161 1.252626  ], bias:-1.5443959813241441, loss:0.5461806447587091\n",
      "epoch:4302, weight:[1.99584718 1.25268574], bias:-1.5445551775254294, loss:0.5461701590356093\n",
      "epoch:4303, weight:[1.99612273 1.25274546], bias:-1.544714354309237, loss:0.546159674590876\n",
      "epoch:4304, weight:[1.99639828 1.25280516], bias:-1.5448735116814036, loss:0.5461491914241073\n",
      "epoch:4305, weight:[1.99667382 1.25286483], bias:-1.5450326496477633, loss:0.5461387095349016\n",
      "epoch:4306, weight:[1.99694936 1.25292449], bias:-1.545191768214148, loss:0.5461282289228574\n",
      "epoch:4307, weight:[1.99722488 1.25298412], bias:-1.5453508673863876, loss:0.5461177495875739\n",
      "epoch:4308, weight:[1.9975004  1.25304373], bias:-1.5455099471703093, loss:0.5461072715286502\n",
      "epoch:4309, weight:[1.99777592 1.25310332], bias:-1.5456690075717383, loss:0.5460967947456855\n",
      "epoch:4310, weight:[1.99805142 1.25316288], bias:-1.5458280485964975, loss:0.5460863192382797\n",
      "epoch:4311, weight:[1.99832692 1.25322243], bias:-1.5459870702504075, loss:0.5460758450060325\n",
      "epoch:4312, weight:[1.99860241 1.25328195], bias:-1.5461460725392868, loss:0.5460653720485441\n",
      "epoch:4313, weight:[1.9988779  1.25334145], bias:-1.5463050554689515, loss:0.546054900365415\n",
      "epoch:4314, weight:[1.99915337 1.25340093], bias:-1.5464640190452152, loss:0.546044429956246\n",
      "epoch:4315, weight:[1.99942884 1.25346039], bias:-1.54662296327389, loss:0.5460339608206378\n",
      "epoch:4316, weight:[1.9997043  1.25351983], bias:-1.5467818881607847, loss:0.5460234929581917\n",
      "epoch:4317, weight:[1.99997976 1.25357924], bias:-1.5469407937117068, loss:0.546013026368509\n",
      "epoch:4318, weight:[2.00025521 1.25363864], bias:-1.547099679932461, loss:0.5460025610511913\n",
      "epoch:4319, weight:[2.00053065 1.25369801], bias:-1.5472585468288498, loss:0.5459920970058408\n",
      "epoch:4320, weight:[2.00080608 1.25375736], bias:-1.5474173944066736, loss:0.5459816342320596\n",
      "epoch:4321, weight:[2.0010815  1.25381669], bias:-1.5475762226717307, loss:0.5459711727294501\n",
      "epoch:4322, weight:[2.00135692 1.25387599], bias:-1.5477350316298166, loss:0.5459607124976148\n",
      "epoch:4323, weight:[2.00163233 1.25393528], bias:-1.5478938212867253, loss:0.5459502535361569\n",
      "epoch:4324, weight:[2.00190774 1.25399454], bias:-1.548052591648248, loss:0.5459397958446794\n",
      "epoch:4325, weight:[2.00218313 1.25405378], bias:-1.5482113427201736, loss:0.5459293394227857\n",
      "epoch:4326, weight:[2.00245852 1.254113  ], bias:-1.5483700745082891, loss:0.5459188842700796\n",
      "epoch:4327, weight:[2.0027339 1.2541722], bias:-1.5485287870183793, loss:0.5459084303861651\n",
      "epoch:4328, weight:[2.00300928 1.25423138], bias:-1.5486874802562265, loss:0.5458979777706462\n",
      "epoch:4329, weight:[2.00328465 1.25429054], bias:-1.5488461542276108, loss:0.5458875264231272\n",
      "epoch:4330, weight:[2.00356001 1.25434967], bias:-1.5490048089383102, loss:0.5458770763432131\n",
      "epoch:4331, weight:[2.00383536 1.25440878], bias:-1.5491634443941, loss:0.5458666275305085\n",
      "epoch:4332, weight:[2.0041107  1.25446787], bias:-1.549322060600754, loss:0.545856179984619\n",
      "epoch:4333, weight:[2.00438604 1.25452694], bias:-1.5494806575640434, loss:0.5458457337051497\n",
      "epoch:4334, weight:[2.00466137 1.25458599], bias:-1.549639235289737, loss:0.5458352886917062\n",
      "epoch:4335, weight:[2.0049367  1.25464502], bias:-1.5497977937836016, loss:0.5458248449438945\n",
      "epoch:4336, weight:[2.00521201 1.25470402], bias:-1.5499563330514015, loss:0.545814402461321\n",
      "epoch:4337, weight:[2.00548732 1.25476301], bias:-1.550114853098899, loss:0.5458039612435917\n",
      "epoch:4338, weight:[2.00576262 1.25482197], bias:-1.5502733539318545, loss:0.5457935212903136\n",
      "epoch:4339, weight:[2.00603792 1.25488091], bias:-1.5504318355560254, loss:0.5457830826010933\n",
      "epoch:4340, weight:[2.0063132  1.25493983], bias:-1.5505902979771673, loss:0.5457726451755381\n",
      "epoch:4341, weight:[2.00658848 1.25499873], bias:-1.5507487412010337, loss:0.5457622090132557\n",
      "epoch:4342, weight:[2.00686376 1.2550576 ], bias:-1.5509071652333755, loss:0.5457517741138531\n",
      "epoch:4343, weight:[2.00713902 1.25511646], bias:-1.5510655700799416, loss:0.5457413404769387\n",
      "epoch:4344, weight:[2.00741428 1.25517529], bias:-1.5512239557464789, loss:0.5457309081021204\n",
      "epoch:4345, weight:[2.00768953 1.2552341 ], bias:-1.5513823222387315, loss:0.5457204769890067\n",
      "epoch:4346, weight:[2.00796477 1.25529289], bias:-1.5515406695624419, loss:0.5457100471372062\n",
      "epoch:4347, weight:[2.00824001 1.25535166], bias:-1.5516989977233497, loss:0.5456996185463275\n",
      "epoch:4348, weight:[2.00851524 1.25541041], bias:-1.551857306727193, loss:0.5456891912159801\n",
      "epoch:4349, weight:[2.00879046 1.25546914], bias:-1.5520155965797073, loss:0.5456787651457735\n",
      "epoch:4350, weight:[2.00906567 1.25552784], bias:-1.5521738672866259, loss:0.5456683403353167\n",
      "epoch:4351, weight:[2.00934088 1.25558652], bias:-1.5523321188536798, loss:0.54565791678422\n",
      "epoch:4352, weight:[2.00961608 1.25564519], bias:-1.552490351286598, loss:0.5456474944920932\n",
      "epoch:4353, weight:[2.00989127 1.25570383], bias:-1.552648564591107, loss:0.545637073458547\n",
      "epoch:4354, weight:[2.01016646 1.25576245], bias:-1.5528067587729313, loss:0.5456266536831917\n",
      "epoch:4355, weight:[2.01044163 1.25582104], bias:-1.552964933837793, loss:0.5456162351656382\n",
      "epoch:4356, weight:[2.0107168  1.25587962], bias:-1.5531230897914126, loss:0.5456058179054978\n",
      "epoch:4357, weight:[2.01099197 1.25593818], bias:-1.5532812266395073, loss:0.5455954019023815\n",
      "epoch:4358, weight:[2.01126712 1.25599671], bias:-1.553439344387793, loss:0.5455849871559009\n",
      "epoch:4359, weight:[2.01154227 1.25605522], bias:-1.553597443041983, loss:0.545574573665668\n",
      "epoch:4360, weight:[2.01181741 1.25611372], bias:-1.5537555226077886, loss:0.5455641614312946\n",
      "epoch:4361, weight:[2.01209255 1.25617219], bias:-1.5539135830909185, loss:0.5455537504523931\n",
      "epoch:4362, weight:[2.01236767 1.25623063], bias:-1.5540716244970798, loss:0.5455433407285764\n",
      "epoch:4363, weight:[2.01264279 1.25628906], bias:-1.5542296468319767, loss:0.5455329322594563\n",
      "epoch:4364, weight:[2.0129179  1.25634747], bias:-1.5543876501013119, loss:0.5455225250446468\n",
      "epoch:4365, weight:[2.01319301 1.25640585], bias:-1.5545456343107853, loss:0.545512119083761\n",
      "epoch:4366, weight:[2.0134681  1.25646422], bias:-1.5547035994660947, loss:0.5455017143764118\n",
      "epoch:4367, weight:[2.01374319 1.25652256], bias:-1.5548615455729362, loss:0.5454913109222136\n",
      "epoch:4368, weight:[2.01401828 1.25658088], bias:-1.555019472637003, loss:0.5454809087207799\n",
      "epoch:4369, weight:[2.01429335 1.25663918], bias:-1.5551773806639866, loss:0.5454705077717251\n",
      "epoch:4370, weight:[2.01456842 1.25669746], bias:-1.555335269659576, loss:0.5454601080746639\n",
      "epoch:4371, weight:[2.01484348 1.25675572], bias:-1.555493139629458, loss:0.5454497096292109\n",
      "epoch:4372, weight:[2.01511853 1.25681396], bias:-1.5556509905793177, loss:0.545439312434981\n",
      "epoch:4373, weight:[2.01539358 1.25687217], bias:-1.5558088225148374, loss:0.5454289164915891\n",
      "epoch:4374, weight:[2.01566862 1.25693037], bias:-1.5559666354416974, loss:0.545418521798651\n",
      "epoch:4375, weight:[2.01594365 1.25698854], bias:-1.556124429365576, loss:0.5454081283557822\n",
      "epoch:4376, weight:[2.01621867 1.25704669], bias:-1.5562822042921491, loss:0.5453977361625988\n",
      "epoch:4377, weight:[2.01649369 1.25710482], bias:-1.5564399602270904, loss:0.5453873452187167\n",
      "epoch:4378, weight:[2.0167687  1.25716293], bias:-1.5565976971760713, loss:0.5453769555237525\n",
      "epoch:4379, weight:[2.0170437  1.25722102], bias:-1.5567554151447613, loss:0.5453665670773227\n",
      "epoch:4380, weight:[2.01731869 1.25727909], bias:-1.5569131141388277, loss:0.5453561798790442\n",
      "epoch:4381, weight:[2.01759368 1.25733713], bias:-1.5570707941639352, loss:0.5453457939285341\n",
      "epoch:4382, weight:[2.01786866 1.25739516], bias:-1.557228455225747, loss:0.5453354092254096\n",
      "epoch:4383, weight:[2.01814363 1.25745316], bias:-1.5573860973299232, loss:0.5453250257692887\n",
      "epoch:4384, weight:[2.01841859 1.25751115], bias:-1.5575437204821225, loss:0.545314643559789\n",
      "epoch:4385, weight:[2.01869355 1.25756911], bias:-1.5577013246880014, loss:0.5453042625965283\n",
      "epoch:4386, weight:[2.0189685  1.25762705], bias:-1.5578589099532134, loss:0.5452938828791253\n",
      "epoch:4387, weight:[2.01924345 1.25768497], bias:-1.5580164762834108, loss:0.5452835044071983\n",
      "epoch:4388, weight:[2.01951838 1.25774287], bias:-1.558174023684243, loss:0.5452731271803661\n",
      "epoch:4389, weight:[2.01979331 1.25780074], bias:-1.5583315521613577, loss:0.5452627511982479\n",
      "epoch:4390, weight:[2.02006823 1.2578586 ], bias:-1.5584890617204001, loss:0.5452523764604628\n",
      "epoch:4391, weight:[2.02034314 1.25791644], bias:-1.5586465523670134, loss:0.5452420029666303\n",
      "epoch:4392, weight:[2.02061805 1.25797425], bias:-1.5588040241068386, loss:0.5452316307163702\n",
      "epoch:4393, weight:[2.02089295 1.25803204], bias:-1.5589614769455142, loss:0.5452212597093022\n",
      "epoch:4394, weight:[2.02116784 1.25808982], bias:-1.5591189108886772, loss:0.545210889945047\n",
      "epoch:4395, weight:[2.02144272 1.25814757], bias:-1.5592763259419617, loss:0.5452005214232245\n",
      "epoch:4396, weight:[2.0217176 1.2582053], bias:-1.5594337221110002, loss:0.5451901541434556\n",
      "epoch:4397, weight:[2.02199247 1.25826301], bias:-1.5595910994014226, loss:0.5451797881053613\n",
      "epoch:4398, weight:[2.02226733 1.2583207 ], bias:-1.559748457818857, loss:0.5451694233085628\n",
      "epoch:4399, weight:[2.02254218 1.25837836], bias:-1.559905797368929, loss:0.5451590597526812\n",
      "epoch:4400, weight:[2.02281703 1.25843601], bias:-1.5600631180572622, loss:0.5451486974373384\n",
      "epoch:4401, weight:[2.02309187 1.25849364], bias:-1.560220419889478, loss:0.5451383363621561\n",
      "epoch:4402, weight:[2.0233667  1.25855124], bias:-1.5603777028711956, loss:0.5451279765267564\n",
      "epoch:4403, weight:[2.02364153 1.25860882], bias:-1.560534967008032, loss:0.5451176179307615\n",
      "epoch:4404, weight:[2.02391635 1.25866639], bias:-1.5606922123056022, loss:0.5451072605737944\n",
      "epoch:4405, weight:[2.02419116 1.25872393], bias:-1.5608494387695189, loss:0.5450969044554775\n",
      "epoch:4406, weight:[2.02446596 1.25878145], bias:-1.5610066464053927, loss:0.5450865495754338\n",
      "epoch:4407, weight:[2.02474076 1.25883895], bias:-1.5611638352188317, loss:0.5450761959332868\n",
      "epoch:4408, weight:[2.02501554 1.25889643], bias:-1.5613210052154425, loss:0.5450658435286598\n",
      "epoch:4409, weight:[2.02529032 1.25895389], bias:-1.5614781564008289, loss:0.5450554923611769\n",
      "epoch:4410, weight:[2.0255651  1.25901133], bias:-1.5616352887805929, loss:0.5450451424304616\n",
      "epoch:4411, weight:[2.02583986 1.25906874], bias:-1.5617924023603342, loss:0.5450347937361383\n",
      "epoch:4412, weight:[2.02611462 1.25912614], bias:-1.5619494971456507, loss:0.5450244462778314\n",
      "epoch:4413, weight:[2.02638937 1.25918351], bias:-1.5621065731421375, loss:0.5450141000551659\n",
      "epoch:4414, weight:[2.02666412 1.25924087], bias:-1.5622636303553878, loss:0.545003755067766\n",
      "epoch:4415, weight:[2.02693885 1.2592982 ], bias:-1.562420668790993, loss:0.5449934113152574\n",
      "epoch:4416, weight:[2.02721358 1.25935551], bias:-1.5625776884545417, loss:0.5449830687972653\n",
      "epoch:4417, weight:[2.0274883 1.2594128], bias:-1.562734689351621, loss:0.5449727275134154\n",
      "epoch:4418, weight:[2.02776302 1.25947007], bias:-1.5628916714878154, loss:0.5449623874633335\n",
      "epoch:4419, weight:[2.02803773 1.25952732], bias:-1.5630486348687074, loss:0.5449520486466454\n",
      "epoch:4420, weight:[2.02831242 1.25958455], bias:-1.5632055794998774, loss:0.5449417110629775\n",
      "epoch:4421, weight:[2.02858712 1.25964176], bias:-1.5633625053869036, loss:0.5449313747119565\n",
      "epoch:4422, weight:[2.0288618  1.25969895], bias:-1.563519412535362, loss:0.5449210395932091\n",
      "epoch:4423, weight:[2.02913648 1.25975612], bias:-1.5636763009508265, loss:0.5449107057063626\n",
      "epoch:4424, weight:[2.02941115 1.25981326], bias:-1.5638331706388688, loss:0.5449003730510436\n",
      "epoch:4425, weight:[2.02968581 1.25987039], bias:-1.5639900216050586, loss:0.5448900416268798\n",
      "epoch:4426, weight:[2.02996047 1.25992749], bias:-1.5641468538549632, loss:0.5448797114334991\n",
      "epoch:4427, weight:[2.03023511 1.25998457], bias:-1.564303667394148, loss:0.5448693824705295\n",
      "epoch:4428, weight:[2.03050975 1.26004164], bias:-1.564460462228176, loss:0.5448590547375984\n",
      "epoch:4429, weight:[2.03078439 1.26009868], bias:-1.5646172383626082, loss:0.5448487282343351\n",
      "epoch:4430, weight:[2.03105901 1.2601557 ], bias:-1.5647739958030038, loss:0.5448384029603678\n",
      "epoch:4431, weight:[2.03133363 1.2602127 ], bias:-1.5649307345549193, loss:0.5448280789153251\n",
      "epoch:4432, weight:[2.03160824 1.26026968], bias:-1.5650874546239093, loss:0.5448177560988365\n",
      "epoch:4433, weight:[2.03188284 1.26032664], bias:-1.5652441560155261, loss:0.5448074345105307\n",
      "epoch:4434, weight:[2.03215744 1.26038358], bias:-1.5654008387353204, loss:0.5447971141500382\n",
      "epoch:4435, weight:[2.03243203 1.2604405 ], bias:-1.56555750278884, loss:0.544786795016988\n",
      "epoch:4436, weight:[2.03270661 1.2604974 ], bias:-1.565714148181631, loss:0.5447764771110103\n",
      "epoch:4437, weight:[2.03298118 1.26055427], bias:-1.5658707749192375, loss:0.5447661604317354\n",
      "epoch:4438, weight:[2.03325575 1.26061113], bias:-1.5660273830072011, loss:0.5447558449787935\n",
      "epoch:4439, weight:[2.03353031 1.26066796], bias:-1.5661839724510616, loss:0.5447455307518154\n",
      "epoch:4440, weight:[2.03380486 1.26072478], bias:-1.5663405432563562, loss:0.5447352177504322\n",
      "epoch:4441, weight:[2.0340794  1.26078157], bias:-1.5664970954286204, loss:0.5447249059742748\n",
      "epoch:4442, weight:[2.03435394 1.26083835], bias:-1.5666536289733874, loss:0.5447145954229746\n",
      "epoch:4443, weight:[2.03462847 1.2608951 ], bias:-1.5668101438961883, loss:0.5447042860961633\n",
      "epoch:4444, weight:[2.03490299 1.26095183], bias:-1.5669666402025522, loss:0.5446939779934726\n",
      "epoch:4445, weight:[2.03517751 1.26100854], bias:-1.5671231178980058, loss:0.5446836711145346\n",
      "epoch:4446, weight:[2.03545201 1.26106523], bias:-1.5672795769880739, loss:0.5446733654589816\n",
      "epoch:4447, weight:[2.03572651 1.26112191], bias:-1.5674360174782789, loss:0.5446630610264459\n",
      "epoch:4448, weight:[2.036001   1.26117856], bias:-1.5675924393741414, loss:0.5446527578165606\n",
      "epoch:4449, weight:[2.03627549 1.26123518], bias:-1.5677488426811799, loss:0.5446424558289584\n",
      "epoch:4450, weight:[2.03654997 1.26129179], bias:-1.5679052274049103, loss:0.5446321550632726\n",
      "epoch:4451, weight:[2.03682444 1.26134838], bias:-1.568061593550847, loss:0.5446218555191363\n",
      "epoch:4452, weight:[2.0370989  1.26140495], bias:-1.5682179411245019, loss:0.5446115571961837\n",
      "epoch:4453, weight:[2.03737335 1.2614615 ], bias:-1.5683742701313845, loss:0.5446012600940481\n",
      "epoch:4454, weight:[2.0376478  1.26151802], bias:-1.568530580577003, loss:0.544590964212364\n",
      "epoch:4455, weight:[2.03792224 1.26157453], bias:-1.5686868724668626, loss:0.5445806695507656\n",
      "epoch:4456, weight:[2.03819667 1.26163102], bias:-1.568843145806467, loss:0.544570376108887\n",
      "epoch:4457, weight:[2.0384711  1.26168748], bias:-1.5689994006013177, loss:0.5445600838863637\n",
      "epoch:4458, weight:[2.03874552 1.26174393], bias:-1.5691556368569137, loss:0.5445497928828301\n",
      "epoch:4459, weight:[2.03901993 1.26180035], bias:-1.5693118545787523, loss:0.5445395030979218\n",
      "epoch:4460, weight:[2.03929433 1.26185675], bias:-1.5694680537723285, loss:0.544529214531274\n",
      "epoch:4461, weight:[2.03956873 1.26191314], bias:-1.569624234443135, loss:0.5445189271825225\n",
      "epoch:4462, weight:[2.03984311 1.2619695 ], bias:-1.569780396596663, loss:0.5445086410513035\n",
      "epoch:4463, weight:[2.04011749 1.26202584], bias:-1.569936540238401, loss:0.5444983561372523\n",
      "epoch:4464, weight:[2.04039187 1.26208216], bias:-1.5700926653738354, loss:0.5444880724400061\n",
      "epoch:4465, weight:[2.04066623 1.26213847], bias:-1.5702487720084508, loss:0.5444777899592009\n",
      "epoch:4466, weight:[2.04094059 1.26219475], bias:-1.5704048601477296, loss:0.5444675086944737\n",
      "epoch:4467, weight:[2.04121494 1.26225101], bias:-1.5705609297971521, loss:0.5444572286454614\n",
      "epoch:4468, weight:[2.04148929 1.26230725], bias:-1.5707169809621964, loss:0.5444469498118013\n",
      "epoch:4469, weight:[2.04176362 1.26236347], bias:-1.5708730136483384, loss:0.5444366721931314\n",
      "epoch:4470, weight:[2.04203795 1.26241967], bias:-1.5710290278610521, loss:0.5444263957890884\n",
      "epoch:4471, weight:[2.04231227 1.26247585], bias:-1.5711850236058094, loss:0.5444161205993109\n",
      "epoch:4472, weight:[2.04258658 1.26253201], bias:-1.57134100088808, loss:0.5444058466234366\n",
      "epoch:4473, weight:[2.04286089 1.26258814], bias:-1.5714969597133313, loss:0.5443955738611043\n",
      "epoch:4474, weight:[2.04313519 1.26264426], bias:-1.5716529000870292, loss:0.5443853023119524\n",
      "epoch:4475, weight:[2.04340948 1.26270036], bias:-1.571808822014637, loss:0.5443750319756194\n",
      "epoch:4476, weight:[2.04368376 1.26275644], bias:-1.5719647255016156, loss:0.5443647628517448\n",
      "epoch:4477, weight:[2.04395804 1.26281249], bias:-1.5721206105534247, loss:0.5443544949399677\n",
      "epoch:4478, weight:[2.04423231 1.26286853], bias:-1.5722764771755213, loss:0.5443442282399273\n",
      "epoch:4479, weight:[2.04450657 1.26292455], bias:-1.5724323253733605, loss:0.5443339627512637\n",
      "epoch:4480, weight:[2.04478083 1.26298054], bias:-1.572588155152395, loss:0.5443236984736165\n",
      "epoch:4481, weight:[2.04505507 1.26303652], bias:-1.5727439665180758, loss:0.5443134354066259\n",
      "epoch:4482, weight:[2.04532931 1.26309247], bias:-1.5728997594758516, loss:0.5443031735499324\n",
      "epoch:4483, weight:[2.04560354 1.26314841], bias:-1.573055534031169, loss:0.5442929129031764\n",
      "epoch:4484, weight:[2.04587777 1.26320432], bias:-1.5732112901894726, loss:0.5442826534659989\n",
      "epoch:4485, weight:[2.04615198 1.26326022], bias:-1.5733670279562049, loss:0.5442723952380407\n",
      "epoch:4486, weight:[2.04642619 1.26331609], bias:-1.573522747336806, loss:0.5442621382189432\n",
      "epoch:4487, weight:[2.04670039 1.26337195], bias:-1.5736784483367146, loss:0.5442518824083475\n",
      "epoch:4488, weight:[2.04697459 1.26342778], bias:-1.5738341309613666, loss:0.544241627805896\n",
      "epoch:4489, weight:[2.04724877 1.26348359], bias:-1.5739897952161963, loss:0.54423137441123\n",
      "epoch:4490, weight:[2.04752295 1.26353939], bias:-1.5741454411066356, loss:0.5442211222239918\n",
      "epoch:4491, weight:[2.04779713 1.26359516], bias:-1.5743010686381143, loss:0.5442108712438237\n",
      "epoch:4492, weight:[2.04807129 1.26365091], bias:-1.5744566778160605, loss:0.5442006214703684\n",
      "epoch:4493, weight:[2.04834545 1.26370665], bias:-1.5746122686458996, loss:0.5441903729032685\n",
      "epoch:4494, weight:[2.0486196  1.26376236], bias:-1.5747678411330557, loss:0.5441801255421673\n",
      "epoch:4495, weight:[2.04889374 1.26381805], bias:-1.5749233952829502, loss:0.5441698793867077\n",
      "epoch:4496, weight:[2.04916787 1.26387372], bias:-1.5750789311010027, loss:0.5441596344365331\n",
      "epoch:4497, weight:[2.049442   1.26392938], bias:-1.5752344485926304, loss:0.5441493906912874\n",
      "epoch:4498, weight:[2.04971612 1.26398501], bias:-1.575389947763249, loss:0.5441391481506146\n",
      "epoch:4499, weight:[2.04999023 1.26404062], bias:-1.5755454286182713, loss:0.5441289068141583\n",
      "epoch:4500, weight:[2.05026434 1.26409621], bias:-1.575700891163109, loss:0.5441186666815633\n",
      "epoch:4501, weight:[2.05053843 1.26415178], bias:-1.575856335403171, loss:0.5441084277524738\n",
      "epoch:4502, weight:[2.05081252 1.26420733], bias:-1.5760117613438642, loss:0.5440981900265347\n",
      "epoch:4503, weight:[2.0510866  1.26426286], bias:-1.5761671689905938, loss:0.544087953503391\n",
      "epoch:4504, weight:[2.05136068 1.26431837], bias:-1.5763225583487626, loss:0.5440777181826877\n",
      "epoch:4505, weight:[2.05163475 1.26437387], bias:-1.5764779294237714, loss:0.5440674840640706\n",
      "epoch:4506, weight:[2.05190881 1.26442934], bias:-1.576633282221019, loss:0.5440572511471848\n",
      "epoch:4507, weight:[2.05218286 1.26448479], bias:-1.576788616745902, loss:0.5440470194316767\n",
      "epoch:4508, weight:[2.0524569  1.26454022], bias:-1.576943933003815, loss:0.5440367889171921\n",
      "epoch:4509, weight:[2.05273094 1.26459563], bias:-1.5770992310001506, loss:0.5440265596033769\n",
      "epoch:4510, weight:[2.05300497 1.26465102], bias:-1.5772545107402993, loss:0.5440163314898782\n",
      "epoch:4511, weight:[2.05327899 1.26470639], bias:-1.5774097722296494, loss:0.5440061045763424\n",
      "epoch:4512, weight:[2.05355301 1.26476174], bias:-1.5775650154735874, loss:0.5439958788624165\n",
      "epoch:4513, weight:[2.05382701 1.26481707], bias:-1.5777202404774973, loss:0.5439856543477476\n",
      "epoch:4514, weight:[2.05410101 1.26487238], bias:-1.5778754472467615, loss:0.543975431031983\n",
      "epoch:4515, weight:[2.054375   1.26492767], bias:-1.5780306357867602, loss:0.5439652089147703\n",
      "epoch:4516, weight:[2.05464899 1.26498294], bias:-1.5781858061028713, loss:0.5439549879957575\n",
      "epoch:4517, weight:[2.05492297 1.26503819], bias:-1.5783409582004708, loss:0.5439447682745924\n",
      "epoch:4518, weight:[2.05519694 1.26509342], bias:-1.5784960920849327, loss:0.5439345497509233\n",
      "epoch:4519, weight:[2.0554709  1.26514863], bias:-1.578651207761629, loss:0.5439243324243983\n",
      "epoch:4520, weight:[2.05574485 1.26520382], bias:-1.5788063052359294, loss:0.5439141162946666\n",
      "epoch:4521, weight:[2.0560188  1.26525899], bias:-1.5789613845132018, loss:0.5439039013613768\n",
      "epoch:4522, weight:[2.05629274 1.26531414], bias:-1.5791164455988118, loss:0.5438936876241779\n",
      "epoch:4523, weight:[2.05656667 1.26536927], bias:-1.579271488498123, loss:0.5438834750827194\n",
      "epoch:4524, weight:[2.0568406  1.26542438], bias:-1.579426513216497, loss:0.5438732637366507\n",
      "epoch:4525, weight:[2.05711451 1.26547947], bias:-1.5795815197592935, loss:0.5438630535856214\n",
      "epoch:4526, weight:[2.05738842 1.26553454], bias:-1.57973650813187, loss:0.5438528446292816\n",
      "epoch:4527, weight:[2.05766233 1.26558959], bias:-1.5798914783395817, loss:0.5438426368672816\n",
      "epoch:4528, weight:[2.05793622 1.26564462], bias:-1.5800464303877821, loss:0.5438324302992714\n",
      "epoch:4529, weight:[2.05821011 1.26569963], bias:-1.5802013642818227, loss:0.543822224924902\n",
      "epoch:4530, weight:[2.05848399 1.26575462], bias:-1.5803562800270525, loss:0.5438120207438236\n",
      "epoch:4531, weight:[2.05875786 1.26580959], bias:-1.580511177628819, loss:0.5438018177556879\n",
      "epoch:4532, weight:[2.05903172 1.26586454], bias:-1.5806660570924673, loss:0.5437916159601456\n",
      "epoch:4533, weight:[2.05930558 1.26591947], bias:-1.5808209184233404, loss:0.5437814153568484\n",
      "epoch:4534, weight:[2.05957943 1.26597439], bias:-1.5809757616267794, loss:0.5437712159454479\n",
      "epoch:4535, weight:[2.05985327 1.26602928], bias:-1.5811305867081236, loss:0.5437610177255959\n",
      "epoch:4536, weight:[2.06012711 1.26608415], bias:-1.5812853936727096, loss:0.5437508206969445\n",
      "epoch:4537, weight:[2.06040093 1.266139  ], bias:-1.5814401825258726, loss:0.5437406248591463\n",
      "epoch:4538, weight:[2.06067475 1.26619383], bias:-1.5815949532729454, loss:0.5437304302118531\n",
      "epoch:4539, weight:[2.06094856 1.26624864], bias:-1.5817497059192591, loss:0.5437202367547181\n",
      "epoch:4540, weight:[2.06122237 1.26630343], bias:-1.5819044404701423, loss:0.5437100444873942\n",
      "epoch:4541, weight:[2.06149617 1.26635821], bias:-1.582059156930922, loss:0.5436998534095344\n",
      "epoch:4542, weight:[2.06176995 1.26641296], bias:-1.5822138553069225, loss:0.5436896635207922\n",
      "epoch:4543, weight:[2.06204374 1.26646769], bias:-1.582368535603467, loss:0.543679474820821\n",
      "epoch:4544, weight:[2.06231751 1.2665224 ], bias:-1.5825231978258756, loss:0.5436692873092747\n",
      "epoch:4545, weight:[2.06259128 1.2665771 ], bias:-1.5826778419794674, loss:0.5436591009858073\n",
      "epoch:4546, weight:[2.06286504 1.26663177], bias:-1.582832468069559, loss:0.5436489158500728\n",
      "epoch:4547, weight:[2.06313879 1.26668642], bias:-1.5829870761014646, loss:0.5436387319017256\n",
      "epoch:4548, weight:[2.06341253 1.26674106], bias:-1.583141666080497, loss:0.5436285491404206\n",
      "epoch:4549, weight:[2.06368627 1.26679567], bias:-1.5832962380119664, loss:0.5436183675658124\n",
      "epoch:4550, weight:[2.06396    1.26685026], bias:-1.5834507919011815, loss:0.5436081871775561\n",
      "epoch:4551, weight:[2.06423372 1.26690484], bias:-1.5836053277534488, loss:0.5435980079753069\n",
      "epoch:4552, weight:[2.06450743 1.26695939], bias:-1.5837598455740725, loss:0.5435878299587201\n",
      "epoch:4553, weight:[2.06478114 1.26701393], bias:-1.583914345368355, loss:0.543577653127452\n",
      "epoch:4554, weight:[2.06505484 1.26706844], bias:-1.5840688271415968, loss:0.5435674774811576\n",
      "epoch:4555, weight:[2.06532853 1.26712294], bias:-1.5842232908990959, loss:0.5435573030194936\n",
      "epoch:4556, weight:[2.06560221 1.26717741], bias:-1.5843777366461487, loss:0.543547129742116\n",
      "epoch:4557, weight:[2.06587589 1.26723187], bias:-1.5845321643880494, loss:0.5435369576486815\n",
      "epoch:4558, weight:[2.06614956 1.2672863 ], bias:-1.5846865741300904, loss:0.5435267867388467\n",
      "epoch:4559, weight:[2.06642322 1.26734072], bias:-1.5848409658775617, loss:0.5435166170122685\n",
      "epoch:4560, weight:[2.06669687 1.26739512], bias:-1.5849953396357517, loss:0.5435064484686041\n",
      "epoch:4561, weight:[2.06697052 1.26744949], bias:-1.5851496954099462, loss:0.5434962811075107\n",
      "epoch:4562, weight:[2.06724416 1.26750385], bias:-1.5853040332054296, loss:0.5434861149286461\n",
      "epoch:4563, weight:[2.06751779 1.26755819], bias:-1.585458353027484, loss:0.5434759499316679\n",
      "epoch:4564, weight:[2.06779141 1.26761251], bias:-1.5856126548813891, loss:0.543465786116234\n",
      "epoch:4565, weight:[2.06806503 1.2676668 ], bias:-1.5857669387724236, loss:0.5434556234820026\n",
      "epoch:4566, weight:[2.06833864 1.26772108], bias:-1.585921204705863, loss:0.5434454620286322\n",
      "epoch:4567, weight:[2.06861224 1.26777534], bias:-1.5860754526869816, loss:0.5434353017557813\n",
      "epoch:4568, weight:[2.06888583 1.26782958], bias:-1.5862296827210514, loss:0.5434251426631086\n",
      "epoch:4569, weight:[2.06915942 1.2678838 ], bias:-1.5863838948133422, loss:0.5434149847502732\n",
      "epoch:4570, weight:[2.069433 1.267938], bias:-1.586538088969122, loss:0.5434048280169343\n",
      "epoch:4571, weight:[2.06970657 1.26799218], bias:-1.586692265193657, loss:0.5433946724627513\n",
      "epoch:4572, weight:[2.06998013 1.26804634], bias:-1.586846423492211, loss:0.543384518087384\n",
      "epoch:4573, weight:[2.07025368 1.26810049], bias:-1.587000563870046, loss:0.5433743648904922\n",
      "epoch:4574, weight:[2.07052723 1.26815461], bias:-1.5871546863324217, loss:0.5433642128717358\n",
      "epoch:4575, weight:[2.07080077 1.26820871], bias:-1.5873087908845962, loss:0.5433540620307747\n",
      "epoch:4576, weight:[2.0710743  1.26826279], bias:-1.5874628775318254, loss:0.54334391236727\n",
      "epoch:4577, weight:[2.07134783 1.26831686], bias:-1.5876169462793632, loss:0.543333763880882\n",
      "epoch:4578, weight:[2.07162135 1.2683709 ], bias:-1.5877709971324614, loss:0.5433236165712715\n",
      "epoch:4579, weight:[2.07189486 1.26842492], bias:-1.5879250300963699, loss:0.5433134704380999\n",
      "epoch:4580, weight:[2.07216836 1.26847893], bias:-1.5880790451763367, loss:0.5433033254810281\n",
      "epoch:4581, weight:[2.07244186 1.26853291], bias:-1.5882330423776074, loss:0.5432931816997179\n",
      "epoch:4582, weight:[2.07271534 1.26858688], bias:-1.5883870217054261, loss:0.5432830390938307\n",
      "epoch:4583, weight:[2.07298882 1.26864083], bias:-1.5885409831650346, loss:0.5432728976630288\n",
      "epoch:4584, weight:[2.07326229 1.26869475], bias:-1.5886949267616726, loss:0.5432627574069736\n",
      "epoch:4585, weight:[2.07353576 1.26874866], bias:-1.5888488525005782, loss:0.5432526183253281\n",
      "epoch:4586, weight:[2.07380922 1.26880255], bias:-1.589002760386987, loss:0.5432424804177546\n",
      "epoch:4587, weight:[2.07408267 1.26885642], bias:-1.589156650426133, loss:0.5432323436839156\n",
      "epoch:4588, weight:[2.07435611 1.26891026], bias:-1.589310522623248, loss:0.5432222081234741\n",
      "epoch:4589, weight:[2.07462954 1.26896409], bias:-1.589464376983562, loss:0.5432120737360933\n",
      "epoch:4590, weight:[2.07490297 1.2690179 ], bias:-1.5896182135123025, loss:0.5432019405214366\n",
      "epoch:4591, weight:[2.07517639 1.26907169], bias:-1.5897720322146958, loss:0.5431918084791671\n",
      "epoch:4592, weight:[2.0754498  1.26912546], bias:-1.5899258330959654, loss:0.5431816776089492\n",
      "epoch:4593, weight:[2.0757232  1.26917922], bias:-1.5900796161613333, loss:0.5431715479104462\n",
      "epoch:4594, weight:[2.0759966  1.26923295], bias:-1.5902333814160194, loss:0.5431614193833226\n",
      "epoch:4595, weight:[2.07626999 1.26928666], bias:-1.5903871288652416, loss:0.5431512920272428\n",
      "epoch:4596, weight:[2.07654337 1.26934035], bias:-1.5905408585142156, loss:0.5431411658418711\n",
      "epoch:4597, weight:[2.07681674 1.26939403], bias:-1.5906945703681552, loss:0.5431310408268724\n",
      "epoch:4598, weight:[2.07709011 1.26944768], bias:-1.5908482644322726, loss:0.5431209169819115\n",
      "epoch:4599, weight:[2.07736347 1.26950132], bias:-1.5910019407117775, loss:0.5431107943066537\n",
      "epoch:4600, weight:[2.07763682 1.26955493], bias:-1.591155599211878, loss:0.5431006728007642\n",
      "epoch:4601, weight:[2.07791016 1.26960853], bias:-1.59130923993778, loss:0.5430905524639088\n",
      "epoch:4602, weight:[2.0781835  1.26966211], bias:-1.5914628628946872, loss:0.5430804332957533\n",
      "epoch:4603, weight:[2.07845683 1.26971566], bias:-1.5916164680878018, loss:0.543070315295963\n",
      "epoch:4604, weight:[2.07873015 1.2697692 ], bias:-1.5917700555223238, loss:0.5430601984642048\n",
      "epoch:4605, weight:[2.07900346 1.26982272], bias:-1.591923625203451, loss:0.5430500828001448\n",
      "epoch:4606, weight:[2.07927676 1.26987622], bias:-1.5920771771363795, loss:0.5430399683034496\n",
      "epoch:4607, weight:[2.07955006 1.2699297 ], bias:-1.5922307113263034, loss:0.543029854973786\n",
      "epoch:4608, weight:[2.07982335 1.26998316], bias:-1.5923842277784146, loss:0.543019742810821\n",
      "epoch:4609, weight:[2.08009664 1.2700366 ], bias:-1.5925377264979033, loss:0.5430096318142213\n",
      "epoch:4610, weight:[2.08036991 1.27009003], bias:-1.5926912074899573, loss:0.5429995219836552\n",
      "epoch:4611, weight:[2.08064318 1.27014343], bias:-1.5928446707597628, loss:0.5429894133187895\n",
      "epoch:4612, weight:[2.08091644 1.27019681], bias:-1.592998116312504, loss:0.5429793058192921\n",
      "epoch:4613, weight:[2.08118969 1.27025018], bias:-1.593151544153363, loss:0.5429691994848311\n",
      "epoch:4614, weight:[2.08146293 1.27030352], bias:-1.59330495428752, loss:0.5429590943150747\n",
      "epoch:4615, weight:[2.08173617 1.27035685], bias:-1.593458346720153, loss:0.5429489903096916\n",
      "epoch:4616, weight:[2.0820094  1.27041015], bias:-1.5936117214564385, loss:0.5429388874683496\n",
      "epoch:4617, weight:[2.08228262 1.27046344], bias:-1.5937650785015505, loss:0.542928785790718\n",
      "epoch:4618, weight:[2.08255584 1.27051671], bias:-1.5939184178606614, loss:0.5429186852764659\n",
      "epoch:4619, weight:[2.08282904 1.27056996], bias:-1.5940717395389412, loss:0.542908585925262\n",
      "epoch:4620, weight:[2.08310224 1.27062319], bias:-1.5942250435415586, loss:0.542898487736776\n",
      "epoch:4621, weight:[2.08337543 1.2706764 ], bias:-1.5943783298736798, loss:0.5428883907106775\n",
      "epoch:4622, weight:[2.08364862 1.27072959], bias:-1.594531598540469, loss:0.542878294846636\n",
      "epoch:4623, weight:[2.08392179 1.27078276], bias:-1.594684849547089, loss:0.5428682001443217\n",
      "epoch:4624, weight:[2.08419496 1.27083592], bias:-1.5948380828986997, loss:0.5428581066034048\n",
      "epoch:4625, weight:[2.08446812 1.27088905], bias:-1.5949912986004597, loss:0.5428480142235556\n",
      "epoch:4626, weight:[2.08474128 1.27094216], bias:-1.5951444966575257, loss:0.5428379230044446\n",
      "epoch:4627, weight:[2.08501442 1.27099526], bias:-1.5952976770750522, loss:0.5428278329457425\n",
      "epoch:4628, weight:[2.08528756 1.27104834], bias:-1.5954508398581917, loss:0.5428177440471207\n",
      "epoch:4629, weight:[2.08556069 1.27110139], bias:-1.5956039850120947, loss:0.54280765630825\n",
      "epoch:4630, weight:[2.08583381 1.27115443], bias:-1.5957571125419099, loss:0.5427975697288019\n",
      "epoch:4631, weight:[2.08610693 1.27120745], bias:-1.5959102224527841, loss:0.5427874843084477\n",
      "epoch:4632, weight:[2.08638003 1.27126045], bias:-1.596063314749862, loss:0.5427774000468595\n",
      "epoch:4633, weight:[2.08665313 1.27131343], bias:-1.5962163894382861, loss:0.5427673169437089\n",
      "epoch:4634, weight:[2.08692623 1.27136639], bias:-1.5963694465231975, loss:0.5427572349986686\n",
      "epoch:4635, weight:[2.08719931 1.27141933], bias:-1.5965224860097347, loss:0.5427471542114104\n",
      "epoch:4636, weight:[2.08747239 1.27147226], bias:-1.5966755079030348, loss:0.5427370745816069\n",
      "epoch:4637, weight:[2.08774546 1.27152516], bias:-1.5968285122082326, loss:0.5427269961089315\n",
      "epoch:4638, weight:[2.08801852 1.27157805], bias:-1.5969814989304612, loss:0.5427169187930563\n",
      "epoch:4639, weight:[2.08829157 1.27163091], bias:-1.5971344680748516, loss:0.542706842633655\n",
      "epoch:4640, weight:[2.08856462 1.27168376], bias:-1.5972874196465328, loss:0.5426967676304006\n",
      "epoch:4641, weight:[2.08883766 1.27173659], bias:-1.5974403536506316, loss:0.542686693782967\n",
      "epoch:4642, weight:[2.08911069 1.2717894 ], bias:-1.5975932700922735, loss:0.5426766210910273\n",
      "epoch:4643, weight:[2.08938371 1.27184219], bias:-1.5977461689765815, loss:0.5426665495542561\n",
      "epoch:4644, weight:[2.08965673 1.27189496], bias:-1.597899050308677, loss:0.5426564791723272\n",
      "epoch:4645, weight:[2.08992974 1.27194771], bias:-1.598051914093679, loss:0.542646409944915\n",
      "epoch:4646, weight:[2.09020274 1.27200044], bias:-1.5982047603367053, loss:0.5426363418716941\n",
      "epoch:4647, weight:[2.09047573 1.27205315], bias:-1.598357589042871, loss:0.5426262749523386\n",
      "epoch:4648, weight:[2.09074872 1.27210585], bias:-1.5985104002172894, loss:0.5426162091865244\n",
      "epoch:4649, weight:[2.0910217  1.27215852], bias:-1.5986631938650722, loss:0.542606144573926\n",
      "epoch:4650, weight:[2.09129467 1.27221118], bias:-1.5988159699913287, loss:0.5425960811142188\n",
      "epoch:4651, weight:[2.09156763 1.27226382], bias:-1.5989687286011667, loss:0.5425860188070781\n",
      "epoch:4652, weight:[2.09184058 1.27231644], bias:-1.5991214696996918, loss:0.5425759576521799\n",
      "epoch:4653, weight:[2.09211353 1.27236904], bias:-1.5992741932920078, loss:0.5425658976491997\n",
      "epoch:4654, weight:[2.09238647 1.27242162], bias:-1.5994268993832164, loss:0.5425558387978142\n",
      "epoch:4655, weight:[2.0926594  1.27247418], bias:-1.5995795879784172, loss:0.542545781097699\n",
      "epoch:4656, weight:[2.09293233 1.27252672], bias:-1.599732259082708, loss:0.5425357245485309\n",
      "epoch:4657, weight:[2.09320524 1.27257925], bias:-1.5998849127011854, loss:0.5425256691499866\n",
      "epoch:4658, weight:[2.09347815 1.27263175], bias:-1.6000375488389427, loss:0.5425156149017428\n",
      "epoch:4659, weight:[2.09375105 1.27268424], bias:-1.6001901675010723, loss:0.5425055618034766\n",
      "epoch:4660, weight:[2.09402395 1.2727367 ], bias:-1.6003427686926643, loss:0.5424955098548652\n",
      "epoch:4661, weight:[2.09429683 1.27278915], bias:-1.6004953524188068, loss:0.5424854590555864\n",
      "epoch:4662, weight:[2.09456971 1.27284158], bias:-1.600647918684586, loss:0.5424754094053171\n",
      "epoch:4663, weight:[2.09484258 1.27289399], bias:-1.6008004674950862, loss:0.5424653609037355\n",
      "epoch:4664, weight:[2.09511544 1.27294638], bias:-1.6009529988553899, loss:0.5424553135505198\n",
      "epoch:4665, weight:[2.0953883  1.27299875], bias:-1.6011055127705773, loss:0.5424452673453479\n",
      "epoch:4666, weight:[2.09566115 1.27305111], bias:-1.6012580092457271, loss:0.5424352222878986\n",
      "epoch:4667, weight:[2.09593399 1.27310344], bias:-1.601410488285916, loss:0.5424251783778499\n",
      "epoch:4668, weight:[2.09620682 1.27315576], bias:-1.6015629498962183, loss:0.5424151356148811\n",
      "epoch:4669, weight:[2.09647964 1.27320806], bias:-1.6017153940817068, loss:0.5424050939986708\n",
      "epoch:4670, weight:[2.09675246 1.27326033], bias:-1.6018678208474526, loss:0.5423950535288985\n",
      "epoch:4671, weight:[2.09702527 1.27331259], bias:-1.6020202301985242, loss:0.5423850142052432\n",
      "epoch:4672, weight:[2.09729807 1.27336483], bias:-1.6021726221399886, loss:0.5423749760273849\n",
      "epoch:4673, weight:[2.09757087 1.27341705], bias:-1.6023249966769109, loss:0.542364938995003\n",
      "epoch:4674, weight:[2.09784365 1.27346926], bias:-1.602477353814354, loss:0.5423549031077776\n",
      "epoch:4675, weight:[2.09811643 1.27352144], bias:-1.6026296935573792, loss:0.5423448683653885\n",
      "epoch:4676, weight:[2.0983892  1.27357361], bias:-1.6027820159110455, loss:0.5423348347675165\n",
      "epoch:4677, weight:[2.09866197 1.27362575], bias:-1.6029343208804103, loss:0.5423248023138417\n",
      "epoch:4678, weight:[2.09893472 1.27367788], bias:-1.603086608470529, loss:0.5423147710040452\n",
      "epoch:4679, weight:[2.09920747 1.27372999], bias:-1.603238878686455, loss:0.5423047408378076\n",
      "epoch:4680, weight:[2.09948021 1.27378208], bias:-1.60339113153324, loss:0.5422947118148099\n",
      "epoch:4681, weight:[2.09975294 1.27383415], bias:-1.6035433670159334, loss:0.5422846839347337\n",
      "epoch:4682, weight:[2.10002567 1.2738862 ], bias:-1.6036955851395829, loss:0.5422746571972603\n",
      "epoch:4683, weight:[2.10029839 1.27393824], bias:-1.6038477859092342, loss:0.5422646316020713\n",
      "epoch:4684, weight:[2.1005711  1.27399025], bias:-1.6039999693299312, loss:0.5422546071488488\n",
      "epoch:4685, weight:[2.1008438  1.27404225], bias:-1.6041521354067159, loss:0.5422445838372743\n",
      "epoch:4686, weight:[2.10111649 1.27409423], bias:-1.6043042841446282, loss:0.5422345616670303\n",
      "epoch:4687, weight:[2.10138918 1.27414618], bias:-1.6044564155487062, loss:0.5422245406377995\n",
      "epoch:4688, weight:[2.10166186 1.27419813], bias:-1.6046085296239863, loss:0.5422145207492641\n",
      "epoch:4689, weight:[2.10193453 1.27425005], bias:-1.6047606263755025, loss:0.5422045020011069\n",
      "epoch:4690, weight:[2.10220719 1.27430195], bias:-1.6049127058082873, loss:0.5421944843930115\n",
      "epoch:4691, weight:[2.10247985 1.27435383], bias:-1.6050647679273709, loss:0.5421844679246604\n",
      "epoch:4692, weight:[2.1027525 1.2744057], bias:-1.605216812737782, loss:0.5421744525957368\n",
      "epoch:4693, weight:[2.10302514 1.27445755], bias:-1.6053688402445472, loss:0.542164438405925\n",
      "epoch:4694, weight:[2.10329777 1.27450937], bias:-1.6055208504526912, loss:0.5421544253549082\n",
      "epoch:4695, weight:[2.1035704  1.27456118], bias:-1.605672843367237, loss:0.5421444134423706\n",
      "epoch:4696, weight:[2.10384301 1.27461297], bias:-1.605824818993205, loss:0.5421344026679962\n",
      "epoch:4697, weight:[2.10411562 1.27466475], bias:-1.6059767773356146, loss:0.5421243930314693\n",
      "epoch:4698, weight:[2.10438823 1.2747165 ], bias:-1.6061287183994828, loss:0.5421143845324743\n",
      "epoch:4699, weight:[2.10466082 1.27476823], bias:-1.6062806421898246, loss:0.5421043771706959\n",
      "epoch:4700, weight:[2.10493341 1.27481995], bias:-1.6064325487116533, loss:0.5420943709458191\n",
      "epoch:4701, weight:[2.10520599 1.27487165], bias:-1.6065844379699803, loss:0.5420843658575287\n",
      "epoch:4702, weight:[2.10547856 1.27492333], bias:-1.606736309969815, loss:0.5420743619055105\n",
      "epoch:4703, weight:[2.10575112 1.27497499], bias:-1.606888164716165, loss:0.5420643590894495\n",
      "epoch:4704, weight:[2.10602368 1.27502663], bias:-1.6070400022140359, loss:0.5420543574090313\n",
      "epoch:4705, weight:[2.10629623 1.27507825], bias:-1.6071918224684314, loss:0.5420443568639416\n",
      "epoch:4706, weight:[2.10656877 1.27512985], bias:-1.6073436254843534, loss:0.5420343574538669\n",
      "epoch:4707, weight:[2.1068413  1.27518144], bias:-1.6074954112668018, loss:0.5420243591784929\n",
      "epoch:4708, weight:[2.10711383 1.27523301], bias:-1.6076471798207748, loss:0.542014362037506\n",
      "epoch:4709, weight:[2.10738634 1.27528456], bias:-1.6077989311512684, loss:0.542004366030593\n",
      "epoch:4710, weight:[2.10765885 1.27533609], bias:-1.607950665263277, loss:0.5419943711574404\n",
      "epoch:4711, weight:[2.10793136 1.2753876 ], bias:-1.6081023821617926, loss:0.5419843774177355\n",
      "epoch:4712, weight:[2.10820385 1.27543909], bias:-1.608254081851806, loss:0.5419743848111649\n",
      "epoch:4713, weight:[2.10847634 1.27549057], bias:-1.6084057643383058, loss:0.5419643933374163\n",
      "epoch:4714, weight:[2.10874882 1.27554202], bias:-1.6085574296262783, loss:0.541954402996177\n",
      "epoch:4715, weight:[2.10902129 1.27559346], bias:-1.6087090777207087, loss:0.5419444137871346\n",
      "epoch:4716, weight:[2.10929375 1.27564488], bias:-1.6088607086265796, loss:0.5419344257099773\n",
      "epoch:4717, weight:[2.10956621 1.27569628], bias:-1.609012322348872, loss:0.5419244387643927\n",
      "epoch:4718, weight:[2.10983865 1.27574766], bias:-1.609163918892565, loss:0.5419144529500692\n",
      "epoch:4719, weight:[2.1101111  1.27579902], bias:-1.609315498262636, loss:0.5419044682666954\n",
      "epoch:4720, weight:[2.11038353 1.27585037], bias:-1.6094670604640602, loss:0.5418944847139596\n",
      "epoch:4721, weight:[2.11065595 1.2759017 ], bias:-1.609618605501811, loss:0.5418845022915509\n",
      "epoch:4722, weight:[2.11092837 1.275953  ], bias:-1.6097701333808598, loss:0.541874520999158\n",
      "epoch:4723, weight:[2.11120078 1.27600429], bias:-1.6099216441061766, loss:0.5418645408364701\n",
      "epoch:4724, weight:[2.11147318 1.27605557], bias:-1.6100731376827289, loss:0.5418545618031764\n",
      "epoch:4725, weight:[2.11174558 1.27610682], bias:-1.6102246141154826, loss:0.5418445838989668\n",
      "epoch:4726, weight:[2.11201796 1.27615805], bias:-1.610376073409402, loss:0.5418346071235308\n",
      "epoch:4727, weight:[2.11229034 1.27620927], bias:-1.6105275155694487, loss:0.5418246314765583\n",
      "epoch:4728, weight:[2.11256271 1.27626047], bias:-1.6106789406005835, loss:0.5418146569577394\n",
      "epoch:4729, weight:[2.11283508 1.27631164], bias:-1.6108303485077644, loss:0.5418046835667643\n",
      "epoch:4730, weight:[2.11310743 1.27636281], bias:-1.610981739295948, loss:0.5417947113033235\n",
      "epoch:4731, weight:[2.11337978 1.27641395], bias:-1.6111331129700888, loss:0.5417847401671076\n",
      "epoch:4732, weight:[2.11365212 1.27646507], bias:-1.6112844695351396, loss:0.5417747701578071\n",
      "epoch:4733, weight:[2.11392445 1.27651618], bias:-1.6114358089960512, loss:0.5417648012751136\n",
      "epoch:4734, weight:[2.11419678 1.27656726], bias:-1.6115871313577725, loss:0.5417548335187179\n",
      "epoch:4735, weight:[2.11446909 1.27661833], bias:-1.6117384366252507, loss:0.5417448668883112\n",
      "epoch:4736, weight:[2.1147414  1.27666938], bias:-1.611889724803431, loss:0.5417349013835856\n",
      "epoch:4737, weight:[2.11501371 1.27672041], bias:-1.6120409958972566, loss:0.5417249370042323\n",
      "epoch:4738, weight:[2.115286   1.27677143], bias:-1.612192249911669, loss:0.5417149737499434\n",
      "epoch:4739, weight:[2.11555829 1.27682242], bias:-1.6123434868516078, loss:0.5417050116204111\n",
      "epoch:4740, weight:[2.11583056 1.2768734 ], bias:-1.6124947067220108, loss:0.5416950506153273\n",
      "epoch:4741, weight:[2.11610283 1.27692436], bias:-1.6126459095278136, loss:0.5416850907343851\n",
      "epoch:4742, weight:[2.1163751 1.2769753], bias:-1.6127970952739503, loss:0.5416751319772763\n",
      "epoch:4743, weight:[2.11664735 1.27702622], bias:-1.6129482639653532, loss:0.5416651743436943\n",
      "epoch:4744, weight:[2.1169196  1.27707712], bias:-1.6130994156069522, loss:0.5416552178333321\n",
      "epoch:4745, weight:[2.11719184 1.27712801], bias:-1.6132505502036758, loss:0.5416452624458827\n",
      "epoch:4746, weight:[2.11746407 1.27717888], bias:-1.6134016677604504, loss:0.5416353081810396\n",
      "epoch:4747, weight:[2.1177363  1.27722973], bias:-1.6135527682822006, loss:0.5416253550384961\n",
      "epoch:4748, weight:[2.11800851 1.27728056], bias:-1.6137038517738493, loss:0.5416154030179461\n",
      "epoch:4749, weight:[2.11828072 1.27733137], bias:-1.6138549182403175, loss:0.5416054521190834\n",
      "epoch:4750, weight:[2.11855292 1.27738216], bias:-1.614005967686524, loss:0.5415955023416024\n",
      "epoch:4751, weight:[2.11882512 1.27743294], bias:-1.6141570001173857, loss:0.5415855536851969\n",
      "epoch:4752, weight:[2.1190973  1.27748369], bias:-1.6143080155378184, loss:0.5415756061495616\n",
      "epoch:4753, weight:[2.11936948 1.27753443], bias:-1.6144590139527353, loss:0.5415656597343911\n",
      "epoch:4754, weight:[2.11964165 1.27758515], bias:-1.6146099953670479, loss:0.5415557144393803\n",
      "epoch:4755, weight:[2.11991381 1.27763586], bias:-1.614760959785666, loss:0.5415457702642242\n",
      "epoch:4756, weight:[2.12018597 1.27768654], bias:-1.6149119072134976, loss:0.5415358272086179\n",
      "epoch:4757, weight:[2.12045811 1.27773721], bias:-1.6150628376554486, loss:0.5415258852722568\n",
      "epoch:4758, weight:[2.12073025 1.27778786], bias:-1.6152137511164228, loss:0.5415159444548361\n",
      "epoch:4759, weight:[2.12100238 1.27783849], bias:-1.6153646476013228, loss:0.541506004756052\n",
      "epoch:4760, weight:[2.12127451 1.2778891 ], bias:-1.615515527115049, loss:0.5414960661756\n",
      "epoch:4761, weight:[2.12154662 1.27793969], bias:-1.6156663896624999, loss:0.5414861287131765\n",
      "epoch:4762, weight:[2.12181873 1.27799027], bias:-1.6158172352485722, loss:0.5414761923684777\n",
      "epoch:4763, weight:[2.12209083 1.27804082], bias:-1.6159680638781608, loss:0.5414662571411996\n",
      "epoch:4764, weight:[2.12236292 1.27809136], bias:-1.6161188755561586, loss:0.5414563230310394\n",
      "epoch:4765, weight:[2.12263501 1.27814188], bias:-1.6162696702874568, loss:0.5414463900376935\n",
      "epoch:4766, weight:[2.12290709 1.27819239], bias:-1.6164204480769446, loss:0.5414364581608591\n",
      "epoch:4767, weight:[2.12317916 1.27824287], bias:-1.6165712089295097, loss:0.5414265274002331\n",
      "epoch:4768, weight:[2.12345122 1.27829334], bias:-1.6167219528500374, loss:0.5414165977555128\n",
      "epoch:4769, weight:[2.12372327 1.27834378], bias:-1.6168726798434117, loss:0.5414066692263961\n",
      "epoch:4770, weight:[2.12399532 1.27839421], bias:-1.617023389914514, loss:0.5413967418125802\n",
      "epoch:4771, weight:[2.12426735 1.27844463], bias:-1.617174083068225, loss:0.5413868155137637\n",
      "epoch:4772, weight:[2.12453939 1.27849502], bias:-1.6173247593094224, loss:0.5413768903296438\n",
      "epoch:4773, weight:[2.12481141 1.2785454 ], bias:-1.6174754186429827, loss:0.5413669662599189\n",
      "epoch:4774, weight:[2.12508342 1.27859575], bias:-1.6176260610737805, loss:0.5413570433042878\n",
      "epoch:4775, weight:[2.12535543 1.27864609], bias:-1.6177766866066883, loss:0.5413471214624488\n",
      "epoch:4776, weight:[2.12562743 1.27869641], bias:-1.6179272952465769, loss:0.5413372007341004\n",
      "epoch:4777, weight:[2.12589942 1.27874672], bias:-1.6180778869983155, loss:0.541327281118942\n",
      "epoch:4778, weight:[2.12617141 1.278797  ], bias:-1.6182284618667708, loss:0.5413173626166724\n",
      "epoch:4779, weight:[2.12644338 1.27884727], bias:-1.6183790198568084, loss:0.5413074452269909\n",
      "epoch:4780, weight:[2.12671535 1.27889752], bias:-1.618529560973292, loss:0.5412975289495974\n",
      "epoch:4781, weight:[2.12698731 1.27894775], bias:-1.6186800852210825, loss:0.5412876137841909\n",
      "epoch:4782, weight:[2.12725926 1.27899796], bias:-1.6188305926050401, loss:0.5412776997304714\n",
      "epoch:4783, weight:[2.12753121 1.27904816], bias:-1.6189810831300229, loss:0.541267786788139\n",
      "epoch:4784, weight:[2.12780315 1.27909834], bias:-1.6191315568008866, loss:0.5412578749568938\n",
      "epoch:4785, weight:[2.12807508 1.2791485 ], bias:-1.6192820136224857, loss:0.5412479642364363\n",
      "epoch:4786, weight:[2.128347   1.27919864], bias:-1.6194324535996725, loss:0.5412380546264667\n",
      "epoch:4787, weight:[2.12861891 1.27924876], bias:-1.6195828767372975, loss:0.541228146126686\n",
      "epoch:4788, weight:[2.12889082 1.27929886], bias:-1.6197332830402096, loss:0.5412182387367948\n",
      "epoch:4789, weight:[2.12916272 1.27934895], bias:-1.6198836725132555, loss:0.5412083324564944\n",
      "epoch:4790, weight:[2.12943461 1.27939902], bias:-1.6200340451612805, loss:0.5411984272854858\n",
      "epoch:4791, weight:[2.12970649 1.27944907], bias:-1.6201844009891275, loss:0.5411885232234703\n",
      "epoch:4792, weight:[2.12997837 1.2794991 ], bias:-1.6203347400016384, loss:0.5411786202701502\n",
      "epoch:4793, weight:[2.13025023 1.27954912], bias:-1.6204850622036524, loss:0.5411687184252264\n",
      "epoch:4794, weight:[2.13052209 1.27959912], bias:-1.6206353676000074, loss:0.5411588176884011\n",
      "epoch:4795, weight:[2.13079394 1.2796491 ], bias:-1.6207856561955392, loss:0.5411489180593763\n",
      "epoch:4796, weight:[2.13106579 1.27969906], bias:-1.620935927995082, loss:0.5411390195378547\n",
      "epoch:4797, weight:[2.13133762 1.279749  ], bias:-1.6210861830034677, loss:0.5411291221235384\n",
      "epoch:4798, weight:[2.13160945 1.27979893], bias:-1.6212364212255272, loss:0.5411192258161299\n",
      "epoch:4799, weight:[2.13188127 1.27984883], bias:-1.621386642666089, loss:0.5411093306153322\n",
      "epoch:4800, weight:[2.13215309 1.27989872], bias:-1.6215368473299798, loss:0.5410994365208484\n",
      "epoch:4801, weight:[2.13242489 1.2799486 ], bias:-1.6216870352220247, loss:0.5410895435323813\n",
      "epoch:4802, weight:[2.13269669 1.27999845], bias:-1.6218372063470468, loss:0.5410796516496345\n",
      "epoch:4803, weight:[2.13296848 1.28004829], bias:-1.6219873607098672, loss:0.5410697608723113\n",
      "epoch:4804, weight:[2.13324026 1.2800981 ], bias:-1.6221374983153054, loss:0.5410598712001153\n",
      "epoch:4805, weight:[2.13351203 1.2801479 ], bias:-1.6222876191681792, loss:0.5410499826327507\n",
      "epoch:4806, weight:[2.1337838  1.28019769], bias:-1.6224377232733045, loss:0.5410400951699212\n",
      "epoch:4807, weight:[2.13405556 1.28024745], bias:-1.6225878106354952, loss:0.5410302088113312\n",
      "epoch:4808, weight:[2.13432731 1.2802972 ], bias:-1.6227378812595634, loss:0.5410203235566851\n",
      "epoch:4809, weight:[2.13459905 1.28034693], bias:-1.6228879351503198, loss:0.541010439405687\n",
      "epoch:4810, weight:[2.13487079 1.28039664], bias:-1.6230379723125727, loss:0.5410005563580419\n",
      "epoch:4811, weight:[2.13514251 1.28044633], bias:-1.623187992751129, loss:0.5409906744134547\n",
      "epoch:4812, weight:[2.13541423 1.280496  ], bias:-1.6233379964707935, loss:0.5409807935716306\n",
      "epoch:4813, weight:[2.13568594 1.28054566], bias:-1.6234879834763694, loss:0.5409709138322746\n",
      "epoch:4814, weight:[2.13595765 1.2805953 ], bias:-1.623637953772658, loss:0.5409610351950919\n",
      "epoch:4815, weight:[2.13622934 1.28064492], bias:-1.6237879073644588, loss:0.5409511576597885\n",
      "epoch:4816, weight:[2.13650103 1.28069453], bias:-1.6239378442565695, loss:0.54094128122607\n",
      "epoch:4817, weight:[2.13677271 1.28074411], bias:-1.6240877644537859, loss:0.5409314058936422\n",
      "epoch:4818, weight:[2.13704439 1.28079368], bias:-1.624237667960902, loss:0.5409215316622112\n",
      "epoch:4819, weight:[2.13731605 1.28084323], bias:-1.6243875547827102, loss:0.5409116585314836\n",
      "epoch:4820, weight:[2.13758771 1.28089277], bias:-1.6245374249240008, loss:0.5409017865011653\n",
      "epoch:4821, weight:[2.13785936 1.28094228], bias:-1.6246872783895625, loss:0.5408919155709632\n",
      "epoch:4822, weight:[2.138131   1.28099178], bias:-1.624837115184182, loss:0.540882045740584\n",
      "epoch:4823, weight:[2.13840263 1.28104126], bias:-1.6249869353126445, loss:0.5408721770097347\n",
      "epoch:4824, weight:[2.13867426 1.28109072], bias:-1.625136738779733, loss:0.5408623093781224\n",
      "epoch:4825, weight:[2.13894587 1.28114016], bias:-1.6252865255902291, loss:0.5408524428454543\n",
      "epoch:4826, weight:[2.13921748 1.28118959], bias:-1.6254362957489121, loss:0.5408425774114382\n",
      "epoch:4827, weight:[2.13948909 1.281239  ], bias:-1.62558604926056, loss:0.5408327130757811\n",
      "epoch:4828, weight:[2.13976068 1.28128839], bias:-1.6257357861299486, loss:0.5408228498381914\n",
      "epoch:4829, weight:[2.14003227 1.28133776], bias:-1.6258855063618523, loss:0.5408129876983766\n",
      "epoch:4830, weight:[2.14030385 1.28138712], bias:-1.6260352099610433, loss:0.5408031266560454\n",
      "epoch:4831, weight:[2.14057542 1.28143646], bias:-1.6261848969322923, loss:0.5407932667109056\n",
      "epoch:4832, weight:[2.14084698 1.28148578], bias:-1.626334567280368, loss:0.5407834078626661\n",
      "epoch:4833, weight:[2.14111854 1.28153508], bias:-1.6264842210100372, loss:0.540773550111035\n",
      "epoch:4834, weight:[2.14139008 1.28158436], bias:-1.6266338581260653, loss:0.5407636934557215\n",
      "epoch:4835, weight:[2.14166162 1.28163363], bias:-1.6267834786332156, loss:0.5407538378964346\n",
      "epoch:4836, weight:[2.14193316 1.28168288], bias:-1.6269330825362498, loss:0.5407439834328834\n",
      "epoch:4837, weight:[2.14220468 1.28173211], bias:-1.6270826698399274, loss:0.5407341300647773\n",
      "epoch:4838, weight:[2.1424762  1.28178133], bias:-1.6272322405490067, loss:0.5407242777918256\n",
      "epoch:4839, weight:[2.1427477  1.28183052], bias:-1.6273817946682436, loss:0.5407144266137381\n",
      "epoch:4840, weight:[2.1430192 1.2818797], bias:-1.6275313322023928, loss:0.540704576530225\n",
      "epoch:4841, weight:[2.1432907  1.28192886], bias:-1.6276808531562066, loss:0.5406947275409956\n",
      "epoch:4842, weight:[2.14356218 1.28197801], bias:-1.627830357534436, loss:0.5406848796457605\n",
      "epoch:4843, weight:[2.14383366 1.28202713], bias:-1.6279798453418297, loss:0.54067503284423\n",
      "epoch:4844, weight:[2.14410513 1.28207624], bias:-1.6281293165831352, loss:0.5406651871361148\n",
      "epoch:4845, weight:[2.14437659 1.28212533], bias:-1.628278771263098, loss:0.540655342521125\n",
      "epoch:4846, weight:[2.14464804 1.2821744 ], bias:-1.6284282093864615, loss:0.5406454989989721\n",
      "epoch:4847, weight:[2.14491949 1.28222346], bias:-1.6285776309579676, loss:0.5406356565693667\n",
      "epoch:4848, weight:[2.14519093 1.2822725 ], bias:-1.6287270359823565, loss:0.5406258152320205\n",
      "epoch:4849, weight:[2.14546236 1.28232152], bias:-1.6288764244643663, loss:0.540615974986644\n",
      "epoch:4850, weight:[2.14573378 1.28237052], bias:-1.6290257964087336, loss:0.5406061358329497\n",
      "epoch:4851, weight:[2.1460052  1.28241951], bias:-1.6291751518201931, loss:0.5405962977706484\n",
      "epoch:4852, weight:[2.1462766  1.28246847], bias:-1.6293244907034776, loss:0.5405864607994527\n",
      "epoch:4853, weight:[2.146548   1.28251742], bias:-1.6294738130633184, loss:0.5405766249190742\n",
      "epoch:4854, weight:[2.14681939 1.28256636], bias:-1.6296231189044448, loss:0.5405667901292251\n",
      "epoch:4855, weight:[2.14709077 1.28261527], bias:-1.629772408231584, loss:0.5405569564296181\n",
      "epoch:4856, weight:[2.14736215 1.28266417], bias:-1.6299216810494623, loss:0.5405471238199655\n",
      "epoch:4857, weight:[2.14763352 1.28271305], bias:-1.6300709373628035, loss:0.5405372922999798\n",
      "epoch:4858, weight:[2.14790488 1.28276191], bias:-1.6302201771763298, loss:0.5405274618693743\n",
      "epoch:4859, weight:[2.14817623 1.28281076], bias:-1.6303694004947615, loss:0.5405176325278618\n",
      "epoch:4860, weight:[2.14844757 1.28285959], bias:-1.6305186073228175, loss:0.5405078042751553\n",
      "epoch:4861, weight:[2.14871891 1.2829084 ], bias:-1.6306677976652144, loss:0.5404979771109686\n",
      "epoch:4862, weight:[2.14899024 1.28295719], bias:-1.6308169715266676, loss:0.5404881510350149\n",
      "epoch:4863, weight:[2.14926156 1.28300596], bias:-1.6309661289118902, loss:0.5404783260470081\n",
      "epoch:4864, weight:[2.14953287 1.28305472], bias:-1.6311152698255937, loss:0.5404685021466618\n",
      "epoch:4865, weight:[2.14980418 1.28310346], bias:-1.631264394272488, loss:0.5404586793336903\n",
      "epoch:4866, weight:[2.15007547 1.28315218], bias:-1.631413502257281, loss:0.5404488576078076\n",
      "epoch:4867, weight:[2.15034676 1.28320089], bias:-1.6315625937846792, loss:0.5404390369687284\n",
      "epoch:4868, weight:[2.15061804 1.28324958], bias:-1.6317116688593867, loss:0.5404292174161669\n",
      "epoch:4869, weight:[2.15088932 1.28329825], bias:-1.6318607274861063, loss:0.5404193989498377\n",
      "epoch:4870, weight:[2.15116058 1.2833469 ], bias:-1.632009769669539, loss:0.540409581569456\n",
      "epoch:4871, weight:[2.15143184 1.28339554], bias:-1.6321587954143837, loss:0.5403997652747368\n",
      "epoch:4872, weight:[2.15170309 1.28344416], bias:-1.6323078047253379, loss:0.5403899500653949\n",
      "epoch:4873, weight:[2.15197433 1.28349276], bias:-1.6324567976070972, loss:0.5403801359411461\n",
      "epoch:4874, weight:[2.15224556 1.28354134], bias:-1.6326057740643554, loss:0.5403703229017057\n",
      "epoch:4875, weight:[2.15251679 1.28358991], bias:-1.6327547341018045, loss:0.5403605109467895\n",
      "epoch:4876, weight:[2.15278801 1.28363845], bias:-1.6329036777241348, loss:0.5403507000761132\n",
      "epoch:4877, weight:[2.15305922 1.28368699], bias:-1.6330526049360348, loss:0.5403408902893929\n",
      "epoch:4878, weight:[2.15333042 1.2837355 ], bias:-1.6332015157421913, loss:0.5403310815863449\n",
      "epoch:4879, weight:[2.15360162 1.283784  ], bias:-1.6333504101472893, loss:0.5403212739666852\n",
      "epoch:4880, weight:[2.1538728  1.28383248], bias:-1.633499288156012, loss:0.5403114674301306\n",
      "epoch:4881, weight:[2.15414398 1.28388094], bias:-1.6336481497730408, loss:0.5403016619763977\n",
      "epoch:4882, weight:[2.15441515 1.28392938], bias:-1.6337969950030555, loss:0.5402918576052036\n",
      "epoch:4883, weight:[2.15468632 1.28397781], bias:-1.633945823850734, loss:0.5402820543162647\n",
      "epoch:4884, weight:[2.15495747 1.28402622], bias:-1.6340946363207525, loss:0.5402722521092987\n",
      "epoch:4885, weight:[2.15522862 1.28407461], bias:-1.6342434324177852, loss:0.5402624509840228\n",
      "epoch:4886, weight:[2.15549976 1.28412299], bias:-1.634392212146505, loss:0.5402526509401543\n",
      "epoch:4887, weight:[2.15577089 1.28417134], bias:-1.6345409755115827, loss:0.540242851977411\n",
      "epoch:4888, weight:[2.15604202 1.28421968], bias:-1.6346897225176873, loss:0.5402330540955106\n",
      "epoch:4889, weight:[2.15631313 1.28426801], bias:-1.6348384531694864, loss:0.5402232572941713\n",
      "epoch:4890, weight:[2.15658424 1.28431631], bias:-1.6349871674716454, loss:0.5402134615731112\n",
      "epoch:4891, weight:[2.15685534 1.2843646 ], bias:-1.6351358654288284, loss:0.5402036669320486\n",
      "epoch:4892, weight:[2.15712643 1.28441287], bias:-1.6352845470456971, loss:0.5401938733707017\n",
      "epoch:4893, weight:[2.15739752 1.28446113], bias:-1.6354332123269124, loss:0.5401840808887894\n",
      "epoch:4894, weight:[2.1576686  1.28450936], bias:-1.6355818612771325, loss:0.5401742894860306\n",
      "epoch:4895, weight:[2.15793966 1.28455758], bias:-1.6357304939010142, loss:0.540164499162144\n",
      "epoch:4896, weight:[2.15821073 1.28460579], bias:-1.6358791102032129, loss:0.5401547099168488\n",
      "epoch:4897, weight:[2.15848178 1.28465397], bias:-1.6360277101883818, loss:0.5401449217498645\n",
      "epoch:4898, weight:[2.15875282 1.28470214], bias:-1.6361762938611724, loss:0.5401351346609101\n",
      "epoch:4899, weight:[2.15902386 1.28475029], bias:-1.6363248612262347, loss:0.5401253486497055\n",
      "epoch:4900, weight:[2.15929489 1.28479842], bias:-1.6364734122882165, loss:0.5401155637159705\n",
      "epoch:4901, weight:[2.15956591 1.28484654], bias:-1.6366219470517644, loss:0.5401057798594251\n",
      "epoch:4902, weight:[2.15983693 1.28489464], bias:-1.636770465521523, loss:0.540095997079789\n",
      "epoch:4903, weight:[2.16010793 1.28494272], bias:-1.636918967702135, loss:0.5400862153767828\n",
      "epoch:4904, weight:[2.16037893 1.28499079], bias:-1.6370674535982415, loss:0.540076434750127\n",
      "epoch:4905, weight:[2.16064992 1.28503883], bias:-1.6372159232144818, loss:0.5400666551995418\n",
      "epoch:4906, weight:[2.1609209  1.28508686], bias:-1.6373643765554937, loss:0.5400568767247482\n",
      "epoch:4907, weight:[2.16119188 1.28513488], bias:-1.637512813625913, loss:0.5400470993254672\n",
      "epoch:4908, weight:[2.16146284 1.28518287], bias:-1.6376612344303736, loss:0.5400373230014196\n",
      "epoch:4909, weight:[2.1617338  1.28523085], bias:-1.6378096389735082, loss:0.5400275477523269\n",
      "epoch:4910, weight:[2.16200475 1.28527881], bias:-1.6379580272599472, loss:0.54001777357791\n",
      "epoch:4911, weight:[2.1622757  1.28532676], bias:-1.6381063992943194, loss:0.540008000477891\n",
      "epoch:4912, weight:[2.16254663 1.28537468], bias:-1.6382547550812523, loss:0.5399982284519912\n",
      "epoch:4913, weight:[2.16281756 1.28542259], bias:-1.638403094625371, loss:0.5399884574999326\n",
      "epoch:4914, weight:[2.16308848 1.28547049], bias:-1.6385514179312992, loss:0.5399786876214375\n",
      "epoch:4915, weight:[2.16335939 1.28551836], bias:-1.638699725003659, loss:0.5399689188162277\n",
      "epoch:4916, weight:[2.16363029 1.28556622], bias:-1.6388480158470704, loss:0.5399591510840257\n",
      "epoch:4917, weight:[2.16390119 1.28561406], bias:-1.638996290466152, loss:0.5399493844245538\n",
      "epoch:4918, weight:[2.16417207 1.28566189], bias:-1.6391445488655203, loss:0.5399396188375352\n",
      "epoch:4919, weight:[2.16444295 1.28570969], bias:-1.6392927910497905, loss:0.539929854322692\n",
      "epoch:4920, weight:[2.16471383 1.28575749], bias:-1.639441017023576, loss:0.5399200908797478\n",
      "epoch:4921, weight:[2.16498469 1.28580526], bias:-1.639589226791488, loss:0.5399103285084252\n",
      "epoch:4922, weight:[2.16525555 1.28585301], bias:-1.6397374203581363, loss:0.539900567208448\n",
      "epoch:4923, weight:[2.16552639 1.28590075], bias:-1.639885597728129, loss:0.5398908069795397\n",
      "epoch:4924, weight:[2.16579723 1.28594848], bias:-1.6400337589060725, loss:0.5398810478214233\n",
      "epoch:4925, weight:[2.16606807 1.28599618], bias:-1.6401819038965715, loss:0.5398712897338233\n",
      "epoch:4926, weight:[2.16633889 1.28604387], bias:-1.6403300327042285, loss:0.539861532716463\n",
      "epoch:4927, weight:[2.16660971 1.28609154], bias:-1.6404781453336448, loss:0.5398517767690667\n",
      "epoch:4928, weight:[2.16688052 1.28613919], bias:-1.64062624178942, loss:0.539842021891359\n",
      "epoch:4929, weight:[2.16715132 1.28618683], bias:-1.6407743220761515, loss:0.539832268083064\n",
      "epoch:4930, weight:[2.16742211 1.28623445], bias:-1.6409223861984352, loss:0.5398225153439064\n",
      "epoch:4931, weight:[2.16769289 1.28628205], bias:-1.6410704341608655, loss:0.5398127636736105\n",
      "epoch:4932, weight:[2.16796367 1.28632964], bias:-1.6412184659680347, loss:0.5398030130719018\n",
      "epoch:4933, weight:[2.16823444 1.28637721], bias:-1.6413664816245337, loss:0.5397932635385051\n",
      "epoch:4934, weight:[2.1685052  1.28642476], bias:-1.6415144811349516, loss:0.5397835150731456\n",
      "epoch:4935, weight:[2.16877596 1.28647229], bias:-1.6416624645038755, loss:0.5397737676755486\n",
      "epoch:4936, weight:[2.1690467  1.28651981], bias:-1.641810431735891, loss:0.5397640213454398\n",
      "epoch:4937, weight:[2.16931744 1.28656731], bias:-1.6419583828355822, loss:0.5397542760825446\n",
      "epoch:4938, weight:[2.16958817 1.2866148 ], bias:-1.642106317807531, loss:0.539744531886589\n",
      "epoch:4939, weight:[2.16985889 1.28666226], bias:-1.642254236656318, loss:0.539734788757299\n",
      "epoch:4940, weight:[2.1701296  1.28670971], bias:-1.6424021393865218, loss:0.5397250466944007\n",
      "epoch:4941, weight:[2.17040031 1.28675715], bias:-1.6425500260027193, loss:0.5397153056976205\n",
      "epoch:4942, weight:[2.17067101 1.28680456], bias:-1.6426978965094858, loss:0.5397055657666847\n",
      "epoch:4943, weight:[2.1709417  1.28685196], bias:-1.6428457509113952, loss:0.5396958269013201\n",
      "epoch:4944, weight:[2.17121238 1.28689934], bias:-1.642993589213019, loss:0.5396860891012534\n",
      "epoch:4945, weight:[2.17148305 1.28694671], bias:-1.6431414114189271, loss:0.5396763523662114\n",
      "epoch:4946, weight:[2.17175372 1.28699406], bias:-1.6432892175336884, loss:0.5396666166959215\n",
      "epoch:4947, weight:[2.17202438 1.28704139], bias:-1.6434370075618692, loss:0.5396568820901106\n",
      "epoch:4948, weight:[2.17229503 1.2870887 ], bias:-1.6435847815080347, loss:0.5396471485485062\n",
      "epoch:4949, weight:[2.17256567 1.287136  ], bias:-1.643732539376748, loss:0.539637416070836\n",
      "epoch:4950, weight:[2.1728363  1.28718328], bias:-1.6438802811725706, loss:0.5396276846568276\n",
      "epoch:4951, weight:[2.17310693 1.28723055], bias:-1.6440280069000623, loss:0.5396179543062091\n",
      "epoch:4952, weight:[2.17337755 1.28727779], bias:-1.6441757165637816, loss:0.539608225018708\n",
      "epoch:4953, weight:[2.17364816 1.28732502], bias:-1.6443234101682844, loss:0.5395984967940528\n",
      "epoch:4954, weight:[2.17391876 1.28737224], bias:-1.6444710877181257, loss:0.5395887696319722\n",
      "epoch:4955, weight:[2.17418936 1.28741943], bias:-1.6446187492178583, loss:0.5395790435321939\n",
      "epoch:4956, weight:[2.17445995 1.28746661], bias:-1.6447663946720337, loss:0.5395693184944472\n",
      "epoch:4957, weight:[2.17473052 1.28751378], bias:-1.6449140240852014, loss:0.5395595945184608\n",
      "epoch:4958, weight:[2.1750011  1.28756092], bias:-1.6450616374619091, loss:0.5395498716039632\n",
      "epoch:4959, weight:[2.17527166 1.28760805], bias:-1.6452092348067031, loss:0.5395401497506842\n",
      "epoch:4960, weight:[2.17554221 1.28765516], bias:-1.6453568161241279, loss:0.5395304289583525\n",
      "epoch:4961, weight:[2.17581276 1.28770226], bias:-1.645504381418726, loss:0.5395207092266978\n",
      "epoch:4962, weight:[2.1760833  1.28774934], bias:-1.6456519306950386, loss:0.5395109905554497\n",
      "epoch:4963, weight:[2.17635383 1.2877964 ], bias:-1.645799463957605, loss:0.5395012729443377\n",
      "epoch:4964, weight:[2.17662436 1.28784344], bias:-1.6459469812109628, loss:0.5394915563930919\n",
      "epoch:4965, weight:[2.17689487 1.28789047], bias:-1.6460944824596482, loss:0.5394818409014422\n",
      "epoch:4966, weight:[2.17716538 1.28793748], bias:-1.646241967708195, loss:0.5394721264691189\n",
      "epoch:4967, weight:[2.17743588 1.28798448], bias:-1.646389436961136, loss:0.5394624130958525\n",
      "epoch:4968, weight:[2.17770637 1.28803146], bias:-1.646536890223002, loss:0.5394527007813731\n",
      "epoch:4969, weight:[2.17797685 1.28807842], bias:-1.646684327498322, loss:0.5394429895254116\n",
      "epoch:4970, weight:[2.17824733 1.28812536], bias:-1.6468317487916235, loss:0.5394332793276988\n",
      "epoch:4971, weight:[2.1785178  1.28817229], bias:-1.6469791541074323, loss:0.5394235701879657\n",
      "epoch:4972, weight:[2.17878826 1.2882192 ], bias:-1.6471265434502724, loss:0.5394138621059434\n",
      "epoch:4973, weight:[2.17905871 1.28826609], bias:-1.6472739168246662, loss:0.539404155081363\n",
      "epoch:4974, weight:[2.17932915 1.28831297], bias:-1.6474212742351342, loss:0.5393944491139561\n",
      "epoch:4975, weight:[2.17959959 1.28835983], bias:-1.6475686156861953, loss:0.5393847442034541\n",
      "epoch:4976, weight:[2.17987002 1.28840668], bias:-1.647715941182367, loss:0.539375040349589\n",
      "epoch:4977, weight:[2.18014044 1.2884535 ], bias:-1.6478632507281645, loss:0.5393653375520926\n",
      "epoch:4978, weight:[2.18041085 1.28850031], bias:-1.648010544328102, loss:0.5393556358106969\n",
      "epoch:4979, weight:[2.18068126 1.28854711], bias:-1.6481578219866915, loss:0.5393459351251337\n",
      "epoch:4980, weight:[2.18095165 1.28859389], bias:-1.6483050837084434, loss:0.5393362354951362\n",
      "epoch:4981, weight:[2.18122204 1.28864065], bias:-1.6484523294978668, loss:0.5393265369204362\n",
      "epoch:4982, weight:[2.18149242 1.28868739], bias:-1.6485995593594687, loss:0.5393168394007665\n",
      "epoch:4983, weight:[2.18176279 1.28873412], bias:-1.6487467732977543, loss:0.5393071429358599\n",
      "epoch:4984, weight:[2.18203316 1.28878083], bias:-1.6488939713172275, loss:0.5392974475254495\n",
      "epoch:4985, weight:[2.18230352 1.28882752], bias:-1.64904115342239, loss:0.5392877531692682\n",
      "epoch:4986, weight:[2.18257386 1.2888742 ], bias:-1.6491883196177428, loss:0.5392780598670494\n",
      "epoch:4987, weight:[2.18284421 1.28892086], bias:-1.649335469907784, loss:0.5392683676185265\n",
      "epoch:4988, weight:[2.18311454 1.2889675 ], bias:-1.6494826042970108, loss:0.5392586764234327\n",
      "epoch:4989, weight:[2.18338486 1.28901413], bias:-1.6496297227899184, loss:0.5392489862815025\n",
      "epoch:4990, weight:[2.18365518 1.28906074], bias:-1.6497768253910006, loss:0.5392392971924688\n",
      "epoch:4991, weight:[2.18392549 1.28910733], bias:-1.649923912104749, loss:0.5392296091560665\n",
      "epoch:4992, weight:[2.18419579 1.28915391], bias:-1.6500709829356541, loss:0.5392199221720291\n",
      "epoch:4993, weight:[2.18446608 1.28920047], bias:-1.6502180378882043, loss:0.5392102362400911\n",
      "epoch:4994, weight:[2.18473637 1.28924702], bias:-1.6503650769668865, loss:0.5392005513599872\n",
      "epoch:4995, weight:[2.18500665 1.28929354], bias:-1.650512100176186, loss:0.5391908675314518\n",
      "epoch:4996, weight:[2.18527692 1.28934005], bias:-1.6506591075205863, loss:0.5391811847542197\n",
      "epoch:4997, weight:[2.18554718 1.28938655], bias:-1.6508060990045692, loss:0.539171503028026\n",
      "epoch:4998, weight:[2.18581743 1.28943303], bias:-1.6509530746326149, loss:0.5391618223526052\n",
      "epoch:4999, weight:[2.18608768 1.28947949], bias:-1.6511000344092017, loss:0.5391521427276933\n"
     ]
    }
   ],
   "source": [
    "my_model = myNN(learning_rate=0.01, epoch=5000, loss_threshold=0.4631)\n",
    "my_model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef935298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "998c28e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0, weight:[0.99949815 0.99896696], bias:-0.0022683735472737165, loss:0.7113403233723417\n",
      "epoch:1, weight:[0.99899854 0.99793742], bias:-0.004531110245838688, loss:0.7106947453938027\n",
      "epoch:2, weight:[0.99850116 0.99691136], bias:-0.006788217377105742, loss:0.7100526623879727\n",
      "epoch:3, weight:[0.99800601 0.9958888 ], bias:-0.009039702278981612, loss:0.7094140604774263\n",
      "epoch:4, weight:[0.99751308 0.99486972], bias:-0.011285572345427677, loss:0.7087789257803064\n",
      "epoch:5, weight:[0.99702238 0.99385412], bias:-0.013525835026017508, loss:0.708147244410992\n",
      "epoch:6, weight:[0.99653391 0.992842  ], bias:-0.015760497825493266, loss:0.7075190024807606\n",
      "epoch:7, weight:[0.99604764 0.99183336], bias:-0.01798956830332102, loss:0.7068941860984489\n",
      "epoch:8, weight:[0.9955636 0.9908282], bias:-0.020213054073245, loss:0.7062727813711064\n",
      "epoch:9, weight:[0.99508177 0.9898265 ], bias:-0.022430962802840876, loss:0.7056547744046482\n",
      "epoch:10, weight:[0.99460215 0.98882828], bias:-0.024643302213068055, loss:0.7050401513045004\n",
      "epoch:11, weight:[0.99412473 0.98783351], bias:-0.026850080077821113, loss:0.7044288981762432\n",
      "epoch:12, weight:[0.99364952 0.98684221], bias:-0.029051304223480342, loss:0.7038210011262495\n",
      "epoch:13, weight:[0.99317651 0.98585437], bias:-0.03124698252846151, loss:0.7032164462623174\n",
      "epoch:14, weight:[0.9927057  0.98486999], bias:-0.03343712292276484, loss:0.7026152196943014\n",
      "epoch:15, weight:[0.99223709 0.98388906], bias:-0.03562173338752331, loss:0.7020173075347361\n",
      "epoch:16, weight:[0.99177067 0.98291157], bias:-0.03780082195455023, loss:0.7014226958994565\n",
      "epoch:17, weight:[0.99130643 0.98193753], bias:-0.03997439670588627, loss:0.7008313709082156\n",
      "epoch:18, weight:[0.99084439 0.98096694], bias:-0.042142465773345836, loss:0.700243318685294\n",
      "epoch:19, weight:[0.99038452 0.97999978], bias:-0.04430503733806299, loss:0.6996585253601076\n",
      "epoch:20, weight:[0.98992684 0.97903606], bias:-0.04646211963003683, loss:0.6990769770678098\n",
      "epoch:21, weight:[0.98947134 0.97807578], bias:-0.04861372092767645, loss:0.6984986599498891\n",
      "epoch:22, weight:[0.98901801 0.97711892], bias:-0.050759849557345506, loss:0.6979235601547609\n",
      "epoch:23, weight:[0.98856685 0.97616549], bias:-0.05290051389290646, loss:0.6973516638383569\n",
      "epoch:24, weight:[0.98811785 0.97521547], bias:-0.05503572235526446, loss:0.6967829571647078\n",
      "epoch:25, weight:[0.98767103 0.97426888], bias:-0.057165483411911, loss:0.6962174263065225\n",
      "epoch:26, weight:[0.98722636 0.9733257 ], bias:-0.05928980557646737, loss:0.6956550574457601\n",
      "epoch:27, weight:[0.98678386 0.97238593], bias:-0.06140869740822787, loss:0.6950958367742014\n",
      "epoch:28, weight:[0.9863435  0.97144956], bias:-0.063522167511703, loss:0.69453975049401\n",
      "epoch:29, weight:[0.9859053 0.9705166], bias:-0.06563022453616243, loss:0.6939867848182939\n",
      "epoch:30, weight:[0.98546925 0.96958704], bias:-0.06773287717517802, loss:0.6934369259716588\n",
      "epoch:31, weight:[0.98503535 0.96866087], bias:-0.06983013416616679, loss:0.6928901601907568\n",
      "epoch:32, weight:[0.98460358 0.9677381 ], bias:-0.07192200428993396, loss:0.692346473724831\n",
      "epoch:33, weight:[0.98417396 0.96681871], bias:-0.07400849637021605, loss:0.6918058528362555\n",
      "epoch:34, weight:[0.98374647 0.9659027 ], bias:-0.07608961927322401, loss:0.6912682838010689\n",
      "epoch:35, weight:[0.98332111 0.96499007], bias:-0.07816538190718672, loss:0.6907337529095036\n",
      "epoch:36, weight:[0.98289789 0.96408082], bias:-0.08023579322189446, loss:0.690202246466511\n",
      "epoch:37, weight:[0.98247678 0.96317494], bias:-0.08230086220824277, loss:0.689673750792279\n",
      "epoch:38, weight:[0.9820578  0.96227242], bias:-0.08436059789777652, loss:0.6891482522227479\n",
      "epoch:39, weight:[0.98164094 0.96137326], bias:-0.08641500936223429, loss:0.6886257371101183\n",
      "epoch:40, weight:[0.98122619 0.96047746], bias:-0.08846410571309318, loss:0.6881061918233548\n",
      "epoch:41, weight:[0.98081356 0.95958502], bias:-0.09050789610111391, loss:0.6875896027486861\n",
      "epoch:42, weight:[0.98040303 0.95869592], bias:-0.09254638971588643, loss:0.6870759562900971\n",
      "epoch:43, weight:[0.97999461 0.95781017], bias:-0.09457959578537596, loss:0.6865652388698186\n",
      "epoch:44, weight:[0.97958829 0.95692776], bias:-0.09660752357546955, loss:0.68605743692881\n",
      "epoch:45, weight:[0.97918406 0.95604868], bias:-0.09863018238952317, loss:0.6855525369272379\n",
      "epoch:46, weight:[0.97878193 0.95517294], bias:-0.10064758156790943, loss:0.6850505253449485\n",
      "epoch:47, weight:[0.97838189 0.95430052], bias:-0.10265973048756578, loss:0.6845513886819368\n",
      "epoch:48, weight:[0.97798394 0.95343142], bias:-0.10466663856154357, loss:0.6840551134588074\n",
      "epoch:49, weight:[0.97758807 0.95256564], bias:-0.10666831523855756, loss:0.6835616862172337\n",
      "epoch:50, weight:[0.97719428 0.95170317], bias:-0.10866477000253635, loss:0.6830710935204094\n",
      "epoch:51, weight:[0.97680257 0.95084401], bias:-0.11065601237217347, loss:0.6825833219534952\n",
      "epoch:52, weight:[0.97641293 0.94998816], bias:-0.11264205190047921, loss:0.6820983581240623\n",
      "epoch:53, weight:[0.97602536 0.9491356 ], bias:-0.1146228981743334, loss:0.6816161886625267\n",
      "epoch:54, weight:[0.97563985 0.94828633], bias:-0.11659856081403892, loss:0.6811368002225829\n",
      "epoch:55, weight:[0.97525641 0.94744035], bias:-0.1185690494728762, loss:0.6806601794816293\n",
      "epoch:56, weight:[0.97487502 0.94659766], bias:-0.12053437383665856, loss:0.6801863131411888\n",
      "epoch:57, weight:[0.97449568 0.94575825], bias:-0.12249454362328852, loss:0.6797151879273255\n",
      "epoch:58, weight:[0.9741184 0.9449221], bias:-0.12444956858231511, loss:0.6792467905910556\n",
      "epoch:59, weight:[0.97374316 0.94408923], bias:-0.12639945849449222, loss:0.6787811079087517\n",
      "epoch:60, weight:[0.97336997 0.94325962], bias:-0.12834422317133792, loss:0.6783181266825439\n",
      "epoch:61, weight:[0.97299882 0.94243327], bias:-0.13028387245469492, loss:0.6778578337407153\n",
      "epoch:62, weight:[0.9726297  0.94161018], bias:-0.13221841621629207, loss:0.6774002159380907\n",
      "epoch:63, weight:[0.97226261 0.94079033], bias:-0.1341478643573071, loss:0.6769452601564231\n",
      "epoch:64, weight:[0.97189755 0.93997372], bias:-0.13607222680793035, loss:0.6764929533047712\n",
      "epoch:65, weight:[0.97153451 0.93916035], bias:-0.1379915135269299, loss:0.676043282319876\n",
      "epoch:66, weight:[0.9711735  0.93835022], bias:-0.1399057345012177, loss:0.6755962341665279\n",
      "epoch:67, weight:[0.9708145  0.93754331], bias:-0.14181489974541722, loss:0.675151795837933\n",
      "epoch:68, weight:[0.97045751 0.93673963], bias:-0.143719019301432, loss:0.6747099543560701\n",
      "epoch:69, weight:[0.97010253 0.93593916], bias:-0.14561810323801583, loss:0.6742706967720457\n",
      "epoch:70, weight:[0.96974955 0.93514191], bias:-0.14751216165034417, loss:0.6738340101664425\n",
      "epoch:71, weight:[0.96939858 0.93434786], bias:-0.14940120465958684, loss:0.6733998816496635\n",
      "epoch:72, weight:[0.9690496  0.93355701], bias:-0.15128524241248206, loss:0.672968298362269\n",
      "epoch:73, weight:[0.96870262 0.93276936], bias:-0.15316428508091207, loss:0.6725392474753118\n",
      "epoch:74, weight:[0.96835762 0.93198489], bias:-0.15503834286148005, loss:0.6721127161906647\n",
      "epoch:75, weight:[0.96801461 0.93120362], bias:-0.15690742597508853, loss:0.6716886917413443\n",
      "epoch:76, weight:[0.96767358 0.93042552], bias:-0.15877154466651916, loss:0.6712671613918284\n",
      "epoch:77, weight:[0.96733452 0.92965059], bias:-0.16063070920401423, loss:0.6708481124383708\n",
      "epoch:78, weight:[0.96699744 0.92887884], bias:-0.16248492987885946, loss:0.6704315322093081\n",
      "epoch:79, weight:[0.96666233 0.92811024], bias:-0.16433421700496842, loss:0.6700174080653636\n",
      "epoch:80, weight:[0.96632919 0.9273448 ], bias:-0.1661785809184686, loss:0.6696057273999457\n",
      "epoch:81, weight:[0.965998   0.92658252], bias:-0.16801803197728898, loss:0.6691964776394415\n",
      "epoch:82, weight:[0.96566878 0.92582337], bias:-0.1698525805607492, loss:0.6687896462435043\n",
      "epoch:83, weight:[0.9653415  0.92506737], bias:-0.1716822370691504, loss:0.6683852207053382\n",
      "epoch:84, weight:[0.96501617 0.92431451], bias:-0.17350701192336768, loss:0.6679831885519761\n",
      "epoch:85, weight:[0.96469279 0.92356477], bias:-0.1753269155644443, loss:0.6675835373445534\n",
      "epoch:86, weight:[0.96437135 0.92281815], bias:-0.17714195845318748, loss:0.6671862546785771\n",
      "epoch:87, weight:[0.96405185 0.92207465], bias:-0.17895215106976592, loss:0.6667913281841898\n",
      "epoch:88, weight:[0.96373428 0.92133426], bias:-0.18075750391330916, loss:0.6663987455264286\n",
      "epoch:89, weight:[0.96341864 0.92059698], bias:-0.18255802750150857, loss:0.6660084944054808\n",
      "epoch:90, weight:[0.96310492 0.91986279], bias:-0.18435373237022004, loss:0.6656205625569313\n",
      "epoch:91, weight:[0.96279312 0.9191317 ], bias:-0.18614462907306872, loss:0.6652349377520096\n",
      "epoch:92, weight:[0.96248324 0.9184037 ], bias:-0.18793072818105527, loss:0.6648516077978288\n",
      "epoch:93, weight:[0.96217528 0.91767878], bias:-0.1897120402821641, loss:0.6644705605376213\n",
      "epoch:94, weight:[0.96186922 0.91695693], bias:-0.19148857598097335, loss:0.6640917838509703\n",
      "epoch:95, weight:[0.96156506 0.91623816], bias:-0.19326034589826682, loss:0.663715265654035\n",
      "epoch:96, weight:[0.9612628  0.91552244], bias:-0.19502736067064766, loss:0.6633409938997725\n",
      "epoch:97, weight:[0.96096244 0.91480979], bias:-0.19678963095015398, loss:0.6629689565781548\n",
      "epoch:98, weight:[0.96066398 0.91410018], bias:-0.19854716740387637, loss:0.662599141716381\n",
      "epoch:99, weight:[0.96036739 0.91339363], bias:-0.20029998071357738, loss:0.6622315373790851\n",
      "epoch:100, weight:[0.9600727  0.91269011], bias:-0.20204808157531276, loss:0.6618661316685395\n",
      "epoch:101, weight:[0.95977988 0.91198962], bias:-0.2037914806990548, loss:0.661502912724853\n",
      "epoch:102, weight:[0.95948893 0.91129216], bias:-0.20553018880831755, loss:0.6611418687261663\n",
      "epoch:103, weight:[0.95919986 0.91059773], bias:-0.20726421663978403, loss:0.6607829878888407\n",
      "epoch:104, weight:[0.95891265 0.90990631], bias:-0.20899357494293538, loss:0.6604262584676442\n",
      "epoch:105, weight:[0.95862731 0.90921789], bias:-0.21071827447968206, loss:0.660071668755932\n",
      "epoch:106, weight:[0.95834382 0.90853248], bias:-0.21243832602399693, loss:0.6597192070858239\n",
      "epoch:107, weight:[0.95806219 0.90785007], bias:-0.21415374036155052, loss:0.6593688618283757\n",
      "epoch:108, weight:[0.9577824  0.90717064], bias:-0.21586452828934816, loss:0.6590206213937482\n",
      "epoch:109, weight:[0.95750447 0.9064942 ], bias:-0.21757070061536923, loss:0.6586744742313704\n",
      "epoch:110, weight:[0.95722837 0.90582074], bias:-0.2192722681582085, loss:0.6583304088300987\n",
      "epoch:111, weight:[0.95695411 0.90515025], bias:-0.2209692417467193, loss:0.657988413718373\n",
      "epoch:112, weight:[0.95668168 0.90448273], bias:-0.22266163221965915, loss:0.6576484774643672\n",
      "epoch:113, weight:[0.95641109 0.90381816], bias:-0.224349450425337, loss:0.6573105886761362\n",
      "epoch:114, weight:[0.95614231 0.90315654], bias:-0.2260327072212629, loss:0.6569747360017595\n",
      "epoch:115, weight:[0.95587536 0.90249787], bias:-0.22771141347379964, loss:0.6566409081294786\n",
      "epoch:116, weight:[0.95561022 0.90184215], bias:-0.22938558005781648, loss:0.6563090937878322\n",
      "epoch:117, weight:[0.95534689 0.90118935], bias:-0.23105521785634503, loss:0.6559792817457879\n",
      "epoch:118, weight:[0.95508537 0.90053948], bias:-0.23272033776023715, loss:0.6556514608128666\n",
      "epoch:119, weight:[0.95482566 0.89989253], bias:-0.2343809506678251, loss:0.6553256198392682\n",
      "epoch:120, weight:[0.95456774 0.8992485 ], bias:-0.2360370674845838, loss:0.6550017477159865\n",
      "epoch:121, weight:[0.95431161 0.89860737], bias:-0.23768869912279508, loss:0.6546798333749279\n",
      "epoch:122, weight:[0.95405728 0.89796915], bias:-0.23933585650121425, loss:0.6543598657890191\n",
      "epoch:123, weight:[0.95380473 0.89733382], bias:-0.2409785505447388, loss:0.6540418339723161\n",
      "epoch:124, weight:[0.95355396 0.89670138], bias:-0.24261679218407908, loss:0.653725726980107\n",
      "epoch:125, weight:[0.95330497 0.89607182], bias:-0.24425059235543145, loss:0.6534115339090117\n",
      "epoch:126, weight:[0.95305776 0.89544513], bias:-0.24587996200015325, loss:0.6530992438970766\n",
      "epoch:127, weight:[0.95281231 0.89482132], bias:-0.2475049120644402, loss:0.6527888461238679\n",
      "epoch:128, weight:[0.95256863 0.89420036], bias:-0.24912545349900583, loss:0.6524803298105594\n",
      "epoch:129, weight:[0.9523267  0.89358227], bias:-0.2507415972587632, loss:0.6521736842200165\n",
      "epoch:130, weight:[0.95208653 0.89296702], bias:-0.25235335430250877, loss:0.651868898656879\n",
      "epoch:131, weight:[0.95184812 0.89235461], bias:-0.2539607355926083, loss:0.6515659624676367\n",
      "epoch:132, weight:[0.95161145 0.89174504], bias:-0.25556375209468524, loss:0.6512648650407047\n",
      "epoch:133, weight:[0.95137652 0.8911383 ], bias:-0.257162414777311, loss:0.6509655958064932\n",
      "epoch:134, weight:[0.95114333 0.89053438], bias:-0.25875673461169774, loss:0.6506681442374735\n",
      "epoch:135, weight:[0.95091187 0.88993328], bias:-0.260346722571393, loss:0.6503724998482444\n",
      "epoch:136, weight:[0.95068215 0.88933499], bias:-0.26193238963197696, loss:0.6500786521955881\n",
      "epoch:137, weight:[0.95045415 0.8887395 ], bias:-0.2635137467707614, loss:0.6497865908785309\n",
      "epoch:138, weight:[0.95022787 0.88814681], bias:-0.26509080496649123, loss:0.6494963055383933\n",
      "epoch:139, weight:[0.95000331 0.88755691], bias:-0.2666635751990482, loss:0.6492077858588421\n",
      "epoch:140, weight:[0.94978046 0.88696979], bias:-0.26823206844915676, loss:0.6489210215659362\n",
      "epoch:141, weight:[0.94955932 0.88638545], bias:-0.26979629569809194, loss:0.6486360024281702\n",
      "epoch:142, weight:[0.94933988 0.88580387], bias:-0.2713562679273898, loss:0.648352718256514\n",
      "epoch:143, weight:[0.94912214 0.88522506], bias:-0.2729119961185598, loss:0.6480711589044511\n",
      "epoch:144, weight:[0.9489061  0.88464901], bias:-0.27446349125279956, loss:0.6477913142680115\n",
      "epoch:145, weight:[0.94869174 0.88407571], bias:-0.27601076431071164, loss:0.6475131742858028\n",
      "epoch:146, weight:[0.94847908 0.88350515], bias:-0.2775538262720228, loss:0.6472367289390376\n",
      "epoch:147, weight:[0.94826809 0.88293732], bias:-0.27909268811530524, loss:0.6469619682515583\n",
      "epoch:148, weight:[0.94805879 0.88237223], bias:-0.2806273608177002, loss:0.6466888822898592\n",
      "epoch:149, weight:[0.94785115 0.88180986], bias:-0.28215785535464344, loss:0.6464174611631036\n",
      "epoch:150, weight:[0.94764519 0.8812502 ], bias:-0.2836841826995936, loss:0.6461476950231416\n",
      "epoch:151, weight:[0.94744089 0.88069326], bias:-0.285206353823762, loss:0.6458795740645201\n",
      "epoch:152, weight:[0.94723825 0.88013901], bias:-0.2867243796958452, loss:0.6456130885244956\n",
      "epoch:153, weight:[0.94703727 0.87958747], bias:-0.2882382712817594, loss:0.6453482286830391\n",
      "epoch:154, weight:[0.94683794 0.87903861], bias:-0.28974803954437733, loss:0.6450849848628405\n",
      "epoch:155, weight:[0.94664025 0.87849243], bias:-0.2912536954432672, loss:0.6448233474293105\n",
      "epoch:156, weight:[0.94644421 0.87794893], bias:-0.2927552499344337, loss:0.6445633067905793\n",
      "epoch:157, weight:[0.94624981 0.8774081 ], bias:-0.29425271397006153, loss:0.6443048533974918\n",
      "epoch:158, weight:[0.94605704 0.87686993], bias:-0.29574609849826083, loss:0.6440479777436012\n",
      "epoch:159, weight:[0.9458659  0.87633442], bias:-0.29723541446281493, loss:0.6437926703651596\n",
      "epoch:160, weight:[0.94567639 0.87580155], bias:-0.29872067280293024, loss:0.6435389218411053\n",
      "epoch:161, weight:[0.9454885  0.87527133], bias:-0.30020188445298834, loss:0.6432867227930484\n",
      "epoch:162, weight:[0.94530222 0.87474374], bias:-0.30167906034230024, loss:0.6430360638852544\n",
      "epoch:163, weight:[0.94511756 0.87421878], bias:-0.3031522113948628, loss:0.6427869358246225\n",
      "epoch:164, weight:[0.94493451 0.87369644], bias:-0.3046213485291174, loss:0.6425393293606654\n",
      "epoch:165, weight:[0.94475306 0.87317672], bias:-0.30608648265771055, loss:0.6422932352854827\n",
      "epoch:166, weight:[0.94457321 0.8726596 ], bias:-0.307547624687257, loss:0.6420486444337347\n",
      "epoch:167, weight:[0.94439495 0.87214508], bias:-0.3090047855181047, loss:0.6418055476826127\n",
      "epoch:168, weight:[0.94421829 0.87163316], bias:-0.310457976044102, loss:0.6415639359518066\n",
      "epoch:169, weight:[0.94404321 0.87112383], bias:-0.31190720715236736, loss:0.6413238002034711\n",
      "epoch:170, weight:[0.94386972 0.87061708], bias:-0.31335248972306023, loss:0.6410851314421886\n",
      "epoch:171, weight:[0.9436978 0.8701129], bias:-0.31479383462915533, loss:0.6408479207149301\n",
      "epoch:172, weight:[0.94352746 0.86961128], bias:-0.31623125273621805, loss:0.6406121591110151\n",
      "epoch:173, weight:[0.94335869 0.86911223], bias:-0.3176647549021825, loss:0.6403778377620667\n",
      "epoch:174, weight:[0.94319148 0.86861573], bias:-0.31909435197713154, loss:0.6401449478419675\n",
      "epoch:175, weight:[0.94302583 0.86812178], bias:-0.32052005480307894, loss:0.6399134805668102\n",
      "epoch:176, weight:[0.94286174 0.86763036], bias:-0.3219418742137534, loss:0.6396834271948497\n",
      "epoch:177, weight:[0.9426992  0.86714148], bias:-0.3233598210343853, loss:0.6394547790264496\n",
      "epoch:178, weight:[0.94253821 0.86665513], bias:-0.3247739060814948, loss:0.6392275274040289\n",
      "epoch:179, weight:[0.94237876 0.86617129], bias:-0.3261841401626825, loss:0.6390016637120054\n",
      "epoch:180, weight:[0.94222085 0.86568997], bias:-0.3275905340764219, loss:0.6387771793767386\n",
      "epoch:181, weight:[0.94206448 0.86521115], bias:-0.32899309861185444, loss:0.6385540658664685\n",
      "epoch:182, weight:[0.94190963 0.86473483], bias:-0.3303918445485859, loss:0.6383323146912544\n",
      "epoch:183, weight:[0.94175632 0.864261  ], bias:-0.3317867826564853, loss:0.638111917402911\n",
      "epoch:184, weight:[0.94160452 0.86378966], bias:-0.33317792369548593, loss:0.6378928655949422\n",
      "epoch:185, weight:[0.94145425 0.86332079], bias:-0.33456527841538797, loss:0.6376751509024735\n",
      "epoch:186, weight:[0.94130548 0.8628544 ], bias:-0.3359488575556638, loss:0.6374587650021833\n",
      "epoch:187, weight:[0.94115823 0.86239047], bias:-0.3373286718452646, loss:0.6372436996122303\n",
      "epoch:188, weight:[0.94101248 0.86192899], bias:-0.33870473200242973, loss:0.6370299464921813\n",
      "epoch:189, weight:[0.94086823 0.86146997], bias:-0.34007704873449746, loss:0.6368174974429374\n",
      "epoch:190, weight:[0.94072548 0.8610134 ], bias:-0.34144563273771816, loss:0.6366063443066544\n",
      "epoch:191, weight:[0.94058422 0.86055926], bias:-0.3428104946970693, loss:0.6363964789666686\n",
      "epoch:192, weight:[0.94044445 0.86010755], bias:-0.3441716452860726, loss:0.636187893347414\n",
      "epoch:193, weight:[0.94030616 0.85965826], bias:-0.3455290951666127, loss:0.6359805794143417\n",
      "epoch:194, weight:[0.94016935 0.85921139], bias:-0.34688285498875854, loss:0.6357745291738368\n",
      "epoch:195, weight:[0.94003402 0.85876693], bias:-0.34823293539058614, loss:0.6355697346731349\n",
      "epoch:196, weight:[0.93990015 0.85832488], bias:-0.3495793469980035, loss:0.6353661880002337\n",
      "epoch:197, weight:[0.93976776 0.85788522], bias:-0.3509221004245776, loss:0.6351638812838067\n",
      "epoch:198, weight:[0.93963683 0.85744794], bias:-0.35226120627136304, loss:0.634962806693114\n",
      "epoch:199, weight:[0.93950735 0.85701306], bias:-0.35359667512673293, loss:0.6347629564379109\n",
      "epoch:200, weight:[0.93937933 0.85658054], bias:-0.3549285175662115, loss:0.6345643227683564\n",
      "epoch:201, weight:[0.93925276 0.8561504 ], bias:-0.3562567441523088, loss:0.6343668979749192\n",
      "epoch:202, weight:[0.93912763 0.85572262], bias:-0.35758136543435703, loss:0.6341706743882828\n",
      "epoch:203, weight:[0.93900395 0.85529719], bias:-0.3589023919483491, loss:0.6339756443792498\n",
      "epoch:204, weight:[0.9388817  0.85487412], bias:-0.36021983421677883, loss:0.6337818003586431\n",
      "epoch:205, weight:[0.93876088 0.85445338], bias:-0.3615337027484832, loss:0.633589134777208\n",
      "epoch:206, weight:[0.9386415  0.85403498], bias:-0.3628440080384863, loss:0.6333976401255114\n",
      "epoch:207, weight:[0.93852354 0.85361891], bias:-0.3641507605678455, loss:0.63320730893384\n",
      "epoch:208, weight:[0.93840699 0.85320516], bias:-0.3654539708034988, loss:0.6330181337720983\n",
      "epoch:209, weight:[0.93829187 0.85279373], bias:-0.3667536491981147, loss:0.6328301072497046\n",
      "epoch:210, weight:[0.93817816 0.8523846 ], bias:-0.3680498061899438, loss:0.6326432220154841\n",
      "epoch:211, weight:[0.93806585 0.85197777], bias:-0.36934245220267176, loss:0.6324574707575651\n",
      "epoch:212, weight:[0.93795495 0.85157324], bias:-0.3706315976452745, loss:0.6322728462032697\n",
      "epoch:213, weight:[0.93784545 0.851171  ], bias:-0.37191725291187516, loss:0.632089341119006\n",
      "epoch:214, weight:[0.93773734 0.85077104], bias:-0.3731994283816028, loss:0.6319069483101583\n",
      "epoch:215, weight:[0.93763063 0.85037335], bias:-0.37447813441845285, loss:0.6317256606209756\n",
      "epoch:216, weight:[0.9375253  0.84997793], bias:-0.3757533813711493, loss:0.6315454709344607\n",
      "epoch:217, weight:[0.93742135 0.84958477], bias:-0.37702517957300874, loss:0.6313663721722569\n",
      "epoch:218, weight:[0.93731879 0.84919386], bias:-0.3782935393418064, loss:0.6311883572945347\n",
      "epoch:219, weight:[0.93721759 0.8488052 ], bias:-0.3795584709796433, loss:0.6310114192998757\n",
      "epoch:220, weight:[0.93711777 0.84841879], bias:-0.38081998477281587, loss:0.6308355512251578\n",
      "epoch:221, weight:[0.93701932 0.8480346 ], bias:-0.38207809099168677, loss:0.6306607461454384\n",
      "epoch:222, weight:[0.93692222 0.84765265], bias:-0.3833327998905576, loss:0.6304869971738365\n",
      "epoch:223, weight:[0.93682649 0.84727291], bias:-0.3845841217075433, loss:0.6303142974614139\n",
      "epoch:224, weight:[0.93673211 0.84689539], bias:-0.38583206666444864, loss:0.6301426401970563\n",
      "epoch:225, weight:[0.93663908 0.84652008], bias:-0.3870766449666455, loss:0.6299720186073531\n",
      "epoch:226, weight:[0.93654739 0.84614696], bias:-0.3883178668029528, loss:0.6298024259564747\n",
      "epoch:227, weight:[0.93645705 0.84577604], bias:-0.3895557423455175, loss:0.6296338555460532\n",
      "epoch:228, weight:[0.93636805 0.84540731], bias:-0.3907902817496974, loss:0.6294663007150578\n",
      "epoch:229, weight:[0.93628037 0.84504076], bias:-0.39202149515394563, loss:0.6292997548396713\n",
      "epoch:230, weight:[0.93619403 0.84467638], bias:-0.39324939267969694, loss:0.629134211333167\n",
      "epoch:231, weight:[0.93610902 0.84431417], bias:-0.3944739844312552, loss:0.6289696636457828\n",
      "epoch:232, weight:[0.93602532 0.84395412], bias:-0.39569528049568287, loss:0.6288061052645959\n",
      "epoch:233, weight:[0.93594294 0.84359623], bias:-0.396913290942692, loss:0.6286435297133962\n",
      "epoch:234, weight:[0.93586188 0.84324048], bias:-0.3981280258245368, loss:0.6284819305525601\n",
      "epoch:235, weight:[0.93578213 0.84288687], bias:-0.3993394951759078, loss:0.6283213013789205\n",
      "epoch:236, weight:[0.93570368 0.8425354 ], bias:-0.40054770901382736, loss:0.6281616358256419\n",
      "epoch:237, weight:[0.93562653 0.84218605], bias:-0.4017526773375474, loss:0.6280029275620888\n",
      "epoch:238, weight:[0.93555068 0.84183883], bias:-0.4029544101284479, loss:0.6278451702936962\n",
      "epoch:239, weight:[0.93547612 0.84149372], bias:-0.4041529173499375, loss:0.6276883577618422\n",
      "epoch:240, weight:[0.93540285 0.84115072], bias:-0.4053482089473554, loss:0.6275324837437137\n",
      "epoch:241, weight:[0.93533087 0.84080982], bias:-0.4065402948478747, loss:0.6273775420521776\n",
      "epoch:242, weight:[0.93526017 0.84047101], bias:-0.4077291849604075, loss:0.6272235265356485\n",
      "epoch:243, weight:[0.93519075 0.8401343 ], bias:-0.40891488917551144, loss:0.6270704310779557\n",
      "epoch:244, weight:[0.9351226  0.83979966], bias:-0.41009741736529753, loss:0.6269182495982119\n",
      "epoch:245, weight:[0.93505572 0.8394671 ], bias:-0.4112767793833398, loss:0.6267669760506783\n",
      "epoch:246, weight:[0.9349901  0.83913661], bias:-0.41245298506458605, loss:0.6266166044246323\n",
      "epoch:247, weight:[0.93492575 0.83880818], bias:-0.41362604422527044, loss:0.6264671287442332\n",
      "epoch:248, weight:[0.93486265 0.83848181], bias:-0.4147959666628272, loss:0.6263185430683863\n",
      "epoch:249, weight:[0.93480081 0.83815749], bias:-0.41596276215580597, loss:0.6261708414906102\n",
      "epoch:250, weight:[0.93474022 0.83783521], bias:-0.41712644046378866, loss:0.6260240181388996\n",
      "epoch:251, weight:[0.93468087 0.83751496], bias:-0.41828701132730745, loss:0.6258780671755908\n",
      "epoch:252, weight:[0.93462277 0.83719675], bias:-0.4194444844677644, loss:0.6257329827972244\n",
      "epoch:253, weight:[0.9345659  0.83688056], bias:-0.4205988695873525, loss:0.6255887592344107\n",
      "epoch:254, weight:[0.93451027 0.83656638], bias:-0.42175017636897794, loss:0.6254453907516914\n",
      "epoch:255, weight:[0.93445587 0.83625422], bias:-0.4228984144761839, loss:0.6253028716474028\n",
      "epoch:256, weight:[0.93440269 0.83594406], bias:-0.4240435935530758, loss:0.6251611962535395\n",
      "epoch:257, weight:[0.93435074 0.8356359 ], bias:-0.42518572322424747, loss:0.6250203589356156\n",
      "epoch:258, weight:[0.9343     0.83532973], bias:-0.42632481309470927, loss:0.6248803540925275\n",
      "epoch:259, weight:[0.93425048 0.83502554], bias:-0.4274608727498171, loss:0.6247411761564153\n",
      "epoch:260, weight:[0.93420217 0.83472334], bias:-0.428593911755203, loss:0.6246028195925253\n",
      "epoch:261, weight:[0.93415507 0.8344231 ], bias:-0.429723939656707, loss:0.62446527889907\n",
      "epoch:262, weight:[0.93410917 0.83412484], bias:-0.4308509659803101, loss:0.6243285486070906\n",
      "epoch:263, weight:[0.93406447 0.83382853], bias:-0.4319750002320688, loss:0.6241926232803173\n",
      "epoch:264, weight:[0.93402097 0.83353417], bias:-0.43309605189805095, loss:0.6240574975150305\n",
      "epoch:265, weight:[0.93397866 0.83324176], bias:-0.4342141304442725, loss:0.6239231659399208\n",
      "epoch:266, weight:[0.93393753 0.83295129], bias:-0.4353292453166359, loss:0.6237896232159502\n",
      "epoch:267, weight:[0.93389759 0.83266276], bias:-0.4364414059408698, loss:0.6236568640362122\n",
      "epoch:268, weight:[0.93385883 0.83237616], bias:-0.4375506217224695, loss:0.623524883125792\n",
      "epoch:269, weight:[0.93382125 0.83209147], bias:-0.4386569020466393, loss:0.623393675241626\n",
      "epoch:270, weight:[0.93378484 0.8318087 ], bias:-0.43976025627823556, loss:0.623263235172363\n",
      "epoch:271, weight:[0.9337496  0.83152784], bias:-0.4408606937617112, loss:0.6231335577382231\n",
      "epoch:272, weight:[0.93371552 0.83124889], bias:-0.4419582238210615, loss:0.6230046377908575\n",
      "epoch:273, weight:[0.93368261 0.83097182], bias:-0.4430528557597708, loss:0.6228764702132091\n",
      "epoch:274, weight:[0.93365085 0.83069665], bias:-0.44414459886076085, loss:0.6227490499193712\n",
      "epoch:275, weight:[0.93362025 0.83042337], bias:-0.44523346238633976, loss:0.6226223718544477\n",
      "epoch:276, weight:[0.9335908  0.83015196], bias:-0.44631945557815267, loss:0.6224964309944125\n",
      "epoch:277, weight:[0.93356249 0.82988243], bias:-0.4474025876571332, loss:0.622371222345969\n",
      "epoch:278, weight:[0.93353533 0.82961475], bias:-0.44848286782345625, loss:0.6222467409464097\n",
      "epoch:279, weight:[0.9335093  0.82934894], bias:-0.44956030525649193, loss:0.6221229818634763\n",
      "epoch:280, weight:[0.93348441 0.82908499], bias:-0.45063490911476045, loss:0.6219999401952178\n",
      "epoch:281, weight:[0.93346066 0.82882288], bias:-0.45170668853588836, loss:0.6218776110698515\n",
      "epoch:282, weight:[0.93343803 0.82856261], bias:-0.4527756526365658, loss:0.6217559896456225\n",
      "epoch:283, weight:[0.93341652 0.82830417], bias:-0.4538418105125048, loss:0.6216350711106623\n",
      "epoch:284, weight:[0.93339614 0.82804756], bias:-0.4549051712383988, loss:0.6215148506828497\n",
      "epoch:285, weight:[0.93337687 0.82779278], bias:-0.45596574386788313, loss:0.6213953236096695\n",
      "epoch:286, weight:[0.93335872 0.82753981], bias:-0.4570235374334966, loss:0.6212764851680735\n",
      "epoch:287, weight:[0.93334168 0.82728866], bias:-0.4580785609466443, loss:0.6211583306643391\n",
      "epoch:288, weight:[0.93332574 0.82703931], bias:-0.45913082339756106, loss:0.6210408554339303\n",
      "epoch:289, weight:[0.9333109  0.82679175], bias:-0.46018033375527656, loss:0.6209240548413569\n",
      "epoch:290, weight:[0.93329717 0.82654599], bias:-0.46122710096758096, loss:0.6208079242800361\n",
      "epoch:291, weight:[0.93328453 0.82630201], bias:-0.4622711339609918, loss:0.6206924591721509\n",
      "epoch:292, weight:[0.93327298 0.82605982], bias:-0.46331244164072166, loss:0.6205776549685127\n",
      "epoch:293, weight:[0.93326252 0.8258194 ], bias:-0.4643510328906474, loss:0.6204635071484196\n",
      "epoch:294, weight:[0.93325314 0.82558075], bias:-0.46538691657327974, loss:0.6203500112195187\n",
      "epoch:295, weight:[0.93324484 0.82534386], bias:-0.4664201015297342, loss:0.6202371627176668\n",
      "epoch:296, weight:[0.93323763 0.82510872], bias:-0.46745059657970295, loss:0.6201249572067911\n",
      "epoch:297, weight:[0.93323148 0.82487534], bias:-0.4684784105214277, loss:0.6200133902787495\n",
      "epoch:298, weight:[0.93322641 0.8246437 ], bias:-0.4695035521316733, loss:0.6199024575531937\n",
      "epoch:299, weight:[0.9332224 0.8244138], bias:-0.47052603016570266, loss:0.6197921546774302\n",
      "epoch:300, weight:[0.93321946 0.82418563], bias:-0.4715458533572524, loss:0.6196824773262809\n",
      "epoch:301, weight:[0.93321757 0.82395918], bias:-0.4725630304185094, loss:0.6195734212019466\n",
      "epoch:302, weight:[0.93321674 0.82373446], bias:-0.47357757004008827, loss:0.6194649820338681\n",
      "epoch:303, weight:[0.93321697 0.82351146], bias:-0.4745894808910101, loss:0.6193571555785888\n",
      "epoch:304, weight:[0.93321824 0.82329016], bias:-0.4755987716186816, loss:0.6192499376196179\n",
      "epoch:305, weight:[0.93322056 0.82307056], bias:-0.47660545084887534, loss:0.6191433239672919\n",
      "epoch:306, weight:[0.93322392 0.82285267], bias:-0.4776095271857112, loss:0.6190373104586392\n",
      "epoch:307, weight:[0.93322832 0.82263646], bias:-0.4786110092116382, loss:0.618931892957242\n",
      "epoch:308, weight:[0.93323376 0.82242194], bias:-0.4796099054874174, loss:0.618827067353101\n",
      "epoch:309, weight:[0.93324023 0.8222091 ], bias:-0.480606224552106, loss:0.6187228295624982\n",
      "epoch:310, weight:[0.93324772 0.82199793], bias:-0.4815999749230417, loss:0.6186191755278616\n",
      "epoch:311, weight:[0.93325624 0.82178843], bias:-0.4825911650958283, loss:0.6185161012176292\n",
      "epoch:312, weight:[0.93326578 0.8215806 ], bias:-0.48357980354432206, loss:0.6184136026261134\n",
      "epoch:313, weight:[0.93327634 0.82137442], bias:-0.48456589872061906, loss:0.618311675773367\n",
      "epoch:314, weight:[0.93328792 0.82116989], bias:-0.48554945905504293, loss:0.6182103167050463\n",
      "epoch:315, weight:[0.9333005  0.82096701], bias:-0.48653049295613393, loss:0.618109521492279\n",
      "epoch:316, weight:[0.9333141  0.82076576], bias:-0.48750900881063836, loss:0.6180092862315276\n",
      "epoch:317, weight:[0.93332869 0.82056615], bias:-0.4884850149834993, loss:0.6179096070444572\n",
      "epoch:318, weight:[0.93334429 0.82036817], bias:-0.4894585198178475, loss:0.617810480077801\n",
      "epoch:319, weight:[0.93336089 0.82017181], bias:-0.49042953163499375, loss:0.6177119015032273\n",
      "epoch:320, weight:[0.93337848 0.81997707], bias:-0.4913980587344215, loss:0.6176138675172061\n",
      "epoch:321, weight:[0.93339706 0.81978393], bias:-0.49236410939378034, loss:0.6175163743408772\n",
      "epoch:322, weight:[0.93341663 0.81959241], bias:-0.49332769186888054, loss:0.6174194182199165\n",
      "epoch:323, weight:[0.93343718 0.81940248], bias:-0.49428881439368805, loss:0.617322995424406\n",
      "epoch:324, weight:[0.93345872 0.81921415], bias:-0.4952474851803203, loss:0.6172271022486996\n",
      "epoch:325, weight:[0.93348123 0.8190274 ], bias:-0.49620371241904276, loss:0.6171317350112941\n",
      "epoch:326, weight:[0.93350472 0.81884224], bias:-0.49715750427826627, loss:0.6170368900546969\n",
      "epoch:327, weight:[0.93352918 0.81865866], bias:-0.4981088689045451, loss:0.6169425637452955\n",
      "epoch:328, weight:[0.9335546  0.81847665], bias:-0.4990578144225756, loss:0.6168487524732277\n",
      "epoch:329, weight:[0.93358099 0.8182962 ], bias:-0.5000043489351956, loss:0.6167554526522511\n",
      "epoch:330, weight:[0.93360834 0.81811731], bias:-0.5009484805233849, loss:0.6166626607196138\n",
      "epoch:331, weight:[0.93363665 0.81793998], bias:-0.5018902172462655, loss:0.6165703731359264\n",
      "epoch:332, weight:[0.93366591 0.8177642 ], bias:-0.5028295671411036, loss:0.6164785863850305\n",
      "epoch:333, weight:[0.93369613 0.81758997], bias:-0.5037665382233116, loss:0.6163872969738726\n",
      "epoch:334, weight:[0.93372729 0.81741727], bias:-0.5047011384864512, loss:0.6162965014323758\n",
      "epoch:335, weight:[0.9337594  0.81724611], bias:-0.5056333759022363, loss:0.6162061963133109\n",
      "epoch:336, weight:[0.93379245 0.81707647], bias:-0.5065632584205382, loss:0.6161163781921701\n",
      "epoch:337, weight:[0.93382643 0.81690836], bias:-0.5074907939693892, loss:0.6160270436670403\n",
      "epoch:338, weight:[0.93386136 0.81674176], bias:-0.5084159904549892, loss:0.6159381893584762\n",
      "epoch:339, weight:[0.93389721 0.81657668], bias:-0.509338855761711, loss:0.6158498119093742\n",
      "epoch:340, weight:[0.93393399 0.8164131 ], bias:-0.5102593977521075, loss:0.6157619079848463\n",
      "epoch:341, weight:[0.9339717  0.81625102], bias:-0.5111776242669188, loss:0.615674474272097\n",
      "epoch:342, weight:[0.93401034 0.81609044], bias:-0.5120935431250803, loss:0.6155875074802953\n",
      "epoch:343, weight:[0.93404989 0.81593135], bias:-0.513007162123731, loss:0.6155010043404524\n",
      "epoch:344, weight:[0.93409035 0.81577374], bias:-0.5139184890382231, loss:0.6154149616052974\n",
      "epoch:345, weight:[0.93413173 0.81561761], bias:-0.5148275316221315, loss:0.6153293760491529\n",
      "epoch:346, weight:[0.93417402 0.81546296], bias:-0.5157342976072639, loss:0.6152442444678128\n",
      "epoch:347, weight:[0.93421722 0.81530977], bias:-0.5166387947036721, loss:0.6151595636784187\n",
      "epoch:348, weight:[0.93426132 0.81515805], bias:-0.5175410305996637, loss:0.6150753305193383\n",
      "epoch:349, weight:[0.93430632 0.81500779], bias:-0.5184410129618132, loss:0.614991541850043\n",
      "epoch:350, weight:[0.93435222 0.81485897], bias:-0.5193387494349757, loss:0.6149081945509868\n",
      "epoch:351, weight:[0.93439901 0.81471161], bias:-0.5202342476422993, loss:0.6148252855234848\n",
      "epoch:352, weight:[0.9344467  0.81456569], bias:-0.5211275151852391, loss:0.6147428116895933\n",
      "epoch:353, weight:[0.93449527 0.81442121], bias:-0.5220185596435717, loss:0.6146607699919889\n",
      "epoch:354, weight:[0.93454473 0.81427816], bias:-0.5229073885754093, loss:0.6145791573938495\n",
      "epoch:355, weight:[0.93459506 0.81413653], bias:-0.5237940095172157, loss:0.6144979708787347\n",
      "epoch:356, weight:[0.93464628 0.81399633], bias:-0.5246784299838215, loss:0.6144172074504664\n",
      "epoch:357, weight:[0.93469838 0.81385754], bias:-0.5255606574684413, loss:0.6143368641330118\n",
      "epoch:358, weight:[0.93475134 0.81372017], bias:-0.5264406994426895, loss:0.6142569379703641\n",
      "epoch:359, weight:[0.93480518 0.8135842 ], bias:-0.5273185633565982, loss:0.614177426026426\n",
      "epoch:360, weight:[0.93485988 0.81344963], bias:-0.5281942566386353, loss:0.6140983253848923\n",
      "epoch:361, weight:[0.93491545 0.81331646], bias:-0.5290677866957221, loss:0.6140196331491331\n",
      "epoch:362, weight:[0.93497188 0.81318467], bias:-0.5299391609132527, loss:0.6139413464420781\n",
      "epoch:363, weight:[0.93502916 0.81305428], bias:-0.530808386655113, loss:0.613863462406101\n",
      "epoch:364, weight:[0.9350873  0.81292526], bias:-0.5316754712637006, loss:0.6137859782029037\n",
      "epoch:365, weight:[0.9351463  0.81279762], bias:-0.5325404220599449, loss:0.6137088910134026\n",
      "epoch:366, weight:[0.93520614 0.81267135], bias:-0.5334032463433277, loss:0.613632198037613\n",
      "epoch:367, weight:[0.93526682 0.81254645], bias:-0.5342639513919046, loss:0.6135558964945372\n",
      "epoch:368, weight:[0.93532835 0.81242291], bias:-0.5351225444623264, loss:0.6134799836220486\n",
      "epoch:369, weight:[0.93539072 0.81230072], bias:-0.535979032789861, loss:0.613404456676781\n",
      "epoch:370, weight:[0.93545393 0.81217988], bias:-0.5368334235884161, loss:0.6133293129340159\n",
      "epoch:371, weight:[0.93551797 0.81206039], bias:-0.5376857240505619, loss:0.6132545496875692\n",
      "epoch:372, weight:[0.93558285 0.81194224], bias:-0.5385359413475543, loss:0.6131801642496811\n",
      "epoch:373, weight:[0.93564855 0.81182543], bias:-0.539384082629359, loss:0.6131061539509052\n",
      "epoch:374, weight:[0.93571507 0.81170994], bias:-0.5402301550246753, loss:0.6130325161399964\n",
      "epoch:375, weight:[0.93578242 0.81159578], bias:-0.5410741656409607, loss:0.6129592481838025\n",
      "epoch:376, weight:[0.93585059 0.81148294], bias:-0.5419161215644558, loss:0.6128863474671543\n",
      "epoch:377, weight:[0.93591957 0.81137142], bias:-0.5427560298602099, loss:0.6128138113927561\n",
      "epoch:378, weight:[0.93598937 0.81126121], bias:-0.5435938975721064, loss:0.6127416373810768\n",
      "epoch:379, weight:[0.93605998 0.81115231], bias:-0.5444297317228892, loss:0.6126698228702424\n",
      "epoch:380, weight:[0.9361314 0.8110447], bias:-0.545263539314189, loss:0.6125983653159284\n",
      "epoch:381, weight:[0.93620363 0.8109384 ], bias:-0.5460953273265501, loss:0.612527262191252\n",
      "epoch:382, weight:[0.93627665 0.81083338], bias:-0.5469251027194578, loss:0.6124565109866654\n",
      "epoch:383, weight:[0.93635048 0.81072965], bias:-0.5477528724313661, loss:0.6123861092098507\n",
      "epoch:384, weight:[0.9364251  0.81062721], bias:-0.5485786433797253, loss:0.6123160543856124\n",
      "epoch:385, weight:[0.93650052 0.81052604], bias:-0.5494024224610108, loss:0.6122463440557736\n",
      "epoch:386, weight:[0.93657673 0.81042614], bias:-0.5502242165507514, loss:0.6121769757790699\n",
      "epoch:387, weight:[0.93665372 0.81032751], bias:-0.5510440325035583, loss:0.6121079471310469\n",
      "epoch:388, weight:[0.93673151 0.81023015], bias:-0.5518618771531548, loss:0.6120392557039535\n",
      "epoch:389, weight:[0.93681007 0.81013404], bias:-0.5526777573124058, loss:0.6119708991066418\n",
      "epoch:390, weight:[0.93688942 0.81003918], bias:-0.5534916797733475, loss:0.6119028749644618\n",
      "epoch:391, weight:[0.93696954 0.80994558], bias:-0.5543036513072183, loss:0.6118351809191602\n",
      "epoch:392, weight:[0.93705044 0.80985322], bias:-0.555113678664489, loss:0.6117678146287774\n",
      "epoch:393, weight:[0.93713211 0.8097621 ], bias:-0.5559217685748943, loss:0.6117007737675476\n",
      "epoch:394, weight:[0.93721455 0.80967221], bias:-0.5567279277474634, loss:0.6116340560257961\n",
      "epoch:395, weight:[0.93729775 0.80958355], bias:-0.5575321628705522, loss:0.6115676591098403\n",
      "epoch:396, weight:[0.93738172 0.80949612], bias:-0.558334480611875, loss:0.6115015807418887\n",
      "epoch:397, weight:[0.93746645 0.80940991], bias:-0.5591348876185365, loss:0.6114358186599413\n",
      "epoch:398, weight:[0.93755194 0.80932492], bias:-0.5599333905170646, loss:0.611370370617692\n",
      "epoch:399, weight:[0.93763818 0.80924114], bias:-0.560729995913443, loss:0.6113052343844275\n",
      "epoch:400, weight:[0.93772518 0.80915856], bias:-0.5615247103931441, loss:0.6112404077449316\n",
      "epoch:401, weight:[0.93781293 0.80907719], bias:-0.562317540521163, loss:0.6111758884993864\n",
      "epoch:402, weight:[0.93790142 0.80899701], bias:-0.5631084928420502, loss:0.6111116744632753\n",
      "epoch:403, weight:[0.93799066 0.80891803], bias:-0.5638975738799462, loss:0.6110477634672861\n",
      "epoch:404, weight:[0.93808064 0.80884024], bias:-0.5646847901386154, loss:0.6109841533572152\n",
      "epoch:405, weight:[0.93817136 0.80876363], bias:-0.5654701481014803, loss:0.6109208419938714\n",
      "epoch:406, weight:[0.93826282 0.8086882 ], bias:-0.5662536542316566, loss:0.610857827252982\n",
      "epoch:407, weight:[0.93835502 0.80861395], bias:-0.567035314971988, loss:0.6107951070250959\n",
      "epoch:408, weight:[0.93844794 0.80854087], bias:-0.567815136745081, loss:0.6107326792154909\n",
      "epoch:409, weight:[0.93854159 0.80846895], bias:-0.5685931259533409, loss:0.6106705417440792\n",
      "epoch:410, weight:[0.93863597 0.8083982 ], bias:-0.5693692889790071, loss:0.6106086925453144\n",
      "epoch:411, weight:[0.93873108 0.80832861], bias:-0.570143632184189, loss:0.6105471295680985\n",
      "epoch:412, weight:[0.93882691 0.80826016], bias:-0.5709161619109022, loss:0.6104858507756893\n",
      "epoch:413, weight:[0.93892345 0.80819287], bias:-0.5716868844811052, loss:0.6104248541456085\n",
      "epoch:414, weight:[0.93902071 0.80812672], bias:-0.5724558061967353, loss:0.6103641376695506\n",
      "epoch:415, weight:[0.93911869 0.80806171], bias:-0.573222933339746, loss:0.6103036993532914\n",
      "epoch:416, weight:[0.93921737 0.80799784], bias:-0.573988272172144, loss:0.6102435372165982\n",
      "epoch:417, weight:[0.93931677 0.80793509], bias:-0.5747518289360258, loss:0.6101836492931386\n",
      "epoch:418, weight:[0.93941687 0.80787348], bias:-0.5755136098536161, loss:0.6101240336303921\n",
      "epoch:419, weight:[0.93951767 0.80781298], bias:-0.5762736211273046, loss:0.6100646882895604\n",
      "epoch:420, weight:[0.93961918 0.80775361], bias:-0.5770318689396846, loss:0.6100056113454784\n",
      "epoch:421, weight:[0.93972138 0.80769535], bias:-0.5777883594535905, loss:0.609946800886527\n",
      "epoch:422, weight:[0.93982428 0.8076382 ], bias:-0.5785430988121364, loss:0.6098882550145442\n",
      "epoch:423, weight:[0.93992787 0.80758215], bias:-0.5792960931387542, loss:0.6098299718447392\n",
      "epoch:424, weight:[0.94003216 0.8075272 ], bias:-0.5800473485372328, loss:0.6097719495056038\n",
      "epoch:425, weight:[0.94013713 0.80747336], bias:-0.5807968710917565, loss:0.6097141861388278\n",
      "epoch:426, weight:[0.94024279 0.8074206 ], bias:-0.5815446668669438, loss:0.6096566798992126\n",
      "epoch:427, weight:[0.94034913 0.80736893], bias:-0.5822907419078873, loss:0.6095994289545849\n",
      "epoch:428, weight:[0.94045615 0.80731835], bias:-0.5830351022401925, loss:0.6095424314857124\n",
      "epoch:429, weight:[0.94056385 0.80726885], bias:-0.5837777538700174, loss:0.6094856856862201\n",
      "epoch:430, weight:[0.94067223 0.80722042], bias:-0.5845187027841122, loss:0.6094291897625048\n",
      "epoch:431, weight:[0.94078128 0.80717306], bias:-0.5852579549498595, loss:0.6093729419336525\n",
      "epoch:432, weight:[0.94089101 0.80712677], bias:-0.5859955163153139, loss:0.6093169404313546\n",
      "epoch:433, weight:[0.9410014  0.80708155], bias:-0.5867313928092422, loss:0.6092611834998258\n",
      "epoch:434, weight:[0.94111246 0.80703738], bias:-0.5874655903411642, loss:0.6092056693957214\n",
      "epoch:435, weight:[0.94122418 0.80699427], bias:-0.5881981148013926, loss:0.609150396388056\n",
      "epoch:436, weight:[0.94133656 0.80695221], bias:-0.588928972061074, loss:0.6090953627581214\n",
      "epoch:437, weight:[0.94144961 0.8069112 ], bias:-0.5896581679722294, loss:0.6090405667994064\n",
      "epoch:438, weight:[0.94156331 0.80687123], bias:-0.5903857083677956, loss:0.6089860068175162\n",
      "epoch:439, weight:[0.94167766 0.8068323 ], bias:-0.5911115990616657, loss:0.6089316811300928\n",
      "epoch:440, weight:[0.94179267 0.8067944 ], bias:-0.5918358458487306, loss:0.6088775880667339\n",
      "epoch:441, weight:[0.94190833 0.80675753], bias:-0.5925584545049204, loss:0.6088237259689154\n",
      "epoch:442, weight:[0.94202463 0.80672169], bias:-0.5932794307872457, loss:0.6087700931899126\n",
      "epoch:443, weight:[0.94214158 0.80668687], bias:-0.593998780433839, loss:0.6087166880947209\n",
      "epoch:444, weight:[0.94225918 0.80665307], bias:-0.5947165091639971, loss:0.6086635090599791\n",
      "epoch:445, weight:[0.94237741 0.80662029], bias:-0.595432622678222, loss:0.6086105544738912\n",
      "epoch:446, weight:[0.94249628 0.80658851], bias:-0.5961471266582635, loss:0.6085578227361502\n",
      "epoch:447, weight:[0.94261579 0.80655775], bias:-0.5968600267671612, loss:0.6085053122578613\n",
      "epoch:448, weight:[0.94273593 0.80652798], bias:-0.5975713286492863, loss:0.6084530214614658\n",
      "epoch:449, weight:[0.9428567  0.80649922], bias:-0.5982810379303843, loss:0.6084009487806656\n",
      "epoch:450, weight:[0.9429781  0.80647144], bias:-0.5989891602176173, loss:0.6083490926603475\n",
      "epoch:451, weight:[0.94310013 0.80644466], bias:-0.5996957010996062, loss:0.6082974515565098\n",
      "epoch:452, weight:[0.94322278 0.80641887], bias:-0.6004006661464738, loss:0.608246023936186\n",
      "epoch:453, weight:[0.94334606 0.80639406], bias:-0.601104060909887, loss:0.6081948082773724\n",
      "epoch:454, weight:[0.94346995 0.80637023], bias:-0.6018058909230999, loss:0.6081438030689544\n",
      "epoch:455, weight:[0.94359446 0.80634737], bias:-0.6025061617009967, loss:0.608093006810633\n",
      "epoch:456, weight:[0.94371959 0.80632548], bias:-0.6032048787401345, loss:0.6080424180128523\n",
      "epoch:457, weight:[0.94384533 0.80630457], bias:-0.6039020475187865, loss:0.6079920351967274\n",
      "epoch:458, weight:[0.94397168 0.80628461], bias:-0.604597673496985, loss:0.6079418568939725\n",
      "epoch:459, weight:[0.94409864 0.80626562], bias:-0.6052917621165649, loss:0.6078918816468298\n",
      "epoch:460, weight:[0.94422621 0.80624758], bias:-0.6059843188012067, loss:0.607842108007998\n",
      "epoch:461, weight:[0.94435438 0.80623049], bias:-0.6066753489564802, loss:0.6077925345405624\n",
      "epoch:462, weight:[0.94448315 0.80621436], bias:-0.6073648579698878, loss:0.6077431598179239\n",
      "epoch:463, weight:[0.94461252 0.80619916], bias:-0.6080528512109079, loss:0.6076939824237302\n",
      "epoch:464, weight:[0.94474249 0.80618491], bias:-0.608739334031039, loss:0.6076450009518063\n",
      "epoch:465, weight:[0.94487306 0.8061716 ], bias:-0.6094243117638427, loss:0.6075962140060845\n",
      "epoch:466, weight:[0.94500422 0.80615922], bias:-0.6101077897249882, loss:0.6075476202005377\n",
      "epoch:467, weight:[0.94513597 0.80614777], bias:-0.6107897732122956, loss:0.60749921815911\n",
      "epoch:468, weight:[0.94526831 0.80613724], bias:-0.6114702675057797, loss:0.6074510065156493\n",
      "epoch:469, weight:[0.94540123 0.80612764], bias:-0.6121492778676946, loss:0.6074029839138401\n",
      "epoch:470, weight:[0.94553475 0.80611895], bias:-0.6128268095425768, loss:0.6073551490071368\n",
      "epoch:471, weight:[0.94566884 0.80611118], bias:-0.6135028677572902, loss:0.6073075004586969\n",
      "epoch:472, weight:[0.94580351 0.80610433], bias:-0.6141774577210694, loss:0.6072600369413146\n",
      "epoch:473, weight:[0.94593876 0.80609838], bias:-0.614850584625564, loss:0.6072127571373562\n",
      "epoch:474, weight:[0.94607459 0.80609333], bias:-0.6155222536448832, loss:0.6071656597386936\n",
      "epoch:475, weight:[0.946211   0.80608919], bias:-0.6161924699356399, loss:0.6071187434466402\n",
      "epoch:476, weight:[0.94634797 0.80608594], bias:-0.6168612386369948, loss:0.6070720069718859\n",
      "epoch:477, weight:[0.94648551 0.80608358], bias:-0.617528564870701, loss:0.6070254490344331\n",
      "epoch:478, weight:[0.94662363 0.80608211], bias:-0.6181944537411479, loss:0.6069790683635332\n",
      "epoch:479, weight:[0.9467623  0.80608154], bias:-0.6188589103354063, loss:0.6069328636976226\n",
      "epoch:480, weight:[0.94690155 0.80608184], bias:-0.6195219397232723, loss:0.6068868337842604\n",
      "epoch:481, weight:[0.94704135 0.80608302], bias:-0.6201835469573121, loss:0.6068409773800659\n",
      "epoch:482, weight:[0.94718171 0.80608508], bias:-0.6208437370729065, loss:0.6067952932506553\n",
      "epoch:483, weight:[0.94732263 0.806088  ], bias:-0.6215025150882951, loss:0.6067497801705812\n",
      "epoch:484, weight:[0.94746411 0.8060918 ], bias:-0.6221598860046215, loss:0.6067044369232704\n",
      "epoch:485, weight:[0.94760614 0.80609646], bias:-0.6228158548059771, loss:0.6066592623009627\n",
      "epoch:486, weight:[0.94774872 0.80610199], bias:-0.6234704264594467, loss:0.6066142551046507\n",
      "epoch:487, weight:[0.94789185 0.80610837], bias:-0.6241236059151524, loss:0.6065694141440192\n",
      "epoch:488, weight:[0.94803552 0.8061156 ], bias:-0.6247753981062985, loss:0.6065247382373855\n",
      "epoch:489, weight:[0.94817975 0.80612369], bias:-0.6254258079492162, loss:0.6064802262116391\n",
      "epoch:490, weight:[0.94832451 0.80613262], bias:-0.6260748403434085, loss:0.6064358769021831\n",
      "epoch:491, weight:[0.94846982 0.8061424 ], bias:-0.6267225001715947, loss:0.6063916891528754\n",
      "epoch:492, weight:[0.94861567 0.80615302], bias:-0.6273687922997552, loss:0.6063476618159697\n",
      "epoch:493, weight:[0.94876205 0.80616447], bias:-0.6280137215771762, loss:0.6063037937520578\n",
      "epoch:494, weight:[0.94890897 0.80617676], bias:-0.6286572928364946, loss:0.6062600838300116\n",
      "epoch:495, weight:[0.94905642 0.80618988], bias:-0.629299510893743, loss:0.6062165309269261\n",
      "epoch:496, weight:[0.9492044  0.80620383], bias:-0.6299403805483939, loss:0.6061731339280612\n",
      "epoch:497, weight:[0.94935292 0.8062186 ], bias:-0.6305799065834047, loss:0.6061298917267867\n",
      "epoch:498, weight:[0.94950196 0.80623419], bias:-0.6312180937652629, loss:0.6060868032245248\n",
      "epoch:499, weight:[0.94965152 0.8062506 ], bias:-0.6318549468440307, loss:0.6060438673306942\n",
      "epoch:500, weight:[0.94980161 0.80626782], bias:-0.6324904705533893, loss:0.6060010829626546\n",
      "epoch:501, weight:[0.94995223 0.80628585], bias:-0.6331246696106844, loss:0.6059584490456514\n",
      "epoch:502, weight:[0.95010336 0.80630469], bias:-0.6337575487169707, loss:0.6059159645127613\n",
      "epoch:503, weight:[0.95025501 0.80632433], bias:-0.6343891125570565, loss:0.6058736283048367\n",
      "epoch:504, weight:[0.95040717 0.80634477], bias:-0.6350193657995491, loss:0.6058314393704521\n",
      "epoch:505, weight:[0.95055985 0.80636601], bias:-0.6356483130968988, loss:0.60578939666585\n",
      "epoch:506, weight:[0.95071304 0.80638804], bias:-0.6362759590854443, loss:0.6057474991548873\n",
      "epoch:507, weight:[0.95086675 0.80641086], bias:-0.636902308385457, loss:0.6057057458089824\n",
      "epoch:508, weight:[0.95102096 0.80643447], bias:-0.6375273656011863, loss:0.6056641356070616\n",
      "epoch:509, weight:[0.95117567 0.80645887], bias:-0.6381511353209037, loss:0.6056226675355072\n",
      "epoch:510, weight:[0.95133089 0.80648404], bias:-0.6387736221169482, loss:0.6055813405881052\n",
      "epoch:511, weight:[0.95148662 0.80651   ], bias:-0.6393948305457705, loss:0.605540153765993\n",
      "epoch:512, weight:[0.95164284 0.80653672], bias:-0.640014765147978, loss:0.6054991060776082\n",
      "epoch:513, weight:[0.95179957 0.80656422], bias:-0.6406334304483791, loss:0.6054581965386373\n",
      "epoch:514, weight:[0.95195679 0.80659249], bias:-0.6412508309560285, loss:0.6054174241719649\n",
      "epoch:515, weight:[0.95211451 0.80662152], bias:-0.6418669711642714, loss:0.6053767880076224\n",
      "epoch:516, weight:[0.95227272 0.80665132], bias:-0.642481855550788, loss:0.6053362870827391\n",
      "epoch:517, weight:[0.95243142 0.80668187], bias:-0.6430954885776385, loss:0.6052959204414912\n",
      "epoch:518, weight:[0.95259061 0.80671317], bias:-0.6437078746913076, loss:0.6052556871350523\n",
      "epoch:519, weight:[0.95275029 0.80674523], bias:-0.6443190183227487, loss:0.6052155862215444\n",
      "epoch:520, weight:[0.95291046 0.80677804], bias:-0.6449289238874288, loss:0.6051756167659886\n",
      "epoch:521, weight:[0.95307111 0.8068116 ], bias:-0.6455375957853728, loss:0.6051357778402577\n",
      "epoch:522, weight:[0.95323224 0.8068459 ], bias:-0.6461450384012082, loss:0.6050960685230253\n",
      "epoch:523, weight:[0.95339385 0.80688093], bias:-0.6467512561042091, loss:0.6050564878997204\n",
      "epoch:524, weight:[0.95355595 0.80691671], bias:-0.6473562532483412, loss:0.6050170350624784\n",
      "epoch:525, weight:[0.95371852 0.80695322], bias:-0.6479600341723057, loss:0.6049777091100936\n",
      "epoch:526, weight:[0.95388156 0.80699046], bias:-0.6485626031995838, loss:0.6049385091479721\n",
      "epoch:527, weight:[0.95404508 0.80702842], bias:-0.649163964638481, loss:0.6048994342880863\n",
      "epoch:528, weight:[0.95420908 0.80706711], bias:-0.6497641227821715, loss:0.6048604836489265\n",
      "epoch:529, weight:[0.95437354 0.80710653], bias:-0.6503630819087424, loss:0.6048216563554558\n",
      "epoch:530, weight:[0.95453847 0.80714666], bias:-0.6509608462812375, loss:0.6047829515390643\n",
      "epoch:531, weight:[0.95470387 0.8071875 ], bias:-0.651557420147702, loss:0.6047443683375227\n",
      "epoch:532, weight:[0.95486973 0.80722906], bias:-0.6521528077412265, loss:0.6047059058949379\n",
      "epoch:533, weight:[0.95503606 0.80727133], bias:-0.6527470132799909, loss:0.6046675633617079\n",
      "epoch:534, weight:[0.95520284 0.80731431], bias:-0.6533400409673084, loss:0.6046293398944763\n",
      "epoch:535, weight:[0.95537009 0.80735799], bias:-0.6539318949916697, loss:0.6045912346560889\n",
      "epoch:536, weight:[0.9555378  0.80740237], bias:-0.654522579526787, loss:0.6045532468155487\n",
      "epoch:537, weight:[0.95570596 0.80744745], bias:-0.6551120987316378, loss:0.6045153755479729\n",
      "epoch:538, weight:[0.95587458 0.80749322], bias:-0.6557004567505084, loss:0.604477620034549\n",
      "epoch:539, weight:[0.95604365 0.80753969], bias:-0.6562876577130383, loss:0.6044399794624912\n",
      "epoch:540, weight:[0.95621317 0.80758684], bias:-0.6568737057342638, loss:0.604402453024998\n",
      "epoch:541, weight:[0.95638314 0.80763468], bias:-0.6574586049146615, loss:0.6043650399212096\n",
      "epoch:542, weight:[0.95655356 0.80768321], bias:-0.658042359340192, loss:0.6043277393561648\n",
      "epoch:543, weight:[0.95672442 0.80773241], bias:-0.6586249730823438, loss:0.6042905505407593\n",
      "epoch:544, weight:[0.95689573 0.80778229], bias:-0.6592064501981767, loss:0.6042534726917044\n",
      "epoch:545, weight:[0.95706749 0.80783285], bias:-0.6597867947303652, loss:0.6042165050314839\n",
      "epoch:546, weight:[0.95723968 0.80788408], bias:-0.660366010707242, loss:0.6041796467883149\n",
      "epoch:547, weight:[0.95741232 0.80793597], bias:-0.6609441021428417, loss:0.6041428971961053\n",
      "epoch:548, weight:[0.95758539 0.80798854], bias:-0.6615210730369437, loss:0.6041062554944134\n",
      "epoch:549, weight:[0.9577589  0.80804177], bias:-0.6620969273751158, loss:0.6040697209284076\n",
      "epoch:550, weight:[0.95793284 0.80809565], bias:-0.6626716691287574, loss:0.6040332927488262\n",
      "epoch:551, weight:[0.95810722 0.8081502 ], bias:-0.6632453022551427, loss:0.6039969702119378\n",
      "epoch:552, weight:[0.95828203 0.8082054 ], bias:-0.6638178306974635, loss:0.6039607525795001\n",
      "epoch:553, weight:[0.95845727 0.80826125], bias:-0.6643892583848727, loss:0.6039246391187232\n",
      "epoch:554, weight:[0.95863294 0.80831775], bias:-0.6649595892325274, loss:0.6038886291022278\n",
      "epoch:555, weight:[0.95880903 0.8083749 ], bias:-0.6655288271416312, loss:0.6038527218080081\n",
      "epoch:556, weight:[0.95898555 0.80843269], bias:-0.6660969759994777, loss:0.6038169165193925\n",
      "epoch:557, weight:[0.9591625  0.80849113], bias:-0.6666640396794931, loss:0.6037812125250048\n",
      "epoch:558, weight:[0.95933986 0.8085502 ], bias:-0.6672300220412788, loss:0.6037456091187277\n",
      "epoch:559, weight:[0.95951765 0.80860991], bias:-0.6677949269306545, loss:0.603710105599663\n",
      "epoch:560, weight:[0.95969585 0.80867025], bias:-0.6683587581797005, loss:0.6036747012720953\n",
      "epoch:561, weight:[0.95987447 0.80873122], bias:-0.6689215196068004, loss:0.6036393954454545\n",
      "epoch:562, weight:[0.96005351 0.80879282], bias:-0.6694832150166835, loss:0.6036041874342783\n",
      "epoch:563, weight:[0.96023296 0.80885504], bias:-0.6700438482004675, loss:0.6035690765581756\n",
      "epoch:564, weight:[0.96041283 0.80891789], bias:-0.6706034229357005, loss:0.6035340621417903\n",
      "epoch:565, weight:[0.96059311 0.80898135], bias:-0.6711619429864039, loss:0.6034991435147645\n",
      "epoch:566, weight:[0.96077379 0.80904544], bias:-0.6717194121031137, loss:0.6034643200117021\n",
      "epoch:567, weight:[0.96095488 0.80911013], bias:-0.6722758340229238, loss:0.6034295909721343\n",
      "epoch:568, weight:[0.96113638 0.80917544], bias:-0.672831212469527, loss:0.6033949557404829\n",
      "epoch:569, weight:[0.96131829 0.80924136], bias:-0.673385551153258, loss:0.6033604136660243\n",
      "epoch:570, weight:[0.9615006  0.80930788], bias:-0.6739388537711348, loss:0.6033259641028568\n",
      "epoch:571, weight:[0.96168331 0.80937501], bias:-0.6744911240069006, loss:0.603291606409863\n",
      "epoch:572, weight:[0.96186642 0.80944274], bias:-0.6750423655310658, loss:0.603257339950677\n",
      "epoch:573, weight:[0.96204993 0.80951107], bias:-0.6755925820009498, loss:0.6032231640936495\n",
      "epoch:574, weight:[0.96223384 0.80957999], bias:-0.6761417770607226, loss:0.6031890782118129\n",
      "epoch:575, weight:[0.96241814 0.80964951], bias:-0.6766899543414463, loss:0.6031550816828487\n",
      "epoch:576, weight:[0.96260284 0.80971962], bias:-0.6772371174611166, loss:0.6031211738890531\n",
      "epoch:577, weight:[0.96278793 0.80979032], bias:-0.6777832700247046, loss:0.6030873542173028\n",
      "epoch:578, weight:[0.96297342 0.8098616 ], bias:-0.6783284156241979, loss:0.6030536220590235\n",
      "epoch:579, weight:[0.96315929 0.80993347], bias:-0.6788725578386419, loss:0.6030199768101551\n",
      "epoch:580, weight:[0.96334555 0.81000592], bias:-0.6794157002341812, loss:0.6029864178711203\n",
      "epoch:581, weight:[0.9635322  0.81007894], bias:-0.6799578463641006, loss:0.6029529446467916\n",
      "epoch:582, weight:[0.96371924 0.81015254], bias:-0.6804989997688664, loss:0.6029195565464578\n",
      "epoch:583, weight:[0.96390666 0.81022672], bias:-0.681039163976167, loss:0.6028862529837945\n",
      "epoch:584, weight:[0.96409446 0.81030146], bias:-0.6815783425009544, loss:0.602853033376829\n",
      "epoch:585, weight:[0.96428264 0.81037678], bias:-0.6821165388454844, loss:0.6028198971479118\n",
      "epoch:586, weight:[0.9644712  0.81045266], bias:-0.682653756499358, loss:0.6027868437236826\n",
      "epoch:587, weight:[0.96466015 0.8105291 ], bias:-0.6831899989395617, loss:0.6027538725350404\n",
      "epoch:588, weight:[0.96484947 0.8106061 ], bias:-0.6837252696305081, loss:0.6027209830171122\n",
      "epoch:589, weight:[0.96503916 0.81068367], bias:-0.6842595720240766, loss:0.602688174609222\n",
      "epoch:590, weight:[0.96522923 0.81076179], bias:-0.6847929095596541, loss:0.6026554467548607\n",
      "epoch:591, weight:[0.96541967 0.81084046], bias:-0.6853252856641747, loss:0.6026227989016554\n",
      "epoch:592, weight:[0.96561049 0.81091968], bias:-0.6858567037521607, loss:0.6025902305013383\n",
      "epoch:593, weight:[0.96580167 0.81099946], bias:-0.6863871672257622, loss:0.6025577410097189\n",
      "epoch:594, weight:[0.96599322 0.81107977], bias:-0.6869166794747978, loss:0.6025253298866523\n",
      "epoch:595, weight:[0.96618514 0.81116064], bias:-0.6874452438767943, loss:0.6024929965960107\n",
      "epoch:596, weight:[0.96637743 0.81124204], bias:-0.6879728637970266, loss:0.6024607406056532\n",
      "epoch:597, weight:[0.96657008 0.81132399], bias:-0.688499542588558, loss:0.6024285613873976\n",
      "epoch:598, weight:[0.96676309 0.81140647], bias:-0.6890252835922794, loss:0.6023964584169913\n",
      "epoch:599, weight:[0.96695647 0.81148948], bias:-0.6895500901369499, loss:0.6023644311740811\n",
      "epoch:600, weight:[0.96715021 0.81157303], bias:-0.6900739655392354, loss:0.6023324791421875\n",
      "epoch:601, weight:[0.9673443  0.81165711], bias:-0.6905969131037488, loss:0.6023006018086734\n",
      "epoch:602, weight:[0.96753875 0.81174172], bias:-0.6911189361230896, loss:0.6022687986647178\n",
      "epoch:603, weight:[0.96773356 0.81182685], bias:-0.6916400378778826, loss:0.6022370692052875\n",
      "epoch:604, weight:[0.96792873 0.8119125 ], bias:-0.692160221636818, loss:0.6022054129291091\n",
      "epoch:605, weight:[0.96812425 0.81199868], bias:-0.69267949065669, loss:0.6021738293386409\n",
      "epoch:606, weight:[0.96832012 0.81208537], bias:-0.6931978481824361, loss:0.6021423179400472\n",
      "epoch:607, weight:[0.96851634 0.81217258], bias:-0.6937152974471765, loss:0.6021108782431698\n",
      "epoch:608, weight:[0.96871291 0.8122603 ], bias:-0.6942318416722525, loss:0.6020795097615008\n",
      "epoch:609, weight:[0.96890983 0.81234853], bias:-0.6947474840672657, loss:0.6020482120121566\n",
      "epoch:610, weight:[0.9691071  0.81243728], bias:-0.6952622278301169, loss:0.6020169845158514\n",
      "epoch:611, weight:[0.96930471 0.81252653], bias:-0.6957760761470445, loss:0.6019858267968701\n",
      "epoch:612, weight:[0.96950267 0.81261628], bias:-0.6962890321926631, loss:0.601954738383042\n",
      "epoch:613, weight:[0.96970097 0.81270654], bias:-0.6968010991300025, loss:0.6019237188057164\n",
      "epoch:614, weight:[0.96989962 0.8127973 ], bias:-0.6973122801105456, loss:0.6018927675997335\n",
      "epoch:615, weight:[0.9700986  0.81288856], bias:-0.6978225782742669, loss:0.6018618843034029\n",
      "epoch:616, weight:[0.97029792 0.81298031], bias:-0.6983319967496708, loss:0.601831068458474\n",
      "epoch:617, weight:[0.97049758 0.81307255], bias:-0.6988405386538302, loss:0.6018003196101137\n",
      "epoch:618, weight:[0.97069758 0.81316529], bias:-0.6993482070924237, loss:0.6017696373068797\n",
      "epoch:619, weight:[0.97089792 0.81325852], bias:-0.6998550051597745, loss:0.6017390211006963\n",
      "epoch:620, weight:[0.97109858 0.81335223], bias:-0.7003609359388875, loss:0.6017084705468284\n",
      "epoch:621, weight:[0.97129959 0.81344643], bias:-0.7008660025014877, loss:0.6016779852038586\n",
      "epoch:622, weight:[0.97150092 0.81354111], bias:-0.7013702079080577, loss:0.6016475646336619\n",
      "epoch:623, weight:[0.97170258 0.81363627], bias:-0.7018735552078756, loss:0.6016172084013807\n",
      "epoch:624, weight:[0.97190458 0.81373191], bias:-0.7023760474390521, loss:0.6015869160754023\n",
      "epoch:625, weight:[0.9721069  0.81382803], bias:-0.7028776876285684, loss:0.6015566872273332\n",
      "epoch:626, weight:[0.97230954 0.81392462], bias:-0.7033784787923131, loss:0.6015265214319775\n",
      "epoch:627, weight:[0.97251252 0.81402168], bias:-0.70387842393512, loss:0.6014964182673107\n",
      "epoch:628, weight:[0.97271581 0.81411922], bias:-0.7043775260508051, loss:0.6014663773144585\n",
      "epoch:629, weight:[0.97291944 0.81421722], bias:-0.7048757881222034, loss:0.6014363981576722\n",
      "epoch:630, weight:[0.97312338 0.81431568], bias:-0.7053732131212066, loss:0.6014064803843066\n",
      "epoch:631, weight:[0.97332764 0.81441461], bias:-0.7058698040087992, loss:0.6013766235847962\n",
      "epoch:632, weight:[0.97353223 0.814514  ], bias:-0.7063655637350958, loss:0.6013468273526327\n",
      "epoch:633, weight:[0.97373713 0.81461386], bias:-0.7068604952393781, loss:0.6013170912843425\n",
      "epoch:634, weight:[0.97394234 0.81471416], bias:-0.7073546014501307, loss:0.6012874149794653\n",
      "epoch:635, weight:[0.97414788 0.81481493], bias:-0.7078478852850787, loss:0.6012577980405289\n",
      "epoch:636, weight:[0.97435373 0.81491614], bias:-0.7083403496512234, loss:0.6012282400730302\n",
      "epoch:637, weight:[0.97455989 0.81501781], bias:-0.7088319974448788, loss:0.601198740685412\n",
      "epoch:638, weight:[0.97476637 0.81511993], bias:-0.7093228315517083, loss:0.6011692994890406\n",
      "epoch:639, weight:[0.97497315 0.8152225 ], bias:-0.7098128548467604, loss:0.6011399160981848\n",
      "epoch:640, weight:[0.97518025 0.8153255 ], bias:-0.7103020701945052, loss:0.601110590129995\n",
      "epoch:641, weight:[0.97538765 0.81542896], bias:-0.71079048044887, loss:0.6010813212044803\n",
      "epoch:642, weight:[0.97559536 0.81553285], bias:-0.7112780884532757, loss:0.6010521089444885\n",
      "epoch:643, weight:[0.97580338 0.81563718], bias:-0.711764897040672, loss:0.6010229529756848\n",
      "epoch:644, weight:[0.97601171 0.81574195], bias:-0.7122509090335738, loss:0.6009938529265308\n",
      "epoch:645, weight:[0.97622034 0.81584716], bias:-0.7127361272440965, loss:0.6009648084282638\n",
      "epoch:646, weight:[0.97642927 0.8159528 ], bias:-0.7132205544739916, loss:0.6009358191148761\n",
      "epoch:647, weight:[0.9766385  0.81605887], bias:-0.713704193514682, loss:0.6009068846230946\n",
      "epoch:648, weight:[0.97684803 0.81616537], bias:-0.7141870471472976, loss:0.600878004592361\n",
      "epoch:649, weight:[0.97705787 0.81627229], bias:-0.7146691181427106, loss:0.6008491786648106\n",
      "epoch:650, weight:[0.977268   0.81637964], bias:-0.7151504092615705, loss:0.6008204064852531\n",
      "epoch:651, weight:[0.97747843 0.81648742], bias:-0.7156309232543392, loss:0.6007916877011529\n",
      "epoch:652, weight:[0.97768916 0.81659561], bias:-0.7161106628613262, loss:0.6007630219626081\n",
      "epoch:653, weight:[0.97790018 0.81670423], bias:-0.7165896308127232, loss:0.6007344089223329\n",
      "epoch:654, weight:[0.97811149 0.81681326], bias:-0.7170678298286391, loss:0.600705848235636\n",
      "epoch:655, weight:[0.9783231  0.81692271], bias:-0.717545262619135, loss:0.6006773395604033\n",
      "epoch:656, weight:[0.978535   0.81703257], bias:-0.718021931884258, loss:0.6006488825570773\n",
      "epoch:657, weight:[0.97874719 0.81714285], bias:-0.7184978403140766, loss:0.6006204768886386\n",
      "epoch:658, weight:[0.97895967 0.81725353], bias:-0.7189729905887148, loss:0.6005921222205871\n",
      "epoch:659, weight:[0.97917243 0.81736462], bias:-0.7194473853783862, loss:0.6005638182209225\n",
      "epoch:660, weight:[0.97938549 0.81747612], bias:-0.7199210273434287, loss:0.600535564560128\n",
      "epoch:661, weight:[0.97959883 0.81758803], bias:-0.7203939191343385, loss:0.6005073609111482\n",
      "epoch:662, weight:[0.97981246 0.81770033], bias:-0.7208660633918039, loss:0.6004792069493735\n",
      "epoch:663, weight:[0.98002637 0.81781304], bias:-0.7213374627467397, loss:0.6004511023526216\n",
      "epoch:664, weight:[0.98024056 0.81792614], bias:-0.7218081198203208, loss:0.6004230468011178\n",
      "epoch:665, weight:[0.98045504 0.81803964], bias:-0.7222780372240161, loss:0.6003950399774786\n",
      "epoch:666, weight:[0.98066979 0.81815354], bias:-0.7227472175596222, loss:0.600367081566694\n",
      "epoch:667, weight:[0.98088483 0.81826783], bias:-0.723215663419297, loss:0.6003391712561084\n",
      "epoch:668, weight:[0.98110015 0.81838251], bias:-0.7236833773855931, loss:0.600311308735404\n",
      "epoch:669, weight:[0.98131574 0.81849758], bias:-0.7241503620314913, loss:0.6002834936965831\n",
      "epoch:670, weight:[0.98153161 0.81861304], bias:-0.7246166199204341, loss:0.6002557258339511\n",
      "epoch:671, weight:[0.98174775 0.81872888], bias:-0.7250821536063587, loss:0.6002280048440993\n",
      "epoch:672, weight:[0.98196417 0.81884511], bias:-0.7255469656337303, loss:0.6002003304258872\n",
      "epoch:673, weight:[0.98218087 0.81896172], bias:-0.7260110585375749, loss:0.600172702280426\n",
      "epoch:674, weight:[0.98239783 0.81907871], bias:-0.7264744348435124, loss:0.6001451201110618\n",
      "epoch:675, weight:[0.98261507 0.81919608], bias:-0.7269370970677896, loss:0.6001175836233592\n",
      "epoch:676, weight:[0.98283258 0.81931383], bias:-0.727399047717313, loss:0.6000900925250837\n",
      "epoch:677, weight:[0.98305035 0.81943195], bias:-0.7278602892896809, loss:0.6000626465261863\n",
      "epoch:678, weight:[0.9832684  0.81955045], bias:-0.728320824273217, loss:0.6000352453387873\n",
      "epoch:679, weight:[0.98348671 0.81966931], bias:-0.7287806551470017, loss:0.6000078886771586\n",
      "epoch:680, weight:[0.98370529 0.81978855], bias:-0.7292397843809058, loss:0.5999805762577088\n",
      "epoch:681, weight:[0.98392414 0.81990816], bias:-0.7296982144356214, loss:0.5999533077989679\n",
      "epoch:682, weight:[0.98414325 0.82002813], bias:-0.7301559477626954, loss:0.5999260830215692\n",
      "epoch:683, weight:[0.98436262 0.82014847], bias:-0.7306129868045608, loss:0.5998989016482361\n",
      "epoch:684, weight:[0.98458225 0.82026917], bias:-0.731069333994569, loss:0.5998717634037642\n",
      "epoch:685, weight:[0.98480215 0.82039023], bias:-0.7315249917570218, loss:0.5998446680150072\n",
      "epoch:686, weight:[0.9850223  0.82051165], bias:-0.7319799625072031, loss:0.5998176152108614\n",
      "epoch:687, weight:[0.98524272 0.82063343], bias:-0.7324342486514108, loss:0.5997906047222498\n",
      "epoch:688, weight:[0.98546339 0.82075557], bias:-0.7328878525869885, loss:0.599763636282107\n",
      "epoch:689, weight:[0.98568433 0.82087806], bias:-0.7333407767023569, loss:0.5997367096253648\n",
      "epoch:690, weight:[0.98590551 0.8210009 ], bias:-0.7337930233770451, loss:0.5997098244889367\n",
      "epoch:691, weight:[0.98612696 0.82112409], bias:-0.7342445949817226, loss:0.5996829806117028\n",
      "epoch:692, weight:[0.98634865 0.82124764], bias:-0.7346954938782299, loss:0.5996561777344956\n",
      "epoch:693, weight:[0.98657061 0.82137153], bias:-0.7351457224196103, loss:0.5996294156000852\n",
      "epoch:694, weight:[0.98679281 0.82149577], bias:-0.7355952829501406, loss:0.5996026939531646\n",
      "epoch:695, weight:[0.98701527 0.82162035], bias:-0.7360441778053625, loss:0.5995760125403351\n",
      "epoch:696, weight:[0.98723797 0.82174528], bias:-0.7364924093121128, loss:0.5995493711100932\n",
      "epoch:697, weight:[0.98746093 0.82187055], bias:-0.7369399797885552, loss:0.5995227694128141\n",
      "epoch:698, weight:[0.98768413 0.82199615], bias:-0.7373868915442103, loss:0.59949620720074\n",
      "epoch:699, weight:[0.98790758 0.8221221 ], bias:-0.7378331468799868, loss:0.5994696842279645\n",
      "epoch:700, weight:[0.98813128 0.82224838], bias:-0.7382787480882116, loss:0.5994432002504196\n",
      "epoch:701, weight:[0.98835523 0.822375  ], bias:-0.7387236974526604, loss:0.5994167550258609\n",
      "epoch:702, weight:[0.98857942 0.82250195], bias:-0.7391679972485884, loss:0.5993903483138551\n",
      "epoch:703, weight:[0.98880385 0.82262923], bias:-0.7396116497427601, loss:0.5993639798757656\n",
      "epoch:704, weight:[0.98902853 0.82275684], bias:-0.7400546571934798, loss:0.5993376494747392\n",
      "epoch:705, weight:[0.98925345 0.82288478], bias:-0.7404970218506219, loss:0.5993113568756926\n",
      "epoch:706, weight:[0.98947861 0.82301305], bias:-0.7409387459556603, loss:0.5992851018452993\n",
      "epoch:707, weight:[0.98970401 0.82314164], bias:-0.7413798317416991, loss:0.5992588841519763\n",
      "epoch:708, weight:[0.98992965 0.82327056], bias:-0.7418202814335015, loss:0.5992327035658709\n",
      "epoch:709, weight:[0.99015553 0.82339979], bias:-0.7422600972475207, loss:0.5992065598588477\n",
      "epoch:710, weight:[0.99038165 0.82352935], bias:-0.7426992813919285, loss:0.5991804528044763\n",
      "epoch:711, weight:[0.990608   0.82365923], bias:-0.7431378360666455, loss:0.5991543821780172\n",
      "epoch:712, weight:[0.99083459 0.82378943], bias:-0.7435757634633704, loss:0.5991283477564101\n",
      "epoch:713, weight:[0.99106141 0.82391994], bias:-0.7440130657656093, loss:0.5991023493182609\n",
      "epoch:714, weight:[0.99128847 0.82405077], bias:-0.7444497451487052, loss:0.5990763866438292\n",
      "epoch:715, weight:[0.99151576 0.8241819 ], bias:-0.744885803779867, loss:0.599050459515016\n",
      "epoch:716, weight:[0.99174329 0.82431336], bias:-0.7453212438181989, loss:0.5990245677153515\n",
      "epoch:717, weight:[0.99197104 0.82444512], bias:-0.7457560674147289, loss:0.5989987110299814\n",
      "epoch:718, weight:[0.99219903 0.82457719], bias:-0.7461902767124383, loss:0.5989728892456574\n",
      "epoch:719, weight:[0.99242724 0.82470956], bias:-0.7466238738462905, loss:0.5989471021507223\n",
      "epoch:720, weight:[0.99265569 0.82484224], bias:-0.7470568609432592, loss:0.5989213495351001\n",
      "epoch:721, weight:[0.99288436 0.82497523], bias:-0.7474892401223578, loss:0.5988956311902828\n",
      "epoch:722, weight:[0.99311326 0.82510852], bias:-0.7479210134946677, loss:0.5988699469093194\n",
      "epoch:723, weight:[0.99334238 0.82524211], bias:-0.7483521831633664, loss:0.5988442964868035\n",
      "epoch:724, weight:[0.99357173 0.82537599], bias:-0.7487827512237566, loss:0.5988186797188622\n",
      "epoch:725, weight:[0.99380131 0.82551018], bias:-0.7492127197632942, loss:0.5987930964031436\n",
      "epoch:726, weight:[0.99403111 0.82564466], bias:-0.7496420908616164, loss:0.5987675463388077\n",
      "epoch:727, weight:[0.99426113 0.82577944], bias:-0.75007086659057, loss:0.5987420293265113\n",
      "epoch:728, weight:[0.99449137 0.82591451], bias:-0.7504990490142395, loss:0.5987165451684006\n",
      "epoch:729, weight:[0.99472184 0.82604988], bias:-0.7509266401889748, loss:0.5986910936680965\n",
      "epoch:730, weight:[0.99495252 0.82618553], bias:-0.7513536421634196, loss:0.5986656746306859\n",
      "epoch:731, weight:[0.99518342 0.82632148], bias:-0.7517800569785387, loss:0.59864028786271\n",
      "epoch:732, weight:[0.99541455 0.82645771], bias:-0.7522058866676459, loss:0.5986149331721523\n",
      "epoch:733, weight:[0.99564589 0.82659423], bias:-0.7526311332564316, loss:0.5985896103684295\n",
      "epoch:734, weight:[0.99587744 0.82673103], bias:-0.7530557987629903, loss:0.5985643192623793\n",
      "epoch:735, weight:[0.99610921 0.82686812], bias:-0.7534798851978484, loss:0.5985390596662499\n",
      "epoch:736, weight:[0.9963412  0.82700548], bias:-0.7539033945639907, loss:0.5985138313936897\n",
      "epoch:737, weight:[0.99657341 0.82714313], bias:-0.7543263288568888, loss:0.5984886342597368\n",
      "epoch:738, weight:[0.99680582 0.82728106], bias:-0.7547486900645273, loss:0.5984634680808075\n",
      "epoch:739, weight:[0.99703845 0.82741927], bias:-0.7551704801674314, loss:0.5984383326746877\n",
      "epoch:740, weight:[0.99727129 0.82755776], bias:-0.755591701138694, loss:0.598413227860521\n",
      "epoch:741, weight:[0.99750434 0.82769652], bias:-0.7560123549440023, loss:0.5983881534587985\n",
      "epoch:742, weight:[0.99773761 0.82783555], bias:-0.756432443541665, loss:0.59836310929135\n",
      "epoch:743, weight:[0.99797108 0.82797485], bias:-0.7568519688826385, loss:0.5983380951813315\n",
      "epoch:744, weight:[0.99820476 0.82811443], bias:-0.7572709329105543, loss:0.5983131109532186\n",
      "epoch:745, weight:[0.99843865 0.82825428], bias:-0.757689337561745, loss:0.5982881564327929\n",
      "epoch:746, weight:[0.99867274 0.82839439], bias:-0.758107184765271, loss:0.5982632314471342\n",
      "epoch:747, weight:[0.99890705 0.82853478], bias:-0.7585244764429471, loss:0.5982383358246103\n",
      "epoch:748, weight:[0.99914155 0.82867542], bias:-0.7589412145093686, loss:0.5982134693948674\n",
      "epoch:749, weight:[0.99937627 0.82881634], bias:-0.7593574008719377, loss:0.5981886319888198\n",
      "epoch:750, weight:[0.99961118 0.82895751], bias:-0.7597730374308894, loss:0.5981638234386412\n",
      "epoch:751, weight:[0.9998463  0.82909895], bias:-0.7601881260793178, loss:0.5981390435777537\n",
      "epoch:752, weight:[1.00008162 0.82924065], bias:-0.7606026687032024, loss:0.5981142922408208\n",
      "epoch:753, weight:[1.00031715 0.8293826 ], bias:-0.761016667181433, loss:0.5980895692637355\n",
      "epoch:754, weight:[1.00055287 0.82952482], bias:-0.7614301233858368, loss:0.5980648744836122\n",
      "epoch:755, weight:[1.0007888  0.82966729], bias:-0.7618430391812033, loss:0.5980402077387775\n",
      "epoch:756, weight:[1.00102492 0.82981002], bias:-0.7622554164253101, loss:0.5980155688687607\n",
      "epoch:757, weight:[1.00126125 0.829953  ], bias:-0.7626672569689489, loss:0.5979909577142849\n",
      "epoch:758, weight:[1.00149777 0.83009623], bias:-0.7630785626559502, loss:0.5979663741172574\n",
      "epoch:759, weight:[1.00173449 0.83023971], bias:-0.7634893353232096, loss:0.5979418179207617\n",
      "epoch:760, weight:[1.0019714  0.83038345], bias:-0.7638995768007124, loss:0.597917288969048\n",
      "epoch:761, weight:[1.00220851 0.83052743], bias:-0.7643092889115594, loss:0.5978927871075244\n",
      "epoch:762, weight:[1.00244582 0.83067166], bias:-0.7647184734719916, loss:0.5978683121827477\n",
      "epoch:763, weight:[1.00268332 0.83081613], bias:-0.7651271322914157, loss:0.5978438640424159\n",
      "epoch:764, weight:[1.00292101 0.83096086], bias:-0.7655352671724286, loss:0.5978194425353581\n",
      "epoch:765, weight:[1.0031589  0.83110582], bias:-0.7659428799108429, loss:0.5977950475115276\n",
      "epoch:766, weight:[1.00339697 0.83125103], bias:-0.7663499722957112, loss:0.5977706788219911\n",
      "epoch:767, weight:[1.00363524 0.83139648], bias:-0.7667565461093514, loss:0.5977463363189225\n",
      "epoch:768, weight:[1.0038737  0.83154216], bias:-0.7671626031273708, loss:0.597722019855593\n",
      "epoch:769, weight:[1.00411235 0.83168809], bias:-0.7675681451186911, loss:0.5976977292863643\n",
      "epoch:770, weight:[1.00435119 0.83183426], bias:-0.7679731738455725, loss:0.5976734644666782\n",
      "epoch:771, weight:[1.00459022 0.83198066], bias:-0.7683776910636387, loss:0.5976492252530503\n",
      "epoch:772, weight:[1.00482943 0.83212729], bias:-0.7687816985219009, loss:0.5976250115030608\n",
      "epoch:773, weight:[1.00506883 0.83227416], bias:-0.7691851979627821, loss:0.5976008230753472\n",
      "epoch:774, weight:[1.00530842 0.83242126], bias:-0.7695881911221409, loss:0.5975766598295954\n",
      "epoch:775, weight:[1.00554819 0.8325686 ], bias:-0.7699906797292967, loss:0.597552521626532\n",
      "epoch:776, weight:[1.00578815 0.83271616], bias:-0.7703926655070524, loss:0.5975284083279173\n",
      "epoch:777, weight:[1.00602829 0.83286395], bias:-0.7707941501717194, loss:0.5975043197965362\n",
      "epoch:778, weight:[1.00626861 0.83301197], bias:-0.7711951354331408, loss:0.5974802558961909\n",
      "epoch:779, weight:[1.00650912 0.83316022], bias:-0.7715956229947155, loss:0.5974562164916939\n",
      "epoch:780, weight:[1.00674981 0.83330869], bias:-0.7719956145534218, loss:0.5974322014488587\n",
      "epoch:781, weight:[1.00699068 0.83345739], bias:-0.7723951117998411, loss:0.5974082106344938\n",
      "epoch:782, weight:[1.00723173 0.8336063 ], bias:-0.7727941164181815, loss:0.5973842439163944\n",
      "epoch:783, weight:[1.00747297 0.83375545], bias:-0.7731926300863011, loss:0.5973603011633352\n",
      "epoch:784, weight:[1.00771438 0.83390481], bias:-0.7735906544757314, loss:0.5973363822450624\n",
      "epoch:785, weight:[1.00795596 0.83405439], bias:-0.7739881912517008, loss:0.5973124870322862\n",
      "epoch:786, weight:[1.00819773 0.83420419], bias:-0.7743852420731577, loss:0.5972886153966759\n",
      "epoch:787, weight:[1.00843968 0.8343542 ], bias:-0.7747818085927938, loss:0.5972647672108484\n",
      "epoch:788, weight:[1.0086818  0.83450444], bias:-0.7751778924570668, loss:0.5972409423483648\n",
      "epoch:789, weight:[1.00892409 0.83465488], bias:-0.7755734953062241, loss:0.5972171406837208\n",
      "epoch:790, weight:[1.00916656 0.83480554], bias:-0.7759686187743249, loss:0.5971933620923413\n",
      "epoch:791, weight:[1.00940921 0.83495642], bias:-0.7763632644892635, loss:0.5971696064505718\n",
      "epoch:792, weight:[1.00965203 0.8351075 ], bias:-0.7767574340727924, loss:0.597145873635673\n",
      "epoch:793, weight:[1.00989502 0.8352588 ], bias:-0.7771511291405442, loss:0.5971221635258123\n",
      "epoch:794, weight:[1.01013819 0.8354103 ], bias:-0.7775443513020547, loss:0.5970984760000573\n",
      "epoch:795, weight:[1.01038152 0.83556201], bias:-0.7779371021607856, loss:0.5970748109383704\n",
      "epoch:796, weight:[1.01062503 0.83571393], bias:-0.7783293833141466, loss:0.5970511682216002\n",
      "epoch:797, weight:[1.01086871 0.83586606], bias:-0.7787211963535178, loss:0.5970275477314749\n",
      "epoch:798, weight:[1.01111256 0.83601839], bias:-0.7791125428642723, loss:0.5970039493505972\n",
      "epoch:799, weight:[1.01135658 0.83617092], bias:-0.7795034244257985, loss:0.5969803729624356\n",
      "epoch:800, weight:[1.01160076 0.83632366], bias:-0.7798938426115216, loss:0.5969568184513195\n",
      "epoch:801, weight:[1.01184512 0.8364766 ], bias:-0.7802837989889264, loss:0.5969332857024315\n",
      "epoch:802, weight:[1.01208964 0.83662973], bias:-0.7806732951195791, loss:0.5969097746018015\n",
      "epoch:803, weight:[1.01233433 0.83678307], bias:-0.7810623325591489, loss:0.5968862850363\n",
      "epoch:804, weight:[1.01257918 0.83693661], bias:-0.7814509128574305, loss:0.5968628168936324\n",
      "epoch:805, weight:[1.0128242  0.83709034], bias:-0.7818390375583653, loss:0.596839370062331\n",
      "epoch:806, weight:[1.01306939 0.83724427], bias:-0.7822267082000632, loss:0.5968159444317508\n",
      "epoch:807, weight:[1.01331474 0.83739839], bias:-0.782613926314825, loss:0.5967925398920614\n",
      "epoch:808, weight:[1.01356025 0.83755271], bias:-0.7830006934291626, loss:0.5967691563342418\n",
      "epoch:809, weight:[1.01380592 0.83770722], bias:-0.7833870110638217, loss:0.5967457936500744\n",
      "epoch:810, weight:[1.01405176 0.83786192], bias:-0.7837728807338027, loss:0.5967224517321384\n",
      "epoch:811, weight:[1.01429776 0.83801681], bias:-0.7841583039483819, loss:0.596699130473804\n",
      "epoch:812, weight:[1.01454392 0.8381719 ], bias:-0.7845432822111333, loss:0.5966758297692252\n",
      "epoch:813, weight:[1.01479024 0.83832717], bias:-0.7849278170199492, loss:0.5966525495133363\n",
      "epoch:814, weight:[1.01503672 0.83848262], bias:-0.7853119098670617, loss:0.5966292896018438\n",
      "epoch:815, weight:[1.01528336 0.83863827], bias:-0.7856955622390637, loss:0.5966060499312212\n",
      "epoch:816, weight:[1.01553016 0.8387941 ], bias:-0.7860787756169297, loss:0.5965828303987034\n",
      "epoch:817, weight:[1.01577711 0.83895012], bias:-0.786461551476037, loss:0.5965596309022811\n",
      "epoch:818, weight:[1.01602423 0.83910631], bias:-0.7868438912861863, loss:0.5965364513406937\n",
      "epoch:819, weight:[1.0162715 0.8392627], bias:-0.7872257965116224, loss:0.5965132916134253\n",
      "epoch:820, weight:[1.01651892 0.83941926], bias:-0.7876072686110552, loss:0.5964901516206981\n",
      "epoch:821, weight:[1.01676651 0.839576  ], bias:-0.7879883090376804, loss:0.5964670312634669\n",
      "epoch:822, weight:[1.01701424 0.83973292], bias:-0.7883689192391992, loss:0.5964439304434136\n",
      "epoch:823, weight:[1.01726213 0.83989002], bias:-0.7887491006578398, loss:0.5964208490629419\n",
      "epoch:824, weight:[1.01751018 0.8400473 ], bias:-0.7891288547303772, loss:0.5963977870251707\n",
      "epoch:825, weight:[1.01775838 0.84020476], bias:-0.7895081828881539, loss:0.5963747442339307\n",
      "epoch:826, weight:[1.01800673 0.84036239], bias:-0.7898870865571, loss:0.5963517205937569\n",
      "epoch:827, weight:[1.01825523 0.84052019], bias:-0.7902655671577532, loss:0.5963287160098844\n",
      "epoch:828, weight:[1.01850388 0.84067817], bias:-0.7906436261052792, loss:0.5963057303882425\n",
      "epoch:829, weight:[1.01875269 0.84083632], bias:-0.7910212648094916, loss:0.5962827636354505\n",
      "epoch:830, weight:[1.01900165 0.84099464], bias:-0.7913984846748722, loss:0.5962598156588101\n",
      "epoch:831, weight:[1.01925075 0.84115313], bias:-0.7917752871005903, loss:0.5962368863663035\n",
      "epoch:832, weight:[1.01950001 0.8413118 ], bias:-0.7921516734805232, loss:0.596213975666585\n",
      "epoch:833, weight:[1.01974941 0.84147063], bias:-0.7925276452032756, loss:0.5961910834689781\n",
      "epoch:834, weight:[1.01999896 0.84162963], bias:-0.7929032036521994, loss:0.5961682096834693\n",
      "epoch:835, weight:[1.02024866 0.84178879], bias:-0.7932783502054134, loss:0.5961453542207035\n",
      "epoch:836, weight:[1.0204985  0.84194812], bias:-0.7936530862358228, loss:0.5961225169919786\n",
      "epoch:837, weight:[1.02074849 0.84210762], bias:-0.7940274131111386, loss:0.5960996979092409\n",
      "epoch:838, weight:[1.02099863 0.84226728], bias:-0.7944013321938973, loss:0.59607689688508\n",
      "epoch:839, weight:[1.02124892 0.8424271 ], bias:-0.7947748448414801, loss:0.5960541138327241\n",
      "epoch:840, weight:[1.02149934 0.84258708], bias:-0.7951479524061321, loss:0.5960313486660346\n",
      "epoch:841, weight:[1.02174991 0.84274723], bias:-0.7955206562349818, loss:0.5960086012995016\n",
      "epoch:842, weight:[1.02200063 0.84290753], bias:-0.7958929576700601, loss:0.5959858716482395\n",
      "epoch:843, weight:[1.02225149 0.843068  ], bias:-0.7962648580483193, loss:0.5959631596279814\n",
      "epoch:844, weight:[1.02250249 0.84322862], bias:-0.7966363587016523, loss:0.5959404651550753\n",
      "epoch:845, weight:[1.02275363 0.8433894 ], bias:-0.7970074609569116, loss:0.5959177881464783\n",
      "epoch:846, weight:[1.02300491 0.84355034], bias:-0.7973781661359279, loss:0.5958951285197533\n",
      "epoch:847, weight:[1.02325634 0.84371143], bias:-0.7977484755555294, loss:0.5958724861930631\n",
      "epoch:848, weight:[1.0235079  0.84387267], bias:-0.7981183905275601, loss:0.5958498610851669\n",
      "epoch:849, weight:[1.02375961 0.84403407], bias:-0.7984879123588986, loss:0.5958272531154146\n",
      "epoch:850, weight:[1.02401145 0.84419563], bias:-0.7988570423514771, loss:0.5958046622037437\n",
      "epoch:851, weight:[1.02426344 0.84435733], bias:-0.7992257818022995, loss:0.5957820882706735\n",
      "epoch:852, weight:[1.02451556 0.84451919], bias:-0.7995941320034602, loss:0.5957595312373013\n",
      "epoch:853, weight:[1.02476782 0.84468119], bias:-0.7999620942421622, loss:0.5957369910252982\n",
      "epoch:854, weight:[1.02502021 0.84484335], bias:-0.8003296698007359, loss:0.5957144675569045\n",
      "epoch:855, weight:[1.02527274 0.84500565], bias:-0.8006968599566573, loss:0.5956919607549243\n",
      "epoch:856, weight:[1.02552541 0.8451681 ], bias:-0.8010636659825657, loss:0.5956694705427235\n",
      "epoch:857, weight:[1.02577822 0.8453307 ], bias:-0.8014300891462829, loss:0.5956469968442235\n",
      "epoch:858, weight:[1.02603116 0.84549344], bias:-0.8017961307108302, loss:0.5956245395838979\n",
      "epoch:859, weight:[1.02628423 0.84565633], bias:-0.8021617919344474, loss:0.5956020986867675\n",
      "epoch:860, weight:[1.02653744 0.84581936], bias:-0.8025270740706099, loss:0.5955796740783977\n",
      "epoch:861, weight:[1.02679078 0.84598253], bias:-0.8028919783680474, loss:0.5955572656848923\n",
      "epoch:862, weight:[1.02704425 0.84614585], bias:-0.8032565060707614, loss:0.5955348734328911\n",
      "epoch:863, weight:[1.02729786 0.84630931], bias:-0.8036206584180429, loss:0.5955124972495647\n",
      "epoch:864, weight:[1.0275516  0.84647291], bias:-0.8039844366444904, loss:0.595490137062611\n",
      "epoch:865, weight:[1.02780547 0.84663665], bias:-0.8043478419800272, loss:0.5954677928002511\n",
      "epoch:866, weight:[1.02805947 0.84680052], bias:-0.8047108756499194, loss:0.5954454643912253\n",
      "epoch:867, weight:[1.0283136  0.84696454], bias:-0.8050735388747932, loss:0.5954231517647887\n",
      "epoch:868, weight:[1.02856786 0.84712869], bias:-0.8054358328706523, loss:0.5954008548507081\n",
      "epoch:869, weight:[1.02882225 0.84729298], bias:-0.8057977588488958, loss:0.5953785735792576\n",
      "epoch:870, weight:[1.02907677 0.8474574 ], bias:-0.8061593180163348, loss:0.5953563078812146\n",
      "epoch:871, weight:[1.02933142 0.84762196], bias:-0.8065205115752102, loss:0.595334057687856\n",
      "epoch:872, weight:[1.0295862  0.84778665], bias:-0.80688134072321, loss:0.595311822930955\n",
      "epoch:873, weight:[1.0298411  0.84795148], bias:-0.8072418066534862, loss:0.5952896035427764\n",
      "epoch:874, weight:[1.03009613 0.84811644], bias:-0.807601910554672, loss:0.5952673994560734\n",
      "epoch:875, weight:[1.03035129 0.84828152], bias:-0.8079616536108987, loss:0.595245210604084\n",
      "epoch:876, weight:[1.03060657 0.84844674], bias:-0.8083210370018129, loss:0.5952230369205265\n",
      "epoch:877, weight:[1.03086198 0.84861209], bias:-0.8086800619025936, loss:0.595200878339597\n",
      "epoch:878, weight:[1.03111751 0.84877757], bias:-0.8090387294839684, loss:0.5951787347959648\n",
      "epoch:879, weight:[1.03137317 0.84894318], bias:-0.8093970409122309, loss:0.5951566062247691\n",
      "epoch:880, weight:[1.03162896 0.84910891], bias:-0.8097549973492573, loss:0.5951344925616154\n",
      "epoch:881, weight:[1.03188486 0.84927477], bias:-0.810112599952523, loss:0.5951123937425722\n",
      "epoch:882, weight:[1.03214089 0.84944076], bias:-0.8104698498751194, loss:0.5950903097041672\n",
      "epoch:883, weight:[1.03239704 0.84960687], bias:-0.81082674826577, loss:0.5950682403833837\n",
      "epoch:884, weight:[1.03265332 0.8497731 ], bias:-0.8111832962688474, loss:0.5950461857176573\n",
      "epoch:885, weight:[1.03290972 0.84993946], bias:-0.8115394950243898, loss:0.5950241456448723\n",
      "epoch:886, weight:[1.03316623 0.85010594], bias:-0.8118953456681167, loss:0.5950021201033586\n",
      "epoch:887, weight:[1.03342287 0.85027254], bias:-0.812250849331446, loss:0.594980109031888\n",
      "epoch:888, weight:[1.03367963 0.85043927], bias:-0.8126060071415098, loss:0.5949581123696709\n",
      "epoch:889, weight:[1.03393651 0.85060611], bias:-0.8129608202211708, loss:0.5949361300563525\n",
      "epoch:890, weight:[1.03419351 0.85077307], bias:-0.8133152896890384, loss:0.594914162032011\n",
      "epoch:891, weight:[1.03445063 0.85094015], bias:-0.813669416659485, loss:0.5948922082371518\n",
      "epoch:892, weight:[1.03470786 0.85110735], bias:-0.8140232022426614, loss:0.5948702686127071\n",
      "epoch:893, weight:[1.03496522 0.85127467], bias:-0.8143766475445136, loss:0.5948483431000301\n",
      "epoch:894, weight:[1.03522269 0.8514421 ], bias:-0.814729753666798, loss:0.5948264316408935\n",
      "epoch:895, weight:[1.03548028 0.85160965], bias:-0.8150825217070978, loss:0.5948045341774855\n",
      "epoch:896, weight:[1.03573798 0.85177732], bias:-0.8154349527588386, loss:0.5947826506524067\n",
      "epoch:897, weight:[1.0359958  0.85194509], bias:-0.8157870479113039, loss:0.594760781008667\n",
      "epoch:898, weight:[1.03625374 0.85211299], bias:-0.8161388082496512, loss:0.5947389251896832\n",
      "epoch:899, weight:[1.0365118  0.85228099], bias:-0.8164902348549276, loss:0.5947170831392742\n",
      "epoch:900, weight:[1.03676996 0.85244911], bias:-0.8168413288040848, loss:0.5946952548016599\n",
      "epoch:901, weight:[1.03702825 0.85261733], bias:-0.8171920911699954, loss:0.5946734401214562\n",
      "epoch:902, weight:[1.03728664 0.85278567], bias:-0.8175425230214678, loss:0.5946516390436745\n",
      "epoch:903, weight:[1.03754515 0.85295412], bias:-0.817892625423262, loss:0.5946298515137154\n",
      "epoch:904, weight:[1.03780378 0.85312267], bias:-0.8182423994361048, loss:0.5946080774773684\n",
      "epoch:905, weight:[1.03806252 0.85329134], bias:-0.8185918461167047, loss:0.5945863168808084\n",
      "epoch:906, weight:[1.03832136 0.85346011], bias:-0.8189409665177678, loss:0.5945645696705912\n",
      "epoch:907, weight:[1.03858033 0.85362899], bias:-0.8192897616880127, loss:0.5945428357936529\n",
      "epoch:908, weight:[1.0388394  0.85379798], bias:-0.8196382326721855, loss:0.5945211151973053\n",
      "epoch:909, weight:[1.03909858 0.85396707], bias:-0.8199863805110751, loss:0.5944994078292336\n",
      "epoch:910, weight:[1.03935788 0.85413626], bias:-0.8203342062415279, loss:0.5944777136374935\n",
      "epoch:911, weight:[1.03961728 0.85430556], bias:-0.8206817108964631, loss:0.5944560325705088\n",
      "epoch:912, weight:[1.0398768  0.85447497], bias:-0.8210288955048877, loss:0.5944343645770674\n",
      "epoch:913, weight:[1.04013642 0.85464447], bias:-0.8213757610919107, loss:0.5944127096063209\n",
      "epoch:914, weight:[1.04039615 0.85481408], bias:-0.8217223086787585, loss:0.5943910676077778\n",
      "epoch:915, weight:[1.04065599 0.85498379], bias:-0.8220685392827898, loss:0.5943694385313056\n",
      "epoch:916, weight:[1.04091594 0.8551536 ], bias:-0.8224144539175094, loss:0.5943478223271241\n",
      "epoch:917, weight:[1.041176  0.8553235], bias:-0.8227600535925841, loss:0.5943262189458048\n",
      "epoch:918, weight:[1.04143616 0.85549351], bias:-0.823105339313856, loss:0.5943046283382682\n",
      "epoch:919, weight:[1.04169644 0.85566362], bias:-0.823450312083358, loss:0.5942830504557798\n",
      "epoch:920, weight:[1.04195681 0.85583382], bias:-0.8237949728993277, loss:0.5942614852499489\n",
      "epoch:921, weight:[1.0422173  0.85600413], bias:-0.8241393227562223, loss:0.5942399326727249\n",
      "epoch:922, weight:[1.04247789 0.85617452], bias:-0.8244833626447324, loss:0.5942183926763954\n",
      "epoch:923, weight:[1.04273858 0.85634502], bias:-0.8248270935517971, loss:0.5941968652135837\n",
      "epoch:924, weight:[1.04299938 0.85651561], bias:-0.8251705164606172, loss:0.5941753502372455\n",
      "epoch:925, weight:[1.04326029 0.85668629], bias:-0.8255136323506707, loss:0.594153847700667\n",
      "epoch:926, weight:[1.0435213  0.85685707], bias:-0.8258564421977257, loss:0.5941323575574619\n",
      "epoch:927, weight:[1.04378241 0.85702794], bias:-0.8261989469738557, loss:0.5941108797615695\n",
      "epoch:928, weight:[1.04404362 0.8571989 ], bias:-0.8265411476474525, loss:0.5940894142672519\n",
      "epoch:929, weight:[1.04430494 0.85736995], bias:-0.8268830451832411, loss:0.5940679610290912\n",
      "epoch:930, weight:[1.04456636 0.8575411 ], bias:-0.8272246405422934, loss:0.5940465200019877\n",
      "epoch:931, weight:[1.04482789 0.85771233], bias:-0.8275659346820419, loss:0.5940250911411569\n",
      "epoch:932, weight:[1.04508951 0.85788366], bias:-0.8279069285562937, loss:0.5940036744021274\n",
      "epoch:933, weight:[1.04535124 0.85805507], bias:-0.8282476231152444, loss:0.5939822697407388\n",
      "epoch:934, weight:[1.04561306 0.85822658], bias:-0.8285880193054918, loss:0.5939608771131387\n",
      "epoch:935, weight:[1.04587499 0.85839817], bias:-0.8289281180700494, loss:0.5939394964757803\n",
      "epoch:936, weight:[1.04613702 0.85856984], bias:-0.8292679203483604, loss:0.593918127785421\n",
      "epoch:937, weight:[1.04639915 0.85874161], bias:-0.8296074270763111, loss:0.593896770999119\n",
      "epoch:938, weight:[1.04666137 0.85891346], bias:-0.8299466391862443, loss:0.593875426074232\n",
      "epoch:939, weight:[1.0469237 0.8590854], bias:-0.8302855576069734, loss:0.593854092968414\n",
      "epoch:940, weight:[1.04718612 0.85925742], bias:-0.8306241832637952, loss:0.5938327716396133\n",
      "epoch:941, weight:[1.04744865 0.85942952], bias:-0.8309625170785033, loss:0.5938114620460706\n",
      "epoch:942, weight:[1.04771127 0.85960171], bias:-0.8313005599694022, loss:0.593790164146317\n",
      "epoch:943, weight:[1.04797399 0.85977398], bias:-0.8316383128513197, loss:0.5937688778991705\n",
      "epoch:944, weight:[1.0482368  0.85994634], bias:-0.831975776635621, loss:0.5937476032637353\n",
      "epoch:945, weight:[1.04849971 0.86011877], bias:-0.8323129522302208, loss:0.5937263401993985\n",
      "epoch:946, weight:[1.04876272 0.86029129], bias:-0.832649840539598, loss:0.5937050886658288\n",
      "epoch:947, weight:[1.04902583 0.86046388], bias:-0.8329864424648072, loss:0.5936838486229741\n",
      "epoch:948, weight:[1.04928903 0.86063656], bias:-0.833322758903493, loss:0.5936626200310582\n",
      "epoch:949, weight:[1.04955232 0.86080931], bias:-0.8336587907499023, loss:0.5936414028505811\n",
      "epoch:950, weight:[1.04981572 0.86098215], bias:-0.8339945388948976, loss:0.5936201970423145\n",
      "epoch:951, weight:[1.0500792  0.86115506], bias:-0.8343300042259697, loss:0.5935990025673014\n",
      "epoch:952, weight:[1.05034278 0.86132805], bias:-0.8346651876272507, loss:0.5935778193868531\n",
      "epoch:953, weight:[1.05060645 0.86150111], bias:-0.835000089979527, loss:0.5935566474625472\n",
      "epoch:954, weight:[1.05087022 0.86167426], bias:-0.8353347121602516, loss:0.5935354867562264\n",
      "epoch:955, weight:[1.05113408 0.86184747], bias:-0.8356690550435573, loss:0.5935143372299952\n",
      "epoch:956, weight:[1.05139803 0.86202077], bias:-0.8360031195002691, loss:0.5934931988462191\n",
      "epoch:957, weight:[1.05166208 0.86219413], bias:-0.836336906397917, loss:0.5934720715675219\n",
      "epoch:958, weight:[1.05192622 0.86236758], bias:-0.8366704166007485, loss:0.5934509553567838\n",
      "epoch:959, weight:[1.05219044 0.86254109], bias:-0.8370036509697412, loss:0.5934298501771398\n",
      "epoch:960, weight:[1.05245477 0.86271468], bias:-0.837336610362615, loss:0.5934087559919775\n",
      "epoch:961, weight:[1.05271918 0.86288834], bias:-0.8376692956338452, loss:0.5933876727649351\n",
      "epoch:962, weight:[1.05298368 0.86306207], bias:-0.8380017076346742, loss:0.5933666004598992\n",
      "epoch:963, weight:[1.05324827 0.86323587], bias:-0.8383338472131242, loss:0.5933455390410043\n",
      "epoch:964, weight:[1.05351295 0.86340974], bias:-0.8386657152140096, loss:0.5933244884726289\n",
      "epoch:965, weight:[1.05377773 0.86358368], bias:-0.838997312478949, loss:0.5933034487193954\n",
      "epoch:966, weight:[1.05404259 0.86375769], bias:-0.8393286398463777, loss:0.5932824197461668\n",
      "epoch:967, weight:[1.05430754 0.86393177], bias:-0.8396596981515596, loss:0.5932614015180462\n",
      "epoch:968, weight:[1.05457258 0.86410592], bias:-0.8399904882265994, loss:0.5932403940003736\n",
      "epoch:969, weight:[1.0548377  0.86428013], bias:-0.8403210109004549, loss:0.5932193971587258\n",
      "epoch:970, weight:[1.05510292 0.86445441], bias:-0.8406512669989488, loss:0.5931984109589129\n",
      "epoch:971, weight:[1.05536822 0.86462876], bias:-0.8409812573447808, loss:0.5931774353669769\n",
      "epoch:972, weight:[1.05563361 0.86480318], bias:-0.8413109827575395, loss:0.5931564703491913\n",
      "epoch:973, weight:[1.05589909 0.86497766], bias:-0.8416404440537142, loss:0.5931355158720576\n",
      "epoch:974, weight:[1.05616465 0.8651522 ], bias:-0.8419696420467071, loss:0.5931145719023043\n",
      "epoch:975, weight:[1.0564303  0.86532681], bias:-0.8422985775468449, loss:0.5930936384068852\n",
      "epoch:976, weight:[1.05669604 0.86550148], bias:-0.8426272513613903, loss:0.5930727153529781\n",
      "epoch:977, weight:[1.05696186 0.86567622], bias:-0.8429556642945543, loss:0.5930518027079819\n",
      "epoch:978, weight:[1.05722777 0.86585101], bias:-0.8432838171475074, loss:0.5930309004395161\n",
      "epoch:979, weight:[1.05749376 0.86602588], bias:-0.8436117107183916, loss:0.5930100085154183\n",
      "epoch:980, weight:[1.05775984 0.8662008 ], bias:-0.8439393458023317, loss:0.5929891269037431\n",
      "epoch:981, weight:[1.058026   0.86637578], bias:-0.8442667231914469, loss:0.5929682555727602\n",
      "epoch:982, weight:[1.05829224 0.86655082], bias:-0.8445938436748626, loss:0.5929473944909529\n",
      "epoch:983, weight:[1.05855857 0.86672593], bias:-0.8449207080387215, loss:0.5929265436270165\n",
      "epoch:984, weight:[1.05882498 0.86690109], bias:-0.8452473170661954, loss:0.5929057029498561\n",
      "epoch:985, weight:[1.05909148 0.86707631], bias:-0.845573671537496, loss:0.5928848724285858\n",
      "epoch:986, weight:[1.05935805 0.86725159], bias:-0.8458997722298869, loss:0.5928640520325265\n",
      "epoch:987, weight:[1.05962471 0.86742693], bias:-0.8462256199176945, loss:0.5928432417312051\n",
      "epoch:988, weight:[1.05989145 0.86760232], bias:-0.8465512153723196, loss:0.5928224414943519\n",
      "epoch:989, weight:[1.06015828 0.86777777], bias:-0.8468765593622479, loss:0.5928016512919\n",
      "epoch:990, weight:[1.06042518 0.86795328], bias:-0.8472016526530621, loss:0.5927808710939829\n",
      "epoch:991, weight:[1.06069217 0.86812885], bias:-0.8475264960074524, loss:0.5927601008709336\n",
      "epoch:992, weight:[1.06095924 0.86830447], bias:-0.8478510901852279, loss:0.5927393405932833\n",
      "epoch:993, weight:[1.06122638 0.86848014], bias:-0.8481754359433271, loss:0.5927185902317589\n",
      "epoch:994, weight:[1.06149361 0.86865587], bias:-0.8484995340358298, loss:0.5926978497572823\n",
      "epoch:995, weight:[1.06176092 0.86883165], bias:-0.8488233852139674, loss:0.592677119140969\n",
      "epoch:996, weight:[1.06202831 0.86900749], bias:-0.8491469902261339, loss:0.592656398354126\n",
      "epoch:997, weight:[1.06229577 0.86918337], bias:-0.8494703498178973, loss:0.5926356873682507\n",
      "epoch:998, weight:[1.06256332 0.86935932], bias:-0.8497934647320095, loss:0.5926149861550295\n",
      "epoch:999, weight:[1.06283094 0.86953531], bias:-0.8501163357084178, loss:0.5925942946863365\n",
      "epoch:1000, weight:[1.06309865 0.86971135], bias:-0.8504389634842758, loss:0.5925736129342317\n",
      "epoch:1001, weight:[1.06336643 0.86988745], bias:-0.8507613487939535, loss:0.5925529408709594\n",
      "epoch:1002, weight:[1.06363429 0.87006359], bias:-0.8510834923690483, loss:0.5925322784689482\n",
      "epoch:1003, weight:[1.06390222 0.87023979], bias:-0.851405394938396, loss:0.5925116257008072\n",
      "epoch:1004, weight:[1.06417023 0.87041603], bias:-0.8517270572280805, loss:0.5924909825393272\n",
      "epoch:1005, weight:[1.06443833 0.87059232], bias:-0.8520484799614453, loss:0.5924703489574774\n",
      "epoch:1006, weight:[1.06470649 0.87076866], bias:-0.8523696638591034, loss:0.5924497249284048\n",
      "epoch:1007, weight:[1.06497474 0.87094505], bias:-0.8526906096389482, loss:0.5924291104254329\n",
      "epoch:1008, weight:[1.06524305 0.87112149], bias:-0.8530113180161635, loss:0.5924085054220609\n",
      "epoch:1009, weight:[1.06551145 0.87129797], bias:-0.8533317897032344, loss:0.5923879098919604\n",
      "epoch:1010, weight:[1.06577992 0.8714745 ], bias:-0.8536520254099573, loss:0.5923673238089767\n",
      "epoch:1011, weight:[1.06604846 0.87165108], bias:-0.8539720258434502, loss:0.5923467471471251\n",
      "epoch:1012, weight:[1.06631709 0.8718277 ], bias:-0.8542917917081634, loss:0.592326179880592\n",
      "epoch:1013, weight:[1.06658578 0.87200437], bias:-0.8546113237058891, loss:0.5923056219837307\n",
      "epoch:1014, weight:[1.06685455 0.87218108], bias:-0.8549306225357723, loss:0.592285073431063\n",
      "epoch:1015, weight:[1.06712339 0.87235784], bias:-0.8552496888943206, loss:0.5922645341972764\n",
      "epoch:1016, weight:[1.06739231 0.87253464], bias:-0.8555685234754142, loss:0.5922440042572228\n",
      "epoch:1017, weight:[1.0676613  0.87271148], bias:-0.8558871269703164, loss:0.5922234835859177\n",
      "epoch:1018, weight:[1.06793036 0.87288836], bias:-0.8562055000676833, loss:0.5922029721585388\n",
      "epoch:1019, weight:[1.0681995  0.87306529], bias:-0.8565236434535738, loss:0.5921824699504249\n",
      "epoch:1020, weight:[1.06846871 0.87324226], bias:-0.8568415578114601, loss:0.5921619769370744\n",
      "epoch:1021, weight:[1.06873799 0.87341927], bias:-0.857159243822237, loss:0.5921414930941444\n",
      "epoch:1022, weight:[1.06900734 0.87359632], bias:-0.857476702164232, loss:0.5921210183974489\n",
      "epoch:1023, weight:[1.06927677 0.87377342], bias:-0.8577939335132154, loss:0.5921005528229589\n",
      "epoch:1024, weight:[1.06954627 0.87395055], bias:-0.85811093854241, loss:0.5920800963467997\n",
      "epoch:1025, weight:[1.06981583 0.87412772], bias:-0.8584277179225009, loss:0.5920596489452504\n",
      "epoch:1026, weight:[1.07008547 0.87430493], bias:-0.8587442723216451, loss:0.5920392105947433\n",
      "epoch:1027, weight:[1.07035518 0.87448218], bias:-0.8590606024054813, loss:0.5920187812718614\n",
      "epoch:1028, weight:[1.07062496 0.87465947], bias:-0.8593767088371398, loss:0.5919983609533384\n",
      "epoch:1029, weight:[1.07089481 0.8748368 ], bias:-0.8596925922772519, loss:0.5919779496160572\n",
      "epoch:1030, weight:[1.07116473 0.87501416], bias:-0.8600082533839596, loss:0.5919575472370487\n",
      "epoch:1031, weight:[1.07143472 0.87519157], bias:-0.860323692812925, loss:0.5919371537934911\n",
      "epoch:1032, weight:[1.07170478 0.875369  ], bias:-0.8606389112173402, loss:0.5919167692627078\n",
      "epoch:1033, weight:[1.07197491 0.87554648], bias:-0.8609539092479365, loss:0.5918963936221672\n",
      "epoch:1034, weight:[1.07224511 0.87572399], bias:-0.861268687552994, loss:0.5918760268494809\n",
      "epoch:1035, weight:[1.07251537 0.87590153], bias:-0.8615832467783511, loss:0.5918556689224042\n",
      "epoch:1036, weight:[1.0727857  0.87607911], bias:-0.8618975875674135, loss:0.5918353198188325\n",
      "epoch:1037, weight:[1.07305611 0.87625673], bias:-0.8622117105611642, loss:0.5918149795168022\n",
      "epoch:1038, weight:[1.07332658 0.87643437], bias:-0.8625256163981722, loss:0.5917946479944892\n",
      "epoch:1039, weight:[1.07359711 0.87661206], bias:-0.8628393057146022, loss:0.5917743252302071\n",
      "epoch:1040, weight:[1.07386772 0.87678977], bias:-0.8631527791442237, loss:0.5917540112024074\n",
      "epoch:1041, weight:[1.07413839 0.87696752], bias:-0.8634660373184202, loss:0.5917337058896772\n",
      "epoch:1042, weight:[1.07440913 0.8771453 ], bias:-0.8637790808661984, loss:0.5917134092707389\n",
      "epoch:1043, weight:[1.07467993 0.87732311], bias:-0.8640919104141974, loss:0.5916931213244493\n",
      "epoch:1044, weight:[1.0749508  0.87750096], bias:-0.8644045265866979, loss:0.5916728420297975\n",
      "epoch:1045, weight:[1.07522174 0.87767883], bias:-0.8647169300056308, loss:0.5916525713659061\n",
      "epoch:1046, weight:[1.07549274 0.87785674], bias:-0.865029121290587, loss:0.5916323093120274\n",
      "epoch:1047, weight:[1.07576381 0.87803467], bias:-0.8653411010588258, loss:0.5916120558475447\n",
      "epoch:1048, weight:[1.07603494 0.87821264], bias:-0.8656528699252842, loss:0.5915918109519697\n",
      "epoch:1049, weight:[1.07630614 0.87839063], bias:-0.8659644285025857, loss:0.5915715746049433\n",
      "epoch:1050, weight:[1.0765774  0.87856866], bias:-0.8662757774010492, loss:0.5915513467862324\n",
      "epoch:1051, weight:[1.07684873 0.87874671], bias:-0.866586917228698, loss:0.591531127475731\n",
      "epoch:1052, weight:[1.07712012 0.87892479], bias:-0.8668978485912684, loss:0.5915109166534579\n",
      "epoch:1053, weight:[1.07739157 0.8791029 ], bias:-0.8672085720922189, loss:0.5914907142995562\n",
      "epoch:1054, weight:[1.07766309 0.87928104], bias:-0.8675190883327386, loss:0.5914705203942929\n",
      "epoch:1055, weight:[1.07793468 0.87945921], bias:-0.8678293979117561, loss:0.591450334918057\n",
      "epoch:1056, weight:[1.07820632 0.8796374 ], bias:-0.8681395014259481, loss:0.5914301578513588\n",
      "epoch:1057, weight:[1.07847803 0.87981561], bias:-0.8684493994697484, loss:0.5914099891748299\n",
      "epoch:1058, weight:[1.0787498  0.87999386], bias:-0.8687590926353562, loss:0.5913898288692212\n",
      "epoch:1059, weight:[1.07902164 0.88017213], bias:-0.8690685815127448, loss:0.5913696769154023\n",
      "epoch:1060, weight:[1.07929353 0.88035042], bias:-0.8693778666896702, loss:0.5913495332943607\n",
      "epoch:1061, weight:[1.07956549 0.88052874], bias:-0.8696869487516796, loss:0.5913293979872013\n",
      "epoch:1062, weight:[1.07983751 0.88070709], bias:-0.8699958282821201, loss:0.5913092709751445\n",
      "epoch:1063, weight:[1.08010959 0.88088545], bias:-0.8703045058621468, loss:0.5912891522395266\n",
      "epoch:1064, weight:[1.08038173 0.88106385], bias:-0.8706129820707317, loss:0.591269041761798\n",
      "epoch:1065, weight:[1.08065394 0.88124226], bias:-0.8709212574846718, loss:0.5912489395235223\n",
      "epoch:1066, weight:[1.0809262 0.8814207], bias:-0.8712293326785975, loss:0.5912288455063766\n",
      "epoch:1067, weight:[1.08119853 0.88159916], bias:-0.8715372082249813, loss:0.5912087596921485\n",
      "epoch:1068, weight:[1.08147092 0.88177764], bias:-0.8718448846941454, loss:0.5911886820627381\n",
      "epoch:1069, weight:[1.08174336 0.88195615], bias:-0.8721523626542711, loss:0.5911686126001544\n",
      "epoch:1070, weight:[1.08201587 0.88213467], bias:-0.8724596426714056, loss:0.5911485512865166\n",
      "epoch:1071, weight:[1.08228843 0.88231322], bias:-0.8727667253094717, loss:0.5911284981040514\n",
      "epoch:1072, weight:[1.08256106 0.88249179], bias:-0.8730736111302749, loss:0.5911084530350943\n",
      "epoch:1073, weight:[1.08283374 0.88267038], bias:-0.8733803006935121, loss:0.5910884160620868\n",
      "epoch:1074, weight:[1.08310649 0.88284898], bias:-0.8736867945567797, loss:0.5910683871675767\n",
      "epoch:1075, weight:[1.08337929 0.88302761], bias:-0.8739930932755814, loss:0.5910483663342171\n",
      "epoch:1076, weight:[1.08365215 0.88320626], bias:-0.8742991974033367, loss:0.591028353544766\n",
      "epoch:1077, weight:[1.08392507 0.88338493], bias:-0.8746051074913886, loss:0.591008348782084\n",
      "epoch:1078, weight:[1.08419805 0.88356361], bias:-0.8749108240890118, loss:0.5909883520291357\n",
      "epoch:1079, weight:[1.08447108 0.88374231], bias:-0.8752163477434204, loss:0.5909683632689869\n",
      "epoch:1080, weight:[1.08474417 0.88392104], bias:-0.8755216789997762, loss:0.5909483824848055\n",
      "epoch:1081, weight:[1.08501732 0.88409977], bias:-0.8758268184011965, loss:0.5909284096598596\n",
      "epoch:1082, weight:[1.08529053 0.88427853], bias:-0.8761317664887619, loss:0.5909084447775172\n",
      "epoch:1083, weight:[1.0855638 0.8844573], bias:-0.8764365238015243, loss:0.5908884878212457\n",
      "epoch:1084, weight:[1.08583712 0.88463609], bias:-0.8767410908765144, loss:0.5908685387746101\n",
      "epoch:1085, weight:[1.0861105 0.8848149], bias:-0.8770454682487501, loss:0.5908485976212735\n",
      "epoch:1086, weight:[1.08638393 0.88499372], bias:-0.8773496564512434, loss:0.5908286643449959\n",
      "epoch:1087, weight:[1.08665742 0.88517255], bias:-0.8776536560150092, loss:0.5908087389296336\n",
      "epoch:1088, weight:[1.08693097 0.88535141], bias:-0.8779574674690721, loss:0.5907888213591378\n",
      "epoch:1089, weight:[1.08720457 0.88553027], bias:-0.8782610913404745, loss:0.590768911617555\n",
      "epoch:1090, weight:[1.08747823 0.88570915], bias:-0.8785645281542841, loss:0.5907490096890249\n",
      "epoch:1091, weight:[1.08775194 0.88588805], bias:-0.8788677784336018, loss:0.5907291155577811\n",
      "epoch:1092, weight:[1.08802571 0.88606696], bias:-0.8791708426995689, loss:0.5907092292081497\n",
      "epoch:1093, weight:[1.08829953 0.88624588], bias:-0.879473721471375, loss:0.5906893506245487\n",
      "epoch:1094, weight:[1.08857341 0.88642482], bias:-0.8797764152662653, loss:0.5906694797914874\n",
      "epoch:1095, weight:[1.08884734 0.88660376], bias:-0.8800789245995481, loss:0.5906496166935651\n",
      "epoch:1096, weight:[1.08912133 0.88678272], bias:-0.8803812499846025, loss:0.5906297613154716\n",
      "epoch:1097, weight:[1.08939537 0.8869617 ], bias:-0.8806833919328858, loss:0.5906099136419853\n",
      "epoch:1098, weight:[1.08966946 0.88714068], bias:-0.8809853509539406, loss:0.5905900736579734\n",
      "epoch:1099, weight:[1.08994361 0.88731968], bias:-0.8812871275554025, loss:0.5905702413483914\n",
      "epoch:1100, weight:[1.09021781 0.88749869], bias:-0.8815887222430075, loss:0.5905504166982811\n",
      "epoch:1101, weight:[1.09049206 0.8876777 ], bias:-0.8818901355205991, loss:0.5905305996927711\n",
      "epoch:1102, weight:[1.09076637 0.88785673], bias:-0.8821913678901357, loss:0.5905107903170763\n",
      "epoch:1103, weight:[1.09104073 0.88803577], bias:-0.8824924198516981, loss:0.5904909885564964\n",
      "epoch:1104, weight:[1.09131514 0.88821482], bias:-0.8827932919034963, loss:0.5904711943964158\n",
      "epoch:1105, weight:[1.09158961 0.88839388], bias:-0.8830939845418772, loss:0.5904514078223033\n",
      "epoch:1106, weight:[1.09186412 0.88857295], bias:-0.8833944982613313, loss:0.5904316288197101\n",
      "epoch:1107, weight:[1.09213869 0.88875202], bias:-0.8836948335545005, loss:0.5904118573742708\n",
      "epoch:1108, weight:[1.09241331 0.88893111], bias:-0.8839949909121847, loss:0.5903920934717022\n",
      "epoch:1109, weight:[1.09268799 0.8891102 ], bias:-0.884294970823349, loss:0.5903723370978021\n",
      "epoch:1110, weight:[1.09296271 0.8892893 ], bias:-0.884594773775131, loss:0.5903525882384497\n",
      "epoch:1111, weight:[1.09323749 0.88946841], bias:-0.8848944002528476, loss:0.5903328468796041\n",
      "epoch:1112, weight:[1.09351231 0.88964753], bias:-0.8851938507400025, loss:0.5903131130073042\n",
      "epoch:1113, weight:[1.09378719 0.88982665], bias:-0.8854931257182924, loss:0.5902933866076677\n",
      "epoch:1114, weight:[1.09406212 0.89000578], bias:-0.885792225667615, loss:0.5902736676668915\n",
      "epoch:1115, weight:[1.0943371  0.89018492], bias:-0.8860911510660748, loss:0.5902539561712494\n",
      "epoch:1116, weight:[1.09461212 0.89036406], bias:-0.8863899023899913, loss:0.5902342521070936\n",
      "epoch:1117, weight:[1.0948872  0.89054321], bias:-0.8866884801139046, loss:0.5902145554608522\n",
      "epoch:1118, weight:[1.09516233 0.89072236], bias:-0.8869868847105832, loss:0.5901948662190301\n",
      "epoch:1119, weight:[1.09543751 0.89090152], bias:-0.8872851166510305, loss:0.590175184368207\n",
      "epoch:1120, weight:[1.09571273 0.89108069], bias:-0.8875831764044918, loss:0.5901555098950384\n",
      "epoch:1121, weight:[1.09598801 0.89125985], bias:-0.8878810644384607, loss:0.5901358427862543\n",
      "epoch:1122, weight:[1.09626334 0.89143903], bias:-0.8881787812186863, loss:0.5901161830286578\n",
      "epoch:1123, weight:[1.09653871 0.8916182 ], bias:-0.8884763272091798, loss:0.5900965306091265\n",
      "epoch:1124, weight:[1.09681413 0.89179739], bias:-0.888773702872221, loss:0.5900768855146098\n",
      "epoch:1125, weight:[1.09708961 0.89197657], bias:-0.8890709086683652, loss:0.59005724773213\n",
      "epoch:1126, weight:[1.09736513 0.89215576], bias:-0.8893679450564501, loss:0.5900376172487811\n",
      "epoch:1127, weight:[1.09764069 0.89233495], bias:-0.8896648124936019, loss:0.5900179940517282\n",
      "epoch:1128, weight:[1.09791631 0.89251414], bias:-0.889961511435242, loss:0.5899983781282071\n",
      "epoch:1129, weight:[1.09819197 0.89269334], bias:-0.8902580423350944, loss:0.5899787694655237\n",
      "epoch:1130, weight:[1.09846769 0.89287254], bias:-0.8905544056451911, loss:0.5899591680510539\n",
      "epoch:1131, weight:[1.09874344 0.89305174], bias:-0.8908506018158793, loss:0.5899395738722419\n",
      "epoch:1132, weight:[1.09901925 0.89323094], bias:-0.8911466312958278, loss:0.5899199869166017\n",
      "epoch:1133, weight:[1.0992951  0.89341014], bias:-0.8914424945320336, loss:0.5899004071717143\n",
      "epoch:1134, weight:[1.099571   0.89358934], bias:-0.8917381919698281, loss:0.5898808346252289\n",
      "epoch:1135, weight:[1.09984695 0.89376855], bias:-0.8920337240528835, loss:0.5898612692648618\n",
      "epoch:1136, weight:[1.10012294 0.89394775], bias:-0.8923290912232197, loss:0.5898417110783957\n",
      "epoch:1137, weight:[1.10039898 0.89412696], bias:-0.8926242939212102, loss:0.5898221600536793\n",
      "epoch:1138, weight:[1.10067507 0.89430616], bias:-0.8929193325855888, loss:0.5898026161786271\n",
      "epoch:1139, weight:[1.1009512  0.89448536], bias:-0.8932142076534554, loss:0.5897830794412188\n",
      "epoch:1140, weight:[1.10122738 0.89466457], bias:-0.8935089195602831, loss:0.5897635498294985\n",
      "epoch:1141, weight:[1.1015036  0.89484377], bias:-0.8938034687399238, loss:0.5897440273315748\n",
      "epoch:1142, weight:[1.10177987 0.89502297], bias:-0.8940978556246149, loss:0.58972451193562\n",
      "epoch:1143, weight:[1.10205618 0.89520217], bias:-0.8943920806449852, loss:0.5897050036298691\n",
      "epoch:1144, weight:[1.10233254 0.89538136], bias:-0.8946861442300615, loss:0.5896855024026201\n",
      "epoch:1145, weight:[1.10260895 0.89556056], bias:-0.8949800468072746, loss:0.5896660082422337\n",
      "epoch:1146, weight:[1.10288539 0.89573975], bias:-0.8952737888024653, loss:0.5896465211371318\n",
      "epoch:1147, weight:[1.10316189 0.89591894], bias:-0.8955673706398909, loss:0.5896270410757982\n",
      "epoch:1148, weight:[1.10343842 0.89609813], bias:-0.895860792742231, loss:0.5896075680467774\n",
      "epoch:1149, weight:[1.10371501 0.89627731], bias:-0.8961540555305937, loss:0.5895881020386741\n",
      "epoch:1150, weight:[1.10399163 0.8964565 ], bias:-0.8964471594245218, loss:0.5895686430401533\n",
      "epoch:1151, weight:[1.1042683  0.89663567], bias:-0.8967401048419988, loss:0.5895491910399401\n",
      "epoch:1152, weight:[1.10454501 0.89681485], bias:-0.8970328921994549, loss:0.5895297460268173\n",
      "epoch:1153, weight:[1.10482177 0.89699402], bias:-0.897325521911773, loss:0.5895103079896281\n",
      "epoch:1154, weight:[1.10509857 0.89717318], bias:-0.8976179943922944, loss:0.5894908769172728\n",
      "epoch:1155, weight:[1.10537542 0.89735234], bias:-0.8979103100528254, loss:0.5894714527987098\n",
      "epoch:1156, weight:[1.1056523 0.8975315], bias:-0.8982024693036428, loss:0.5894520356229553\n",
      "epoch:1157, weight:[1.10592923 0.89771065], bias:-0.8984944725534999, loss:0.589432625379082\n",
      "epoch:1158, weight:[1.1062062  0.89788979], bias:-0.8987863202096322, loss:0.5894132220562196\n",
      "epoch:1159, weight:[1.10648322 0.89806893], bias:-0.8990780126777638, loss:0.5893938256435535\n",
      "epoch:1160, weight:[1.10676028 0.89824806], bias:-0.8993695503621125, loss:0.589374436130325\n",
      "epoch:1161, weight:[1.10703737 0.89842719], bias:-0.8996609336653963, loss:0.5893550535058312\n",
      "epoch:1162, weight:[1.10731452 0.89860631], bias:-0.899952162988839, loss:0.5893356777594233\n",
      "epoch:1163, weight:[1.1075917  0.89878542], bias:-0.9002432387321755, loss:0.5893163088805079\n",
      "epoch:1164, weight:[1.10786892 0.89896453], bias:-0.9005341612936585, loss:0.5892969468585446\n",
      "epoch:1165, weight:[1.10814619 0.89914363], bias:-0.9008249310700632, loss:0.5892775916830479\n",
      "epoch:1166, weight:[1.1084235  0.89932272], bias:-0.901115548456694, loss:0.5892582433435852\n",
      "epoch:1167, weight:[1.10870085 0.8995018 ], bias:-0.9014060138473892, loss:0.5892389018297765\n",
      "epoch:1168, weight:[1.10897824 0.89968088], bias:-0.9016963276345275, loss:0.5892195671312946\n",
      "epoch:1169, weight:[1.10925567 0.89985995], bias:-0.9019864902090332, loss:0.5892002392378647\n",
      "epoch:1170, weight:[1.10953314 0.90003901], bias:-0.9022765019603821, loss:0.5891809181392632\n",
      "epoch:1171, weight:[1.10981066 0.90021806], bias:-0.9025663632766068, loss:0.5891616038253185\n",
      "epoch:1172, weight:[1.11008821 0.9003971 ], bias:-0.9028560745443023, loss:0.5891422962859095\n",
      "epoch:1173, weight:[1.1103658  0.90057614], bias:-0.903145636148632, loss:0.5891229955109663\n",
      "epoch:1174, weight:[1.11064344 0.90075516], bias:-0.9034350484733327, loss:0.589103701490469\n",
      "epoch:1175, weight:[1.11092111 0.90093417], bias:-0.9037243119007203, loss:0.5890844142144472\n",
      "epoch:1176, weight:[1.11119882 0.90111318], bias:-0.9040134268116957, loss:0.589065133672981\n",
      "epoch:1177, weight:[1.11147658 0.90129217], bias:-0.9043023935857495, loss:0.5890458598561988\n",
      "epoch:1178, weight:[1.11175437 0.90147116], bias:-0.904591212600968, loss:0.5890265927542783\n",
      "epoch:1179, weight:[1.1120322  0.90165013], bias:-0.9048798842340386, loss:0.5890073323574451\n",
      "epoch:1180, weight:[1.11231007 0.90182909], bias:-0.9051684088602552, loss:0.5889880786559739\n",
      "epoch:1181, weight:[1.11258798 0.90200805], bias:-0.9054567868535232, loss:0.5889688316401864\n",
      "epoch:1182, weight:[1.11286593 0.90218699], bias:-0.9057450185863652, loss:0.5889495913004518\n",
      "epoch:1183, weight:[1.11314392 0.90236592], bias:-0.9060331044299268, loss:0.5889303576271868\n",
      "epoch:1184, weight:[1.11342195 0.90254483], bias:-0.9063210447539809, loss:0.588911130610854\n",
      "epoch:1185, weight:[1.11370002 0.90272374], bias:-0.9066088399269339, loss:0.5888919102419633\n",
      "epoch:1186, weight:[1.11397812 0.90290263], bias:-0.9068964903158304, loss:0.58887269651107\n",
      "epoch:1187, weight:[1.11425626 0.90308152], bias:-0.9071839962863589, loss:0.5888534894087756\n",
      "epoch:1188, weight:[1.11453444 0.90326039], bias:-0.907471358202857, loss:0.5888342889257264\n",
      "epoch:1189, weight:[1.11481266 0.90343924], bias:-0.907758576428316, loss:0.5888150950526141\n",
      "epoch:1190, weight:[1.11509092 0.90361809], bias:-0.9080456513243872, loss:0.5887959077801755\n",
      "epoch:1191, weight:[1.11536921 0.90379692], bias:-0.908332583251386, loss:0.5887767270991907\n",
      "epoch:1192, weight:[1.11564754 0.90397573], bias:-0.9086193725682978, loss:0.5887575530004853\n",
      "epoch:1193, weight:[1.11592591 0.90415454], bias:-0.908906019632783, loss:0.5887383854749273\n",
      "epoch:1194, weight:[1.11620431 0.90433332], bias:-0.9091925248011816, loss:0.588719224513429\n",
      "epoch:1195, weight:[1.11648276 0.9045121 ], bias:-0.9094788884285193, loss:0.5887000701069456\n",
      "epoch:1196, weight:[1.11676124 0.90469086], bias:-0.9097651108685116, loss:0.588680922246475\n",
      "epoch:1197, weight:[1.11703975 0.90486961], bias:-0.9100511924735695, loss:0.5886617809230575\n",
      "epoch:1198, weight:[1.1173183  0.90504834], bias:-0.9103371335948042, loss:0.5886426461277761\n",
      "epoch:1199, weight:[1.11759689 0.90522706], bias:-0.9106229345820324, loss:0.5886235178517549\n",
      "epoch:1200, weight:[1.11787552 0.90540576], bias:-0.9109085957837809, loss:0.5886043960861603\n",
      "epoch:1201, weight:[1.11815418 0.90558445], bias:-0.9111941175472923, loss:0.5885852808221999\n",
      "epoch:1202, weight:[1.11843288 0.90576312], bias:-0.9114795002185292, loss:0.5885661720511213\n",
      "epoch:1203, weight:[1.11871161 0.90594177], bias:-0.9117647441421797, loss:0.5885470697642143\n",
      "epoch:1204, weight:[1.11899038 0.90612041], bias:-0.9120498496616619, loss:0.5885279739528081\n",
      "epoch:1205, weight:[1.11926919 0.90629903], bias:-0.9123348171191292, loss:0.5885088846082721\n",
      "epoch:1206, weight:[1.11954803 0.90647764], bias:-0.9126196468554749, loss:0.5884898017220158\n",
      "epoch:1207, weight:[1.1198269  0.90665623], bias:-0.9129043392103373, loss:0.5884707252854878\n",
      "epoch:1208, weight:[1.12010581 0.90683481], bias:-0.9131888945221045, loss:0.5884516552901765\n",
      "epoch:1209, weight:[1.12038476 0.90701336], bias:-0.913473313127919, loss:0.588432591727609\n",
      "epoch:1210, weight:[1.12066374 0.9071919 ], bias:-0.913757595363683, loss:0.5884135345893505\n",
      "epoch:1211, weight:[1.12094276 0.90737042], bias:-0.9140417415640626, loss:0.5883944838670057\n",
      "epoch:1212, weight:[1.12122181 0.90754893], bias:-0.9143257520624931, loss:0.5883754395522165\n",
      "epoch:1213, weight:[1.12150089 0.90772742], bias:-0.9146096271911837, loss:0.5883564016366631\n",
      "epoch:1214, weight:[1.12178001 0.90790588], bias:-0.9148933672811216, loss:0.5883373701120631\n",
      "epoch:1215, weight:[1.12205917 0.90808434], bias:-0.9151769726620778, loss:0.5883183449701714\n",
      "epoch:1216, weight:[1.12233836 0.90826277], bias:-0.9154604436626108, loss:0.58829932620278\n",
      "epoch:1217, weight:[1.12261758 0.90844118], bias:-0.9157437806100721, loss:0.5882803138017176\n",
      "epoch:1218, weight:[1.12289683 0.90861958], bias:-0.9160269838306102, loss:0.5882613077588498\n",
      "epoch:1219, weight:[1.12317612 0.90879795], bias:-0.9163100536491757, loss:0.5882423080660775\n",
      "epoch:1220, weight:[1.12345545 0.90897631], bias:-0.9165929903895258, loss:0.5882233147153384\n",
      "epoch:1221, weight:[1.1237348  0.90915465], bias:-0.9168757943742288, loss:0.5882043276986058\n",
      "epoch:1222, weight:[1.12401419 0.90933297], bias:-0.9171584659246691, loss:0.5881853470078883\n",
      "epoch:1223, weight:[1.12429362 0.90951127], bias:-0.9174410053610511, loss:0.5881663726352296\n",
      "epoch:1224, weight:[1.12457307 0.90968954], bias:-0.9177234130024043, loss:0.5881474045727086\n",
      "epoch:1225, weight:[1.12485256 0.9098678 ], bias:-0.9180056891665879, loss:0.5881284428124391\n",
      "epoch:1226, weight:[1.12513208 0.91004604], bias:-0.9182878341702948, loss:0.5881094873465688\n",
      "epoch:1227, weight:[1.12541164 0.91022426], bias:-0.9185698483290567, loss:0.5880905381672803\n",
      "epoch:1228, weight:[1.12569123 0.91040246], bias:-0.9188517319572483, loss:0.5880715952667891\n",
      "epoch:1229, weight:[1.12597085 0.91058063], bias:-0.9191334853680917, loss:0.5880526586373458\n",
      "epoch:1230, weight:[1.1262505  0.91075879], bias:-0.919415108873661, loss:0.5880337282712333\n",
      "epoch:1231, weight:[1.12653018 0.91093692], bias:-0.9196966027848867, loss:0.5880148041607687\n",
      "epoch:1232, weight:[1.1268099  0.91111504], bias:-0.9199779674115605, loss:0.5879958862983015\n",
      "epoch:1233, weight:[1.12708965 0.91129313], bias:-0.9202592030623387, loss:0.5879769746762138\n",
      "epoch:1234, weight:[1.12736943 0.9114712 ], bias:-0.9205403100447477, loss:0.5879580692869211\n",
      "epoch:1235, weight:[1.12764924 0.91164925], bias:-0.9208212886651879, loss:0.5879391701228706\n",
      "epoch:1236, weight:[1.12792909 0.91182727], bias:-0.9211021392289379, loss:0.5879202771765415\n",
      "epoch:1237, weight:[1.12820896 0.91200528], bias:-0.9213828620401591, loss:0.5879013904404452\n",
      "epoch:1238, weight:[1.12848887 0.91218326], bias:-0.9216634574018998, loss:0.5878825099071247\n",
      "epoch:1239, weight:[1.12876881 0.91236122], bias:-0.9219439256161, loss:0.5878636355691539\n",
      "epoch:1240, weight:[1.12904878 0.91253915], bias:-0.9222242669835948, loss:0.5878447674191387\n",
      "epoch:1241, weight:[1.12932878 0.91271707], bias:-0.9225044818041198, loss:0.5878259054497154\n",
      "epoch:1242, weight:[1.12960881 0.91289496], bias:-0.9227845703763142, loss:0.5878070496535512\n",
      "epoch:1243, weight:[1.12988887 0.91307282], bias:-0.9230645329977261, loss:0.5877882000233436\n",
      "epoch:1244, weight:[1.13016896 0.91325066], bias:-0.9233443699648156, loss:0.5877693565518208\n",
      "epoch:1245, weight:[1.13044908 0.91342848], bias:-0.9236240815729604, loss:0.587750519231741\n",
      "epoch:1246, weight:[1.13072924 0.91360628], bias:-0.9239036681164585, loss:0.5877316880558923\n",
      "epoch:1247, weight:[1.13100942 0.91378405], bias:-0.9241831298885337, loss:0.5877128630170918\n",
      "epoch:1248, weight:[1.13128963 0.9139618 ], bias:-0.9244624671813387, loss:0.5876940441081873\n",
      "epoch:1249, weight:[1.13156988 0.91413952], bias:-0.9247416802859599, loss:0.5876752313220548\n",
      "epoch:1250, weight:[1.13185015 0.91431722], bias:-0.9250207694924214, loss:0.5876564246515996\n",
      "epoch:1251, weight:[1.13213045 0.9144949 ], bias:-0.9252997350896889, loss:0.5876376240897566\n",
      "epoch:1252, weight:[1.13241079 0.91467254], bias:-0.9255785773656738, loss:0.5876188296294881\n",
      "epoch:1253, weight:[1.13269115 0.91485017], bias:-0.9258572966072378, loss:0.5876000412637857\n",
      "epoch:1254, weight:[1.13297154 0.91502777], bias:-0.9261358931001963, loss:0.5875812589856689\n",
      "epoch:1255, weight:[1.13325196 0.91520534], bias:-0.9264143671293227, loss:0.5875624827881858\n",
      "epoch:1256, weight:[1.13353241 0.91538289], bias:-0.9266927189783525, loss:0.5875437126644113\n",
      "epoch:1257, weight:[1.13381289 0.91556041], bias:-0.9269709489299873, loss:0.5875249486074491\n",
      "epoch:1258, weight:[1.1340934  0.91573791], bias:-0.9272490572658988, loss:0.587506190610429\n",
      "epoch:1259, weight:[1.13437394 0.91591538], bias:-0.9275270442667326, loss:0.5874874386665098\n",
      "epoch:1260, weight:[1.13465451 0.91609283], bias:-0.9278049102121125, loss:0.5874686927688758\n",
      "epoch:1261, weight:[1.1349351  0.91627024], bias:-0.9280826553806442, loss:0.587449952910739\n",
      "epoch:1262, weight:[1.13521573 0.91644764], bias:-0.9283602800499191, loss:0.5874312190853378\n",
      "epoch:1263, weight:[1.13549638 0.916625  ], bias:-0.9286377844965188, loss:0.5874124912859376\n",
      "epoch:1264, weight:[1.13577706 0.91680234], bias:-0.9289151689960183, loss:0.5873937695058292\n",
      "epoch:1265, weight:[1.13605777 0.91697965], bias:-0.9291924338229907, loss:0.5873750537383308\n",
      "epoch:1266, weight:[1.1363385  0.91715694], bias:-0.92946957925101, loss:0.5873563439767852\n",
      "epoch:1267, weight:[1.13661927 0.91733419], bias:-0.9297466055526561, loss:0.5873376402145619\n",
      "epoch:1268, weight:[1.13690006 0.91751142], bias:-0.9300235129995178, loss:0.5873189424450556\n",
      "epoch:1269, weight:[1.13718088 0.91768863], bias:-0.930300301862197, loss:0.5873002506616866\n",
      "epoch:1270, weight:[1.13746173 0.9178658 ], bias:-0.9305769724103127, loss:0.5872815648579005\n",
      "epoch:1271, weight:[1.13774261 0.91804295], bias:-0.9308535249125043, loss:0.5872628850271676\n",
      "epoch:1272, weight:[1.13802351 0.91822007], bias:-0.9311299596364359, loss:0.5872442111629839\n",
      "epoch:1273, weight:[1.13830444 0.91839716], bias:-0.9314062768487996, loss:0.5872255432588689\n",
      "epoch:1274, weight:[1.1385854  0.91857422], bias:-0.9316824768153197, loss:0.5872068813083676\n",
      "epoch:1275, weight:[1.13886638 0.91875126], bias:-0.931958559800756, loss:0.5871882253050493\n",
      "epoch:1276, weight:[1.13914739 0.91892826], bias:-0.9322345260689082, loss:0.5871695752425069\n",
      "epoch:1277, weight:[1.13942843 0.91910524], bias:-0.9325103758826188, loss:0.5871509311143581\n",
      "epoch:1278, weight:[1.1397095  0.91928219], bias:-0.9327861095037772, loss:0.587132292914244\n",
      "epoch:1279, weight:[1.13999059 0.91945911], bias:-0.9330617271933235, loss:0.5871136606358295\n",
      "epoch:1280, weight:[1.14027171 0.919636  ], bias:-0.9333372292112521, loss:0.5870950342728031\n",
      "epoch:1281, weight:[1.14055286 0.91981286], bias:-0.9336126158166151, loss:0.5870764138188767\n",
      "epoch:1282, weight:[1.14083403 0.91998969], bias:-0.9338878872675265, loss:0.5870577992677857\n",
      "epoch:1283, weight:[1.14111523 0.92016649], bias:-0.934163043821165, loss:0.5870391906132876\n",
      "epoch:1284, weight:[1.14139645 0.92034326], bias:-0.9344380857337784, loss:0.5870205878491641\n",
      "epoch:1285, weight:[1.1416777 0.92052  ], bias:-0.9347130132606869, loss:0.587001990969219\n",
      "epoch:1286, weight:[1.14195898 0.92069671], bias:-0.9349878266562867, loss:0.5869833999672784\n",
      "epoch:1287, weight:[1.14224028 0.9208734 ], bias:-0.9352625261740533, loss:0.5869648148371911\n",
      "epoch:1288, weight:[1.14252161 0.92105005], bias:-0.9355371120665456, loss:0.5869462355728289\n",
      "epoch:1289, weight:[1.14280296 0.92122667], bias:-0.9358115845854089, loss:0.5869276621680845\n",
      "epoch:1290, weight:[1.14308434 0.92140326], bias:-0.936085943981379, loss:0.586909094616873\n",
      "epoch:1291, weight:[1.14336575 0.92157982], bias:-0.9363601905042852, loss:0.586890532913132\n",
      "epoch:1292, weight:[1.14364718 0.92175635], bias:-0.936634324403054, loss:0.5868719770508201\n",
      "epoch:1293, weight:[1.14392863 0.92193284], bias:-0.9369083459257128, loss:0.5868534270239176\n",
      "epoch:1294, weight:[1.14421011 0.92210931], bias:-0.937182255319393, loss:0.5868348828264262\n",
      "epoch:1295, weight:[1.14449162 0.92228574], bias:-0.9374560528303337, loss:0.5868163444523685\n",
      "epoch:1296, weight:[1.14477315 0.92246215], bias:-0.9377297387038852, loss:0.5867978118957891\n",
      "epoch:1297, weight:[1.14505471 0.92263852], bias:-0.9380033131845121, loss:0.5867792851507527\n",
      "epoch:1298, weight:[1.14533629 0.92281486], bias:-0.9382767765157972, loss:0.5867607642113452\n",
      "epoch:1299, weight:[1.14561789 0.92299117], bias:-0.9385501289404445, loss:0.5867422490716726\n",
      "epoch:1300, weight:[1.14589952 0.92316745], bias:-0.9388233707002829, loss:0.5867237397258624\n",
      "epoch:1301, weight:[1.14618118 0.92334369], bias:-0.9390965020362693, loss:0.586705236168062\n",
      "epoch:1302, weight:[1.14646286 0.9235199 ], bias:-0.9393695231884923, loss:0.5866867383924388\n",
      "epoch:1303, weight:[1.14674456 0.92369608], bias:-0.9396424343961753, loss:0.5866682463931805\n",
      "epoch:1304, weight:[1.14702629 0.92387223], bias:-0.9399152358976799, loss:0.5866497601644951\n",
      "epoch:1305, weight:[1.14730804 0.92404835], bias:-0.9401879279305092, loss:0.5866312797006097\n",
      "epoch:1306, weight:[1.14758982 0.92422443], bias:-0.9404605107313113, loss:0.5866128049957718\n",
      "epoch:1307, weight:[1.14787162 0.92440048], bias:-0.9407329845358825, loss:0.5865943360442486\n",
      "epoch:1308, weight:[1.14815344 0.92457649], bias:-0.9410053495791705, loss:0.586575872840326\n",
      "epoch:1309, weight:[1.14843529 0.92475248], bias:-0.9412776060952777, loss:0.5865574153783094\n",
      "epoch:1310, weight:[1.14871716 0.92492843], bias:-0.9415497543174645, loss:0.5865389636525241\n",
      "epoch:1311, weight:[1.14899905 0.92510434], bias:-0.9418217944781527, loss:0.5865205176573137\n",
      "epoch:1312, weight:[1.14928097 0.92528023], bias:-0.9420937268089288, loss:0.5865020773870409\n",
      "epoch:1313, weight:[1.14956291 0.92545608], bias:-0.9423655515405466, loss:0.5864836428360873\n",
      "epoch:1314, weight:[1.14984488 0.92563189], bias:-0.9426372689029311, loss:0.5864652139988532\n",
      "epoch:1315, weight:[1.15012686 0.92580767], bias:-0.9429088791251815, loss:0.5864467908697574\n",
      "epoch:1316, weight:[1.15040887 0.92598342], bias:-0.9431803824355743, loss:0.5864283734432371\n",
      "epoch:1317, weight:[1.15069091 0.92615914], bias:-0.9434517790615666, loss:0.5864099617137477\n",
      "epoch:1318, weight:[1.15097297 0.92633481], bias:-0.9437230692297991, loss:0.586391555675763\n",
      "epoch:1319, weight:[1.15125504 0.92651046], bias:-0.9439942531660995, loss:0.5863731553237747\n",
      "epoch:1320, weight:[1.15153715 0.92668607], bias:-0.9442653310954854, loss:0.5863547606522924\n",
      "epoch:1321, weight:[1.15181927 0.92686165], bias:-0.9445363032421675, loss:0.5863363716558436\n",
      "epoch:1322, weight:[1.15210142 0.92703719], bias:-0.944807169829553, loss:0.586317988328974\n",
      "epoch:1323, weight:[1.15238359 0.92721269], bias:-0.9450779310802482, loss:0.5862996106662454\n",
      "epoch:1324, weight:[1.15266578 0.92738817], bias:-0.9453485872160619, loss:0.5862812386622389\n",
      "epoch:1325, weight:[1.152948  0.9275636], bias:-0.9456191384580085, loss:0.586262872311552\n",
      "epoch:1326, weight:[1.15323024 0.927739  ], bias:-0.945889585026311, loss:0.5862445116087992\n",
      "epoch:1327, weight:[1.15351249 0.92791437], bias:-0.9461599271404041, loss:0.5862261565486123\n",
      "epoch:1328, weight:[1.15379478 0.9280897 ], bias:-0.9464301650189371, loss:0.5862078071256408\n",
      "epoch:1329, weight:[1.15407708 0.92826499], bias:-0.946700298879777, loss:0.5861894633345505\n",
      "epoch:1330, weight:[1.1543594  0.92844025], bias:-0.9469703289400119, loss:0.5861711251700235\n",
      "epoch:1331, weight:[1.15464175 0.92861548], bias:-0.9472402554159532, loss:0.5861527926267595\n",
      "epoch:1332, weight:[1.15492412 0.92879066], bias:-0.9475100785231395, loss:0.5861344656994745\n",
      "epoch:1333, weight:[1.15520651 0.92896582], bias:-0.947779798476339, loss:0.5861161443829004\n",
      "epoch:1334, weight:[1.15548892 0.92914093], bias:-0.9480494154895525, loss:0.5860978286717861\n",
      "epoch:1335, weight:[1.15577135 0.92931601], bias:-0.9483189297760166, loss:0.5860795185608964\n",
      "epoch:1336, weight:[1.15605381 0.92949105], bias:-0.9485883415482068, loss:0.5860612140450123\n",
      "epoch:1337, weight:[1.15633628 0.92966606], bias:-0.9488576510178398, loss:0.5860429151189315\n",
      "epoch:1338, weight:[1.15661878 0.92984103], bias:-0.9491268583958771, loss:0.5860246217774661\n",
      "epoch:1339, weight:[1.1569013  0.93001596], bias:-0.9493959638925275, loss:0.5860063340154453\n",
      "epoch:1340, weight:[1.15718384 0.93019086], bias:-0.9496649677172502, loss:0.5859880518277137\n",
      "epoch:1341, weight:[1.1574664  0.93036572], bias:-0.9499338700787577, loss:0.5859697752091312\n",
      "epoch:1342, weight:[1.15774898 0.93054054], bias:-0.9502026711850187, loss:0.5859515041545736\n",
      "epoch:1343, weight:[1.15803158 0.93071533], bias:-0.9504713712432605, loss:0.585933238658932\n",
      "epoch:1344, weight:[1.1583142  0.93089007], bias:-0.9507399704599728, loss:0.5859149787171125\n",
      "epoch:1345, weight:[1.15859685 0.93106478], bias:-0.9510084690409097, loss:0.585896724324037\n",
      "epoch:1346, weight:[1.15887951 0.93123946], bias:-0.9512768671910931, loss:0.5858784754746418\n",
      "epoch:1347, weight:[1.15916219 0.93141409], bias:-0.9515451651148148, loss:0.585860232163879\n",
      "epoch:1348, weight:[1.1594449  0.93158869], bias:-0.9518133630156403, loss:0.5858419943867148\n",
      "epoch:1349, weight:[1.15972762 0.93176325], bias:-0.952081461096411, loss:0.5858237621381307\n",
      "epoch:1350, weight:[1.16001037 0.93193777], bias:-0.952349459559247, loss:0.5858055354131232\n",
      "epoch:1351, weight:[1.16029313 0.93211226], bias:-0.95261735860555, loss:0.5857873142067026\n",
      "epoch:1352, weight:[1.16057592 0.9322867 ], bias:-0.9528851584360061, loss:0.5857690985138946\n",
      "epoch:1353, weight:[1.16085872 0.93246111], bias:-0.9531528592505886, loss:0.5857508883297388\n",
      "epoch:1354, weight:[1.16114155 0.93263548], bias:-0.9534204612485605, loss:0.5857326836492893\n",
      "epoch:1355, weight:[1.16142439 0.93280981], bias:-0.9536879646284776, loss:0.5857144844676142\n",
      "epoch:1356, weight:[1.16170726 0.93298411], bias:-0.953955369588191, loss:0.5856962907797966\n",
      "epoch:1357, weight:[1.16199014 0.93315836], bias:-0.9542226763248499, loss:0.5856781025809324\n",
      "epoch:1358, weight:[1.16227304 0.93333258], bias:-0.9544898850349042, loss:0.5856599198661327\n",
      "epoch:1359, weight:[1.16255597 0.93350676], bias:-0.9547569959141072, loss:0.5856417426305218\n",
      "epoch:1360, weight:[1.16283891 0.93368089], bias:-0.9550240091575186, loss:0.5856235708692378\n",
      "epoch:1361, weight:[1.16312187 0.93385499], bias:-0.9552909249595068, loss:0.5856054045774332\n",
      "epoch:1362, weight:[1.16340485 0.93402905], bias:-0.9555577435137519, loss:0.5855872437502728\n",
      "epoch:1363, weight:[1.16368785 0.93420307], bias:-0.9558244650132479, loss:0.5855690883829366\n",
      "epoch:1364, weight:[1.16397087 0.93437706], bias:-0.9560910896503058, loss:0.5855509384706169\n",
      "epoch:1365, weight:[1.16425391 0.934551  ], bias:-0.956357617616556, loss:0.5855327940085195\n",
      "epoch:1366, weight:[1.16453697 0.9347249 ], bias:-0.9566240491029511, loss:0.5855146549918642\n",
      "epoch:1367, weight:[1.16482004 0.93489876], bias:-0.9568903842997681, loss:0.5854965214158828\n",
      "epoch:1368, weight:[1.16510314 0.93507259], bias:-0.9571566233966118, loss:0.5854783932758214\n",
      "epoch:1369, weight:[1.16538625 0.93524637], bias:-0.9574227665824164, loss:0.5854602705669386\n",
      "epoch:1370, weight:[1.16566938 0.93542012], bias:-0.9576888140454489, loss:0.5854421532845059\n",
      "epoch:1371, weight:[1.16595253 0.93559382], bias:-0.9579547659733112, loss:0.5854240414238078\n",
      "epoch:1372, weight:[1.1662357  0.93576748], bias:-0.9582206225529429, loss:0.5854059349801415\n",
      "epoch:1373, weight:[1.16651889 0.93594111], bias:-0.958486383970624, loss:0.585387833948817\n",
      "epoch:1374, weight:[1.1668021  0.93611469], bias:-0.9587520504119769, loss:0.5853697383251572\n",
      "epoch:1375, weight:[1.16708532 0.93628824], bias:-0.9590176220619693, loss:0.5853516481044969\n",
      "epoch:1376, weight:[1.16736856 0.93646174], bias:-0.9592830991049168, loss:0.585333563282184\n",
      "epoch:1377, weight:[1.16765183 0.9366352 ], bias:-0.9595484817244855, loss:0.5853154838535786\n",
      "epoch:1378, weight:[1.1679351  0.93680862], bias:-0.9598137701036938, loss:0.5852974098140528\n",
      "epoch:1379, weight:[1.1682184 0.936982 ], bias:-0.960078964424916, loss:0.5852793411589914\n",
      "epoch:1380, weight:[1.16850172 0.93715534], bias:-0.9603440648698839, loss:0.585261277883791\n",
      "epoch:1381, weight:[1.16878505 0.93732864], bias:-0.9606090716196894, loss:0.5852432199838605\n",
      "epoch:1382, weight:[1.1690684 0.9375019], bias:-0.9608739848547877, loss:0.585225167454621\n",
      "epoch:1383, weight:[1.16935177 0.93767512], bias:-0.9611388047549986, loss:0.5852071202915053\n",
      "epoch:1384, weight:[1.16963515 0.9378483 ], bias:-0.9614035314995099, loss:0.5851890784899578\n",
      "epoch:1385, weight:[1.16991856 0.93802143], bias:-0.9616681652668793, loss:0.5851710420454354\n",
      "epoch:1386, weight:[1.17020198 0.93819453], bias:-0.9619327062350372, loss:0.5851530109534058\n",
      "epoch:1387, weight:[1.17048541 0.93836758], bias:-0.962197154581289, loss:0.5851349852093493\n",
      "epoch:1388, weight:[1.17076887 0.93854059], bias:-0.962461510482317, loss:0.5851169648087573\n",
      "epoch:1389, weight:[1.17105234 0.93871356], bias:-0.9627257741141838, loss:0.5850989497471327\n",
      "epoch:1390, weight:[1.17133583 0.93888649], bias:-0.9629899456523339, loss:0.5850809400199897\n",
      "epoch:1391, weight:[1.17161934 0.93905937], bias:-0.9632540252715961, loss:0.5850629356228544\n",
      "epoch:1392, weight:[1.17190286 0.93923222], bias:-0.9635180131461866, loss:0.5850449365512636\n",
      "epoch:1393, weight:[1.17218641 0.93940502], bias:-0.9637819094497104, loss:0.5850269428007654\n",
      "epoch:1394, weight:[1.17246996 0.93957778], bias:-0.9640457143551644, loss:0.5850089543669198\n",
      "epoch:1395, weight:[1.17275354 0.9397505 ], bias:-0.9643094280349394, loss:0.584990971245297\n",
      "epoch:1396, weight:[1.17303713 0.93992318], bias:-0.9645730506608223, loss:0.5849729934314786\n",
      "epoch:1397, weight:[1.17332074 0.94009581], bias:-0.9648365824039989, loss:0.5849550209210569\n",
      "epoch:1398, weight:[1.17360436 0.9402684 ], bias:-0.9651000234350559, loss:0.5849370537096357\n",
      "epoch:1399, weight:[1.17388801 0.94044095], bias:-0.965363373923983, loss:0.584919091792829\n",
      "epoch:1400, weight:[1.17417166 0.94061346], bias:-0.9656266340401758, loss:0.5849011351662617\n",
      "epoch:1401, weight:[1.17445534 0.94078592], bias:-0.9658898039524375, loss:0.5848831838255699\n",
      "epoch:1402, weight:[1.17473903 0.94095835], bias:-0.9661528838289816, loss:0.5848652377663995\n",
      "epoch:1403, weight:[1.17502274 0.94113072], bias:-0.9664158738374338, loss:0.5848472969844076\n",
      "epoch:1404, weight:[1.17530646 0.94130306], bias:-0.9666787741448346, loss:0.5848293614752614\n",
      "epoch:1405, weight:[1.1755902  0.94147535], bias:-0.9669415849176414, loss:0.584811431234639\n",
      "epoch:1406, weight:[1.17587396 0.9416476 ], bias:-0.9672043063217307, loss:0.5847935062582285\n",
      "epoch:1407, weight:[1.17615773 0.94181981], bias:-0.9674669385224005, loss:0.5847755865417281\n",
      "epoch:1408, weight:[1.17644152 0.94199198], bias:-0.9677294816843725, loss:0.5847576720808471\n",
      "epoch:1409, weight:[1.17672532 0.9421641 ], bias:-0.9679919359717939, loss:0.5847397628713041\n",
      "epoch:1410, weight:[1.17700914 0.94233617], bias:-0.9682543015482404, loss:0.5847218589088284\n",
      "epoch:1411, weight:[1.17729298 0.94250821], bias:-0.9685165785767178, loss:0.5847039601891589\n",
      "epoch:1412, weight:[1.17757683 0.9426802 ], bias:-0.9687787672196642, loss:0.5846860667080451\n",
      "epoch:1413, weight:[1.1778607  0.94285215], bias:-0.9690408676389525, loss:0.584668178461246\n",
      "epoch:1414, weight:[1.17814458 0.94302405], bias:-0.9693028799958925, loss:0.5846502954445308\n",
      "epoch:1415, weight:[1.17842848 0.94319591], bias:-0.9695648044512328, loss:0.584632417653678\n",
      "epoch:1416, weight:[1.17871239 0.94336773], bias:-0.9698266411651635, loss:0.5846145450844765\n",
      "epoch:1417, weight:[1.17899632 0.9435395 ], bias:-0.9700883902973175, loss:0.5845966777327247\n",
      "epoch:1418, weight:[1.17928027 0.94371123], bias:-0.9703500520067736, loss:0.5845788155942304\n",
      "epoch:1419, weight:[1.17956423 0.94388292], bias:-0.970611626452058, loss:0.5845609586648115\n",
      "epoch:1420, weight:[1.1798482  0.94405456], bias:-0.9708731137911467, loss:0.584543106940295\n",
      "epoch:1421, weight:[1.18013219 0.94422615], bias:-0.9711345141814673, loss:0.5845252604165175\n",
      "epoch:1422, weight:[1.1804162  0.94439771], bias:-0.9713958277799017, loss:0.5845074190893255\n",
      "epoch:1423, weight:[1.18070022 0.94456921], bias:-0.9716570547427876, loss:0.5844895829545739\n",
      "epoch:1424, weight:[1.18098426 0.94474068], bias:-0.971918195225921, loss:0.5844717520081281\n",
      "epoch:1425, weight:[1.18126831 0.9449121 ], bias:-0.972179249384558, loss:0.5844539262458619\n",
      "epoch:1426, weight:[1.18155237 0.94508347], bias:-0.972440217373417, loss:0.5844361056636587\n",
      "epoch:1427, weight:[1.18183645 0.9452548 ], bias:-0.9727010993466808, loss:0.5844182902574108\n",
      "epoch:1428, weight:[1.18212055 0.94542609], bias:-0.9729618954579987, loss:0.5844004800230199\n",
      "epoch:1429, weight:[1.18240466 0.94559733], bias:-0.9732226058604885, loss:0.5843826749563971\n",
      "epoch:1430, weight:[1.18268878 0.94576853], bias:-0.9734832307067385, loss:0.5843648750534615\n",
      "epoch:1431, weight:[1.18297292 0.94593968], bias:-0.9737437701488094, loss:0.5843470803101418\n",
      "epoch:1432, weight:[1.18325707 0.94611079], bias:-0.974004224338237, loss:0.5843292907223759\n",
      "epoch:1433, weight:[1.18354124 0.94628185], bias:-0.9742645934260331, loss:0.58431150628611\n",
      "epoch:1434, weight:[1.18382542 0.94645287], bias:-0.9745248775626886, loss:0.584293726997299\n",
      "epoch:1435, weight:[1.18410962 0.94662384], bias:-0.9747850768981748, loss:0.5842759528519074\n",
      "epoch:1436, weight:[1.18439383 0.94679477], bias:-0.9750451915819459, loss:0.5842581838459076\n",
      "epoch:1437, weight:[1.18467806 0.94696565], bias:-0.9753052217629404, loss:0.5842404199752806\n",
      "epoch:1438, weight:[1.1849623  0.94713649], bias:-0.9755651675895837, loss:0.5842226612360167\n",
      "epoch:1439, weight:[1.18524655 0.94730728], bias:-0.9758250292097895, loss:0.5842049076241143\n",
      "epoch:1440, weight:[1.18553082 0.94747802], bias:-0.9760848067709625, loss:0.5841871591355807\n",
      "epoch:1441, weight:[1.1858151  0.94764872], bias:-0.9763445004199997, loss:0.5841694157664307\n",
      "epoch:1442, weight:[1.18609939 0.94781938], bias:-0.9766041103032923, loss:0.5841516775126885\n",
      "epoch:1443, weight:[1.1863837  0.94798999], bias:-0.9768636365667283, loss:0.5841339443703861\n",
      "epoch:1444, weight:[1.18666803 0.94816055], bias:-0.9771230793556939, loss:0.5841162163355645\n",
      "epoch:1445, weight:[1.18695236 0.94833107], bias:-0.9773824388150756, loss:0.5840984934042722\n",
      "epoch:1446, weight:[1.18723671 0.94850154], bias:-0.977641715089262, loss:0.5840807755725664\n",
      "epoch:1447, weight:[1.18752108 0.94867197], bias:-0.9779009083221462, loss:0.584063062836512\n",
      "epoch:1448, weight:[1.18780545 0.94884235], bias:-0.9781600186571268, loss:0.5840453551921827\n",
      "epoch:1449, weight:[1.18808985 0.94901268], bias:-0.9784190462371106, loss:0.5840276526356598\n",
      "epoch:1450, weight:[1.18837425 0.94918297], bias:-0.9786779912045143, loss:0.5840099551630327\n",
      "epoch:1451, weight:[1.18865867 0.94935321], bias:-0.9789368537012662, loss:0.5839922627703991\n",
      "epoch:1452, weight:[1.1889431  0.94952341], bias:-0.979195633868808, loss:0.5839745754538642\n",
      "epoch:1453, weight:[1.18922754 0.94969356], bias:-0.9794543318480973, loss:0.5839568932095415\n",
      "epoch:1454, weight:[1.189512   0.94986366], bias:-0.9797129477796085, loss:0.5839392160335521\n",
      "epoch:1455, weight:[1.18979647 0.95003372], bias:-0.9799714818033355, loss:0.5839215439220253\n",
      "epoch:1456, weight:[1.19008096 0.95020373], bias:-0.9802299340587931, loss:0.5839038768710977\n",
      "epoch:1457, weight:[1.19036546 0.95037369], bias:-0.9804883046850191, loss:0.5838862148769138\n",
      "epoch:1458, weight:[1.19064997 0.95054361], bias:-0.9807465938205758, loss:0.5838685579356261\n",
      "epoch:1459, weight:[1.19093449 0.95071348], bias:-0.9810048016035521, loss:0.5838509060433941\n",
      "epoch:1460, weight:[1.19121903 0.95088331], bias:-0.9812629281715651, loss:0.5838332591963858\n",
      "epoch:1461, weight:[1.19150358 0.95105308], bias:-0.9815209736617623, loss:0.5838156173907761\n",
      "epoch:1462, weight:[1.19178814 0.95122282], bias:-0.981778938210823, loss:0.5837979806227476\n",
      "epoch:1463, weight:[1.19207271 0.9513925 ], bias:-0.9820368219549602, loss:0.5837803488884905\n",
      "epoch:1464, weight:[1.1923573  0.95156214], bias:-0.9822946250299226, loss:0.5837627221842022\n",
      "epoch:1465, weight:[1.1926419  0.95173173], bias:-0.9825523475709962, loss:0.5837451005060879\n",
      "epoch:1466, weight:[1.19292651 0.95190127], bias:-0.9828099897130059, loss:0.5837274838503596\n",
      "epoch:1467, weight:[1.19321114 0.95207077], bias:-0.9830675515903178, loss:0.5837098722132371\n",
      "epoch:1468, weight:[1.19349578 0.95224022], bias:-0.9833250333368403, loss:0.5836922655909477\n",
      "epoch:1469, weight:[1.19378043 0.95240962], bias:-0.9835824350860265, loss:0.5836746639797252\n",
      "epoch:1470, weight:[1.19406509 0.95257897], bias:-0.9838397569708754, loss:0.583657067375811\n",
      "epoch:1471, weight:[1.19434976 0.95274828], bias:-0.9840969991239341, loss:0.5836394757754543\n",
      "epoch:1472, weight:[1.19463445 0.95291754], bias:-0.9843541616772992, loss:0.5836218891749099\n",
      "epoch:1473, weight:[1.19491915 0.95308675], bias:-0.9846112447626186, loss:0.5836043075704411\n",
      "epoch:1474, weight:[1.19520386 0.95325592], bias:-0.9848682485110934, loss:0.583586730958318\n",
      "epoch:1475, weight:[1.19548859 0.95342504], bias:-0.9851251730534795, loss:0.5835691593348172\n",
      "epoch:1476, weight:[1.19577332 0.95359411], bias:-0.9853820185200891, loss:0.5835515926962227\n",
      "epoch:1477, weight:[1.19605807 0.95376313], bias:-0.9856387850407928, loss:0.5835340310388255\n",
      "epoch:1478, weight:[1.19634283 0.95393211], bias:-0.9858954727450211, loss:0.5835164743589227\n",
      "epoch:1479, weight:[1.1966276  0.95410103], bias:-0.9861520817617659, loss:0.5834989226528199\n",
      "epoch:1480, weight:[1.19691239 0.95426991], bias:-0.9864086122195828, loss:0.5834813759168278\n",
      "epoch:1481, weight:[1.19719718 0.95443875], bias:-0.9866650642465917, loss:0.583463834147265\n",
      "epoch:1482, weight:[1.19748199 0.95460753], bias:-0.9869214379704797, loss:0.5834462973404565\n",
      "epoch:1483, weight:[1.19776681 0.95477627], bias:-0.9871777335185018, loss:0.5834287654927341\n",
      "epoch:1484, weight:[1.19805164 0.95494495], bias:-0.9874339510174832, loss:0.5834112386004362\n",
      "epoch:1485, weight:[1.19833648 0.95511359], bias:-0.9876900905938205, loss:0.5833937166599079\n",
      "epoch:1486, weight:[1.19862134 0.95528219], bias:-0.9879461523734836, loss:0.5833761996675009\n",
      "epoch:1487, weight:[1.1989062  0.95545073], bias:-0.9882021364820173, loss:0.5833586876195742\n",
      "epoch:1488, weight:[1.19919108 0.95561923], bias:-0.9884580430445429, loss:0.5833411805124916\n",
      "epoch:1489, weight:[1.19947597 0.95578767], bias:-0.9887138721857597, loss:0.5833236783426258\n",
      "epoch:1490, weight:[1.19976087 0.95595607], bias:-0.9889696240299468, loss:0.5833061811063536\n",
      "epoch:1491, weight:[1.20004578 0.95612442], bias:-0.9892252987009649, loss:0.5832886888000602\n",
      "epoch:1492, weight:[1.2003307  0.95629273], bias:-0.9894808963222572, loss:0.5832712014201363\n",
      "epoch:1493, weight:[1.20061564 0.95646098], bias:-0.9897364170168518, loss:0.5832537189629787\n",
      "epoch:1494, weight:[1.20090058 0.95662919], bias:-0.9899918609073628, loss:0.5832362414249915\n",
      "epoch:1495, weight:[1.20118554 0.95679734], bias:-0.9902472281159922, loss:0.5832187688025844\n",
      "epoch:1496, weight:[1.20147051 0.95696545], bias:-0.9905025187645311, loss:0.5832013010921736\n",
      "epoch:1497, weight:[1.20175548 0.95713351], bias:-0.9907577329743616, loss:0.5831838382901816\n",
      "epoch:1498, weight:[1.20204047 0.95730152], bias:-0.9910128708664583, loss:0.5831663803930371\n",
      "epoch:1499, weight:[1.20232547 0.95746949], bias:-0.9912679325613897, loss:0.5831489273971754\n",
      "epoch:1500, weight:[1.20261049 0.9576374 ], bias:-0.99152291817932, loss:0.5831314792990372\n",
      "epoch:1501, weight:[1.20289551 0.95780527], bias:-0.9917778278400106, loss:0.5831140360950696\n",
      "epoch:1502, weight:[1.20318054 0.95797308], bias:-0.9920326616628212, loss:0.5830965977817266\n",
      "epoch:1503, weight:[1.20346558 0.95814085], bias:-0.9922874197667122, loss:0.583079164355467\n",
      "epoch:1504, weight:[1.20375064 0.95830857], bias:-0.9925421022702454, loss:0.5830617358127568\n",
      "epoch:1505, weight:[1.2040357  0.95847624], bias:-0.992796709291586, loss:0.583044312150067\n",
      "epoch:1506, weight:[1.20432078 0.95864386], bias:-0.993051240948504, loss:0.5830268933638757\n",
      "epoch:1507, weight:[1.20460587 0.95881143], bias:-0.9933056973583758, loss:0.583009479450666\n",
      "epoch:1508, weight:[1.20489096 0.95897895], bias:-0.9935600786381853, loss:0.5829920704069272\n",
      "epoch:1509, weight:[1.20517607 0.95914643], bias:-0.993814384904526, loss:0.5829746662291548\n",
      "epoch:1510, weight:[1.20546119 0.95931385], bias:-0.9940686162736021, loss:0.5829572669138501\n",
      "epoch:1511, weight:[1.20574632 0.95948123], bias:-0.99432277286123, loss:0.5829398724575199\n",
      "epoch:1512, weight:[1.20603146 0.95964855], bias:-0.9945768547828402, loss:0.5829224828566771\n",
      "epoch:1513, weight:[1.20631661 0.95981583], bias:-0.994830862153478, loss:0.5829050981078404\n",
      "epoch:1514, weight:[1.20660177 0.95998305], bias:-0.995084795087806, loss:0.5828877182075342\n",
      "epoch:1515, weight:[1.20688694 0.96015023], bias:-0.9953386537001045, loss:0.5828703431522887\n",
      "epoch:1516, weight:[1.20717212 0.96031736], bias:-0.9955924381042738, loss:0.5828529729386396\n",
      "epoch:1517, weight:[1.20745731 0.96048444], bias:-0.9958461484138351, loss:0.5828356075631285\n",
      "epoch:1518, weight:[1.20774251 0.96065147], bias:-0.9960997847419323, loss:0.5828182470223026\n",
      "epoch:1519, weight:[1.20802772 0.96081845], bias:-0.9963533472013333, loss:0.5828008913127145\n",
      "epoch:1520, weight:[1.20831294 0.96098538], bias:-0.9966068359044314, loss:0.5827835404309227\n",
      "epoch:1521, weight:[1.20859817 0.96115226], bias:-0.996860250963247, loss:0.5827661943734914\n",
      "epoch:1522, weight:[1.20888341 0.96131909], bias:-0.9971135924894285, loss:0.5827488531369899\n",
      "epoch:1523, weight:[1.20916866 0.96148587], bias:-0.9973668605942543, loss:0.5827315167179932\n",
      "epoch:1524, weight:[1.20945392 0.9616526 ], bias:-0.9976200553886337, loss:0.5827141851130819\n",
      "epoch:1525, weight:[1.20973919 0.96181928], bias:-0.997873176983109, loss:0.5826968583188421\n",
      "epoch:1526, weight:[1.21002447 0.96198591], bias:-0.998126225487856, loss:0.582679536331865\n",
      "epoch:1527, weight:[1.21030975 0.96215249], bias:-0.9983792010126862, loss:0.5826622191487475\n",
      "epoch:1528, weight:[1.21059505 0.96231902], bias:-0.9986321036670476, loss:0.5826449067660918\n",
      "epoch:1529, weight:[1.21088036 0.9624855 ], bias:-0.9988849335600266, loss:0.5826275991805059\n",
      "epoch:1530, weight:[1.21116568 0.96265194], bias:-0.9991376908003491, loss:0.5826102963886022\n",
      "epoch:1531, weight:[1.21145101 0.96281832], bias:-0.9993903754963819, loss:0.5825929983869993\n",
      "epoch:1532, weight:[1.21173634 0.96298465], bias:-0.9996429877561339, loss:0.5825757051723205\n",
      "epoch:1533, weight:[1.21202169 0.96315093], bias:-0.9998955276872581, loss:0.582558416741195\n",
      "epoch:1534, weight:[1.21230705 0.96331716], bias:-1.000147995397052, loss:0.5825411330902566\n",
      "epoch:1535, weight:[1.21259241 0.96348334], bias:-1.00040039099246, loss:0.5825238542161444\n",
      "epoch:1536, weight:[1.21287779 0.96364947], bias:-1.0006527145800737, loss:0.5825065801155032\n",
      "epoch:1537, weight:[1.21316317 0.96381555], bias:-1.0009049662661342, loss:0.5824893107849825\n",
      "epoch:1538, weight:[1.21344856 0.96398158], bias:-1.001157146156533, loss:0.582472046221237\n",
      "epoch:1539, weight:[1.21373397 0.96414756], bias:-1.001409254356813, loss:0.5824547864209269\n",
      "epoch:1540, weight:[1.21401938 0.96431349], bias:-1.0016612909721705, loss:0.5824375313807169\n",
      "epoch:1541, weight:[1.2143048  0.96447937], bias:-1.0019132561074564, loss:0.5824202810972772\n",
      "epoch:1542, weight:[1.21459023 0.9646452 ], bias:-1.0021651498671769, loss:0.5824030355672829\n",
      "epoch:1543, weight:[1.21487567 0.96481097], bias:-1.0024169723554954, loss:0.5823857947874145\n",
      "epoch:1544, weight:[1.21516112 0.9649767 ], bias:-1.002668723676234, loss:0.5823685587543568\n",
      "epoch:1545, weight:[1.21544657 0.96514238], bias:-1.0029204039328736, loss:0.5823513274648001\n",
      "epoch:1546, weight:[1.21573204 0.965308  ], bias:-1.003172013228557, loss:0.5823341009154394\n",
      "epoch:1547, weight:[1.21601751 0.96547358], bias:-1.003423551666089, loss:0.582316879102975\n",
      "epoch:1548, weight:[1.216303  0.9656391], bias:-1.0036750193479376, loss:0.5822996620241118\n",
      "epoch:1549, weight:[1.21658849 0.96580458], bias:-1.003926416376236, loss:0.5822824496755596\n",
      "epoch:1550, weight:[1.21687399 0.96597   ], bias:-1.0041777428527834, loss:0.5822652420540336\n",
      "epoch:1551, weight:[1.2171595  0.96613537], bias:-1.0044289988790465, loss:0.5822480391562529\n",
      "epoch:1552, weight:[1.21744502 0.96630069], bias:-1.0046801845561604, loss:0.5822308409789422\n",
      "epoch:1553, weight:[1.21773055 0.96646596], bias:-1.0049312999849302, loss:0.5822136475188309\n",
      "epoch:1554, weight:[1.21801608 0.96663118], bias:-1.0051823452658326, loss:0.5821964587726529\n",
      "epoch:1555, weight:[1.21830163 0.96679635], bias:-1.0054333204990162, loss:0.5821792747371468\n",
      "epoch:1556, weight:[1.21858718 0.96696147], bias:-1.0056842257843035, loss:0.5821620954090567\n",
      "epoch:1557, weight:[1.21887274 0.96712654], bias:-1.005935061221192, loss:0.5821449207851308\n",
      "epoch:1558, weight:[1.21915831 0.96729155], bias:-1.0061858269088553, loss:0.5821277508621218\n",
      "epoch:1559, weight:[1.21944389 0.96745652], bias:-1.0064365229461443, loss:0.5821105856367877\n",
      "epoch:1560, weight:[1.21972948 0.96762143], bias:-1.0066871494315888, loss:0.5820934251058909\n",
      "epoch:1561, weight:[1.22001507 0.96778629], bias:-1.0069377064633984, loss:0.5820762692661985\n",
      "epoch:1562, weight:[1.22030068 0.96795111], bias:-1.0071881941394638, loss:0.582059118114482\n",
      "epoch:1563, weight:[1.22058629 0.96811587], bias:-1.0074386125573578, loss:0.5820419716475175\n",
      "epoch:1564, weight:[1.22087191 0.96828058], bias:-1.007688961814337, loss:0.5820248298620864\n",
      "epoch:1565, weight:[1.22115754 0.96844523], bias:-1.0079392420073423, loss:0.5820076927549739\n",
      "epoch:1566, weight:[1.22144318 0.96860984], bias:-1.0081894532330011, loss:0.5819905603229699\n",
      "epoch:1567, weight:[1.22172882 0.9687744 ], bias:-1.0084395955876277, loss:0.581973432562869\n",
      "epoch:1568, weight:[1.22201447 0.9689389 ], bias:-1.0086896691672247, loss:0.5819563094714701\n",
      "epoch:1569, weight:[1.22230013 0.96910335], bias:-1.0089396740674839, loss:0.5819391910455769\n",
      "epoch:1570, weight:[1.2225858  0.96926775], bias:-1.0091896103837883, loss:0.5819220772819974\n",
      "epoch:1571, weight:[1.22287148 0.9694321 ], bias:-1.0094394782112124, loss:0.5819049681775441\n",
      "epoch:1572, weight:[1.22315716 0.9695964 ], bias:-1.0096892776445239, loss:0.5818878637290339\n",
      "epoch:1573, weight:[1.22344286 0.96976065], bias:-1.0099390087781848, loss:0.5818707639332878\n",
      "epoch:1574, weight:[1.22372856 0.96992485], bias:-1.0101886717063524, loss:0.5818536687871322\n",
      "epoch:1575, weight:[1.22401427 0.97008899], bias:-1.0104382665228806, loss:0.5818365782873965\n",
      "epoch:1576, weight:[1.22429998 0.97025308], bias:-1.0106877933213207, loss:0.5818194924309157\n",
      "epoch:1577, weight:[1.22458571 0.97041712], bias:-1.0109372521949234, loss:0.5818024112145284\n",
      "epoch:1578, weight:[1.22487144 0.97058111], bias:-1.0111866432366388, loss:0.5817853346350778\n",
      "epoch:1579, weight:[1.22515718 0.97074505], bias:-1.0114359665391184, loss:0.5817682626894111\n",
      "epoch:1580, weight:[1.22544292 0.97090894], bias:-1.0116852221947161, loss:0.5817511953743806\n",
      "epoch:1581, weight:[1.22572868 0.97107277], bias:-1.0119344102954893, loss:0.581734132686842\n",
      "epoch:1582, weight:[1.22601444 0.97123655], bias:-1.0121835309331995, loss:0.5817170746236558\n",
      "epoch:1583, weight:[1.22630021 0.97140028], bias:-1.012432584199314, loss:0.5817000211816864\n",
      "epoch:1584, weight:[1.22658599 0.97156396], bias:-1.0126815701850074, loss:0.5816829723578025\n",
      "epoch:1585, weight:[1.22687177 0.97172759], bias:-1.0129304889811614, loss:0.5816659281488773\n",
      "epoch:1586, weight:[1.22715757 0.97189116], bias:-1.0131793406783673, loss:0.581648888551788\n",
      "epoch:1587, weight:[1.22744337 0.97205469], bias:-1.0134281253669264, loss:0.5816318535634157\n",
      "epoch:1588, weight:[1.22772917 0.97221816], bias:-1.013676843136851, loss:0.5816148231806462\n",
      "epoch:1589, weight:[1.22801499 0.97238158], bias:-1.0139254940778661, loss:0.5815977974003689\n",
      "epoch:1590, weight:[1.22830081 0.97254495], bias:-1.0141740782794098, loss:0.5815807762194777\n",
      "epoch:1591, weight:[1.22858664 0.97270826], bias:-1.0144225958306348, loss:0.5815637596348705\n",
      "epoch:1592, weight:[1.22887248 0.97287153], bias:-1.0146710468204094, loss:0.5815467476434494\n",
      "epoch:1593, weight:[1.22915832 0.97303474], bias:-1.0149194313373189, loss:0.5815297402421203\n",
      "epoch:1594, weight:[1.22944417 0.9731979 ], bias:-1.0151677494696656, loss:0.5815127374277934\n",
      "epoch:1595, weight:[1.22973003 0.97336101], bias:-1.0154160013054714, loss:0.5814957391973833\n",
      "epoch:1596, weight:[1.23001589 0.97352406], bias:-1.0156641869324776, loss:0.5814787455478073\n",
      "epoch:1597, weight:[1.23030177 0.97368707], bias:-1.0159123064381468, loss:0.5814617564759884\n",
      "epoch:1598, weight:[1.23058765 0.97385002], bias:-1.0161603599096634, loss:0.5814447719788526\n",
      "epoch:1599, weight:[1.23087353 0.97401292], bias:-1.016408347433935, loss:0.5814277920533301\n",
      "epoch:1600, weight:[1.23115942 0.97417576], bias:-1.0166562690975933, loss:0.5814108166963551\n",
      "epoch:1601, weight:[1.23144532 0.97433856], bias:-1.0169041249869952, loss:0.5813938459048656\n",
      "epoch:1602, weight:[1.23173123 0.9745013 ], bias:-1.0171519151882238, loss:0.5813768796758042\n",
      "epoch:1603, weight:[1.23201715 0.97466399], bias:-1.0173996397870892, loss:0.5813599180061164\n",
      "epoch:1604, weight:[1.23230307 0.97482663], bias:-1.0176472988691305, loss:0.5813429608927523\n",
      "epoch:1605, weight:[1.23258899 0.97498922], bias:-1.0178948925196156, loss:0.5813260083326657\n",
      "epoch:1606, weight:[1.23287493 0.97515175], bias:-1.0181424208235428, loss:0.5813090603228142\n",
      "epoch:1607, weight:[1.23316087 0.97531423], bias:-1.0183898838656418, loss:0.5812921168601594\n",
      "epoch:1608, weight:[1.23344682 0.97547666], bias:-1.0186372817303748, loss:0.5812751779416672\n",
      "epoch:1609, weight:[1.23373277 0.97563904], bias:-1.0188846145019377, loss:0.581258243564306\n",
      "epoch:1610, weight:[1.23401873 0.97580136], bias:-1.0191318822642603, loss:0.5812413137250494\n",
      "epoch:1611, weight:[1.2343047  0.97596363], bias:-1.0193790851010083, loss:0.5812243884208746\n",
      "epoch:1612, weight:[1.23459068 0.97612585], bias:-1.0196262230955833, loss:0.5812074676487616\n",
      "epoch:1613, weight:[1.23487666 0.97628802], bias:-1.019873296331125, loss:0.5811905514056955\n",
      "epoch:1614, weight:[1.23516265 0.97645013], bias:-1.0201203048905112, loss:0.581173639688664\n",
      "epoch:1615, weight:[1.23544864 0.9766122 ], bias:-1.020367248856359, loss:0.5811567324946595\n",
      "epoch:1616, weight:[1.23573464 0.97677421], bias:-1.0206141283110266, loss:0.5811398298206775\n",
      "epoch:1617, weight:[1.23602065 0.97693616], bias:-1.020860943336613, loss:0.5811229316637175\n",
      "epoch:1618, weight:[1.23630666 0.97709807], bias:-1.0211076940149593, loss:0.581106038020783\n",
      "epoch:1619, weight:[1.23659268 0.97725992], bias:-1.0213543804276508, loss:0.5810891488888802\n",
      "epoch:1620, weight:[1.23687871 0.97742172], bias:-1.021601002656017, loss:0.5810722642650202\n",
      "epoch:1621, weight:[1.23716474 0.97758346], bias:-1.021847560781132, loss:0.5810553841462173\n",
      "epoch:1622, weight:[1.23745078 0.97774516], bias:-1.0220940548838169, loss:0.5810385085294891\n",
      "epoch:1623, weight:[1.23773682 0.9779068 ], bias:-1.02234048504464, loss:0.5810216374118573\n",
      "epoch:1624, weight:[1.23802287 0.97806839], bias:-1.0225868513439174, loss:0.5810047707903472\n",
      "epoch:1625, weight:[1.23830893 0.97822992], bias:-1.0228331538617146, loss:0.5809879086619872\n",
      "epoch:1626, weight:[1.238595   0.97839141], bias:-1.0230793926778474, loss:0.5809710510238102\n",
      "epoch:1627, weight:[1.23888107 0.97855284], bias:-1.0233255678718824, loss:0.580954197872852\n",
      "epoch:1628, weight:[1.23916714 0.97871421], bias:-1.0235716795231382, loss:0.5809373492061521\n",
      "epoch:1629, weight:[1.23945322 0.97887554], bias:-1.0238177277106866, loss:0.5809205050207541\n",
      "epoch:1630, weight:[1.23973931 0.97903681], bias:-1.024063712513353, loss:0.580903665313704\n",
      "epoch:1631, weight:[1.24002541 0.97919803], bias:-1.0243096340097175, loss:0.5808868300820529\n",
      "epoch:1632, weight:[1.24031151 0.9793592 ], bias:-1.0245554922781164, loss:0.5808699993228539\n",
      "epoch:1633, weight:[1.24059761 0.97952031], bias:-1.0248012873966423, loss:0.5808531730331649\n",
      "epoch:1634, weight:[1.24088372 0.97968137], bias:-1.0250470194431456, loss:0.5808363512100466\n",
      "epoch:1635, weight:[1.24116984 0.97984238], bias:-1.0252926884952351, loss:0.5808195338505632\n",
      "epoch:1636, weight:[1.24145597 0.98000333], bias:-1.0255382946302791, loss:0.5808027209517825\n",
      "epoch:1637, weight:[1.24174209 0.98016423], bias:-1.025783837925406, loss:0.580785912510776\n",
      "epoch:1638, weight:[1.24202823 0.98032508], bias:-1.0260293184575058, loss:0.5807691085246186\n",
      "epoch:1639, weight:[1.24231437 0.98048588], bias:-1.0262747363032303, loss:0.580752308990388\n",
      "epoch:1640, weight:[1.24260052 0.98064662], bias:-1.0265200915389947, loss:0.5807355139051665\n",
      "epoch:1641, weight:[1.24288667 0.98080731], bias:-1.0267653842409779, loss:0.580718723266039\n",
      "epoch:1642, weight:[1.24317283 0.98096795], bias:-1.0270106144851234, loss:0.5807019370700938\n",
      "epoch:1643, weight:[1.24345899 0.98112853], bias:-1.027255782347141, loss:0.580685155314423\n",
      "epoch:1644, weight:[1.24374516 0.98128906], bias:-1.027500887902507, loss:0.5806683779961219\n",
      "epoch:1645, weight:[1.24403134 0.98144954], bias:-1.0277459312264645, loss:0.580651605112289\n",
      "epoch:1646, weight:[1.24431752 0.98160997], bias:-1.027990912394026, loss:0.5806348366600269\n",
      "epoch:1647, weight:[1.2446037  0.98177034], bias:-1.0282358314799727, loss:0.5806180726364405\n",
      "epoch:1648, weight:[1.2448899  0.98193066], bias:-1.0284806885588555, loss:0.580601313038639\n",
      "epoch:1649, weight:[1.24517609 0.98209092], bias:-1.0287254837049973, loss:0.5805845578637341\n",
      "epoch:1650, weight:[1.2454623  0.98225113], bias:-1.0289702169924921, loss:0.5805678071088417\n",
      "epoch:1651, weight:[1.24574851 0.98241129], bias:-1.0292148884952068, loss:0.5805510607710803\n",
      "epoch:1652, weight:[1.24603472 0.9825714 ], bias:-1.0294594982867822, loss:0.580534318847572\n",
      "epoch:1653, weight:[1.24632094 0.98273145], bias:-1.0297040464406328, loss:0.5805175813354423\n",
      "epoch:1654, weight:[1.24660716 0.98289145], bias:-1.0299485330299494, loss:0.5805008482318196\n",
      "epoch:1655, weight:[1.24689339 0.9830514 ], bias:-1.030192958127698, loss:0.5804841195338363\n",
      "epoch:1656, weight:[1.24717963 0.98321129], bias:-1.0304373218066223, loss:0.5804673952386273\n",
      "epoch:1657, weight:[1.24746587 0.98337113], bias:-1.0306816241392434, loss:0.5804506753433314\n",
      "epoch:1658, weight:[1.24775211 0.98353092], bias:-1.030925865197861, loss:0.5804339598450897\n",
      "epoch:1659, weight:[1.24803836 0.98369065], bias:-1.0311700450545547, loss:0.5804172487410476\n",
      "epoch:1660, weight:[1.24832462 0.98385033], bias:-1.0314141637811842, loss:0.580400542028353\n",
      "epoch:1661, weight:[1.24861088 0.98400996], bias:-1.0316582214493903, loss:0.5803838397041579\n",
      "epoch:1662, weight:[1.24889715 0.98416953], bias:-1.0319022181305961, loss:0.580367141765616\n",
      "epoch:1663, weight:[1.24918342 0.98432905], bias:-1.032146153896007, loss:0.5803504482098855\n",
      "epoch:1664, weight:[1.2494697  0.98448852], bias:-1.0323900288166126, loss:0.5803337590341276\n",
      "epoch:1665, weight:[1.24975598 0.98464793], bias:-1.0326338429631867, loss:0.5803170742355062\n",
      "epoch:1666, weight:[1.25004226 0.98480729], bias:-1.0328775964062882, loss:0.5803003938111885\n",
      "epoch:1667, weight:[1.25032856 0.9849666 ], bias:-1.0331212892162625, loss:0.5802837177583452\n",
      "epoch:1668, weight:[1.25061485 0.98512585], bias:-1.0333649214632412, loss:0.5802670460741497\n",
      "epoch:1669, weight:[1.25090115 0.98528505], bias:-1.0336084932171443, loss:0.5802503787557787\n",
      "epoch:1670, weight:[1.25118746 0.9854442 ], bias:-1.0338520045476802, loss:0.5802337158004126\n",
      "epoch:1671, weight:[1.25147377 0.98560329], bias:-1.034095455524346, loss:0.5802170572052338\n",
      "epoch:1672, weight:[1.25176009 0.98576233], bias:-1.0343388462164296, loss:0.5802004029674287\n",
      "epoch:1673, weight:[1.25204641 0.98592132], bias:-1.0345821766930092, loss:0.580183753084186\n",
      "epoch:1674, weight:[1.25233274 0.98608025], bias:-1.0348254470229552, loss:0.580167107552699\n",
      "epoch:1675, weight:[1.25261907 0.98623913], bias:-1.03506865727493, loss:0.5801504663701621\n",
      "epoch:1676, weight:[1.2529054  0.98639795], bias:-1.0353118075173893, loss:0.5801338295337738\n",
      "epoch:1677, weight:[1.25319174 0.98655673], bias:-1.035554897818583, loss:0.5801171970407364\n",
      "epoch:1678, weight:[1.25347809 0.98671545], bias:-1.0357979282465557, loss:0.5801005688882536\n",
      "epoch:1679, weight:[1.25376444 0.98687411], bias:-1.0360408988691476, loss:0.5800839450735334\n",
      "epoch:1680, weight:[1.25405079 0.98703272], bias:-1.0362838097539953, loss:0.5800673255937865\n",
      "epoch:1681, weight:[1.25433715 0.98719128], bias:-1.036526660968532, loss:0.5800507104462261\n",
      "epoch:1682, weight:[1.25462351 0.98734979], bias:-1.0367694525799893, loss:0.5800340996280694\n",
      "epoch:1683, weight:[1.25490988 0.98750824], bias:-1.0370121846553975, loss:0.5800174931365359\n",
      "epoch:1684, weight:[1.25519626 0.98766664], bias:-1.0372548572615858, loss:0.5800008909688482\n",
      "epoch:1685, weight:[1.25548263 0.98782498], bias:-1.037497470465184, loss:0.579984293122232\n",
      "epoch:1686, weight:[1.25576902 0.98798327], bias:-1.0377400243326225, loss:0.5799676995939159\n",
      "epoch:1687, weight:[1.2560554  0.98814151], bias:-1.0379825189301335, loss:0.5799511103811317\n",
      "epoch:1688, weight:[1.25634179 0.98829969], bias:-1.0382249543237514, loss:0.5799345254811138\n",
      "epoch:1689, weight:[1.25662819 0.98845782], bias:-1.0384673305793137, loss:0.5799179448910997\n",
      "epoch:1690, weight:[1.25691459 0.9886159 ], bias:-1.0387096477624622, loss:0.5799013686083302\n",
      "epoch:1691, weight:[1.25720099 0.98877392], bias:-1.038951905938643, loss:0.5798847966300484\n",
      "epoch:1692, weight:[1.2574874  0.98893189], bias:-1.0391941051731073, loss:0.5798682289535012\n",
      "epoch:1693, weight:[1.25777381 0.9890898 ], bias:-1.039436245530913, loss:0.5798516655759373\n",
      "epoch:1694, weight:[1.25806023 0.98924766], bias:-1.039678327076924, loss:0.5798351064946092\n",
      "epoch:1695, weight:[1.25834665 0.98940547], bias:-1.0399203498758127, loss:0.5798185517067721\n",
      "epoch:1696, weight:[1.25863308 0.98956323], bias:-1.040162313992059, loss:0.5798020012096837\n",
      "epoch:1697, weight:[1.25891951 0.98972093], bias:-1.040404219489952, loss:0.5797854550006053\n",
      "epoch:1698, weight:[1.25920594 0.98987857], bias:-1.0406460664335906, loss:0.5797689130768003\n",
      "epoch:1699, weight:[1.25949238 0.99003617], bias:-1.0408878548868838, loss:0.5797523754355359\n",
      "epoch:1700, weight:[1.25977883 0.9901937 ], bias:-1.0411295849135522, loss:0.5797358420740811\n",
      "epoch:1701, weight:[1.26006527 0.99035119], bias:-1.041371256577128, loss:0.5797193129897086\n",
      "epoch:1702, weight:[1.26035172 0.99050862], bias:-1.041612869940956, loss:0.5797027881796933\n",
      "epoch:1703, weight:[1.26063818 0.990666  ], bias:-1.0418544250681938, loss:0.579686267641314\n",
      "epoch:1704, weight:[1.26092464 0.99082332], bias:-1.0420959220218136, loss:0.579669751371851\n",
      "epoch:1705, weight:[1.2612111  0.99098059], bias:-1.0423373608646018, loss:0.5796532393685884\n",
      "epoch:1706, weight:[1.26149757 0.99113781], bias:-1.0425787416591605, loss:0.5796367316288125\n",
      "epoch:1707, weight:[1.26178404 0.99129497], bias:-1.0428200644679075, loss:0.579620228149813\n",
      "epoch:1708, weight:[1.26207052 0.99145208], bias:-1.0430613293530777, loss:0.5796037289288818\n",
      "epoch:1709, weight:[1.262357   0.99160914], bias:-1.043302536376723, loss:0.5795872339633142\n",
      "epoch:1710, weight:[1.26264348 0.99176614], bias:-1.0435436856007136, loss:0.579570743250408\n",
      "epoch:1711, weight:[1.26292997 0.99192309], bias:-1.0437847770867386, loss:0.5795542567874633\n",
      "epoch:1712, weight:[1.26321646 0.99207998], bias:-1.044025810896306, loss:0.579537774571784\n",
      "epoch:1713, weight:[1.26350295 0.99223682], bias:-1.044266787090745, loss:0.5795212966006761\n",
      "epoch:1714, weight:[1.26378945 0.99239361], bias:-1.0445077057312044, loss:0.5795048228714486\n",
      "epoch:1715, weight:[1.26407596 0.99255034], bias:-1.0447485668786554, loss:0.5794883533814129\n",
      "epoch:1716, weight:[1.26436246 0.99270702], bias:-1.0449893705938909, loss:0.5794718881278835\n",
      "epoch:1717, weight:[1.26464897 0.99286365], bias:-1.0452301169375267, loss:0.5794554271081774\n",
      "epoch:1718, weight:[1.26493549 0.99302022], bias:-1.0454708059700022, loss:0.5794389703196147\n",
      "epoch:1719, weight:[1.265222   0.99317673], bias:-1.0457114377515808, loss:0.579422517759518\n",
      "epoch:1720, weight:[1.26550853 0.9933332 ], bias:-1.045952012342351, loss:0.5794060694252124\n",
      "epoch:1721, weight:[1.26579505 0.99348961], bias:-1.0461925298022263, loss:0.5793896253140263\n",
      "epoch:1722, weight:[1.26608158 0.99364596], bias:-1.0464329901909468, loss:0.57937318542329\n",
      "epoch:1723, weight:[1.26636811 0.99380226], bias:-1.046673393568079, loss:0.5793567497503372\n",
      "epoch:1724, weight:[1.26665465 0.99395851], bias:-1.046913739993017, loss:0.5793403182925042\n",
      "epoch:1725, weight:[1.26694119 0.99411471], bias:-1.047154029524983, loss:0.5793238910471297\n",
      "epoch:1726, weight:[1.26722773 0.99427085], bias:-1.0473942622230277, loss:0.579307468011555\n",
      "epoch:1727, weight:[1.26751428 0.99442693], bias:-1.0476344381460312, loss:0.5792910491831244\n",
      "epoch:1728, weight:[1.26780083 0.99458297], bias:-1.047874557352704, loss:0.5792746345591847\n",
      "epoch:1729, weight:[1.26808739 0.99473894], bias:-1.0481146199015865, loss:0.5792582241370856\n",
      "epoch:1730, weight:[1.26837395 0.99489487], bias:-1.048354625851051, loss:0.5792418179141792\n",
      "epoch:1731, weight:[1.26866051 0.99505074], bias:-1.0485945752593016, loss:0.57922541588782\n",
      "epoch:1732, weight:[1.26894707 0.99520656], bias:-1.0488344681843744, loss:0.5792090180553658\n",
      "epoch:1733, weight:[1.26923364 0.99536232], bias:-1.0490743046841393, loss:0.5791926244141767\n",
      "epoch:1734, weight:[1.26952021 0.99551803], bias:-1.0493140848162994, loss:0.5791762349616152\n",
      "epoch:1735, weight:[1.26980679 0.99567368], bias:-1.0495538086383926, loss:0.5791598496950466\n",
      "epoch:1736, weight:[1.27009337 0.99582928], bias:-1.0497934762077918, loss:0.579143468611839\n",
      "epoch:1737, weight:[1.27037995 0.99598483], bias:-1.0500330875817054, loss:0.5791270917093633\n",
      "epoch:1738, weight:[1.27066653 0.99614032], bias:-1.050272642817178, loss:0.5791107189849919\n",
      "epoch:1739, weight:[1.27095312 0.99629576], bias:-1.0505121419710912, loss:0.5790943504361009\n",
      "epoch:1740, weight:[1.27123971 0.99645115], bias:-1.0507515851001639, loss:0.5790779860600686\n",
      "epoch:1741, weight:[1.27152631 0.99660648], bias:-1.0509909722609532, loss:0.579061625854276\n",
      "epoch:1742, weight:[1.27181291 0.99676175], bias:-1.0512303035098547, loss:0.5790452698161068\n",
      "epoch:1743, weight:[1.27209951 0.99691698], bias:-1.0514695789031034, loss:0.5790289179429468\n",
      "epoch:1744, weight:[1.27238611 0.99707215], bias:-1.0517087984967746, loss:0.5790125702321847\n",
      "epoch:1745, weight:[1.27267272 0.99722726], bias:-1.0519479623467831, loss:0.5789962266812118\n",
      "epoch:1746, weight:[1.27295933 0.99738232], bias:-1.0521870705088858, loss:0.5789798872874214\n",
      "epoch:1747, weight:[1.27324595 0.99753733], bias:-1.0524261230386807, loss:0.5789635520482106\n",
      "epoch:1748, weight:[1.27353257 0.99769228], bias:-1.052665119991608, loss:0.5789472209609776\n",
      "epoch:1749, weight:[1.27381919 0.99784718], bias:-1.0529040614229508, loss:0.578930894023124\n",
      "epoch:1750, weight:[1.27410581 0.99800203], bias:-1.053142947387836, loss:0.5789145712320537\n",
      "epoch:1751, weight:[1.27439244 0.99815682], bias:-1.0533817779412342, loss:0.5788982525851734\n",
      "epoch:1752, weight:[1.27467907 0.99831156], bias:-1.0536205531379608, loss:0.5788819380798916\n",
      "epoch:1753, weight:[1.2749657  0.99846624], bias:-1.0538592730326761, loss:0.57886562771362\n",
      "epoch:1754, weight:[1.27525234 0.99862087], bias:-1.0540979376798865, loss:0.5788493214837727\n",
      "epoch:1755, weight:[1.27553898 0.99877545], bias:-1.0543365471339443, loss:0.5788330193877659\n",
      "epoch:1756, weight:[1.27582562 0.99892997], bias:-1.054575101449049, loss:0.5788167214230189\n",
      "epoch:1757, weight:[1.27611226 0.99908443], bias:-1.0548136006792475, loss:0.5788004275869529\n",
      "epoch:1758, weight:[1.27639891 0.99923885], bias:-1.0550520448784346, loss:0.5787841378769919\n",
      "epoch:1759, weight:[1.27668556 0.99939321], bias:-1.0552904341003542, loss:0.5787678522905623\n",
      "epoch:1760, weight:[1.27697221 0.99954751], bias:-1.0555287683985988, loss:0.5787515708250932\n",
      "epoch:1761, weight:[1.27725887 0.99970176], bias:-1.055767047826611, loss:0.5787352934780158\n",
      "epoch:1762, weight:[1.27754553 0.99985596], bias:-1.0560052724376836, loss:0.5787190202467641\n",
      "epoch:1763, weight:[1.27783219 1.0000101 ], bias:-1.05624344228496, loss:0.5787027511287742\n",
      "epoch:1764, weight:[1.27811886 1.00016419], bias:-1.0564815574214355, loss:0.578686486121485\n",
      "epoch:1765, weight:[1.27840553 1.00031823], bias:-1.056719617899957, loss:0.5786702252223376\n",
      "epoch:1766, weight:[1.2786922  1.00047221], bias:-1.0569576237732239, loss:0.5786539684287758\n",
      "epoch:1767, weight:[1.27897887 1.00062614], bias:-1.057195575093789, loss:0.5786377157382453\n",
      "epoch:1768, weight:[1.27926555 1.00078001], bias:-1.0574334719140581, loss:0.578621467148195\n",
      "epoch:1769, weight:[1.27955223 1.00093383], bias:-1.057671314286292, loss:0.5786052226560755\n",
      "epoch:1770, weight:[1.27983891 1.00108759], bias:-1.0579091022626053, loss:0.5785889822593404\n",
      "epoch:1771, weight:[1.28012559 1.00124131], bias:-1.0581468358949684, loss:0.5785727459554457\n",
      "epoch:1772, weight:[1.28041228 1.00139496], bias:-1.0583845152352074, loss:0.5785565137418491\n",
      "epoch:1773, weight:[1.28069897 1.00154857], bias:-1.0586221403350047, loss:0.5785402856160111\n",
      "epoch:1774, weight:[1.28098566 1.00170212], bias:-1.0588597112458993, loss:0.5785240615753953\n",
      "epoch:1775, weight:[1.28127236 1.00185561], bias:-1.0590972280192879, loss:0.5785078416174666\n",
      "epoch:1776, weight:[1.28155905 1.00200905], bias:-1.0593346907064247, loss:0.5784916257396929\n",
      "epoch:1777, weight:[1.28184575 1.00216244], bias:-1.059572099358423, loss:0.5784754139395444\n",
      "epoch:1778, weight:[1.28213246 1.00231577], bias:-1.0598094540262544, loss:0.5784592062144935\n",
      "epoch:1779, weight:[1.28241916 1.00246905], bias:-1.0600467547607504, loss:0.5784430025620152\n",
      "epoch:1780, weight:[1.28270587 1.00262227], bias:-1.0602840016126023, loss:0.5784268029795869\n",
      "epoch:1781, weight:[1.28299258 1.00277545], bias:-1.0605211946323618, loss:0.578410607464688\n",
      "epoch:1782, weight:[1.28327929 1.00292856], bias:-1.060758333870442, loss:0.5783944160148007\n",
      "epoch:1783, weight:[1.28356601 1.00308162], bias:-1.0609954193771174, loss:0.5783782286274092\n",
      "epoch:1784, weight:[1.28385273 1.00323463], bias:-1.0612324512025244, loss:0.5783620453000005\n",
      "epoch:1785, weight:[1.28413945 1.00338759], bias:-1.0614694293966622, loss:0.5783458660300633\n",
      "epoch:1786, weight:[1.28442617 1.00354049], bias:-1.0617063540093932, loss:0.5783296908150891\n",
      "epoch:1787, weight:[1.2847129  1.00369334], bias:-1.0619432250904428, loss:0.578313519652572\n",
      "epoch:1788, weight:[1.28499962 1.00384613], bias:-1.0621800426894012, loss:0.5782973525400078\n",
      "epoch:1789, weight:[1.28528635 1.00399887], bias:-1.0624168068557232, loss:0.5782811894748946\n",
      "epoch:1790, weight:[1.28557308 1.00415155], bias:-1.062653517638728, loss:0.5782650304547334\n",
      "epoch:1791, weight:[1.28585982 1.00430418], bias:-1.0628901750876012, loss:0.5782488754770275\n",
      "epoch:1792, weight:[1.28614656 1.00445676], bias:-1.063126779251394, loss:0.578232724539282\n",
      "epoch:1793, weight:[1.28643329 1.00460928], bias:-1.0633633301790246, loss:0.5782165776390044\n",
      "epoch:1794, weight:[1.28672004 1.00476175], bias:-1.063599827919278, loss:0.578200434773705\n",
      "epoch:1795, weight:[1.28700678 1.00491416], bias:-1.0638362725208068, loss:0.5781842959408958\n",
      "epoch:1796, weight:[1.28729353 1.00506652], bias:-1.0640726640321319, loss:0.5781681611380914\n",
      "epoch:1797, weight:[1.28758027 1.00521883], bias:-1.0643090025016424, loss:0.5781520303628086\n",
      "epoch:1798, weight:[1.28786702 1.00537108], bias:-1.064545287977597, loss:0.5781359036125671\n",
      "epoch:1799, weight:[1.28815378 1.00552328], bias:-1.0647815205081235, loss:0.5781197808848876\n",
      "epoch:1800, weight:[1.28844053 1.00567543], bias:-1.0650177001412198, loss:0.578103662177294\n",
      "epoch:1801, weight:[1.28872729 1.00582752], bias:-1.0652538269247545, loss:0.5780875474873125\n",
      "epoch:1802, weight:[1.28901405 1.00597955], bias:-1.0654899009064671, loss:0.5780714368124712\n",
      "epoch:1803, weight:[1.28930081 1.00613153], bias:-1.0657259221339686, loss:0.5780553301503004\n",
      "epoch:1804, weight:[1.28958757 1.00628346], bias:-1.0659618906547417, loss:0.5780392274983331\n",
      "epoch:1805, weight:[1.28987434 1.00643534], bias:-1.0661978065161417, loss:0.5780231288541046\n",
      "epoch:1806, weight:[1.2901611  1.00658716], bias:-1.0664336697653967, loss:0.5780070342151515\n",
      "epoch:1807, weight:[1.29044787 1.00673892], bias:-1.0666694804496084, loss:0.5779909435790138\n",
      "epoch:1808, weight:[1.29073464 1.00689064], bias:-1.066905238615752, loss:0.5779748569432331\n",
      "epoch:1809, weight:[1.29102142 1.00704229], bias:-1.0671409443106772, loss:0.5779587743053535\n",
      "epoch:1810, weight:[1.29130819 1.0071939 ], bias:-1.0673765975811085, loss:0.5779426956629211\n",
      "epoch:1811, weight:[1.29159497 1.00734545], bias:-1.0676121984736453, loss:0.5779266210134846\n",
      "epoch:1812, weight:[1.29188175 1.00749695], bias:-1.067847747034763, loss:0.5779105503545944\n",
      "epoch:1813, weight:[1.29216853 1.00764839], bias:-1.0680832433108127, loss:0.5778944836838035\n",
      "epoch:1814, weight:[1.29245531 1.00779978], bias:-1.0683186873480228, loss:0.5778784209986673\n",
      "epoch:1815, weight:[1.2927421  1.00795111], bias:-1.0685540791924981, loss:0.5778623622967428\n",
      "epoch:1816, weight:[1.29302889 1.00810239], bias:-1.0687894188902212, loss:0.5778463075755899\n",
      "epoch:1817, weight:[1.29331568 1.00825362], bias:-1.0690247064870526, loss:0.5778302568327697\n",
      "epoch:1818, weight:[1.29360247 1.00840479], bias:-1.0692599420287312, loss:0.577814210065847\n",
      "epoch:1819, weight:[1.29388926 1.00855591], bias:-1.069495125560875, loss:0.5777981672723874\n",
      "epoch:1820, weight:[1.29417605 1.00870697], bias:-1.0697302571289806, loss:0.5777821284499596\n",
      "epoch:1821, weight:[1.29446285 1.00885798], bias:-1.069965336778425, loss:0.5777660935961338\n",
      "epoch:1822, weight:[1.29474965 1.00900894], bias:-1.070200364554465, loss:0.5777500627084832\n",
      "epoch:1823, weight:[1.29503645 1.00915984], bias:-1.0704353405022387, loss:0.5777340357845822\n",
      "epoch:1824, weight:[1.29532325 1.00931069], bias:-1.0706702646667643, loss:0.5777180128220084\n",
      "epoch:1825, weight:[1.29561005 1.00946149], bias:-1.070905137092942, loss:0.5777019938183406\n",
      "epoch:1826, weight:[1.29589686 1.00961223], bias:-1.0711399578255543, loss:0.5776859787711605\n",
      "epoch:1827, weight:[1.29618367 1.00976291], bias:-1.0713747269092653, loss:0.5776699676780517\n",
      "epoch:1828, weight:[1.29647047 1.00991355], bias:-1.0716094443886224, loss:0.5776539605365999\n",
      "epoch:1829, weight:[1.29675728 1.01006413], bias:-1.0718441103080563, loss:0.577637957344393\n",
      "epoch:1830, weight:[1.2970441  1.01021465], bias:-1.072078724711881, loss:0.5776219580990212\n",
      "epoch:1831, weight:[1.29733091 1.01036512], bias:-1.072313287644295, loss:0.5776059627980765\n",
      "epoch:1832, weight:[1.29761773 1.01051554], bias:-1.0725477991493808, loss:0.5775899714391536\n",
      "epoch:1833, weight:[1.29790454 1.0106659 ], bias:-1.0727822592711065, loss:0.5775739840198487\n",
      "epoch:1834, weight:[1.29819136 1.01081621], bias:-1.073016668053325, loss:0.5775580005377606\n",
      "epoch:1835, weight:[1.29847818 1.01096647], bias:-1.0732510255397756, loss:0.5775420209904902\n",
      "epoch:1836, weight:[1.298765   1.01111667], bias:-1.0734853317740831, loss:0.5775260453756406\n",
      "epoch:1837, weight:[1.29905183 1.01126682], bias:-1.0737195867997595, loss:0.5775100736908164\n",
      "epoch:1838, weight:[1.29933865 1.01141691], bias:-1.0739537906602037, loss:0.577494105933625\n",
      "epoch:1839, weight:[1.29962548 1.01156695], bias:-1.0741879433987018, loss:0.5774781421016756\n",
      "epoch:1840, weight:[1.29991231 1.01171694], bias:-1.074422045058428, loss:0.5774621821925802\n",
      "epoch:1841, weight:[1.30019914 1.01186687], bias:-1.074656095682445, loss:0.5774462262039515\n",
      "epoch:1842, weight:[1.30048597 1.01201675], bias:-1.0748900953137035, loss:0.5774302741334056\n",
      "epoch:1843, weight:[1.3007728  1.01216657], bias:-1.075124043995044, loss:0.5774143259785605\n",
      "epoch:1844, weight:[1.30105963 1.01231634], bias:-1.0753579417691965, loss:0.5773983817370354\n",
      "epoch:1845, weight:[1.30134647 1.01246606], bias:-1.0755917886787805, loss:0.5773824414064528\n",
      "epoch:1846, weight:[1.30163331 1.01261572], bias:-1.0758255847663059, loss:0.5773665049844365\n",
      "epoch:1847, weight:[1.30192014 1.01276533], bias:-1.0760593300741734, loss:0.577350572468613\n",
      "epoch:1848, weight:[1.30220698 1.01291488], bias:-1.0762930246446751, loss:0.5773346438566102\n",
      "epoch:1849, weight:[1.30249382 1.01306439], bias:-1.0765266685199943, loss:0.5773187191460585\n",
      "epoch:1850, weight:[1.30278067 1.01321383], bias:-1.0767602617422065, loss:0.5773027983345904\n",
      "epoch:1851, weight:[1.30306751 1.01336323], bias:-1.0769938043532792, loss:0.5772868814198402\n",
      "epoch:1852, weight:[1.30335436 1.01351257], bias:-1.0772272963950726, loss:0.5772709683994448\n",
      "epoch:1853, weight:[1.3036412  1.01366185], bias:-1.0774607379093402, loss:0.5772550592710426\n",
      "epoch:1854, weight:[1.30392805 1.01381108], bias:-1.0776941289377289, loss:0.5772391540322744\n",
      "epoch:1855, weight:[1.3042149  1.01396026], bias:-1.0779274695217795, loss:0.577223252680783\n",
      "epoch:1856, weight:[1.30450175 1.01410939], bias:-1.0781607597029275, loss:0.577207355214213\n",
      "epoch:1857, weight:[1.3047886  1.01425846], bias:-1.078393999522502, loss:0.5771914616302118\n",
      "epoch:1858, weight:[1.30507545 1.01440747], bias:-1.0786271890217283, loss:0.5771755719264277\n",
      "epoch:1859, weight:[1.30536231 1.01455644], bias:-1.0788603282417264, loss:0.5771596861005123\n",
      "epoch:1860, weight:[1.30564916 1.01470535], bias:-1.0790934172235125, loss:0.5771438041501183\n",
      "epoch:1861, weight:[1.30593602 1.0148542 ], bias:-1.079326456007999, loss:0.5771279260729011\n",
      "epoch:1862, weight:[1.30622288 1.015003  ], bias:-1.0795594446359942, loss:0.5771120518665177\n",
      "epoch:1863, weight:[1.30650974 1.01515175], bias:-1.0797923831482044, loss:0.5770961815286273\n",
      "epoch:1864, weight:[1.3067966  1.01530045], bias:-1.0800252715852323, loss:0.5770803150568908\n",
      "epoch:1865, weight:[1.30708346 1.01544909], bias:-1.080258109987579, loss:0.5770644524489719\n",
      "epoch:1866, weight:[1.30737032 1.01559767], bias:-1.0804908983956432, loss:0.5770485937025357\n",
      "epoch:1867, weight:[1.30765718 1.01574621], bias:-1.0807236368497222, loss:0.5770327388152495\n",
      "epoch:1868, weight:[1.30794405 1.01589469], bias:-1.080956325390012, loss:0.5770168877847829\n",
      "epoch:1869, weight:[1.30823091 1.01604311], bias:-1.0811889640566084, loss:0.577001040608807\n",
      "epoch:1870, weight:[1.30851778 1.01619148], bias:-1.081421552889506, loss:0.576985197284995\n",
      "epoch:1871, weight:[1.30880465 1.0163398 ], bias:-1.0816540919285993, loss:0.5769693578110228\n",
      "epoch:1872, weight:[1.30909152 1.01648807], bias:-1.081886581213684, loss:0.5769535221845673\n",
      "epoch:1873, weight:[1.30937839 1.01663628], bias:-1.0821190207844553, loss:0.5769376904033081\n",
      "epoch:1874, weight:[1.30966526 1.01678443], bias:-1.0823514106805103, loss:0.5769218624649267\n",
      "epoch:1875, weight:[1.30995213 1.01693254], bias:-1.0825837509413472, loss:0.5769060383671065\n",
      "epoch:1876, weight:[1.310239   1.01708059], bias:-1.0828160416063655, loss:0.5768902181075328\n",
      "epoch:1877, weight:[1.31052588 1.01722858], bias:-1.0830482827148673, loss:0.5768744016838933\n",
      "epoch:1878, weight:[1.31081275 1.01737653], bias:-1.0832804743060571, loss:0.5768585890938769\n",
      "epoch:1879, weight:[1.31109963 1.01752441], bias:-1.0835126164190423, loss:0.5768427803351753\n",
      "epoch:1880, weight:[1.31138651 1.01767225], bias:-1.083744709092833, loss:0.576826975405482\n",
      "epoch:1881, weight:[1.31167338 1.01782003], bias:-1.083976752366343, loss:0.5768111743024922\n",
      "epoch:1882, weight:[1.31196026 1.01796776], bias:-1.0842087462783903, loss:0.5767953770239032\n",
      "epoch:1883, weight:[1.31224714 1.01811543], bias:-1.0844406908676967, loss:0.5767795835674142\n",
      "epoch:1884, weight:[1.31253402 1.01826305], bias:-1.0846725861728888, loss:0.5767637939307267\n",
      "epoch:1885, weight:[1.31282091 1.01841062], bias:-1.0849044322324977, loss:0.5767480081115441\n",
      "epoch:1886, weight:[1.31310779 1.01855813], bias:-1.0851362290849604, loss:0.5767322261075714\n",
      "epoch:1887, weight:[1.31339467 1.01870559], bias:-1.085367976768619, loss:0.5767164479165158\n",
      "epoch:1888, weight:[1.31368156 1.018853  ], bias:-1.0855996753217219, loss:0.5767006735360868\n",
      "epoch:1889, weight:[1.31396844 1.01900035], bias:-1.0858313247824234, loss:0.5766849029639951\n",
      "epoch:1890, weight:[1.31425533 1.01914765], bias:-1.0860629251887846, loss:0.5766691361979537\n",
      "epoch:1891, weight:[1.31454221 1.01929489], bias:-1.0862944765787736, loss:0.5766533732356781\n",
      "epoch:1892, weight:[1.3148291  1.01944209], bias:-1.086525978990266, loss:0.5766376140748849\n",
      "epoch:1893, weight:[1.31511599 1.01958922], bias:-1.0867574324610443, loss:0.5766218587132934\n",
      "epoch:1894, weight:[1.31540288 1.01973631], bias:-1.0869888370288, loss:0.5766061071486243\n",
      "epoch:1895, weight:[1.31568977 1.01988334], bias:-1.0872201927311318, loss:0.5765903593786003\n",
      "epoch:1896, weight:[1.31597666 1.02003032], bias:-1.0874514996055482, loss:0.5765746154009462\n",
      "epoch:1897, weight:[1.31626355 1.02017724], bias:-1.0876827576894657, loss:0.5765588752133891\n",
      "epoch:1898, weight:[1.31655044 1.02032411], bias:-1.0879139670202105, loss:0.5765431388136568\n",
      "epoch:1899, weight:[1.31683733 1.02047093], bias:-1.0881451276350185, loss:0.5765274061994806\n",
      "epoch:1900, weight:[1.31712423 1.02061769], bias:-1.0883762395710355, loss:0.5765116773685928\n",
      "epoch:1901, weight:[1.31741112 1.0207644 ], bias:-1.0886073028653174, loss:0.5764959523187277\n",
      "epoch:1902, weight:[1.31769801 1.02091106], bias:-1.0888383175548308, loss:0.5764802310476218\n",
      "epoch:1903, weight:[1.31798491 1.02105766], bias:-1.0890692836764535, loss:0.5764645135530134\n",
      "epoch:1904, weight:[1.3182718  1.02120421], bias:-1.0893002012669741, loss:0.5764487998326424\n",
      "epoch:1905, weight:[1.3185587  1.02135071], bias:-1.0895310703630932, loss:0.5764330898842513\n",
      "epoch:1906, weight:[1.3188456  1.02149715], bias:-1.0897618910014228, loss:0.5764173837055837\n",
      "epoch:1907, weight:[1.3191325  1.02164354], bias:-1.0899926632184878, loss:0.5764016812943858\n",
      "epoch:1908, weight:[1.31941939 1.02178988], bias:-1.090223387050725, loss:0.5763859826484055\n",
      "epoch:1909, weight:[1.31970629 1.02193616], bias:-1.0904540625344843, loss:0.5763702877653922\n",
      "epoch:1910, weight:[1.31999319 1.02208239], bias:-1.0906846897060285, loss:0.5763545966430976\n",
      "epoch:1911, weight:[1.32028009 1.02222856], bias:-1.0909152686015344, loss:0.5763389092792757\n",
      "epoch:1912, weight:[1.32056699 1.02237468], bias:-1.0911457992570923, loss:0.5763232256716814\n",
      "epoch:1913, weight:[1.32085389 1.02252075], bias:-1.0913762817087063, loss:0.5763075458180721\n",
      "epoch:1914, weight:[1.32114079 1.02266677], bias:-1.0916067159922953, loss:0.5762918697162073\n",
      "epoch:1915, weight:[1.3214277  1.02281273], bias:-1.091837102143693, loss:0.576276197363848\n",
      "epoch:1916, weight:[1.3217146  1.02295864], bias:-1.0920674401986479, loss:0.576260528758757\n",
      "epoch:1917, weight:[1.3220015  1.02310449], bias:-1.0922977301928236, loss:0.5762448638986993\n",
      "epoch:1918, weight:[1.32228841 1.0232503 ], bias:-1.0925279721618, loss:0.5762292027814416\n",
      "epoch:1919, weight:[1.32257531 1.02339605], bias:-1.0927581661410721, loss:0.5762135454047529\n",
      "epoch:1920, weight:[1.32286221 1.02354174], bias:-1.092988312166052, loss:0.5761978917664032\n",
      "epoch:1921, weight:[1.32314912 1.02368738], bias:-1.0932184102720677, loss:0.5761822418641651\n",
      "epoch:1922, weight:[1.32343602 1.02383297], bias:-1.0934484604943644, loss:0.5761665956958127\n",
      "epoch:1923, weight:[1.32372293 1.02397851], bias:-1.0936784628681042, loss:0.5761509532591224\n",
      "epoch:1924, weight:[1.32400983 1.02412399], bias:-1.0939084174283669, loss:0.5761353145518722\n",
      "epoch:1925, weight:[1.32429674 1.02426942], bias:-1.09413832421015, loss:0.5761196795718416\n",
      "epoch:1926, weight:[1.32458365 1.02441479], bias:-1.0943681832483685, loss:0.5761040483168126\n",
      "epoch:1927, weight:[1.32487055 1.02456011], bias:-1.0945979945778568, loss:0.5760884207845687\n",
      "epoch:1928, weight:[1.32515746 1.02470538], bias:-1.094827758233367, loss:0.5760727969728953\n",
      "epoch:1929, weight:[1.32544437 1.0248506 ], bias:-1.0950574742495705, loss:0.5760571768795796\n",
      "epoch:1930, weight:[1.32573128 1.02499576], bias:-1.0952871426610575, loss:0.5760415605024108\n",
      "epoch:1931, weight:[1.32601819 1.02514087], bias:-1.0955167635023386, loss:0.5760259478391802\n",
      "epoch:1932, weight:[1.32630509 1.02528593], bias:-1.0957463368078433, loss:0.5760103388876802\n",
      "epoch:1933, weight:[1.326592   1.02543093], bias:-1.0959758626119216, loss:0.5759947336457054\n",
      "epoch:1934, weight:[1.32687891 1.02557588], bias:-1.096205340948844, loss:0.5759791321110524\n",
      "epoch:1935, weight:[1.32716582 1.02572078], bias:-1.096434771852801, loss:0.5759635342815201\n",
      "epoch:1936, weight:[1.32745273 1.02586562], bias:-1.0966641553579046, loss:0.5759479401549079\n",
      "epoch:1937, weight:[1.32773964 1.02601041], bias:-1.0968934914981883, loss:0.5759323497290182\n",
      "epoch:1938, weight:[1.32802655 1.02615515], bias:-1.0971227803076062, loss:0.575916763001655\n",
      "epoch:1939, weight:[1.32831346 1.02629983], bias:-1.097352021820035, loss:0.5759011799706234\n",
      "epoch:1940, weight:[1.32860037 1.02644446], bias:-1.097581216069273, loss:0.5758856006337315\n",
      "epoch:1941, weight:[1.32888728 1.02658904], bias:-1.0978103630890412, loss:0.5758700249887885\n",
      "epoch:1942, weight:[1.32917419 1.02673356], bias:-1.0980394629129828, loss:0.5758544530336053\n",
      "epoch:1943, weight:[1.32946111 1.02687803], bias:-1.098268515574664, loss:0.5758388847659949\n",
      "epoch:1944, weight:[1.32974802 1.02702245], bias:-1.0984975211075747, loss:0.5758233201837724\n",
      "epoch:1945, weight:[1.33003493 1.02716682], bias:-1.0987264795451275, loss:0.5758077592847541\n",
      "epoch:1946, weight:[1.33032184 1.02731113], bias:-1.0989553909206593, loss:0.5757922020667586\n",
      "epoch:1947, weight:[1.33060875 1.02745539], bias:-1.0991842552674307, loss:0.5757766485276059\n",
      "epoch:1948, weight:[1.33089566 1.02759959], bias:-1.0994130726186266, loss:0.5757610986651183\n",
      "epoch:1949, weight:[1.33118257 1.02774375], bias:-1.0996418430073565, loss:0.5757455524771194\n",
      "epoch:1950, weight:[1.33146949 1.02788785], bias:-1.0998705664666546, loss:0.5757300099614351\n",
      "epoch:1951, weight:[1.3317564  1.02803189], bias:-1.1000992430294805, loss:0.5757144711158925\n",
      "epoch:1952, weight:[1.33204331 1.02817589], bias:-1.100327872728719, loss:0.5756989359383211\n",
      "epoch:1953, weight:[1.33233022 1.02831983], bias:-1.10055645559718, loss:0.5756834044265519\n",
      "epoch:1954, weight:[1.33261713 1.02846372], bias:-1.1007849916676002, loss:0.5756678765784177\n",
      "epoch:1955, weight:[1.33290405 1.02860755], bias:-1.1010134809726417, loss:0.575652352391753\n",
      "epoch:1956, weight:[1.33319096 1.02875133], bias:-1.1012419235448936, loss:0.5756368318643946\n",
      "epoch:1957, weight:[1.33347787 1.02889506], bias:-1.101470319416871, loss:0.5756213149941802\n",
      "epoch:1958, weight:[1.33376478 1.02903874], bias:-1.1016986686210164, loss:0.5756058017789499\n",
      "epoch:1959, weight:[1.3340517  1.02918236], bias:-1.1019269711896995, loss:0.5755902922165459\n",
      "epoch:1960, weight:[1.33433861 1.02932593], bias:-1.1021552271552173, loss:0.5755747863048112\n",
      "epoch:1961, weight:[1.33462552 1.02946945], bias:-1.1023834365497944, loss:0.5755592840415914\n",
      "epoch:1962, weight:[1.33491243 1.02961291], bias:-1.1026115994055838, loss:0.5755437854247335\n",
      "epoch:1963, weight:[1.33519934 1.02975632], bias:-1.1028397157546663, loss:0.5755282904520865\n",
      "epoch:1964, weight:[1.33548626 1.02989968], bias:-1.1030677856290514, loss:0.5755127991215011\n",
      "epoch:1965, weight:[1.33577317 1.03004299], bias:-1.103295809060677, loss:0.5754973114308294\n",
      "epoch:1966, weight:[1.33606008 1.03018624], bias:-1.1035237860814107, loss:0.5754818273779259\n",
      "epoch:1967, weight:[1.33634699 1.03032944], bias:-1.1037517167230486, loss:0.5754663469606464\n",
      "epoch:1968, weight:[1.3366339  1.03047259], bias:-1.1039796010173166, loss:0.5754508701768487\n",
      "epoch:1969, weight:[1.33692082 1.03061568], bias:-1.1042074389958705, loss:0.5754353970243922\n",
      "epoch:1970, weight:[1.33720773 1.03075872], bias:-1.1044352306902958, loss:0.5754199275011382\n",
      "epoch:1971, weight:[1.33749464 1.03090171], bias:-1.1046629761321087, loss:0.5754044616049495\n",
      "epoch:1972, weight:[1.33778155 1.03104465], bias:-1.1048906753527554, loss:0.575388999333691\n",
      "epoch:1973, weight:[1.33806846 1.03118753], bias:-1.105118328383613, loss:0.5753735406852294\n",
      "epoch:1974, weight:[1.33835537 1.03133036], bias:-1.1053459352559896, loss:0.5753580856574327\n",
      "epoch:1975, weight:[1.33864228 1.03147314], bias:-1.1055734960011245, loss:0.5753426342481709\n",
      "epoch:1976, weight:[1.33892919 1.03161586], bias:-1.1058010106501888, loss:0.5753271864553159\n",
      "epoch:1977, weight:[1.3392161  1.03175853], bias:-1.1060284792342847, loss:0.5753117422767411\n",
      "epoch:1978, weight:[1.33950301 1.03190115], bias:-1.1062559017844469, loss:0.5752963017103215\n",
      "epoch:1979, weight:[1.33978992 1.03204372], bias:-1.106483278331642, loss:0.5752808647539345\n",
      "epoch:1980, weight:[1.34007683 1.03218623], bias:-1.1067106089067693, loss:0.5752654314054585\n",
      "epoch:1981, weight:[1.34036374 1.03232869], bias:-1.1069378935406606, loss:0.5752500016627741\n",
      "epoch:1982, weight:[1.34065065 1.0324711 ], bias:-1.1071651322640805, loss:0.5752345755237633\n",
      "epoch:1983, weight:[1.34093756 1.03261346], bias:-1.1073923251077271, loss:0.5752191529863101\n",
      "epoch:1984, weight:[1.34122447 1.03275576], bias:-1.1076194721022317, loss:0.5752037340483004\n",
      "epoch:1985, weight:[1.34151138 1.03289801], bias:-1.107846573278159, loss:0.5751883187076212\n",
      "epoch:1986, weight:[1.34179828 1.03304021], bias:-1.108073628666008, loss:0.5751729069621616\n",
      "epoch:1987, weight:[1.34208519 1.03318235], bias:-1.1083006382962115, loss:0.5751574988098127\n",
      "epoch:1988, weight:[1.3423721  1.03332445], bias:-1.1085276021991368, loss:0.575142094248467\n",
      "epoch:1989, weight:[1.34265901 1.03346649], bias:-1.1087545204050857, loss:0.5751266932760186\n",
      "epoch:1990, weight:[1.34294591 1.03360847], bias:-1.1089813929442949, loss:0.5751112958903634\n",
      "epoch:1991, weight:[1.34323282 1.03375041], bias:-1.1092082198469357, loss:0.5750959020893991\n",
      "epoch:1992, weight:[1.34351972 1.03389229], bias:-1.1094350011431153, loss:0.5750805118710253\n",
      "epoch:1993, weight:[1.34380663 1.03403412], bias:-1.109661736862876, loss:0.5750651252331431\n",
      "epoch:1994, weight:[1.34409353 1.0341759 ], bias:-1.109888427036196, loss:0.5750497421736552\n",
      "epoch:1995, weight:[1.34438044 1.03431762], bias:-1.1101150716929888, loss:0.5750343626904663\n",
      "epoch:1996, weight:[1.34466734 1.03445929], bias:-1.110341670863105, loss:0.5750189867814822\n",
      "epoch:1997, weight:[1.34495425 1.03460091], bias:-1.1105682245763313, loss:0.5750036144446115\n",
      "epoch:1998, weight:[1.34524115 1.03474248], bias:-1.1107947328623906, loss:0.5749882456777634\n",
      "epoch:1999, weight:[1.34552806 1.03488399], bias:-1.111021195750943, loss:0.5749728804788495\n",
      "epoch:2000, weight:[1.34581496 1.03502546], bias:-1.1112476132715856, loss:0.5749575188457826\n",
      "epoch:2001, weight:[1.34610186 1.03516686], bias:-1.1114739854538527, loss:0.5749421607764774\n",
      "epoch:2002, weight:[1.34638876 1.03530822], bias:-1.1117003123272162, loss:0.5749268062688505\n",
      "epoch:2003, weight:[1.34667566 1.03544953], bias:-1.1119265939210856, loss:0.5749114553208201\n",
      "epoch:2004, weight:[1.34696256 1.03559078], bias:-1.1121528302648087, loss:0.5748961079303059\n",
      "epoch:2005, weight:[1.34724946 1.03573198], bias:-1.112379021387671, loss:0.5748807640952293\n",
      "epoch:2006, weight:[1.34753636 1.03587313], bias:-1.1126051673188966, loss:0.5748654238135136\n",
      "epoch:2007, weight:[1.34782326 1.03601422], bias:-1.112831268087648, loss:0.5748500870830836\n",
      "epoch:2008, weight:[1.34811016 1.03615526], bias:-1.113057323723027, loss:0.5748347539018659\n",
      "epoch:2009, weight:[1.34839706 1.03629625], bias:-1.113283334254074, loss:0.5748194242677891\n",
      "epoch:2010, weight:[1.34868396 1.03643719], bias:-1.1135092997097686, loss:0.5748040981787823\n",
      "epoch:2011, weight:[1.34897086 1.03657808], bias:-1.11373522011903, loss:0.5747887756327779\n",
      "epoch:2012, weight:[1.34925775 1.03671891], bias:-1.1139610955107173, loss:0.5747734566277086\n",
      "epoch:2013, weight:[1.34954465 1.03685969], bias:-1.114186925913629, loss:0.5747581411615095\n",
      "epoch:2014, weight:[1.34983155 1.03700042], bias:-1.1144127113565039, loss:0.5747428292321173\n",
      "epoch:2015, weight:[1.35011844 1.0371411 ], bias:-1.1146384518680212, loss:0.5747275208374704\n",
      "epoch:2016, weight:[1.35040534 1.03728172], bias:-1.1148641474768006, loss:0.5747122159755084\n",
      "epoch:2017, weight:[1.35069223 1.03742229], bias:-1.1150897982114025, loss:0.5746969146441729\n",
      "epoch:2018, weight:[1.35097912 1.03756281], bias:-1.115315404100328, loss:0.5746816168414077\n",
      "epoch:2019, weight:[1.35126602 1.03770328], bias:-1.1155409651720194, loss:0.5746663225651572\n",
      "epoch:2020, weight:[1.35155291 1.0378437 ], bias:-1.1157664814548607, loss:0.5746510318133683\n",
      "epoch:2021, weight:[1.3518398  1.03798406], bias:-1.1159919529771771, loss:0.5746357445839889\n",
      "epoch:2022, weight:[1.35212669 1.03812437], bias:-1.1162173797672357, loss:0.5746204608749693\n",
      "epoch:2023, weight:[1.35241358 1.03826463], bias:-1.116442761853245, loss:0.5746051806842609\n",
      "epoch:2024, weight:[1.35270047 1.03840484], bias:-1.1166680992633569, loss:0.5745899040098169\n",
      "epoch:2025, weight:[1.35298736 1.03854499], bias:-1.116893392025664, loss:0.574574630849592\n",
      "epoch:2026, weight:[1.35327425 1.03868509], bias:-1.117118640168203, loss:0.5745593612015432\n",
      "epoch:2027, weight:[1.35356113 1.03882514], bias:-1.1173438437189525, loss:0.5745440950636282\n",
      "epoch:2028, weight:[1.35384802 1.03896514], bias:-1.117569002705834, loss:0.574528832433807\n",
      "epoch:2029, weight:[1.35413491 1.03910509], bias:-1.1177941171567127, loss:0.5745135733100409\n",
      "epoch:2030, weight:[1.35442179 1.03924498], bias:-1.1180191870993967, loss:0.5744983176902934\n",
      "epoch:2031, weight:[1.35470868 1.03938482], bias:-1.1182442125616379, loss:0.5744830655725286\n",
      "epoch:2032, weight:[1.35499556 1.03952461], bias:-1.1184691935711317, loss:0.5744678169547134\n",
      "epoch:2033, weight:[1.35528244 1.03966435], bias:-1.1186941301555178, loss:0.5744525718348155\n",
      "epoch:2034, weight:[1.35556933 1.03980403], bias:-1.1189190223423797, loss:0.5744373302108049\n",
      "epoch:2035, weight:[1.35585621 1.03994367], bias:-1.1191438701592453, loss:0.5744220920806522\n",
      "epoch:2036, weight:[1.35614309 1.04008325], bias:-1.1193686736335873, loss:0.5744068574423311\n",
      "epoch:2037, weight:[1.35642997 1.04022278], bias:-1.1195934327928228, loss:0.5743916262938156\n",
      "epoch:2038, weight:[1.35671685 1.04036226], bias:-1.1198181476643139, loss:0.5743763986330821\n",
      "epoch:2039, weight:[1.35700373 1.04050168], bias:-1.1200428182753677, loss:0.5743611744581083\n",
      "epoch:2040, weight:[1.3572906  1.04064105], bias:-1.1202674446532368, loss:0.5743459537668735\n",
      "epoch:2041, weight:[1.35757748 1.04078038], bias:-1.1204920268251195, loss:0.5743307365573589\n",
      "epoch:2042, weight:[1.35786436 1.04091965], bias:-1.1207165648181592, loss:0.574315522827547\n",
      "epoch:2043, weight:[1.35815123 1.04105886], bias:-1.1209410586594455, loss:0.5743003125754225\n",
      "epoch:2044, weight:[1.35843811 1.04119803], bias:-1.121165508376014, loss:0.5742851057989706\n",
      "epoch:2045, weight:[1.35872498 1.04133714], bias:-1.1213899139948464, loss:0.5742699024961795\n",
      "epoch:2046, weight:[1.35901185 1.04147621], bias:-1.121614275542871, loss:0.5742547026650379\n",
      "epoch:2047, weight:[1.35929872 1.04161522], bias:-1.121838593046963, loss:0.5742395063035364\n",
      "epoch:2048, weight:[1.3595856  1.04175417], bias:-1.1220628665339436, loss:0.5742243134096676\n",
      "epoch:2049, weight:[1.35987247 1.04189308], bias:-1.1222870960305815, loss:0.5742091239814257\n",
      "epoch:2050, weight:[1.36015933 1.04203193], bias:-1.1225112815635927, loss:0.5741939380168056\n",
      "epoch:2051, weight:[1.3604462  1.04217074], bias:-1.1227354231596403, loss:0.574178755513805\n",
      "epoch:2052, weight:[1.36073307 1.04230949], bias:-1.122959520845335, loss:0.5741635764704225\n",
      "epoch:2053, weight:[1.36101994 1.04244819], bias:-1.123183574647235, loss:0.5741484008846582\n",
      "epoch:2054, weight:[1.3613068  1.04258684], bias:-1.1234075845918468, loss:0.5741332287545147\n",
      "epoch:2055, weight:[1.36159367 1.04272543], bias:-1.1236315507056245, loss:0.5741180600779949\n",
      "epoch:2056, weight:[1.36188053 1.04286398], bias:-1.123855473014971, loss:0.5741028948531044\n",
      "epoch:2057, weight:[1.36216739 1.04300247], bias:-1.124079351546237, loss:0.5740877330778497\n",
      "epoch:2058, weight:[1.36245425 1.04314091], bias:-1.1243031863257225, loss:0.5740725747502392\n",
      "epoch:2059, weight:[1.36274112 1.0432793 ], bias:-1.1245269773796756, loss:0.5740574198682828\n",
      "epoch:2060, weight:[1.36302797 1.04341763], bias:-1.1247507247342936, loss:0.5740422684299923\n",
      "epoch:2061, weight:[1.36331483 1.04355592], bias:-1.1249744284157233, loss:0.5740271204333802\n",
      "epoch:2062, weight:[1.36360169 1.04369415], bias:-1.1251980884500603, loss:0.574011975876462\n",
      "epoch:2063, weight:[1.36388855 1.04383234], bias:-1.1254217048633501, loss:0.5739968347572536\n",
      "epoch:2064, weight:[1.3641754  1.04397047], bias:-1.1256452776815875, loss:0.5739816970737729\n",
      "epoch:2065, weight:[1.36446226 1.04410855], bias:-1.1258688069307174, loss:0.5739665628240392\n",
      "epoch:2066, weight:[1.36474911 1.04424657], bias:-1.1260922926366346, loss:0.5739514320060736\n",
      "epoch:2067, weight:[1.36503596 1.04438455], bias:-1.126315734825184, loss:0.5739363046178991\n",
      "epoch:2068, weight:[1.36532282 1.04452247], bias:-1.126539133522161, loss:0.573921180657539\n",
      "epoch:2069, weight:[1.36560967 1.04466035], bias:-1.1267624887533114, loss:0.5739060601230201\n",
      "epoch:2070, weight:[1.36589652 1.04479817], bias:-1.1269858005443318, loss:0.573890943012369\n",
      "epoch:2071, weight:[1.36618337 1.04493594], bias:-1.1272090689208696, loss:0.5738758293236151\n",
      "epoch:2072, weight:[1.36647021 1.04507365], bias:-1.127432293908523, loss:0.5738607190547885\n",
      "epoch:2073, weight:[1.36675706 1.04521132], bias:-1.127655475532842, loss:0.5738456122039215\n",
      "epoch:2074, weight:[1.3670439  1.04534894], bias:-1.1278786138193275, loss:0.5738305087690475\n",
      "epoch:2075, weight:[1.36733075 1.0454865 ], bias:-1.128101708793432, loss:0.5738154087482017\n",
      "epoch:2076, weight:[1.36761759 1.04562401], bias:-1.1283247604805595, loss:0.5738003121394212\n",
      "epoch:2077, weight:[1.36790443 1.04576147], bias:-1.1285477689060663, loss:0.5737852189407437\n",
      "epoch:2078, weight:[1.36819127 1.04589888], bias:-1.1287707340952606, loss:0.5737701291502098\n",
      "epoch:2079, weight:[1.36847811 1.04603624], bias:-1.1289936560734024, loss:0.57375504276586\n",
      "epoch:2080, weight:[1.36876495 1.04617355], bias:-1.1292165348657046, loss:0.5737399597857382\n",
      "epoch:2081, weight:[1.36905179 1.0463108 ], bias:-1.1294393704973322, loss:0.5737248802078886\n",
      "epoch:2082, weight:[1.36933862 1.046448  ], bias:-1.1296621629934032, loss:0.5737098040303571\n",
      "epoch:2083, weight:[1.36962546 1.04658516], bias:-1.1298849123789882, loss:0.5736947312511913\n",
      "epoch:2084, weight:[1.36991229 1.04672226], bias:-1.130107618679111, loss:0.5736796618684409\n",
      "epoch:2085, weight:[1.37019913 1.04685931], bias:-1.1303302819187484, loss:0.5736645958801562\n",
      "epoch:2086, weight:[1.37048596 1.0469963 ], bias:-1.1305529021228307, loss:0.5736495332843895\n",
      "epoch:2087, weight:[1.37077279 1.04713325], bias:-1.1307754793162414, loss:0.573634474079195\n",
      "epoch:2088, weight:[1.37105962 1.04727015], bias:-1.130998013523818, loss:0.5736194182626276\n",
      "epoch:2089, weight:[1.37134644 1.04740699], bias:-1.1312205047703514, loss:0.5736043658327447\n",
      "epoch:2090, weight:[1.37163327 1.04754378], bias:-1.1314429530805867, loss:0.5735893167876043\n",
      "epoch:2091, weight:[1.3719201  1.04768053], bias:-1.1316653584792233, loss:0.5735742711252668\n",
      "epoch:2092, weight:[1.37220692 1.04781722], bias:-1.1318877209909144, loss:0.5735592288437936\n",
      "epoch:2093, weight:[1.37249374 1.04795386], bias:-1.132110040640268, loss:0.5735441899412478\n",
      "epoch:2094, weight:[1.37278057 1.04809044], bias:-1.1323323174518465, loss:0.5735291544156939\n",
      "epoch:2095, weight:[1.37306739 1.04822698], bias:-1.1325545514501671, loss:0.5735141222651983\n",
      "epoch:2096, weight:[1.3733542  1.04836347], bias:-1.1327767426597022, loss:0.5734990934878283\n",
      "epoch:2097, weight:[1.37364102 1.0484999 ], bias:-1.1329988911048785, loss:0.5734840680816536\n",
      "epoch:2098, weight:[1.37392784 1.04863629], bias:-1.1332209968100786, loss:0.5734690460447447\n",
      "epoch:2099, weight:[1.37421465 1.04877262], bias:-1.13344305979964, loss:0.5734540273751738\n",
      "epoch:2100, weight:[1.37450147 1.0489089 ], bias:-1.1336650800978563, loss:0.5734390120710148\n",
      "epoch:2101, weight:[1.37478828 1.04904513], bias:-1.1338870577289757, loss:0.573424000130343\n",
      "epoch:2102, weight:[1.37507509 1.04918131], bias:-1.1341089927172032, loss:0.5734089915512353\n",
      "epoch:2103, weight:[1.3753619  1.04931744], bias:-1.1343308850866993, loss:0.5733939863317701\n",
      "epoch:2104, weight:[1.37564871 1.04945351], bias:-1.1345527348615807, loss:0.5733789844700271\n",
      "epoch:2105, weight:[1.37593552 1.04958954], bias:-1.1347745420659203, loss:0.5733639859640879\n",
      "epoch:2106, weight:[1.37622232 1.04972551], bias:-1.1349963067237474, loss:0.5733489908120353\n",
      "epoch:2107, weight:[1.37650913 1.04986144], bias:-1.1352180288590479, loss:0.5733339990119538\n",
      "epoch:2108, weight:[1.37679593 1.04999731], bias:-1.1354397084957644, loss:0.5733190105619294\n",
      "epoch:2109, weight:[1.37708273 1.05013313], bias:-1.1356613456577962, loss:0.5733040254600495\n",
      "epoch:2110, weight:[1.37736953 1.0502689 ], bias:-1.1358829403689998, loss:0.5732890437044031\n",
      "epoch:2111, weight:[1.37765633 1.05040462], bias:-1.1361044926531887, loss:0.5732740652930809\n",
      "epoch:2112, weight:[1.37794313 1.05054029], bias:-1.1363260025341335, loss:0.5732590902241744\n",
      "epoch:2113, weight:[1.37822993 1.05067591], bias:-1.1365474700355627, loss:0.5732441184957776\n",
      "epoch:2114, weight:[1.37851672 1.05081148], bias:-1.1367688951811619, loss:0.5732291501059854\n",
      "epoch:2115, weight:[1.37880352 1.05094699], bias:-1.1369902779945744, loss:0.5732141850528941\n",
      "epoch:2116, weight:[1.37909031 1.05108246], bias:-1.1372116184994019, loss:0.5731992233346017\n",
      "epoch:2117, weight:[1.3793771  1.05121787], bias:-1.1374329167192034, loss:0.5731842649492083\n",
      "epoch:2118, weight:[1.37966389 1.05135324], bias:-1.1376541726774965, loss:0.5731693098948143\n",
      "epoch:2119, weight:[1.37995068 1.05148855], bias:-1.1378753863977566, loss:0.5731543581695224\n",
      "epoch:2120, weight:[1.38023746 1.05162381], bias:-1.1380965579034183, loss:0.5731394097714366\n",
      "epoch:2121, weight:[1.38052425 1.05175902], bias:-1.138317687217874, loss:0.5731244646986624\n",
      "epoch:2122, weight:[1.38081103 1.05189418], bias:-1.138538774364475, loss:0.5731095229493071\n",
      "epoch:2123, weight:[1.38109781 1.05202929], bias:-1.1387598193665318, loss:0.5730945845214787\n",
      "epoch:2124, weight:[1.38138459 1.05216435], bias:-1.1389808222473132, loss:0.5730796494132874\n",
      "epoch:2125, weight:[1.38167137 1.05229936], bias:-1.1392017830300478, loss:0.5730647176228445\n",
      "epoch:2126, weight:[1.38195815 1.05243432], bias:-1.1394227017379228, loss:0.5730497891482635\n",
      "epoch:2127, weight:[1.38224492 1.05256922], bias:-1.1396435783940853, loss:0.5730348639876586\n",
      "epoch:2128, weight:[1.3825317  1.05270408], bias:-1.1398644130216415, loss:0.5730199421391451\n",
      "epoch:2129, weight:[1.38281847 1.05283888], bias:-1.140085205643658, loss:0.5730050236008415\n",
      "epoch:2130, weight:[1.38310524 1.05297364], bias:-1.14030595628316, loss:0.5729901083708658\n",
      "epoch:2131, weight:[1.38339201 1.05310834], bias:-1.1405266649631336, loss:0.5729751964473387\n",
      "epoch:2132, weight:[1.38367878 1.053243  ], bias:-1.1407473317065246, loss:0.5729602878283823\n",
      "epoch:2133, weight:[1.38396555 1.0533776 ], bias:-1.1409679565362392, loss:0.5729453825121197\n",
      "epoch:2134, weight:[1.38425231 1.05351215], bias:-1.1411885394751433, loss:0.5729304804966756\n",
      "epoch:2135, weight:[1.38453908 1.05364665], bias:-1.141409080546064, loss:0.5729155817801765\n",
      "epoch:2136, weight:[1.38482584 1.0537811 ], bias:-1.1416295797717886, loss:0.5729006863607502\n",
      "epoch:2137, weight:[1.3851126 1.0539155], bias:-1.1418500371750653, loss:0.5728857942365256\n",
      "epoch:2138, weight:[1.38539936 1.05404985], bias:-1.142070452778603, loss:0.5728709054056338\n",
      "epoch:2139, weight:[1.38568612 1.05418415], bias:-1.1422908266050715, loss:0.5728560198662067\n",
      "epoch:2140, weight:[1.38597287 1.0543184 ], bias:-1.142511158677102, loss:0.572841137616378\n",
      "epoch:2141, weight:[1.38625963 1.0544526 ], bias:-1.1427314490172866, loss:0.5728262586542829\n",
      "epoch:2142, weight:[1.38654638 1.05458675], bias:-1.1429516976481793, loss:0.572811382978058\n",
      "epoch:2143, weight:[1.38683313 1.05472085], bias:-1.143171904592295, loss:0.5727965105858411\n",
      "epoch:2144, weight:[1.38711988 1.05485489], bias:-1.1433920698721105, loss:0.5727816414757719\n",
      "epoch:2145, weight:[1.38740663 1.05498889], bias:-1.1436121935100643, loss:0.5727667756459914\n",
      "epoch:2146, weight:[1.38769337 1.05512283], bias:-1.1438322755285568, loss:0.5727519130946419\n",
      "epoch:2147, weight:[1.38798012 1.05525673], bias:-1.1440523159499507, loss:0.5727370538198673\n",
      "epoch:2148, weight:[1.38826686 1.05539058], bias:-1.1442723147965703, loss:0.5727221978198128\n",
      "epoch:2149, weight:[1.3885536  1.05552437], bias:-1.1444922720907025, loss:0.5727073450926257\n",
      "epoch:2150, weight:[1.38884034 1.05565811], bias:-1.1447121878545963, loss:0.5726924956364535\n",
      "epoch:2151, weight:[1.38912708 1.05579181], bias:-1.1449320621104635, loss:0.5726776494494463\n",
      "epoch:2152, weight:[1.38941382 1.05592545], bias:-1.1451518948804786, loss:0.5726628065297555\n",
      "epoch:2153, weight:[1.38970055 1.05605905], bias:-1.1453716861867786, loss:0.5726479668755331\n",
      "epoch:2154, weight:[1.38998728 1.05619259], bias:-1.1455914360514636, loss:0.5726331304849336\n",
      "epoch:2155, weight:[1.39027401 1.05632608], bias:-1.1458111444965964, loss:0.5726182973561124\n",
      "epoch:2156, weight:[1.39056074 1.05645952], bias:-1.146030811544203, loss:0.5726034674872262\n",
      "epoch:2157, weight:[1.39084747 1.05659292], bias:-1.1462504372162732, loss:0.5725886408764338\n",
      "epoch:2158, weight:[1.3911342  1.05672626], bias:-1.1464700215347592, loss:0.5725738175218947\n",
      "epoch:2159, weight:[1.39142092 1.05685955], bias:-1.1466895645215776, loss:0.5725589974217703\n",
      "epoch:2160, weight:[1.39170764 1.05699279], bias:-1.146909066198608, loss:0.5725441805742233\n",
      "epoch:2161, weight:[1.39199436 1.05712598], bias:-1.1471285265876943, loss:0.5725293669774177\n",
      "epoch:2162, weight:[1.39228108 1.05725912], bias:-1.1473479457106435, loss:0.5725145566295192\n",
      "epoch:2163, weight:[1.3925678  1.05739222], bias:-1.1475673235892272, loss:0.5724997495286952\n",
      "epoch:2164, weight:[1.39285452 1.05752526], bias:-1.1477866602451807, loss:0.5724849456731134\n",
      "epoch:2165, weight:[1.39314123 1.05765825], bias:-1.1480059557002038, loss:0.5724701450609443\n",
      "epoch:2166, weight:[1.39342794 1.05779119], bias:-1.1482252099759604, loss:0.5724553476903588\n",
      "epoch:2167, weight:[1.39371465 1.05792408], bias:-1.1484444230940791, loss:0.5724405535595299\n",
      "epoch:2168, weight:[1.39400136 1.05805692], bias:-1.1486635950761528, loss:0.5724257626666317\n",
      "epoch:2169, weight:[1.39428807 1.05818971], bias:-1.1488827259437393, loss:0.57241097500984\n",
      "epoch:2170, weight:[1.39457477 1.05832245], bias:-1.149101815718361, loss:0.5723961905873315\n",
      "epoch:2171, weight:[1.39486147 1.05845514], bias:-1.1493208644215052, loss:0.5723814093972847\n",
      "epoch:2172, weight:[1.39514818 1.05858778], bias:-1.1495398720746242, loss:0.5723666314378801\n",
      "epoch:2173, weight:[1.39543488 1.05872037], bias:-1.1497588386991358, loss:0.5723518567072982\n",
      "epoch:2174, weight:[1.39572157 1.05885291], bias:-1.1499777643164226, loss:0.572337085203722\n",
      "epoch:2175, weight:[1.39600827 1.0589854 ], bias:-1.1501966489478328, loss:0.5723223169253356\n",
      "epoch:2176, weight:[1.39629496 1.05911784], bias:-1.1504154926146801, loss:0.572307551870325\n",
      "epoch:2177, weight:[1.39658165 1.05925023], bias:-1.1506342953382436, loss:0.5722927900368769\n",
      "epoch:2178, weight:[1.39686834 1.05938257], bias:-1.1508530571397682, loss:0.5722780314231793\n",
      "epoch:2179, weight:[1.39715503 1.05951486], bias:-1.1510717780404647, loss:0.5722632760274227\n",
      "epoch:2180, weight:[1.39744172 1.0596471 ], bias:-1.1512904580615098, loss:0.572248523847798\n",
      "epoch:2181, weight:[1.3977284  1.05977929], bias:-1.151509097224046, loss:0.5722337748824977\n",
      "epoch:2182, weight:[1.39801509 1.05991144], bias:-1.1517276955491824, loss:0.5722190291297161\n",
      "epoch:2183, weight:[1.39830177 1.06004353], bias:-1.1519462530579943, loss:0.5722042865876487\n",
      "epoch:2184, weight:[1.39858845 1.06017557], bias:-1.1521647697715227, loss:0.5721895472544921\n",
      "epoch:2185, weight:[1.39887512 1.06030756], bias:-1.1523832457107759, loss:0.5721748111284449\n",
      "epoch:2186, weight:[1.3991618 1.0604395], bias:-1.1526016808967283, loss:0.5721600782077064\n",
      "epoch:2187, weight:[1.39944847 1.06057139], bias:-1.1528200753503213, loss:0.5721453484904782\n",
      "epoch:2188, weight:[1.39973514 1.06070324], bias:-1.1530384290924627, loss:0.5721306219749622\n",
      "epoch:2189, weight:[1.40002181 1.06083503], bias:-1.1532567421440276, loss:0.5721158986593629\n",
      "epoch:2190, weight:[1.40030848 1.06096677], bias:-1.153475014525858, loss:0.5721011785418852\n",
      "epoch:2191, weight:[1.40059515 1.06109846], bias:-1.1536932462587632, loss:0.5720864616207358\n",
      "epoch:2192, weight:[1.40088181 1.06123011], bias:-1.1539114373635195, loss:0.572071747894123\n",
      "epoch:2193, weight:[1.40116847 1.0613617 ], bias:-1.1541295878608704, loss:0.5720570373602563\n",
      "epoch:2194, weight:[1.40145513 1.06149324], bias:-1.1543476977715272, loss:0.5720423300173463\n",
      "epoch:2195, weight:[1.40174179 1.06162474], bias:-1.1545657671161687, loss:0.5720276258636052\n",
      "epoch:2196, weight:[1.40202844 1.06175618], bias:-1.154783795915441, loss:0.5720129248972473\n",
      "epoch:2197, weight:[1.4023151  1.06188758], bias:-1.1550017841899582, loss:0.5719982271164871\n",
      "epoch:2198, weight:[1.40260175 1.06201892], bias:-1.1552197319603026, loss:0.5719835325195413\n",
      "epoch:2199, weight:[1.4028884  1.06215022], bias:-1.155437639247024, loss:0.5719688411046278\n",
      "epoch:2200, weight:[1.40317505 1.06228147], bias:-1.1556555060706404, loss:0.5719541528699655\n",
      "epoch:2201, weight:[1.40346169 1.06241266], bias:-1.1558733324516381, loss:0.5719394678137754\n",
      "epoch:2202, weight:[1.40374834 1.06254381], bias:-1.1560911184104716, loss:0.5719247859342793\n",
      "epoch:2203, weight:[1.40403498 1.06267491], bias:-1.1563088639675636, loss:0.5719101072297007\n",
      "epoch:2204, weight:[1.40432162 1.06280595], bias:-1.1565265691433058, loss:0.5718954316982642\n",
      "epoch:2205, weight:[1.40460826 1.06293695], bias:-1.1567442339580578, loss:0.5718807593381962\n",
      "epoch:2206, weight:[1.40489489 1.0630679 ], bias:-1.1569618584321484, loss:0.5718660901477239\n",
      "epoch:2207, weight:[1.40518153 1.0631988 ], bias:-1.157179442585875, loss:0.5718514241250765\n",
      "epoch:2208, weight:[1.40546816 1.06332965], bias:-1.157396986439504, loss:0.5718367612684842\n",
      "epoch:2209, weight:[1.40575479 1.06346045], bias:-1.1576144900132705, loss:0.5718221015761785\n",
      "epoch:2210, weight:[1.40604141 1.0635912 ], bias:-1.1578319533273793, loss:0.5718074450463928\n",
      "epoch:2211, weight:[1.40632804 1.06372191], bias:-1.1580493764020037, loss:0.5717927916773611\n",
      "epoch:2212, weight:[1.40661466 1.06385256], bias:-1.1582667592572866, loss:0.5717781414673194\n",
      "epoch:2213, weight:[1.40690129 1.06398316], bias:-1.1584841019133403, loss:0.5717634944145051\n",
      "epoch:2214, weight:[1.4071879  1.06411372], bias:-1.1587014043902466, loss:0.5717488505171562\n",
      "epoch:2215, weight:[1.40747452 1.06424422], bias:-1.1589186667080567, loss:0.571734209773513\n",
      "epoch:2216, weight:[1.40776114 1.06437468], bias:-1.1591358888867915, loss:0.5717195721818166\n",
      "epoch:2217, weight:[1.40804775 1.06450508], bias:-1.1593530709464421, loss:0.5717049377403097\n",
      "epoch:2218, weight:[1.40833436 1.06463544], bias:-1.159570212906969, loss:0.5716903064472363\n",
      "epoch:2219, weight:[1.40862097 1.06476575], bias:-1.1597873147883027, loss:0.5716756783008416\n",
      "epoch:2220, weight:[1.40890758 1.064896  ], bias:-1.160004376610344, loss:0.5716610532993728\n",
      "epoch:2221, weight:[1.40919418 1.06502621], bias:-1.160221398392964, loss:0.5716464314410772\n",
      "epoch:2222, weight:[1.40948078 1.06515637], bias:-1.1604383801560034, loss:0.571631812724205\n",
      "epoch:2223, weight:[1.40976738 1.06528648], bias:-1.160655321919274, loss:0.5716171971470065\n",
      "epoch:2224, weight:[1.41005398 1.06541654], bias:-1.1608722237025573, loss:0.5716025847077343\n",
      "epoch:2225, weight:[1.41034058 1.06554656], bias:-1.161089085525606, loss:0.5715879754046415\n",
      "epoch:2226, weight:[1.41062717 1.06567652], bias:-1.161305907408143, loss:0.5715733692359832\n",
      "epoch:2227, weight:[1.41091376 1.06580643], bias:-1.1615226893698625, loss:0.5715587662000156\n",
      "epoch:2228, weight:[1.41120035 1.0659363 ], bias:-1.1617394314304288, loss:0.5715441662949963\n",
      "epoch:2229, weight:[1.41148694 1.06606611], bias:-1.1619561336094775, loss:0.5715295695191841\n",
      "epoch:2230, weight:[1.41177353 1.06619588], bias:-1.162172795926615, loss:0.5715149758708394\n",
      "epoch:2231, weight:[1.41206011 1.0663256 ], bias:-1.1623894184014194, loss:0.5715003853482238\n",
      "epoch:2232, weight:[1.41234669 1.06645526], bias:-1.1626060010534391, loss:0.5714857979496002\n",
      "epoch:2233, weight:[1.41263327 1.06658488], bias:-1.1628225439021944, loss:0.5714712136732334\n",
      "epoch:2234, weight:[1.41291985 1.06671445], bias:-1.1630390469671767, loss:0.5714566325173882\n",
      "epoch:2235, weight:[1.41320642 1.06684398], bias:-1.163255510267849, loss:0.5714420544803325\n",
      "epoch:2236, weight:[1.41349299 1.06697345], bias:-1.1634719338236457, loss:0.5714274795603341\n",
      "epoch:2237, weight:[1.41377956 1.06710287], bias:-1.163688317653973, loss:0.571412907755663\n",
      "epoch:2238, weight:[1.41406613 1.06723225], bias:-1.1639046617782087, loss:0.5713983390645901\n",
      "epoch:2239, weight:[1.4143527  1.06736157], bias:-1.1641209662157026, loss:0.5713837734853878\n",
      "epoch:2240, weight:[1.41463926 1.06749085], bias:-1.1643372309857762, loss:0.5713692110163298\n",
      "epoch:2241, weight:[1.41492582 1.06762007], bias:-1.1645534561077233, loss:0.5713546516556911\n",
      "epoch:2242, weight:[1.41521238 1.06774925], bias:-1.1647696416008095, loss:0.5713400954017485\n",
      "epoch:2243, weight:[1.41549894 1.06787838], bias:-1.1649857874842726, loss:0.571325542252779\n",
      "epoch:2244, weight:[1.41578549 1.06800746], bias:-1.1652018937773228, loss:0.5713109922070626\n",
      "epoch:2245, weight:[1.41607204 1.0681365 ], bias:-1.1654179604991424, loss:0.5712964452628788\n",
      "epoch:2246, weight:[1.41635859 1.06826548], bias:-1.1656339876688866, loss:0.57128190141851\n",
      "epoch:2247, weight:[1.41664514 1.06839441], bias:-1.1658499753056826, loss:0.5712673606722387\n",
      "epoch:2248, weight:[1.41693168 1.0685233 ], bias:-1.1660659234286306, loss:0.5712528230223498\n",
      "epoch:2249, weight:[1.41721823 1.06865214], bias:-1.1662818320568034, loss:0.5712382884671287\n",
      "epoch:2250, weight:[1.41750477 1.06878092], bias:-1.1664977012092463, loss:0.5712237570048625\n",
      "epoch:2251, weight:[1.41779131 1.06890966], bias:-1.1667135309049779, loss:0.5712092286338396\n",
      "epoch:2252, weight:[1.41807784 1.06903835], bias:-1.1669293211629894, loss:0.5711947033523497\n",
      "epoch:2253, weight:[1.41836438 1.069167  ], bias:-1.1671450720022454, loss:0.5711801811586837\n",
      "epoch:2254, weight:[1.41865091 1.06929559], bias:-1.1673607834416833, loss:0.5711656620511344\n",
      "epoch:2255, weight:[1.41893744 1.06942413], bias:-1.1675764555002137, loss:0.5711511460279947\n",
      "epoch:2256, weight:[1.41922396 1.06955263], bias:-1.1677920881967208, loss:0.57113663308756\n",
      "epoch:2257, weight:[1.41951049 1.06968108], bias:-1.168007681550062, loss:0.5711221232281267\n",
      "epoch:2258, weight:[1.41979701 1.06980948], bias:-1.1682232355790678, loss:0.5711076164479922\n",
      "epoch:2259, weight:[1.42008353 1.06993783], bias:-1.168438750302543, loss:0.5710931127454558\n",
      "epoch:2260, weight:[1.42037005 1.07006613], bias:-1.1686542257392654, loss:0.571078612118817\n",
      "epoch:2261, weight:[1.42065656 1.07019438], bias:-1.1688696619079866, loss:0.5710641145663781\n",
      "epoch:2262, weight:[1.42094308 1.07032258], bias:-1.1690850588274322, loss:0.5710496200864416\n",
      "epoch:2263, weight:[1.42122959 1.07045074], bias:-1.1693004165163017, loss:0.5710351286773118\n",
      "epoch:2264, weight:[1.4215161  1.07057885], bias:-1.169515734993268, loss:0.571020640337294\n",
      "epoch:2265, weight:[1.4218026  1.07070691], bias:-1.169731014276979, loss:0.5710061550646953\n",
      "epoch:2266, weight:[1.4220891  1.07083492], bias:-1.1699462543860557, loss:0.5709916728578237\n",
      "epoch:2267, weight:[1.42237561 1.07096288], bias:-1.170161455339094, loss:0.5709771937149883\n",
      "epoch:2268, weight:[1.4226621  1.07109079], bias:-1.1703766171546637, loss:0.5709627176345003\n",
      "epoch:2269, weight:[1.4229486  1.07121866], bias:-1.1705917398513088, loss:0.5709482446146716\n",
      "epoch:2270, weight:[1.42323509 1.07134647], bias:-1.1708068234475484, loss:0.5709337746538156\n",
      "epoch:2271, weight:[1.42352159 1.07147424], bias:-1.1710218679618754, loss:0.5709193077502464\n",
      "epoch:2272, weight:[1.42380807 1.07160196], bias:-1.1712368734127576, loss:0.5709048439022802\n",
      "epoch:2273, weight:[1.42409456 1.07172963], bias:-1.1714518398186375, loss:0.5708903831082348\n",
      "epoch:2274, weight:[1.42438104 1.07185725], bias:-1.1716667671979324, loss:0.570875925366428\n",
      "epoch:2275, weight:[1.42466753 1.07198483], bias:-1.1718816555690343, loss:0.57086147067518\n",
      "epoch:2276, weight:[1.42495401 1.07211235], bias:-1.17209650495031, loss:0.5708470190328117\n",
      "epoch:2277, weight:[1.42524048 1.07223983], bias:-1.1723113153601015, loss:0.5708325704376458\n",
      "epoch:2278, weight:[1.42552696 1.07236726], bias:-1.1725260868167255, loss:0.5708181248880058\n",
      "epoch:2279, weight:[1.42581343 1.07249464], bias:-1.1727408193384745, loss:0.5708036823822163\n",
      "epoch:2280, weight:[1.4260999  1.07262198], bias:-1.1729555129436156, loss:0.5707892429186047\n",
      "epoch:2281, weight:[1.42638637 1.07274926], bias:-1.1731701676503912, loss:0.5707748064954977\n",
      "epoch:2282, weight:[1.42667283 1.0728765 ], bias:-1.1733847834770195, loss:0.5707603731112244\n",
      "epoch:2283, weight:[1.42695929 1.07300369], bias:-1.1735993604416937, loss:0.570745942764115\n",
      "epoch:2284, weight:[1.42724575 1.07313083], bias:-1.1738138985625826, loss:0.5707315154525009\n",
      "epoch:2285, weight:[1.42753221 1.07325792], bias:-1.1740283978578308, loss:0.5707170911747148\n",
      "epoch:2286, weight:[1.42781866 1.07338496], bias:-1.1742428583455584, loss:0.570702669929091\n",
      "epoch:2287, weight:[1.42810512 1.07351196], bias:-1.1744572800438615, loss:0.5706882517139644\n",
      "epoch:2288, weight:[1.42839157 1.0736389 ], bias:-1.1746716629708114, loss:0.5706738365276721\n",
      "epoch:2289, weight:[1.42867801 1.0737658 ], bias:-1.1748860071444558, loss:0.5706594243685514\n",
      "epoch:2290, weight:[1.42896446 1.07389265], bias:-1.1751003125828183, loss:0.5706450152349416\n",
      "epoch:2291, weight:[1.4292509  1.07401946], bias:-1.1753145793038984, loss:0.5706306091251836\n",
      "epoch:2292, weight:[1.42953734 1.07414621], bias:-1.1755288073256718, loss:0.5706162060376186\n",
      "epoch:2293, weight:[1.42982378 1.07427292], bias:-1.1757429966660902, loss:0.5706018059705898\n",
      "epoch:2294, weight:[1.43011021 1.07439958], bias:-1.1759571473430819, loss:0.5705874089224413\n",
      "epoch:2295, weight:[1.43039664 1.07452619], bias:-1.176171259374551, loss:0.570573014891519\n",
      "epoch:2296, weight:[1.43068307 1.07465275], bias:-1.1763853327783786, loss:0.5705586238761692\n",
      "epoch:2297, weight:[1.4309695  1.07477927], bias:-1.1765993675724218, loss:0.5705442358747403\n",
      "epoch:2298, weight:[1.43125593 1.07490574], bias:-1.1768133637745144, loss:0.5705298508855818\n",
      "epoch:2299, weight:[1.43154235 1.07503215], bias:-1.177027321402467, loss:0.5705154689070441\n",
      "epoch:2300, weight:[1.43182877 1.07515853], bias:-1.1772412404740664, loss:0.5705010899374791\n",
      "epoch:2301, weight:[1.43211518 1.07528485], bias:-1.1774551210070767, loss:0.5704867139752398\n",
      "epoch:2302, weight:[1.4324016  1.07541112], bias:-1.1776689630192385, loss:0.5704723410186813\n",
      "epoch:2303, weight:[1.43268801 1.07553735], bias:-1.1778827665282692, loss:0.5704579710661583\n",
      "epoch:2304, weight:[1.43297442 1.07566353], bias:-1.1780965315518634, loss:0.5704436041160286\n",
      "epoch:2305, weight:[1.43326083 1.07578966], bias:-1.1783102581076927, loss:0.5704292401666501\n",
      "epoch:2306, weight:[1.43354723 1.07591575], bias:-1.1785239462134058, loss:0.5704148792163821\n",
      "epoch:2307, weight:[1.43383363 1.07604178], bias:-1.1787375958866284, loss:0.5704005212635858\n",
      "epoch:2308, weight:[1.43412003 1.07616777], bias:-1.1789512071449637, loss:0.5703861663066229\n",
      "epoch:2309, weight:[1.43440643 1.07629371], bias:-1.179164780005992, loss:0.5703718143438566\n",
      "epoch:2310, weight:[1.43469282 1.07641961], bias:-1.1793783144872707, loss:0.5703574653736517\n",
      "epoch:2311, weight:[1.43497921 1.07654545], bias:-1.1795918106063354, loss:0.570343119394374\n",
      "epoch:2312, weight:[1.4352656  1.07667125], bias:-1.1798052683806988, loss:0.5703287764043904\n",
      "epoch:2313, weight:[1.43555198 1.076797  ], bias:-1.180018687827851, loss:0.570314436402069\n",
      "epoch:2314, weight:[1.43583837 1.0769227 ], bias:-1.18023206896526, loss:0.5703000993857796\n",
      "epoch:2315, weight:[1.43612475 1.07704835], bias:-1.1804454118103713, loss:0.5702857653538929\n",
      "epoch:2316, weight:[1.43641113 1.07717396], bias:-1.1806587163806086, loss:0.5702714343047813\n",
      "epoch:2317, weight:[1.4366975  1.07729952], bias:-1.1808719826933731, loss:0.5702571062368176\n",
      "epoch:2318, weight:[1.43698387 1.07742503], bias:-1.181085210766044, loss:0.5702427811483767\n",
      "epoch:2319, weight:[1.43727024 1.07755049], bias:-1.1812984006159781, loss:0.5702284590378341\n",
      "epoch:2320, weight:[1.43755661 1.07767591], bias:-1.1815115522605109, loss:0.5702141399035672\n",
      "epoch:2321, weight:[1.43784298 1.07780128], bias:-1.1817246657169556, loss:0.5701998237439543\n",
      "epoch:2322, weight:[1.43812934 1.0779266 ], bias:-1.1819377410026037, loss:0.5701855105573744\n",
      "epoch:2323, weight:[1.4384157  1.07805187], bias:-1.1821507781347251, loss:0.5701712003422089\n",
      "epoch:2324, weight:[1.43870205 1.0781771 ], bias:-1.1823637771305677, loss:0.5701568930968395\n",
      "epoch:2325, weight:[1.43898841 1.07830228], bias:-1.182576738007358, loss:0.5701425888196497\n",
      "epoch:2326, weight:[1.43927476 1.07842741], bias:-1.1827896607823007, loss:0.5701282875090239\n",
      "epoch:2327, weight:[1.43956111 1.07855249], bias:-1.1830025454725792, loss:0.5701139891633479\n",
      "epoch:2328, weight:[1.43984745 1.07867753], bias:-1.1832153920953554, loss:0.5700996937810084\n",
      "epoch:2329, weight:[1.4401338  1.07880252], bias:-1.1834282006677699, loss:0.5700854013603941\n",
      "epoch:2330, weight:[1.44042014 1.07892746], bias:-1.183640971206942, loss:0.5700711118998941\n",
      "epoch:2331, weight:[1.44070647 1.07905235], bias:-1.1838537037299695, loss:0.5700568253978994\n",
      "epoch:2332, weight:[1.44099281 1.0791772 ], bias:-1.1840663982539292, loss:0.5700425418528017\n",
      "epoch:2333, weight:[1.44127914 1.079302  ], bias:-1.184279054795877, loss:0.5700282612629942\n",
      "epoch:2334, weight:[1.44156547 1.07942675], bias:-1.1844916733728472, loss:0.5700139836268714\n",
      "epoch:2335, weight:[1.4418518  1.07955145], bias:-1.1847042540018538, loss:0.5699997089428289\n",
      "epoch:2336, weight:[1.44213812 1.07967611], bias:-1.1849167966998893, loss:0.5699854372092635\n",
      "epoch:2337, weight:[1.44242444 1.07980072], bias:-1.1851293014839253, loss:0.5699711684245736\n",
      "epoch:2338, weight:[1.44271076 1.07992528], bias:-1.185341768370913, loss:0.5699569025871581\n",
      "epoch:2339, weight:[1.44299708 1.0800498 ], bias:-1.185554197377783, loss:0.5699426396954179\n",
      "epoch:2340, weight:[1.44328339 1.08017426], bias:-1.1857665885214443, loss:0.5699283797477543\n",
      "epoch:2341, weight:[1.4435697  1.08029868], bias:-1.1859789418187863, loss:0.5699141227425709\n",
      "epoch:2342, weight:[1.44385601 1.08042306], bias:-1.186191257286677, loss:0.5698998686782715\n",
      "epoch:2343, weight:[1.44414231 1.08054738], bias:-1.1864035349419646, loss:0.5698856175532617\n",
      "epoch:2344, weight:[1.44442862 1.08067166], bias:-1.1866157748014763, loss:0.5698713693659483\n",
      "epoch:2345, weight:[1.44471491 1.08079589], bias:-1.1868279768820194, loss:0.5698571241147389\n",
      "epoch:2346, weight:[1.44500121 1.08092008], bias:-1.1870401412003804, loss:0.5698428817980425\n",
      "epoch:2347, weight:[1.4452875  1.08104422], bias:-1.1872522677733257, loss:0.5698286424142702\n",
      "epoch:2348, weight:[1.4455738  1.08116831], bias:-1.1874643566176017, loss:0.5698144059618329\n",
      "epoch:2349, weight:[1.44586008 1.08129235], bias:-1.1876764077499344, loss:0.5698001724391433\n",
      "epoch:2350, weight:[1.44614637 1.08141635], bias:-1.18788842118703, loss:0.569785941844616\n",
      "epoch:2351, weight:[1.44643265 1.0815403 ], bias:-1.1881003969455743, loss:0.5697717141766653\n",
      "epoch:2352, weight:[1.44671893 1.0816642 ], bias:-1.1883123350422335, loss:0.5697574894337083\n",
      "epoch:2353, weight:[1.44700521 1.08178805], bias:-1.1885242354936536, loss:0.5697432676141623\n",
      "epoch:2354, weight:[1.44729148 1.08191186], bias:-1.1887360983164608, loss:0.5697290487164464\n",
      "epoch:2355, weight:[1.44757775 1.08203562], bias:-1.1889479235272615, loss:0.5697148327389803\n",
      "epoch:2356, weight:[1.44786402 1.08215933], bias:-1.1891597111426424, loss:0.5697006196801856\n",
      "epoch:2357, weight:[1.44815029 1.082283  ], bias:-1.1893714611791706, loss:0.5696864095384844\n",
      "epoch:2358, weight:[1.44843655 1.08240662], bias:-1.1895831736533935, loss:0.5696722023123008\n",
      "epoch:2359, weight:[1.44872281 1.0825302 ], bias:-1.189794848581839, loss:0.5696579980000591\n",
      "epoch:2360, weight:[1.44900907 1.08265372], bias:-1.1900064859810153, loss:0.5696437966001859\n",
      "epoch:2361, weight:[1.44929532 1.0827772 ], bias:-1.1902180858674114, loss:0.5696295981111082\n",
      "epoch:2362, weight:[1.44958157 1.08290063], bias:-1.1904296482574965, loss:0.5696154025312546\n",
      "epoch:2363, weight:[1.44986782 1.08302402], bias:-1.1906411731677211, loss:0.5696012098590549\n",
      "epoch:2364, weight:[1.45015407 1.08314736], bias:-1.1908526606145158, loss:0.5695870200929397\n",
      "epoch:2365, weight:[1.45044031 1.08327065], bias:-1.191064110614292, loss:0.569572833231341\n",
      "epoch:2366, weight:[1.45072655 1.08339389], bias:-1.1912755231834427, loss:0.5695586492726927\n",
      "epoch:2367, weight:[1.45101278 1.08351709], bias:-1.1914868983383406, loss:0.5695444682154288\n",
      "epoch:2368, weight:[1.45129902 1.08364024], bias:-1.1916982360953405, loss:0.5695302900579851\n",
      "epoch:2369, weight:[1.45158525 1.08376335], bias:-1.1919095364707772, loss:0.5695161147987984\n",
      "epoch:2370, weight:[1.45187148 1.08388641], bias:-1.1921207994809673, loss:0.5695019424363067\n",
      "epoch:2371, weight:[1.4521577  1.08400942], bias:-1.1923320251422078, loss:0.5694877729689496\n",
      "epoch:2372, weight:[1.45244393 1.08413238], bias:-1.1925432134707776, loss:0.5694736063951673\n",
      "epoch:2373, weight:[1.45273015 1.0842553 ], bias:-1.1927543644829364, loss:0.5694594427134017\n",
      "epoch:2374, weight:[1.45301636 1.08437817], bias:-1.1929654781949248, loss:0.5694452819220953\n",
      "epoch:2375, weight:[1.45330258 1.084501  ], bias:-1.1931765546229656, loss:0.5694311240196922\n",
      "epoch:2376, weight:[1.45358879 1.08462377], bias:-1.193387593783262, loss:0.5694169690046377\n",
      "epoch:2377, weight:[1.45387499 1.0847465 ], bias:-1.1935985956919997, loss:0.5694028168753783\n",
      "epoch:2378, weight:[1.4541612  1.08486919], bias:-1.193809560365345, loss:0.5693886676303616\n",
      "epoch:2379, weight:[1.4544474  1.08499183], bias:-1.1940204878194458, loss:0.569374521268036\n",
      "epoch:2380, weight:[1.4547336  1.08511442], bias:-1.1942313780704321, loss:0.569360377786852\n",
      "epoch:2381, weight:[1.4550198  1.08523696], bias:-1.194442231134415, loss:0.5693462371852603\n",
      "epoch:2382, weight:[1.45530599 1.08535946], bias:-1.1946530470274874, loss:0.5693320994617136\n",
      "epoch:2383, weight:[1.45559218 1.08548191], bias:-1.1948638257657245, loss:0.5693179646146651\n",
      "epoch:2384, weight:[1.45587837 1.08560432], bias:-1.1950745673651824, loss:0.5693038326425699\n",
      "epoch:2385, weight:[1.45616455 1.08572668], bias:-1.1952852718418996, loss:0.5692897035438833\n",
      "epoch:2386, weight:[1.45645073 1.08584899], bias:-1.1954959392118965, loss:0.5692755773170629\n",
      "epoch:2387, weight:[1.45673691 1.08597126], bias:-1.195706569491175, loss:0.5692614539605668\n",
      "epoch:2388, weight:[1.45702309 1.08609347], bias:-1.1959171626957197, loss:0.5692473334728541\n",
      "epoch:2389, weight:[1.45730926 1.08621565], bias:-1.1961277188414967, loss:0.5692332158523855\n",
      "epoch:2390, weight:[1.45759543 1.08633777], bias:-1.1963382379444543, loss:0.569219101097623\n",
      "epoch:2391, weight:[1.45788159 1.08645985], bias:-1.196548720020523, loss:0.5692049892070292\n",
      "epoch:2392, weight:[1.45816776 1.08658189], bias:-1.1967591650856153, loss:0.5691908801790685\n",
      "epoch:2393, weight:[1.45845392 1.08670388], bias:-1.1969695731556265, loss:0.5691767740122061\n",
      "epoch:2394, weight:[1.45874007 1.08682582], bias:-1.1971799442464335, loss:0.5691626707049081\n",
      "epoch:2395, weight:[1.45902623 1.08694771], bias:-1.197390278373896, loss:0.5691485702556427\n",
      "epoch:2396, weight:[1.45931238 1.08706956], bias:-1.1976005755538561, loss:0.5691344726628784\n",
      "epoch:2397, weight:[1.45959853 1.08719136], bias:-1.197810835802138, loss:0.569120377925085\n",
      "epoch:2398, weight:[1.45988467 1.08731312], bias:-1.1980210591345488, loss:0.5691062860407338\n",
      "epoch:2399, weight:[1.46017082 1.08743483], bias:-1.198231245566878, loss:0.5690921970082969\n",
      "epoch:2400, weight:[1.46045696 1.08755649], bias:-1.1984413951148976, loss:0.5690781108262483\n",
      "epoch:2401, weight:[1.46074309 1.08767811], bias:-1.198651507794362, loss:0.5690640274930618\n",
      "epoch:2402, weight:[1.46102922 1.08779968], bias:-1.198861583621009, loss:0.5690499470072138\n",
      "epoch:2403, weight:[1.46131535 1.0879212 ], bias:-1.1990716226105587, loss:0.5690358693671809\n",
      "epoch:2404, weight:[1.46160148 1.08804268], bias:-1.1992816247787137, loss:0.5690217945714413\n",
      "epoch:2405, weight:[1.46188761 1.08816411], bias:-1.19949159014116, loss:0.5690077226184744\n",
      "epoch:2406, weight:[1.46217373 1.0882855 ], bias:-1.1997015187135662, loss:0.5689936535067606\n",
      "epoch:2407, weight:[1.46245984 1.08840684], bias:-1.199911410511584, loss:0.5689795872347809\n",
      "epoch:2408, weight:[1.46274596 1.08852813], bias:-1.2001212655508477, loss:0.5689655238010187\n",
      "epoch:2409, weight:[1.46303207 1.08864938], bias:-1.2003310838469752, loss:0.5689514632039577\n",
      "epoch:2410, weight:[1.46331818 1.08877058], bias:-1.2005408654155667, loss:0.568937405442083\n",
      "epoch:2411, weight:[1.46360429 1.08889174], bias:-1.2007506102722063, loss:0.5689233505138805\n",
      "epoch:2412, weight:[1.46389039 1.08901285], bias:-1.2009603184324609, loss:0.5689092984178381\n",
      "epoch:2413, weight:[1.46417649 1.08913391], bias:-1.2011699899118806, loss:0.5688952491524437\n",
      "epoch:2414, weight:[1.46446258 1.08925493], bias:-1.201379624725999, loss:0.568881202716187\n",
      "epoch:2415, weight:[1.46474868 1.0893759 ], bias:-1.2015892228903324, loss:0.5688671591075593\n",
      "epoch:2416, weight:[1.46503477 1.08949683], bias:-1.2017987844203812, loss:0.5688531183250523\n",
      "epoch:2417, weight:[1.46532085 1.08961771], bias:-1.2020083093316287, loss:0.5688390803671589\n",
      "epoch:2418, weight:[1.46560694 1.08973854], bias:-1.2022177976395418, loss:0.5688250452323735\n",
      "epoch:2419, weight:[1.46589302 1.08985933], bias:-1.2024272493595711, loss:0.5688110129191914\n",
      "epoch:2420, weight:[1.4661791  1.08998007], bias:-1.2026366645071505, loss:0.5687969834261092\n",
      "epoch:2421, weight:[1.46646517 1.09010077], bias:-1.2028460430976973, loss:0.5687829567516247\n",
      "epoch:2422, weight:[1.46675124 1.09022142], bias:-1.2030553851466128, loss:0.5687689328942367\n",
      "epoch:2423, weight:[1.46703731 1.09034202], bias:-1.2032646906692817, loss:0.5687549118524449\n",
      "epoch:2424, weight:[1.46732338 1.09046258], bias:-1.2034739596810726, loss:0.568740893624751\n",
      "epoch:2425, weight:[1.46760944 1.09058309], bias:-1.2036831921973379, loss:0.5687268782096563\n",
      "epoch:2426, weight:[1.4678955  1.09070356], bias:-1.2038923882334136, loss:0.5687128656056648\n",
      "epoch:2427, weight:[1.46818155 1.09082398], bias:-1.2041015478046195, loss:0.568698855811281\n",
      "epoch:2428, weight:[1.46846761 1.09094436], bias:-1.2043106709262597, loss:0.5686848488250107\n",
      "epoch:2429, weight:[1.46875365 1.09106469], bias:-1.2045197576136217, loss:0.5686708446453603\n",
      "epoch:2430, weight:[1.4690397  1.09118497], bias:-1.2047288078819776, loss:0.5686568432708382\n",
      "epoch:2431, weight:[1.46932574 1.09130521], bias:-1.204937821746583, loss:0.5686428446999529\n",
      "epoch:2432, weight:[1.46961178 1.0914254 ], bias:-1.2051467992226776, loss:0.568628848931215\n",
      "epoch:2433, weight:[1.46989782 1.09154555], bias:-1.2053557403254855, loss:0.5686148559631357\n",
      "epoch:2434, weight:[1.47018385 1.09166565], bias:-1.2055646450702149, loss:0.5686008657942274\n",
      "epoch:2435, weight:[1.47046988 1.09178571], bias:-1.205773513472058, loss:0.568586878423004\n",
      "epoch:2436, weight:[1.47075591 1.09190572], bias:-1.205982345546191, loss:0.5685728938479799\n",
      "epoch:2437, weight:[1.47104194 1.09202568], bias:-1.2061911413077755, loss:0.5685589120676711\n",
      "epoch:2438, weight:[1.47132796 1.0921456 ], bias:-1.206399900771956, loss:0.5685449330805945\n",
      "epoch:2439, weight:[1.47161397 1.09226547], bias:-1.2066086239538623, loss:0.5685309568852684\n",
      "epoch:2440, weight:[1.47189999 1.0923853 ], bias:-1.2068173108686082, loss:0.5685169834802118\n",
      "epoch:2441, weight:[1.472186   1.09250508], bias:-1.2070259615312922, loss:0.5685030128639451\n",
      "epoch:2442, weight:[1.47247201 1.09262482], bias:-1.2072345759569971, loss:0.5684890450349899\n",
      "epoch:2443, weight:[1.47275801 1.09274451], bias:-1.2074431541607904, loss:0.5684750799918686\n",
      "epoch:2444, weight:[1.47304401 1.09286416], bias:-1.2076516961577242, loss:0.5684611177331051\n",
      "epoch:2445, weight:[1.47333001 1.09298376], bias:-1.2078602019628348, loss:0.5684471582572244\n",
      "epoch:2446, weight:[1.47361601 1.09310331], bias:-1.2080686715911437, loss:0.5684332015627521\n",
      "epoch:2447, weight:[1.473902   1.09322282], bias:-1.2082771050576568, loss:0.5684192476482156\n",
      "epoch:2448, weight:[1.47418799 1.09334228], bias:-1.2084855023773649, loss:0.568405296512143\n",
      "epoch:2449, weight:[1.47447397 1.0934617 ], bias:-1.2086938635652433, loss:0.5683913481530636\n",
      "epoch:2450, weight:[1.47475996 1.09358108], bias:-1.2089021886362525, loss:0.5683774025695075\n",
      "epoch:2451, weight:[1.47504593 1.0937004 ], bias:-1.2091104776053379, loss:0.5683634597600071\n",
      "epoch:2452, weight:[1.47533191 1.09381968], bias:-1.209318730487429, loss:0.5683495197230941\n",
      "epoch:2453, weight:[1.47561788 1.09393892], bias:-1.2095269472974415, loss:0.568335582457303\n",
      "epoch:2454, weight:[1.47590385 1.09405811], bias:-1.2097351280502748, loss:0.5683216479611685\n",
      "epoch:2455, weight:[1.47618982 1.09417726], bias:-1.2099432727608144, loss:0.5683077162332265\n",
      "epoch:2456, weight:[1.47647578 1.09429636], bias:-1.2101513814439302, loss:0.5682937872720141\n",
      "epoch:2457, weight:[1.47676174 1.09441542], bias:-1.2103594541144775, loss:0.5682798610760698\n",
      "epoch:2458, weight:[1.4770477  1.09453443], bias:-1.2105674907872965, loss:0.5682659376439325\n",
      "epoch:2459, weight:[1.47733365 1.09465339], bias:-1.2107754914772129, loss:0.5682520169741431\n",
      "epoch:2460, weight:[1.4776196  1.09477231], bias:-1.2109834561990374, loss:0.5682380990652427\n",
      "epoch:2461, weight:[1.47790554 1.09489119], bias:-1.2111913849675662, loss:0.5682241839157745\n",
      "epoch:2462, weight:[1.47819149 1.09501002], bias:-1.2113992777975804, loss:0.5682102715242817\n",
      "epoch:2463, weight:[1.47847743 1.0951288 ], bias:-1.2116071347038468, loss:0.5681963618893096\n",
      "epoch:2464, weight:[1.47876336 1.09524754], bias:-1.2118149557011175, loss:0.568182455009404\n",
      "epoch:2465, weight:[1.4790493  1.09536623], bias:-1.2120227408041298, loss:0.5681685508831119\n",
      "epoch:2466, weight:[1.47933523 1.09548488], bias:-1.2122304900276066, loss:0.5681546495089815\n",
      "epoch:2467, weight:[1.47962115 1.09560349], bias:-1.2124382033862564, loss:0.5681407508855623\n",
      "epoch:2468, weight:[1.47990707 1.09572205], bias:-1.212645880894773, loss:0.5681268550114044\n",
      "epoch:2469, weight:[1.48019299 1.09584056], bias:-1.2128535225678363, loss:0.5681129618850593\n",
      "epoch:2470, weight:[1.48047891 1.09595903], bias:-1.2130611284201112, loss:0.5680990715050798\n",
      "epoch:2471, weight:[1.48076482 1.09607745], bias:-1.2132686984662484, loss:0.5680851838700194\n",
      "epoch:2472, weight:[1.48105073 1.09619583], bias:-1.2134762327208843, loss:0.5680712989784328\n",
      "epoch:2473, weight:[1.48133664 1.09631416], bias:-1.2136837311986413, loss:0.5680574168288759\n",
      "epoch:2474, weight:[1.48162254 1.09643245], bias:-1.213891193914127, loss:0.5680435374199058\n",
      "epoch:2475, weight:[1.48190844 1.0965507 ], bias:-1.2140986208819355, loss:0.5680296607500807\n",
      "epoch:2476, weight:[1.48219434 1.09666889], bias:-1.214306012116646, loss:0.5680157868179591\n",
      "epoch:2477, weight:[1.48248023 1.09678705], bias:-1.2145133676328241, loss:0.5680019156221017\n",
      "epoch:2478, weight:[1.48276612 1.09690516], bias:-1.2147206874450212, loss:0.5679880471610695\n",
      "epoch:2479, weight:[1.48305201 1.09702322], bias:-1.2149279715677743, loss:0.5679741814334256\n",
      "epoch:2480, weight:[1.48333789 1.09714124], bias:-1.215135220015607, loss:0.5679603184377329\n",
      "epoch:2481, weight:[1.48362377 1.09725921], bias:-1.2153424328030282, loss:0.5679464581725561\n",
      "epoch:2482, weight:[1.48390965 1.09737714], bias:-1.2155496099445335, loss:0.5679326006364609\n",
      "epoch:2483, weight:[1.48419552 1.09749503], bias:-1.2157567514546044, loss:0.5679187458280142\n",
      "epoch:2484, weight:[1.48448139 1.09761287], bias:-1.215963857347708, loss:0.5679048937457835\n",
      "epoch:2485, weight:[1.48476726 1.09773066], bias:-1.2161709276382984, loss:0.5678910443883379\n",
      "epoch:2486, weight:[1.48505312 1.09784841], bias:-1.216377962340815, loss:0.5678771977542475\n",
      "epoch:2487, weight:[1.48533898 1.09796612], bias:-1.2165849614696844, loss:0.5678633538420834\n",
      "epoch:2488, weight:[1.48562483 1.09808378], bias:-1.2167919250393187, loss:0.5678495126504178\n",
      "epoch:2489, weight:[1.48591069 1.09820139], bias:-1.2169988530641165, loss:0.5678356741778238\n",
      "epoch:2490, weight:[1.48619653 1.09831897], bias:-1.217205745558463, loss:0.5678218384228756\n",
      "epoch:2491, weight:[1.48648238 1.09843649], bias:-1.2174126025367296, loss:0.567808005384149\n",
      "epoch:2492, weight:[1.48676822 1.09855397], bias:-1.2176194240132738, loss:0.5677941750602203\n",
      "epoch:2493, weight:[1.48705406 1.09867141], bias:-1.2178262100024402, loss:0.5677803474496671\n",
      "epoch:2494, weight:[1.4873399 1.0987888], bias:-1.2180329605185594, loss:0.567766522551068\n",
      "epoch:2495, weight:[1.48762573 1.09890615], bias:-1.2182396755759484, loss:0.5677527003630027\n",
      "epoch:2496, weight:[1.48791156 1.09902345], bias:-1.218446355188911, loss:0.5677388808840522\n",
      "epoch:2497, weight:[1.48819738 1.09914071], bias:-1.2186529993717379, loss:0.5677250641127979\n",
      "epoch:2498, weight:[1.4884832  1.09925793], bias:-1.2188596081387055, loss:0.5677112500478232\n",
      "epoch:2499, weight:[1.48876902 1.0993751 ], bias:-1.2190661815040778, loss:0.5676974386877118\n",
      "epoch:2500, weight:[1.48905484 1.09949222], bias:-1.2192727194821047, loss:0.5676836300310492\n",
      "epoch:2501, weight:[1.48934065 1.0996093 ], bias:-1.2194792220870236, loss:0.5676698240764211\n",
      "epoch:2502, weight:[1.48962646 1.09972634], bias:-1.219685689333058, loss:0.5676560208224148\n",
      "epoch:2503, weight:[1.48991226 1.09984333], bias:-1.2198921212344185, loss:0.5676422202676187\n",
      "epoch:2504, weight:[1.49019806 1.09996028], bias:-1.2200985178053023, loss:0.5676284224106222\n",
      "epoch:2505, weight:[1.49048386 1.10007718], bias:-1.2203048790598938, loss:0.5676146272500158\n",
      "epoch:2506, weight:[1.49076965 1.10019404], bias:-1.2205112050123639, loss:0.5676008347843905\n",
      "epoch:2507, weight:[1.49105544 1.10031085], bias:-1.2207174956768707, loss:0.5675870450123394\n",
      "epoch:2508, weight:[1.49134123 1.10042762], bias:-1.220923751067559, loss:0.5675732579324557\n",
      "epoch:2509, weight:[1.49162702 1.10054434], bias:-1.2211299711985608, loss:0.5675594735433344\n",
      "epoch:2510, weight:[1.4919128  1.10066103], bias:-1.221336156083995, loss:0.5675456918435713\n",
      "epoch:2511, weight:[1.49219857 1.10077766], bias:-1.2215423057379675, loss:0.5675319128317627\n",
      "epoch:2512, weight:[1.49248435 1.10089425], bias:-1.2217484201745714, loss:0.5675181365065067\n",
      "epoch:2513, weight:[1.49277012 1.1010108 ], bias:-1.2219544994078868, loss:0.5675043628664024\n",
      "epoch:2514, weight:[1.49305588 1.1011273 ], bias:-1.222160543451981, loss:0.5674905919100497\n",
      "epoch:2515, weight:[1.49334164 1.10124376], bias:-1.2223665523209086, loss:0.5674768236360495\n",
      "epoch:2516, weight:[1.4936274  1.10136018], bias:-1.2225725260287112, loss:0.5674630580430038\n",
      "epoch:2517, weight:[1.49391316 1.10147655], bias:-1.2227784645894177, loss:0.567449295129516\n",
      "epoch:2518, weight:[1.49419891 1.10159287], bias:-1.2229843680170445, loss:0.5674355348941902\n",
      "epoch:2519, weight:[1.49448466 1.10170915], bias:-1.2231902363255949, loss:0.5674217773356317\n",
      "epoch:2520, weight:[1.49477041 1.10182539], bias:-1.2233960695290595, loss:0.5674080224524466\n",
      "epoch:2521, weight:[1.49505615 1.10194159], bias:-1.2236018676414169, loss:0.5673942702432424\n",
      "epoch:2522, weight:[1.49534188 1.10205773], bias:-1.2238076306766326, loss:0.5673805207066276\n",
      "epoch:2523, weight:[1.49562762 1.10217384], bias:-1.2240133586486595, loss:0.5673667738412115\n",
      "epoch:2524, weight:[1.49591335 1.1022899 ], bias:-1.2242190515714382, loss:0.5673530296456045\n",
      "epoch:2525, weight:[1.49619908 1.10240592], bias:-1.2244247094588965, loss:0.5673392881184185\n",
      "epoch:2526, weight:[1.4964848  1.10252189], bias:-1.22463033232495, loss:0.567325549258266\n",
      "epoch:2527, weight:[1.49677052 1.10263782], bias:-1.224835920183502, loss:0.5673118130637602\n",
      "epoch:2528, weight:[1.49705624 1.1027537 ], bias:-1.2250414730484427, loss:0.5672980795335166\n",
      "epoch:2529, weight:[1.49734195 1.10286954], bias:-1.2252469909336505, loss:0.56728434866615\n",
      "epoch:2530, weight:[1.49762766 1.10298534], bias:-1.2254524738529913, loss:0.5672706204602778\n",
      "epoch:2531, weight:[1.49791337 1.10310109], bias:-1.2256579218203185, loss:0.5672568949145177\n",
      "epoch:2532, weight:[1.49819907 1.1032168 ], bias:-1.2258633348494736, loss:0.5672431720274888\n",
      "epoch:2533, weight:[1.49848477 1.10333247], bias:-1.2260687129542855, loss:0.5672294517978106\n",
      "epoch:2534, weight:[1.49877047 1.10344809], bias:-1.226274056148571, loss:0.567215734224104\n",
      "epoch:2535, weight:[1.49905616 1.10356366], bias:-1.2264793644461347, loss:0.5672020193049915\n",
      "epoch:2536, weight:[1.49934185 1.10367919], bias:-1.2266846378607688, loss:0.5671883070390956\n",
      "epoch:2537, weight:[1.49962753 1.10379468], bias:-1.2268898764062537, loss:0.5671745974250407\n",
      "epoch:2538, weight:[1.49991321 1.10391013], bias:-1.2270950800963574, loss:0.5671608904614517\n",
      "epoch:2539, weight:[1.50019889 1.10402553], bias:-1.227300248944836, loss:0.5671471861469549\n",
      "epoch:2540, weight:[1.50048456 1.10414089], bias:-1.2275053829654334, loss:0.5671334844801772\n",
      "epoch:2541, weight:[1.50077023 1.1042562 ], bias:-1.2277104821718816, loss:0.567119785459747\n",
      "epoch:2542, weight:[1.5010559  1.10437147], bias:-1.2279155465779006, loss:0.5671060890842938\n",
      "epoch:2543, weight:[1.50134156 1.10448669], bias:-1.2281205761971983, loss:0.5670923953524476\n",
      "epoch:2544, weight:[1.50162722 1.10460187], bias:-1.2283255710434706, loss:0.5670787042628395\n",
      "epoch:2545, weight:[1.50191288 1.10471701], bias:-1.228530531130402, loss:0.5670650158141022\n",
      "epoch:2546, weight:[1.50219853 1.10483211], bias:-1.2287354564716644, loss:0.567051330004869\n",
      "epoch:2547, weight:[1.50248418 1.10494716], bias:-1.2289403470809181, loss:0.567037646833774\n",
      "epoch:2548, weight:[1.50276983 1.10506216], bias:-1.229145202971812, loss:0.5670239662994528\n",
      "epoch:2549, weight:[1.50305547 1.10517713], bias:-1.2293500241579827, loss:0.567010288400542\n",
      "epoch:2550, weight:[1.50334111 1.10529205], bias:-1.2295548106530552, loss:0.5669966131356791\n",
      "epoch:2551, weight:[1.50362674 1.10540692], bias:-1.2297595624706428, loss:0.5669829405035023\n",
      "epoch:2552, weight:[1.50391237 1.10552175], bias:-1.2299642796243468, loss:0.5669692705026513\n",
      "epoch:2553, weight:[1.504198   1.10563654], bias:-1.2301689621277574, loss:0.5669556031317667\n",
      "epoch:2554, weight:[1.50448362 1.10575129], bias:-1.2303736099944524, loss:0.5669419383894899\n",
      "epoch:2555, weight:[1.50476924 1.10586599], bias:-1.2305782232379987, loss:0.5669282762744637\n",
      "epoch:2556, weight:[1.50505486 1.10598064], bias:-1.230782801871951, loss:0.5669146167853317\n",
      "epoch:2557, weight:[1.50534047 1.10609526], bias:-1.2309873459098528, loss:0.5669009599207384\n",
      "epoch:2558, weight:[1.50562608 1.10620983], bias:-1.231191855365236, loss:0.5668873056793298\n",
      "epoch:2559, weight:[1.50591168 1.10632435], bias:-1.2313963302516207, loss:0.5668736540597519\n",
      "epoch:2560, weight:[1.50619728 1.10643884], bias:-1.2316007705825158, loss:0.5668600050606529\n",
      "epoch:2561, weight:[1.50648288 1.10655328], bias:-1.2318051763714188, loss:0.5668463586806818\n",
      "epoch:2562, weight:[1.50676848 1.10666767], bias:-1.2320095476318156, loss:0.5668327149184877\n",
      "epoch:2563, weight:[1.50705407 1.10678202], bias:-1.2322138843771806, loss:0.5668190737727216\n",
      "epoch:2564, weight:[1.50733965 1.10689633], bias:-1.2324181866209771, loss:0.5668054352420353\n",
      "epoch:2565, weight:[1.50762524 1.1070106 ], bias:-1.2326224543766569, loss:0.5667917993250817\n",
      "epoch:2566, weight:[1.50791081 1.10712482], bias:-1.2328266876576601, loss:0.5667781660205142\n",
      "epoch:2567, weight:[1.50819639 1.107239  ], bias:-1.2330308864774162, loss:0.566764535326988\n",
      "epoch:2568, weight:[1.50848196 1.10735314], bias:-1.2332350508493428, loss:0.5667509072431587\n",
      "epoch:2569, weight:[1.50876753 1.10746723], bias:-1.2334391807868468, loss:0.5667372817676831\n",
      "epoch:2570, weight:[1.50905309 1.10758128], bias:-1.2336432763033232, loss:0.5667236588992193\n",
      "epoch:2571, weight:[1.50933866 1.10769528], bias:-1.2338473374121564, loss:0.5667100386364257\n",
      "epoch:2572, weight:[1.50962421 1.10780924], bias:-1.2340513641267195, loss:0.5666964209779626\n",
      "epoch:2573, weight:[1.50990977 1.10792316], bias:-1.2342553564603742, loss:0.5666828059224905\n",
      "epoch:2574, weight:[1.51019532 1.10803704], bias:-1.2344593144264715, loss:0.5666691934686715\n",
      "epoch:2575, weight:[1.51048086 1.10815087], bias:-1.2346632380383509, loss:0.5666555836151685\n",
      "epoch:2576, weight:[1.5107664  1.10826466], bias:-1.234867127309341, loss:0.5666419763606452\n",
      "epoch:2577, weight:[1.51105194 1.1083784 ], bias:-1.2350709822527595, loss:0.5666283717037665\n",
      "epoch:2578, weight:[1.51133748 1.1084921 ], bias:-1.2352748028819127, loss:0.5666147696431982\n",
      "epoch:2579, weight:[1.51162301 1.10860576], bias:-1.2354785892100963, loss:0.5666011701776076\n",
      "epoch:2580, weight:[1.51190854 1.10871938], bias:-1.235682341250595, loss:0.5665875733056619\n",
      "epoch:2581, weight:[1.51219406 1.10883295], bias:-1.2358860590166822, loss:0.5665739790260307\n",
      "epoch:2582, weight:[1.51247958 1.10894648], bias:-1.2360897425216208, loss:0.5665603873373835\n",
      "epoch:2583, weight:[1.51276509 1.10905997], bias:-1.2362933917786625, loss:0.5665467982383912\n",
      "epoch:2584, weight:[1.51305061 1.10917341], bias:-1.2364970068010483, loss:0.5665332117277256\n",
      "epoch:2585, weight:[1.51333612 1.10928681], bias:-1.2367005876020085, loss:0.5665196278040597\n",
      "epoch:2586, weight:[1.51362162 1.10940017], bias:-1.2369041341947622, loss:0.5665060464660677\n",
      "epoch:2587, weight:[1.51390712 1.10951348], bias:-1.2371076465925182, loss:0.5664924677124239\n",
      "epoch:2588, weight:[1.51419262 1.10962675], bias:-1.237311124808474, loss:0.5664788915418044\n",
      "epoch:2589, weight:[1.51447811 1.10973998], bias:-1.237514568855817, loss:0.566465317952886\n",
      "epoch:2590, weight:[1.5147636  1.10985316], bias:-1.237717978747723, loss:0.5664517469443466\n",
      "epoch:2591, weight:[1.51504909 1.10996631], bias:-1.237921354497358, loss:0.5664381785148653\n",
      "epoch:2592, weight:[1.51533457 1.11007941], bias:-1.2381246961178767, loss:0.5664246126631215\n",
      "epoch:2593, weight:[1.51562005 1.11019246], bias:-1.2383280036224236, loss:0.5664110493877963\n",
      "epoch:2594, weight:[1.51590552 1.11030547], bias:-1.2385312770241323, loss:0.5663974886875714\n",
      "epoch:2595, weight:[1.51619099 1.11041844], bias:-1.238734516336126, loss:0.5663839305611298\n",
      "epoch:2596, weight:[1.51647646 1.11053137], bias:-1.2389377215715174, loss:0.5663703750071549\n",
      "epoch:2597, weight:[1.51676192 1.11064425], bias:-1.2391408927434082, loss:0.5663568220243319\n",
      "epoch:2598, weight:[1.51704738 1.11075709], bias:-1.23934402986489, loss:0.5663432716113461\n",
      "epoch:2599, weight:[1.51733284 1.11086989], bias:-1.2395471329490435, loss:0.5663297237668851\n",
      "epoch:2600, weight:[1.51761829 1.11098265], bias:-1.2397502020089397, loss:0.5663161784896356\n",
      "epoch:2601, weight:[1.51790374 1.11109536], bias:-1.2399532370576383, loss:0.5663026357782869\n",
      "epoch:2602, weight:[1.51818918 1.11120803], bias:-1.240156238108189, loss:0.5662890956315288\n",
      "epoch:2603, weight:[1.51847462 1.11132066], bias:-1.240359205173631, loss:0.5662755580480516\n",
      "epoch:2604, weight:[1.51876006 1.11143324], bias:-1.2405621382669931, loss:0.5662620230265473\n",
      "epoch:2605, weight:[1.51904549 1.11154578], bias:-1.240765037401294, loss:0.5662484905657083\n",
      "epoch:2606, weight:[1.51933092 1.11165828], bias:-1.2409679025895415, loss:0.5662349606642283\n",
      "epoch:2607, weight:[1.51961635 1.11177074], bias:-1.2411707338447338, loss:0.566221433320802\n",
      "epoch:2608, weight:[1.51990177 1.11188315], bias:-1.2413735311798582, loss:0.5662079085341252\n",
      "epoch:2609, weight:[1.52018719 1.11199552], bias:-1.241576294607892, loss:0.5661943863028939\n",
      "epoch:2610, weight:[1.5204726  1.11210785], bias:-1.2417790241418025, loss:0.5661808666258058\n",
      "epoch:2611, weight:[1.52075801 1.11222013], bias:-1.2419817197945462, loss:0.5661673495015599\n",
      "epoch:2612, weight:[1.52104342 1.11233237], bias:-1.2421843815790699, loss:0.5661538349288553\n",
      "epoch:2613, weight:[1.52132882 1.11244457], bias:-1.2423870095083098, loss:0.5661403229063924\n",
      "epoch:2614, weight:[1.52161422 1.11255673], bias:-1.2425896035951924, loss:0.5661268134328726\n",
      "epoch:2615, weight:[1.52189961 1.11266884], bias:-1.242792163852634, loss:0.5661133065069989\n",
      "epoch:2616, weight:[1.522185   1.11278091], bias:-1.2429946902935405, loss:0.5660998021274742\n",
      "epoch:2617, weight:[1.52247039 1.11289294], bias:-1.243197182930808, loss:0.5660863002930027\n",
      "epoch:2618, weight:[1.52275577 1.11300493], bias:-1.2433996417773223, loss:0.56607280100229\n",
      "epoch:2619, weight:[1.52304115 1.11311687], bias:-1.2436020668459595, loss:0.5660593042540424\n",
      "epoch:2620, weight:[1.52332652 1.11322877], bias:-1.2438044581495853, loss:0.5660458100469669\n",
      "epoch:2621, weight:[1.52361189 1.11334063], bias:-1.2440068157010555, loss:0.5660323183797721\n",
      "epoch:2622, weight:[1.52389726 1.11345245], bias:-1.2442091395132162, loss:0.5660188292511671\n",
      "epoch:2623, weight:[1.52418262 1.11356422], bias:-1.2444114295989033, loss:0.566005342659862\n",
      "epoch:2624, weight:[1.52446798 1.11367595], bias:-1.2446136859709427, loss:0.5659918586045679\n",
      "epoch:2625, weight:[1.52475334 1.11378764], bias:-1.2448159086421506, loss:0.5659783770839968\n",
      "epoch:2626, weight:[1.52503869 1.11389929], bias:-1.2450180976253333, loss:0.5659648980968621\n",
      "epoch:2627, weight:[1.52532404 1.11401089], bias:-1.2452202529332872, loss:0.5659514216418775\n",
      "epoch:2628, weight:[1.52560938 1.11412246], bias:-1.2454223745787987, loss:0.5659379477177582\n",
      "epoch:2629, weight:[1.52589472 1.11423397], bias:-1.2456244625746444, loss:0.56592447632322\n",
      "epoch:2630, weight:[1.52618006 1.11434545], bias:-1.2458265169335916, loss:0.5659110074569798\n",
      "epoch:2631, weight:[1.52646539 1.11445689], bias:-1.246028537668397, loss:0.5658975411177556\n",
      "epoch:2632, weight:[1.52675072 1.11456828], bias:-1.2462305247918082, loss:0.5658840773042662\n",
      "epoch:2633, weight:[1.52703604 1.11467963], bias:-1.2464324783165628, loss:0.5658706160152313\n",
      "epoch:2634, weight:[1.52732136 1.11479094], bias:-1.2466343982553887, loss:0.5658571572493715\n",
      "epoch:2635, weight:[1.52760668 1.1149022 ], bias:-1.2468362846210042, loss:0.5658437010054088\n",
      "epoch:2636, weight:[1.52789199 1.11501342], bias:-1.2470381374261177, loss:0.5658302472820658\n",
      "epoch:2637, weight:[1.5281773 1.1151246], bias:-1.247239956683428, loss:0.5658167960780659\n",
      "epoch:2638, weight:[1.52846261 1.11523574], bias:-1.2474417424056246, loss:0.565803347392134\n",
      "epoch:2639, weight:[1.52874791 1.11534684], bias:-1.2476434946053871, loss:0.5657899012229954\n",
      "epoch:2640, weight:[1.5290332  1.11545789], bias:-1.2478452132953857, loss:0.5657764575693766\n",
      "epoch:2641, weight:[1.5293185 1.1155689], bias:-1.2480468984882807, loss:0.5657630164300048\n",
      "epoch:2642, weight:[1.52960379 1.11567987], bias:-1.2482485501967229, loss:0.5657495778036087\n",
      "epoch:2643, weight:[1.52988907 1.1157908 ], bias:-1.248450168433354, loss:0.5657361416889175\n",
      "epoch:2644, weight:[1.53017435 1.11590169], bias:-1.248651753210806, loss:0.5657227080846616\n",
      "epoch:2645, weight:[1.53045963 1.11601253], bias:-1.248853304541701, loss:0.5657092769895721\n",
      "epoch:2646, weight:[1.5307449  1.11612333], bias:-1.249054822438652, loss:0.5656958484023812\n",
      "epoch:2647, weight:[1.53103017 1.11623409], bias:-1.2492563069142626, loss:0.5656824223218219\n",
      "epoch:2648, weight:[1.53131544 1.11634481], bias:-1.249457757981127, loss:0.5656689987466285\n",
      "epoch:2649, weight:[1.5316007  1.11645548], bias:-1.2496591756518298, loss:0.5656555776755358\n",
      "epoch:2650, weight:[1.53188595 1.11656611], bias:-1.2498605599389463, loss:0.5656421591072798\n",
      "epoch:2651, weight:[1.53217121 1.1166767 ], bias:-1.2500619108550421, loss:0.5656287430405975\n",
      "epoch:2652, weight:[1.53245646 1.11678725], bias:-1.2502632284126742, loss:0.5656153294742269\n",
      "epoch:2653, weight:[1.5327417  1.11689776], bias:-1.2504645126243896, loss:0.5656019184069062\n",
      "epoch:2654, weight:[1.53302694 1.11700822], bias:-1.2506657635027263, loss:0.5655885098373759\n",
      "epoch:2655, weight:[1.53331218 1.11711865], bias:-1.2508669810602129, loss:0.5655751037643758\n",
      "epoch:2656, weight:[1.53359741 1.11722903], bias:-1.2510681653093687, loss:0.5655617001866482\n",
      "epoch:2657, weight:[1.53388264 1.11733937], bias:-1.251269316262704, loss:0.5655482991029355\n",
      "epoch:2658, weight:[1.53416787 1.11744966], bias:-1.2514704339327196, loss:0.5655349005119811\n",
      "epoch:2659, weight:[1.53445309 1.11755992], bias:-1.2516715183319072, loss:0.5655215044125292\n",
      "epoch:2660, weight:[1.53473831 1.11767013], bias:-1.251872569472749, loss:0.5655081108033256\n",
      "epoch:2661, weight:[1.53502352 1.1177803 ], bias:-1.252073587367719, loss:0.5654947196831164\n",
      "epoch:2662, weight:[1.53530873 1.11789043], bias:-1.2522745720292805, loss:0.5654813310506488\n",
      "epoch:2663, weight:[1.53559394 1.11800052], bias:-1.252475523469889, loss:0.5654679449046709\n",
      "epoch:2664, weight:[1.53587914 1.11811057], bias:-1.2526764417019904, loss:0.565454561243932\n",
      "epoch:2665, weight:[1.53616433 1.11822057], bias:-1.2528773267380215, loss:0.565441180067182\n",
      "epoch:2666, weight:[1.53644953 1.11833053], bias:-1.25307817859041, loss:0.565427801373172\n",
      "epoch:2667, weight:[1.53673472 1.11844045], bias:-1.2532789972715743, loss:0.5654144251606538\n",
      "epoch:2668, weight:[1.5370199  1.11855033], bias:-1.2534797827939246, loss:0.5654010514283802\n",
      "epoch:2669, weight:[1.53730508 1.11866017], bias:-1.253680535169861, loss:0.565387680175105\n",
      "epoch:2670, weight:[1.53759026 1.11876996], bias:-1.2538812544117752, loss:0.5653743113995829\n",
      "epoch:2671, weight:[1.53787543 1.11887972], bias:-1.25408194053205, loss:0.5653609451005696\n",
      "epoch:2672, weight:[1.5381606  1.11898943], bias:-1.254282593543059, loss:0.5653475812768215\n",
      "epoch:2673, weight:[1.53844577 1.1190991 ], bias:-1.2544832134571668, loss:0.5653342199270961\n",
      "epoch:2674, weight:[1.53873093 1.11920873], bias:-1.2546838002867293, loss:0.5653208610501518\n",
      "epoch:2675, weight:[1.53901608 1.11931832], bias:-1.2548843540440933, loss:0.5653075046447481\n",
      "epoch:2676, weight:[1.53930124 1.11942786], bias:-1.2550848747415966, loss:0.565294150709645\n",
      "epoch:2677, weight:[1.53958639 1.11953737], bias:-1.2552853623915685, loss:0.5652807992436037\n",
      "epoch:2678, weight:[1.53987153 1.11964683], bias:-1.2554858170063292, loss:0.5652674502453867\n",
      "epoch:2679, weight:[1.54015667 1.11975625], bias:-1.25568623859819, loss:0.5652541037137564\n",
      "epoch:2680, weight:[1.54044181 1.11986563], bias:-1.2558866271794535, loss:0.5652407596474774\n",
      "epoch:2681, weight:[1.54072694 1.11997496], bias:-1.2560869827624135, loss:0.565227418045314\n",
      "epoch:2682, weight:[1.54101207 1.12008426], bias:-1.256287305359355, loss:0.5652140789060323\n",
      "epoch:2683, weight:[1.54129719 1.12019351], bias:-1.2564875949825542, loss:0.5652007422283989\n",
      "epoch:2684, weight:[1.54158231 1.12030273], bias:-1.2566878516442785, loss:0.5651874080111813\n",
      "epoch:2685, weight:[1.54186743 1.1204119 ], bias:-1.2568880753567868, loss:0.5651740762531484\n",
      "epoch:2686, weight:[1.54215254 1.12052103], bias:-1.257088266132329, loss:0.5651607469530693\n",
      "epoch:2687, weight:[1.54243765 1.12063012], bias:-1.2572884239831466, loss:0.5651474201097145\n",
      "epoch:2688, weight:[1.54272275 1.12073916], bias:-1.257488548921472, loss:0.5651340957218555\n",
      "epoch:2689, weight:[1.54300785 1.12084817], bias:-1.2576886409595291, loss:0.5651207737882642\n",
      "epoch:2690, weight:[1.54329295 1.12095713], bias:-1.2578887001095336, loss:0.5651074543077138\n",
      "epoch:2691, weight:[1.54357804 1.12106606], bias:-1.258088726383692, loss:0.5650941372789785\n",
      "epoch:2692, weight:[1.54386313 1.12117494], bias:-1.2582887197942023, loss:0.5650808227008329\n",
      "epoch:2693, weight:[1.54414821 1.12128378], bias:-1.258488680353254, loss:0.5650675105720532\n",
      "epoch:2694, weight:[1.54443329 1.12139258], bias:-1.2586886080730282, loss:0.5650542008914161\n",
      "epoch:2695, weight:[1.54471836 1.12150134], bias:-1.258888502965697, loss:0.5650408936576992\n",
      "epoch:2696, weight:[1.54500344 1.12161005], bias:-1.2590883650434248, loss:0.5650275888696812\n",
      "epoch:2697, weight:[1.5452885  1.12171873], bias:-1.2592881943183662, loss:0.5650142865261413\n",
      "epoch:2698, weight:[1.54557357 1.12182736], bias:-1.2594879908026684, loss:0.5650009866258603\n",
      "epoch:2699, weight:[1.54585862 1.12193595], bias:-1.2596877545084697, loss:0.5649876891676192\n",
      "epoch:2700, weight:[1.54614368 1.12204451], bias:-1.2598874854478999, loss:0.5649743941502003\n",
      "epoch:2701, weight:[1.54642873 1.12215302], bias:-1.26008718363308, loss:0.5649611015723871\n",
      "epoch:2702, weight:[1.54671377 1.12226148], bias:-1.2602868490761234, loss:0.5649478114329631\n",
      "epoch:2703, weight:[1.54699882 1.12236991], bias:-1.2604864817891344, loss:0.5649345237307133\n",
      "epoch:2704, weight:[1.54728385 1.1224783 ], bias:-1.260686081784209, loss:0.5649212384644242\n",
      "epoch:2705, weight:[1.54756889 1.12258664], bias:-1.260885649073435, loss:0.5649079556328818\n",
      "epoch:2706, weight:[1.54785392 1.12269495], bias:-1.2610851836688919, loss:0.5648946752348739\n",
      "epoch:2707, weight:[1.54813894 1.12280321], bias:-1.2612846855826503, loss:0.564881397269189\n",
      "epoch:2708, weight:[1.54842396 1.12291143], bias:-1.261484154826773, loss:0.5648681217346169\n",
      "epoch:2709, weight:[1.54870898 1.12301961], bias:-1.2616835914133144, loss:0.5648548486299477\n",
      "epoch:2710, weight:[1.54899399 1.12312775], bias:-1.2618829953543205, loss:0.5648415779539726\n",
      "epoch:2711, weight:[1.549279   1.12323585], bias:-1.2620823666618288, loss:0.5648283097054839\n",
      "epoch:2712, weight:[1.54956401 1.12334391], bias:-1.2622817053478688, loss:0.5648150438832746\n",
      "epoch:2713, weight:[1.54984901 1.12345193], bias:-1.2624810114244616, loss:0.5648017804861388\n",
      "epoch:2714, weight:[1.550134  1.1235599], bias:-1.26268028490362, loss:0.5647885195128709\n",
      "epoch:2715, weight:[1.550419   1.12366784], bias:-1.262879525797349, loss:0.5647752609622669\n",
      "epoch:2716, weight:[1.55070398 1.12377573], bias:-1.263078734117645, loss:0.5647620048331237\n",
      "epoch:2717, weight:[1.55098897 1.12388359], bias:-1.2632779098764961, loss:0.5647487511242383\n",
      "epoch:2718, weight:[1.55127395 1.1239914 ], bias:-1.2634770530858823, loss:0.5647354998344092\n",
      "epoch:2719, weight:[1.55155892 1.12409917], bias:-1.2636761637577758, loss:0.564722250962436\n",
      "epoch:2720, weight:[1.55184389 1.1242069 ], bias:-1.2638752419041401, loss:0.5647090045071189\n",
      "epoch:2721, weight:[1.55212886 1.12431459], bias:-1.264074287536931, loss:0.5646957604672588\n",
      "epoch:2722, weight:[1.55241382 1.12442224], bias:-1.264273300668096, loss:0.5646825188416575\n",
      "epoch:2723, weight:[1.55269878 1.12452984], bias:-1.2644722813095743, loss:0.5646692796291185\n",
      "epoch:2724, weight:[1.55298374 1.12463741], bias:-1.2646712294732976, loss:0.5646560428284452\n",
      "epoch:2725, weight:[1.55326869 1.12474494], bias:-1.2648701451711888, loss:0.5646428084384417\n",
      "epoch:2726, weight:[1.55355363 1.12485242], bias:-1.265069028415163, loss:0.5646295764579146\n",
      "epoch:2727, weight:[1.55383857 1.12495987], bias:-1.2652678792171277, loss:0.5646163468856696\n",
      "epoch:2728, weight:[1.55412351 1.12506727], bias:-1.2654666975889817, loss:0.564603119720514\n",
      "epoch:2729, weight:[1.55440845 1.12517463], bias:-1.2656654835426162, loss:0.5645898949612563\n",
      "epoch:2730, weight:[1.55469337 1.12528195], bias:-1.2658642370899145, loss:0.5645766726067056\n",
      "epoch:2731, weight:[1.5549783  1.12538923], bias:-1.2660629582427514, loss:0.5645634526556716\n",
      "epoch:2732, weight:[1.55526322 1.12549647], bias:-1.2662616470129944, loss:0.5645502351069653\n",
      "epoch:2733, weight:[1.55554814 1.12560367], bias:-1.2664603034125024, loss:0.5645370199593984\n",
      "epoch:2734, weight:[1.55583305 1.12571083], bias:-1.2666589274531268, loss:0.5645238072117836\n",
      "epoch:2735, weight:[1.55611796 1.12581795], bias:-1.2668575191467109, loss:0.5645105968629344\n",
      "epoch:2736, weight:[1.55640286 1.12592503], bias:-1.2670560785050902, loss:0.564497388911665\n",
      "epoch:2737, weight:[1.55668776 1.12603207], bias:-1.2672546055400922, loss:0.5644841833567905\n",
      "epoch:2738, weight:[1.55697265 1.12613906], bias:-1.2674531002635365, loss:0.5644709801971276\n",
      "epoch:2739, weight:[1.55725755 1.12624602], bias:-1.267651562687235, loss:0.5644577794314927\n",
      "epoch:2740, weight:[1.55754243 1.12635293], bias:-1.2678499928229914, loss:0.5644445810587041\n",
      "epoch:2741, weight:[1.55782731 1.12645981], bias:-1.2680483906826021, loss:0.5644313850775805\n",
      "epoch:2742, weight:[1.55811219 1.12656664], bias:-1.2682467562778552, loss:0.5644181914869413\n",
      "epoch:2743, weight:[1.55839707 1.12667344], bias:-1.2684450896205315, loss:0.5644050002856074\n",
      "epoch:2744, weight:[1.55868194 1.12678019], bias:-1.2686433907224033, loss:0.5643918114723998\n",
      "epoch:2745, weight:[1.5589668 1.1268869], bias:-1.2688416595952359, loss:0.5643786250461408\n",
      "epoch:2746, weight:[1.55925166 1.12699358], bias:-1.2690398962507863, loss:0.564365441005654\n",
      "epoch:2747, weight:[1.55953652 1.12710021], bias:-1.2692381007008038, loss:0.5643522593497629\n",
      "epoch:2748, weight:[1.55982137 1.1272068 ], bias:-1.26943627295703, loss:0.5643390800772924\n",
      "epoch:2749, weight:[1.56010622 1.12731335], bias:-1.2696344130311994, loss:0.5643259031870687\n",
      "epoch:2750, weight:[1.56039106 1.12741986], bias:-1.2698325209350378, loss:0.5643127286779178\n",
      "epoch:2751, weight:[1.5606759  1.12752633], bias:-1.2700305966802639, loss:0.5642995565486678\n",
      "epoch:2752, weight:[1.56096074 1.12763276], bias:-1.2702286402785885, loss:0.5642863867981465\n",
      "epoch:2753, weight:[1.56124557 1.12773915], bias:-1.2704266517417149, loss:0.5642732194251835\n",
      "epoch:2754, weight:[1.5615304 1.1278455], bias:-1.2706246310813387, loss:0.5642600544286089\n",
      "epoch:2755, weight:[1.56181522 1.1279518 ], bias:-1.2708225783091478, loss:0.5642468918072534\n",
      "epoch:2756, weight:[1.56210004 1.12805807], bias:-1.2710204934368226, loss:0.5642337315599492\n",
      "epoch:2757, weight:[1.56238485 1.1281643 ], bias:-1.2712183764760356, loss:0.5642205736855285\n",
      "epoch:2758, weight:[1.56266966 1.12827049], bias:-1.2714162274384524, loss:0.5642074181828253\n",
      "epoch:2759, weight:[1.56295447 1.12837664], bias:-1.2716140463357302, loss:0.5641942650506737\n",
      "epoch:2760, weight:[1.56323927 1.12848274], bias:-1.271811833179519, loss:0.5641811142879092\n",
      "epoch:2761, weight:[1.56352406 1.12858881], bias:-1.2720095879814612, loss:0.5641679658933679\n",
      "epoch:2762, weight:[1.56380885 1.12869484], bias:-1.2722073107531917, loss:0.5641548198658868\n",
      "epoch:2763, weight:[1.56409364 1.12880082], bias:-1.272405001506338, loss:0.5641416762043038\n",
      "epoch:2764, weight:[1.56437843 1.12890677], bias:-1.2726026602525198, loss:0.5641285349074575\n",
      "epoch:2765, weight:[1.56466321 1.12901267], bias:-1.2728002870033495, loss:0.5641153959741877\n",
      "epoch:2766, weight:[1.56494798 1.12911854], bias:-1.272997881770432, loss:0.5641022594033344\n",
      "epoch:2767, weight:[1.56523275 1.12922437], bias:-1.2731954445653646, loss:0.5640891251937394\n",
      "epoch:2768, weight:[1.56551752 1.12933015], bias:-1.2733929753997375, loss:0.5640759933442449\n",
      "epoch:2769, weight:[1.56580228 1.1294359 ], bias:-1.273590474285133, loss:0.5640628638536934\n",
      "epoch:2770, weight:[1.56608704 1.1295416 ], bias:-1.273787941233126, loss:0.5640497367209291\n",
      "epoch:2771, weight:[1.56637179 1.12964727], bias:-1.2739853762552846, loss:0.5640366119447967\n",
      "epoch:2772, weight:[1.56665654 1.12975289], bias:-1.2741827793631688, loss:0.564023489524142\n",
      "epoch:2773, weight:[1.56694128 1.12985848], bias:-1.2743801505683314, loss:0.5640103694578111\n",
      "epoch:2774, weight:[1.56722602 1.12996402], bias:-1.274577489882318, loss:0.5639972517446513\n",
      "epoch:2775, weight:[1.56751076 1.13006953], bias:-1.2747747973166663, loss:0.5639841363835111\n",
      "epoch:2776, weight:[1.56779549 1.13017499], bias:-1.2749720728829077, loss:0.563971023373239\n",
      "epoch:2777, weight:[1.56808022 1.13028042], bias:-1.2751693165925653, loss:0.5639579127126854\n",
      "epoch:2778, weight:[1.56836494 1.1303858 ], bias:-1.2753665284571551, loss:0.5639448044007004\n",
      "epoch:2779, weight:[1.56864966 1.13049114], bias:-1.275563708488186, loss:0.5639316984361362\n",
      "epoch:2780, weight:[1.56893437 1.13059645], bias:-1.2757608566971592, loss:0.5639185948178448\n",
      "epoch:2781, weight:[1.56921908 1.13070171], bias:-1.2759579730955692, loss:0.5639054935446793\n",
      "epoch:2782, weight:[1.56950379 1.13080694], bias:-1.276155057694903, loss:0.563892394615494\n",
      "epoch:2783, weight:[1.56978849 1.13091212], bias:-1.27635211050664, loss:0.5638792980291439\n",
      "epoch:2784, weight:[1.57007319 1.13101727], bias:-1.2765491315422528, loss:0.5638662037844847\n",
      "epoch:2785, weight:[1.57035788 1.13112238], bias:-1.2767461208132065, loss:0.5638531118803731\n",
      "epoch:2786, weight:[1.57064257 1.13122744], bias:-1.276943078330959, loss:0.5638400223156665\n",
      "epoch:2787, weight:[1.57092725 1.13133247], bias:-1.277140004106961, loss:0.5638269350892234\n",
      "epoch:2788, weight:[1.57121193 1.13143745], bias:-1.2773368981526558, loss:0.5638138501999026\n",
      "epoch:2789, weight:[1.5714966 1.1315424], bias:-1.27753376047948, loss:0.5638007676465645\n",
      "epoch:2790, weight:[1.57178127 1.13164731], bias:-1.277730591098863, loss:0.5637876874280696\n",
      "epoch:2791, weight:[1.57206594 1.13175217], bias:-1.2779273900222263, loss:0.5637746095432798\n",
      "epoch:2792, weight:[1.5723506 1.131857 ], bias:-1.2781241572609852, loss:0.5637615339910578\n",
      "epoch:2793, weight:[1.57263526 1.13196179], bias:-1.278320892826547, loss:0.5637484607702663\n",
      "epoch:2794, weight:[1.57291991 1.13206653], bias:-1.2785175967303126, loss:0.5637353898797702\n",
      "epoch:2795, weight:[1.57320456 1.13217124], bias:-1.2787142689836755, loss:0.5637223213184345\n",
      "epoch:2796, weight:[1.5734892  1.13227591], bias:-1.2789109095980218, loss:0.5637092550851248\n",
      "epoch:2797, weight:[1.57377384 1.13238054], bias:-1.279107518584731, loss:0.5636961911787081\n",
      "epoch:2798, weight:[1.57405847 1.13248512], bias:-1.2793040959551751, loss:0.5636831295980514\n",
      "epoch:2799, weight:[1.5743431  1.13258967], bias:-1.2795006417207195, loss:0.5636700703420238\n",
      "epoch:2800, weight:[1.57462773 1.13269418], bias:-1.2796971558927221, loss:0.563657013409494\n",
      "epoch:2801, weight:[1.57491235 1.13279865], bias:-1.279893638482534, loss:0.5636439587993325\n",
      "epoch:2802, weight:[1.57519697 1.13290308], bias:-1.280090089501499, loss:0.5636309065104099\n",
      "epoch:2803, weight:[1.57548158 1.13300747], bias:-1.2802865089609545, loss:0.563617856541598\n",
      "epoch:2804, weight:[1.57576619 1.13311182], bias:-1.2804828968722304, loss:0.5636048088917693\n",
      "epoch:2805, weight:[1.57605079 1.13321614], bias:-1.2806792532466493, loss:0.5635917635597976\n",
      "epoch:2806, weight:[1.57633539 1.13332041], bias:-1.2808755780955277, loss:0.5635787205445568\n",
      "epoch:2807, weight:[1.57661999 1.13342464], bias:-1.2810718714301743, loss:0.5635656798449216\n",
      "epoch:2808, weight:[1.57690458 1.13352883], bias:-1.2812681332618916, loss:0.5635526414597686\n",
      "epoch:2809, weight:[1.57718916 1.13363298], bias:-1.2814643636019745, loss:0.5635396053879741\n",
      "epoch:2810, weight:[1.57747374 1.1337371 ], bias:-1.281660562461711, loss:0.5635265716284157\n",
      "epoch:2811, weight:[1.57775832 1.13384117], bias:-1.2818567298523826, loss:0.5635135401799717\n",
      "epoch:2812, weight:[1.57804289 1.13394521], bias:-1.282052865785264, loss:0.5635005110415215\n",
      "epoch:2813, weight:[1.57832746 1.1340492 ], bias:-1.282248970271622, loss:0.5634874842119451\n",
      "epoch:2814, weight:[1.57861203 1.13415316], bias:-1.2824450433227177, loss:0.5634744596901233\n",
      "epoch:2815, weight:[1.57889658 1.13425708], bias:-1.2826410849498044, loss:0.5634614374749376\n",
      "epoch:2816, weight:[1.57918114 1.13436095], bias:-1.2828370951641292, loss:0.5634484175652709\n",
      "epoch:2817, weight:[1.57946569 1.13446479], bias:-1.2830330739769322, loss:0.5634353999600061\n",
      "epoch:2818, weight:[1.57975024 1.13456859], bias:-1.2832290213994464, loss:0.5634223846580276\n",
      "epoch:2819, weight:[1.58003478 1.13467235], bias:-1.283424937442898, loss:0.5634093716582205\n",
      "epoch:2820, weight:[1.58031931 1.13477607], bias:-1.2836208221185068, loss:0.5633963609594702\n",
      "epoch:2821, weight:[1.58060385 1.13487975], bias:-1.2838166754374851, loss:0.5633833525606636\n",
      "epoch:2822, weight:[1.58088837 1.13498339], bias:-1.284012497411039, loss:0.5633703464606881\n",
      "epoch:2823, weight:[1.5811729  1.13508699], bias:-1.2842082880503676, loss:0.5633573426584321\n",
      "epoch:2824, weight:[1.58145742 1.13519055], bias:-1.2844040473666631, loss:0.5633443411527841\n",
      "epoch:2825, weight:[1.58174193 1.13529408], bias:-1.2845997753711111, loss:0.5633313419426347\n",
      "epoch:2826, weight:[1.58202644 1.13539756], bias:-1.2847954720748904, loss:0.5633183450268742\n",
      "epoch:2827, weight:[1.58231094 1.13550101], bias:-1.2849911374891732, loss:0.5633053504043942\n",
      "epoch:2828, weight:[1.58259545 1.13560441], bias:-1.2851867716251244, loss:0.563292358074087\n",
      "epoch:2829, weight:[1.58287994 1.13570778], bias:-1.285382374493903, loss:0.5632793680348459\n",
      "epoch:2830, weight:[1.58316443 1.13581111], bias:-1.2855779461066608, loss:0.5632663802855647\n",
      "epoch:2831, weight:[1.58344892 1.1359144 ], bias:-1.285773486474543, loss:0.5632533948251384\n",
      "epoch:2832, weight:[1.5837334  1.13601764], bias:-1.285968995608688, loss:0.5632404116524625\n",
      "epoch:2833, weight:[1.58401788 1.13612085], bias:-1.2861644735202278, loss:0.5632274307664334\n",
      "epoch:2834, weight:[1.58430235 1.13622403], bias:-1.2863599202202876, loss:0.5632144521659483\n",
      "epoch:2835, weight:[1.58458682 1.13632716], bias:-1.2865553357199857, loss:0.5632014758499053\n",
      "epoch:2836, weight:[1.58487129 1.13643025], bias:-1.286750720030434, loss:0.5631885018172031\n",
      "epoch:2837, weight:[1.58515575 1.1365333 ], bias:-1.2869460731627378, loss:0.5631755300667417\n",
      "epoch:2838, weight:[1.5854402  1.13663632], bias:-1.2871413951279955, loss:0.5631625605974211\n",
      "epoch:2839, weight:[1.58572465 1.13673929], bias:-1.2873366859372992, loss:0.5631495934081431\n",
      "epoch:2840, weight:[1.5860091  1.13684223], bias:-1.2875319456017345, loss:0.5631366284978092\n",
      "epoch:2841, weight:[1.58629354 1.13694513], bias:-1.28772717413238, loss:0.5631236658653228\n",
      "epoch:2842, weight:[1.58657798 1.13704799], bias:-1.2879223715403079, loss:0.5631107055095872\n",
      "epoch:2843, weight:[1.58686241 1.13715081], bias:-1.2881175378365837, loss:0.5630977474295072\n",
      "epoch:2844, weight:[1.58714684 1.13725359], bias:-1.2883126730322667, loss:0.5630847916239882\n",
      "epoch:2845, weight:[1.58743126 1.13735633], bias:-1.2885077771384095, loss:0.5630718380919361\n",
      "epoch:2846, weight:[1.58771568 1.13745903], bias:-1.2887028501660578, loss:0.5630588868322577\n",
      "epoch:2847, weight:[1.5880001 1.1375617], bias:-1.288897892126251, loss:0.5630459378438609\n",
      "epoch:2848, weight:[1.58828451 1.13766432], bias:-1.2890929030300224, loss:0.5630329911256544\n",
      "epoch:2849, weight:[1.58856891 1.13776691], bias:-1.2892878828883982, loss:0.5630200466765474\n",
      "epoch:2850, weight:[1.58885331 1.13786945], bias:-1.2894828317123985, loss:0.5630071044954496\n",
      "epoch:2851, weight:[1.58913771 1.13797196], bias:-1.2896777495130365, loss:0.5629941645812727\n",
      "epoch:2852, weight:[1.5894221  1.13807443], bias:-1.2898726363013193, loss:0.5629812269329278\n",
      "epoch:2853, weight:[1.58970649 1.13817686], bias:-1.2900674920882473, loss:0.5629682915493279\n",
      "epoch:2854, weight:[1.58999087 1.13827926], bias:-1.2902623168848146, loss:0.5629553584293859\n",
      "epoch:2855, weight:[1.59027525 1.13838161], bias:-1.2904571107020089, loss:0.5629424275720164\n",
      "epoch:2856, weight:[1.59055962 1.13848392], bias:-1.290651873550811, loss:0.5629294989761341\n",
      "epoch:2857, weight:[1.59084399 1.1385862 ], bias:-1.2908466054421959, loss:0.5629165726406545\n",
      "epoch:2858, weight:[1.59112836 1.13868844], bias:-1.2910413063871318, loss:0.5629036485644943\n",
      "epoch:2859, weight:[1.59141271 1.13879063], bias:-1.2912359763965804, loss:0.562890726746571\n",
      "epoch:2860, weight:[1.59169707 1.13889279], bias:-1.2914306154814974, loss:0.5628778071858026\n",
      "epoch:2861, weight:[1.59198142 1.13899492], bias:-1.291625223652832, loss:0.5628648898811078\n",
      "epoch:2862, weight:[1.59226577 1.139097  ], bias:-1.2918198009215267, loss:0.5628519748314068\n",
      "epoch:2863, weight:[1.59255011 1.13919904], bias:-1.292014347298518, loss:0.5628390620356196\n",
      "epoch:2864, weight:[1.59283444 1.13930105], bias:-1.2922088627947357, loss:0.5628261514926676\n",
      "epoch:2865, weight:[1.59311878 1.13940301], bias:-1.2924033474211036, loss:0.562813243201473\n",
      "epoch:2866, weight:[1.5934031  1.13950494], bias:-1.292597801188539, loss:0.5628003371609587\n",
      "epoch:2867, weight:[1.59368742 1.13960683], bias:-1.292792224107953, loss:0.5627874333700483\n",
      "epoch:2868, weight:[1.59397174 1.13970868], bias:-1.2929866161902501, loss:0.562774531827666\n",
      "epoch:2869, weight:[1.59425606 1.13981049], bias:-1.2931809774463285, loss:0.5627616325327376\n",
      "epoch:2870, weight:[1.59454037 1.13991227], bias:-1.2933753078870804, loss:0.5627487354841887\n",
      "epoch:2871, weight:[1.59482467 1.140014  ], bias:-1.2935696075233916, loss:0.5627358406809461\n",
      "epoch:2872, weight:[1.59510897 1.1401157 ], bias:-1.2937638763661414, loss:0.5627229481219376\n",
      "epoch:2873, weight:[1.59539326 1.14021735], bias:-1.2939581144262031, loss:0.5627100578060916\n",
      "epoch:2874, weight:[1.59567755 1.14031897], bias:-1.2941523217144435, loss:0.5626971697323373\n",
      "epoch:2875, weight:[1.59596184 1.14042056], bias:-1.2943464982417234, loss:0.5626842838996043\n",
      "epoch:2876, weight:[1.59624612 1.1405221 ], bias:-1.2945406440188973, loss:0.5626714003068239\n",
      "epoch:2877, weight:[1.5965304 1.1406236], bias:-1.2947347590568132, loss:0.5626585189529273\n",
      "epoch:2878, weight:[1.59681467 1.14072507], bias:-1.2949288433663133, loss:0.5626456398368469\n",
      "epoch:2879, weight:[1.59709894 1.14082649], bias:-1.2951228969582331, loss:0.5626327629575157\n",
      "epoch:2880, weight:[1.5973832  1.14092788], bias:-1.2953169198434022, loss:0.5626198883138677\n",
      "epoch:2881, weight:[1.59766746 1.14102923], bias:-1.295510912032644, loss:0.5626070159048374\n",
      "epoch:2882, weight:[1.59795171 1.14113055], bias:-1.2957048735367758, loss:0.5625941457293605\n",
      "epoch:2883, weight:[1.59823596 1.14123182], bias:-1.2958988043666084, loss:0.5625812777863731\n",
      "epoch:2884, weight:[1.5985202  1.14133305], bias:-1.2960927045329467, loss:0.5625684120748122\n",
      "epoch:2885, weight:[1.59880444 1.14143425], bias:-1.2962865740465892, loss:0.5625555485936158\n",
      "epoch:2886, weight:[1.59908867 1.14153541], bias:-1.2964804129183285, loss:0.562542687341722\n",
      "epoch:2887, weight:[1.5993729  1.14163653], bias:-1.296674221158951, loss:0.5625298283180705\n",
      "epoch:2888, weight:[1.59965713 1.14173761], bias:-1.2968679987792369, loss:0.5625169715216013\n",
      "epoch:2889, weight:[1.59994135 1.14183866], bias:-1.2970617457899603, loss:0.5625041169512554\n",
      "epoch:2890, weight:[1.60022557 1.14193966], bias:-1.297255462201889, loss:0.5624912646059742\n",
      "epoch:2891, weight:[1.60050978 1.14204063], bias:-1.297449148025785, loss:0.5624784144847004\n",
      "epoch:2892, weight:[1.60079398 1.14214156], bias:-1.2976428032724043, loss:0.5624655665863773\n",
      "epoch:2893, weight:[1.60107818 1.14224245], bias:-1.2978364279524963, loss:0.5624527209099486\n",
      "epoch:2894, weight:[1.60136238 1.1423433 ], bias:-1.2980300220768046, loss:0.5624398774543591\n",
      "epoch:2895, weight:[1.60164657 1.14244412], bias:-1.2982235856560669, loss:0.5624270362185547\n",
      "epoch:2896, weight:[1.60193076 1.14254489], bias:-1.2984171187010147, loss:0.5624141972014812\n",
      "epoch:2897, weight:[1.60221494 1.14264563], bias:-1.2986106212223734, loss:0.5624013604020863\n",
      "epoch:2898, weight:[1.60249912 1.14274633], bias:-1.2988040932308622, loss:0.5623885258193174\n",
      "epoch:2899, weight:[1.6027833 1.142847 ], bias:-1.2989975347371945, loss:0.5623756934521233\n",
      "epoch:2900, weight:[1.60306746 1.14294762], bias:-1.2991909457520776, loss:0.5623628632994532\n",
      "epoch:2901, weight:[1.60335163 1.14304821], bias:-1.299384326286213, loss:0.5623500353602576\n",
      "epoch:2902, weight:[1.60363579 1.14314875], bias:-1.299577676350296, loss:0.562337209633487\n",
      "epoch:2903, weight:[1.60391994 1.14324926], bias:-1.2997709959550157, loss:0.5623243861180935\n",
      "epoch:2904, weight:[1.60420409 1.14334974], bias:-1.2999642851110553, loss:0.5623115648130292\n",
      "epoch:2905, weight:[1.60448824 1.14345017], bias:-1.3001575438290924, loss:0.562298745717248\n",
      "epoch:2906, weight:[1.60477238 1.14355057], bias:-1.3003507721197982, loss:0.5622859288297031\n",
      "epoch:2907, weight:[1.60505651 1.14365092], bias:-1.300543969993838, loss:0.5622731141493498\n",
      "epoch:2908, weight:[1.60534065 1.14375124], bias:-1.3007371374618713, loss:0.5622603016751432\n",
      "epoch:2909, weight:[1.60562477 1.14385153], bias:-1.3009302745345515, loss:0.56224749140604\n",
      "epoch:2910, weight:[1.60590889 1.14395177], bias:-1.3011233812225262, loss:0.5622346833409971\n",
      "epoch:2911, weight:[1.60619301 1.14405198], bias:-1.301316457536437, loss:0.5622218774789723\n",
      "epoch:2912, weight:[1.60647712 1.14415214], bias:-1.3015095034869197, loss:0.5622090738189243\n",
      "epoch:2913, weight:[1.60676123 1.14425227], bias:-1.3017025190846037, loss:0.5621962723598123\n",
      "epoch:2914, weight:[1.60704533 1.14435237], bias:-1.301895504340113, loss:0.5621834731005964\n",
      "epoch:2915, weight:[1.60732943 1.14445242], bias:-1.3020884592640656, loss:0.5621706760402374\n",
      "epoch:2916, weight:[1.60761352 1.14455244], bias:-1.3022813838670735, loss:0.5621578811776974\n",
      "epoch:2917, weight:[1.60789761 1.14465242], bias:-1.302474278159743, loss:0.5621450885119381\n",
      "epoch:2918, weight:[1.6081817  1.14475236], bias:-1.3026671421526743, loss:0.5621322980419232\n",
      "epoch:2919, weight:[1.60846577 1.14485226], bias:-1.3028599758564618, loss:0.5621195097666162\n",
      "epoch:2920, weight:[1.60874985 1.14495213], bias:-1.3030527792816942, loss:0.5621067236849822\n",
      "epoch:2921, weight:[1.60903392 1.14505195], bias:-1.3032455524389541, loss:0.5620939397959861\n",
      "epoch:2922, weight:[1.60931798 1.14515174], bias:-1.3034382953388186, loss:0.5620811580985943\n",
      "epoch:2923, weight:[1.60960204 1.1452515 ], bias:-1.3036310079918585, loss:0.562068378591774\n",
      "epoch:2924, weight:[1.6098861  1.14535121], bias:-1.303823690408639, loss:0.5620556012744925\n",
      "epoch:2925, weight:[1.61017015 1.14545089], bias:-1.30401634259972, loss:0.5620428261457183\n",
      "epoch:2926, weight:[1.61045419 1.14555053], bias:-1.3042089645756545, loss:0.5620300532044209\n",
      "epoch:2927, weight:[1.61073823 1.14565013], bias:-1.3044015563469906, loss:0.5620172824495698\n",
      "epoch:2928, weight:[1.61102227 1.14574969], bias:-1.3045941179242704, loss:0.5620045138801358\n",
      "epoch:2929, weight:[1.6113063  1.14584922], bias:-1.30478664931803, loss:0.5619917474950908\n",
      "epoch:2930, weight:[1.61159033 1.14594871], bias:-1.3049791505387998, loss:0.5619789832934063\n",
      "epoch:2931, weight:[1.61187435 1.14604816], bias:-1.3051716215971045, loss:0.5619662212740558\n",
      "epoch:2932, weight:[1.61215837 1.14614757], bias:-1.305364062503463, loss:0.5619534614360128\n",
      "epoch:2933, weight:[1.61244238 1.14624694], bias:-1.3055564732683886, loss:0.5619407037782516\n",
      "epoch:2934, weight:[1.61272638 1.14634628], bias:-1.3057488539023887, loss:0.5619279482997475\n",
      "epoch:2935, weight:[1.61301039 1.14644558], bias:-1.305941204415965, loss:0.5619151949994766\n",
      "epoch:2936, weight:[1.61329438 1.14654485], bias:-1.3061335248196135, loss:0.5619024438764154\n",
      "epoch:2937, weight:[1.61357838 1.14664407], bias:-1.3063258151238244, loss:0.5618896949295414\n",
      "epoch:2938, weight:[1.61386237 1.14674326], bias:-1.3065180753390822, loss:0.5618769481578328\n",
      "epoch:2939, weight:[1.61414635 1.14684241], bias:-1.3067103054758655, loss:0.5618642035602686\n",
      "epoch:2940, weight:[1.61443033 1.14694152], bias:-1.3069025055446477, loss:0.5618514611358282\n",
      "epoch:2941, weight:[1.6147143 1.1470406], bias:-1.307094675555896, loss:0.5618387208834922\n",
      "epoch:2942, weight:[1.61499827 1.14713964], bias:-1.3072868155200725, loss:0.5618259828022419\n",
      "epoch:2943, weight:[1.61528223 1.14723864], bias:-1.3074789254476331, loss:0.5618132468910592\n",
      "epoch:2944, weight:[1.61556619 1.1473376 ], bias:-1.3076710053490281, loss:0.5618005131489263\n",
      "epoch:2945, weight:[1.61585015 1.14743652], bias:-1.3078630552347026, loss:0.561787781574827\n",
      "epoch:2946, weight:[1.6161341  1.14753541], bias:-1.3080550751150952, loss:0.5617750521677455\n",
      "epoch:2947, weight:[1.61641804 1.14763426], bias:-1.3082470650006397, loss:0.5617623249266663\n",
      "epoch:2948, weight:[1.61670198 1.14773308], bias:-1.308439024901764, loss:0.5617495998505755\n",
      "epoch:2949, weight:[1.61698592 1.14783185], bias:-1.30863095482889, loss:0.5617368769384589\n",
      "epoch:2950, weight:[1.61726985 1.14793059], bias:-1.3088228547924343, loss:0.561724156189304\n",
      "epoch:2951, weight:[1.61755377 1.14802929], bias:-1.3090147248028081, loss:0.5617114376020984\n",
      "epoch:2952, weight:[1.61783769 1.14812796], bias:-1.3092065648704165, loss:0.561698721175831\n",
      "epoch:2953, weight:[1.61812161 1.14822658], bias:-1.3093983750056593, loss:0.5616860069094908\n",
      "epoch:2954, weight:[1.61840552 1.14832517], bias:-1.3095901552189306, loss:0.5616732948020676\n",
      "epoch:2955, weight:[1.61868942 1.14842373], bias:-1.3097819055206192, loss:0.5616605848525529\n",
      "epoch:2956, weight:[1.61897333 1.14852224], bias:-1.3099736259211079, loss:0.5616478770599375\n",
      "epoch:2957, weight:[1.61925722 1.14862072], bias:-1.3101653164307743, loss:0.5616351714232142\n",
      "epoch:2958, weight:[1.61954111 1.14871916], bias:-1.31035697705999, loss:0.5616224679413756\n",
      "epoch:2959, weight:[1.619825   1.14881756], bias:-1.3105486078191217, loss:0.5616097666134156\n",
      "epoch:2960, weight:[1.62010888 1.14891593], bias:-1.3107402087185298, loss:0.5615970674383283\n",
      "epoch:2961, weight:[1.62039276 1.14901426], bias:-1.3109317797685696, loss:0.5615843704151096\n",
      "epoch:2962, weight:[1.62067663 1.14911255], bias:-1.3111233209795907, loss:0.5615716755427548\n",
      "epoch:2963, weight:[1.6209605 1.1492108], bias:-1.3113148323619375, loss:0.5615589828202606\n",
      "epoch:2964, weight:[1.62124436 1.14930902], bias:-1.3115063139259486, loss:0.5615462922466248\n",
      "epoch:2965, weight:[1.62152822 1.1494072 ], bias:-1.311697765681957, loss:0.5615336038208449\n",
      "epoch:2966, weight:[1.62181207 1.14950535], bias:-1.3118891876402905, loss:0.5615209175419201\n",
      "epoch:2967, weight:[1.62209592 1.14960345], bias:-1.3120805798112711, loss:0.56150823340885\n",
      "epoch:2968, weight:[1.62237976 1.14970152], bias:-1.3122719422052154, loss:0.5614955514206347\n",
      "epoch:2969, weight:[1.6226636  1.14979955], bias:-1.3124632748324347, loss:0.5614828715762752\n",
      "epoch:2970, weight:[1.62294743 1.14989755], bias:-1.3126545777032346, loss:0.5614701938747736\n",
      "epoch:2971, weight:[1.62323126 1.14999551], bias:-1.3128458508279153, loss:0.5614575183151319\n",
      "epoch:2972, weight:[1.62351508 1.15009343], bias:-1.3130370942167715, loss:0.5614448448963537\n",
      "epoch:2973, weight:[1.6237989  1.15019131], bias:-1.3132283078800926, loss:0.5614321736174427\n",
      "epoch:2974, weight:[1.62408271 1.15028916], bias:-1.3134194918281625, loss:0.5614195044774033\n",
      "epoch:2975, weight:[1.62436652 1.15038697], bias:-1.3136106460712595, loss:0.5614068374752416\n",
      "epoch:2976, weight:[1.62465032 1.15048474], bias:-1.3138017706196568, loss:0.5613941726099627\n",
      "epoch:2977, weight:[1.62493412 1.15058248], bias:-1.3139928654836215, loss:0.5613815098805743\n",
      "epoch:2978, weight:[1.62521792 1.15068018], bias:-1.3141839306734162, loss:0.5613688492860835\n",
      "epoch:2979, weight:[1.62550171 1.15077784], bias:-1.3143749661992974, loss:0.5613561908254989\n",
      "epoch:2980, weight:[1.62578549 1.15087547], bias:-1.3145659720715164, loss:0.561343534497829\n",
      "epoch:2981, weight:[1.62606927 1.15097305], bias:-1.3147569483003192, loss:0.5613308803020838\n",
      "epoch:2982, weight:[1.62635304 1.15107061], bias:-1.314947894895946, loss:0.5613182282372736\n",
      "epoch:2983, weight:[1.62663681 1.15116812], bias:-1.3151388118686325, loss:0.5613055783024099\n",
      "epoch:2984, weight:[1.62692058 1.1512656 ], bias:-1.315329699228608, loss:0.561292930496504\n",
      "epoch:2985, weight:[1.62720434 1.15136304], bias:-1.3155205569860973, loss:0.5612802848185687\n",
      "epoch:2986, weight:[1.62748809 1.15146044], bias:-1.315711385151319, loss:0.5612676412676176\n",
      "epoch:2987, weight:[1.62777184 1.15155781], bias:-1.3159021837344869, loss:0.5612549998426644\n",
      "epoch:2988, weight:[1.62805558 1.15165514], bias:-1.3160929527458094, loss:0.5612423605427238\n",
      "epoch:2989, weight:[1.62833932 1.15175244], bias:-1.3162836921954892, loss:0.5612297233668113\n",
      "epoch:2990, weight:[1.62862306 1.15184969], bias:-1.3164744020937242, loss:0.5612170883139432\n",
      "epoch:2991, weight:[1.62890679 1.15194691], bias:-1.3166650824507067, loss:0.5612044553831361\n",
      "epoch:2992, weight:[1.62919051 1.1520441 ], bias:-1.3168557332766235, loss:0.561191824573408\n",
      "epoch:2993, weight:[1.62947423 1.15214125], bias:-1.3170463545816564, loss:0.561179195883777\n",
      "epoch:2994, weight:[1.62975795 1.15223836], bias:-1.3172369463759819, loss:0.5611665693132619\n",
      "epoch:2995, weight:[1.63004166 1.15233543], bias:-1.3174275086697707, loss:0.5611539448608824\n",
      "epoch:2996, weight:[1.63032536 1.15243247], bias:-1.3176180414731886, loss:0.5611413225256595\n",
      "epoch:2997, weight:[1.63060906 1.15252947], bias:-1.3178085447963963, loss:0.561128702306614\n",
      "epoch:2998, weight:[1.63089276 1.15262643], bias:-1.3179990186495487, loss:0.5611160842027677\n",
      "epoch:2999, weight:[1.63117645 1.15272336], bias:-1.3181894630427957, loss:0.5611034682131432\n",
      "epoch:3000, weight:[1.63146013 1.15282025], bias:-1.318379877986282, loss:0.561090854336764\n",
      "epoch:3001, weight:[1.63174381 1.1529171 ], bias:-1.318570263490147, loss:0.5610782425726536\n",
      "epoch:3002, weight:[1.63202749 1.15301392], bias:-1.3187606195645247, loss:0.5610656329198374\n",
      "epoch:3003, weight:[1.63231116 1.1531107 ], bias:-1.318950946219544, loss:0.56105302537734\n",
      "epoch:3004, weight:[1.63259482 1.15320745], bias:-1.3191412434653282, loss:0.5610404199441882\n",
      "epoch:3005, weight:[1.63287848 1.15330415], bias:-1.319331511311996, loss:0.5610278166194086\n",
      "epoch:3006, weight:[1.63316214 1.15340083], bias:-1.3195217497696605, loss:0.5610152154020285\n",
      "epoch:3007, weight:[1.63344579 1.15349746], bias:-1.3197119588484294, loss:0.5610026162910766\n",
      "epoch:3008, weight:[1.63372944 1.15359406], bias:-1.3199021385584053, loss:0.5609900192855815\n",
      "epoch:3009, weight:[1.63401308 1.15369062], bias:-1.3200922889096858, loss:0.5609774243845727\n",
      "epoch:3010, weight:[1.63429671 1.15378715], bias:-1.3202824099123631, loss:0.5609648315870808\n",
      "epoch:3011, weight:[1.63458034 1.15388364], bias:-1.3204725015765244, loss:0.5609522408921367\n",
      "epoch:3012, weight:[1.63486397 1.15398009], bias:-1.3206625639122513, loss:0.5609396522987725\n",
      "epoch:3013, weight:[1.63514759 1.1540765 ], bias:-1.3208525969296208, loss:0.5609270658060201\n",
      "epoch:3014, weight:[1.6354312  1.15417288], bias:-1.321042600638704, loss:0.5609144814129132\n",
      "epoch:3015, weight:[1.63571481 1.15426923], bias:-1.3212325750495673, loss:0.5609018991184855\n",
      "epoch:3016, weight:[1.63599842 1.15436553], bias:-1.3214225201722718, loss:0.5608893189217713\n",
      "epoch:3017, weight:[1.63628202 1.15446181], bias:-1.3216124360168735, loss:0.560876740821806\n",
      "epoch:3018, weight:[1.63656561 1.15455804], bias:-1.3218023225934235, loss:0.5608641648176257\n",
      "epoch:3019, weight:[1.6368492  1.15465424], bias:-1.321992179911967, loss:0.5608515909082669\n",
      "epoch:3020, weight:[1.63713279 1.1547504 ], bias:-1.3221820079825446, loss:0.5608390190927668\n",
      "epoch:3021, weight:[1.63741637 1.15484652], bias:-1.3223718068151917, loss:0.5608264493701639\n",
      "epoch:3022, weight:[1.63769995 1.15494261], bias:-1.3225615764199388, loss:0.5608138817394965\n",
      "epoch:3023, weight:[1.63798352 1.15503867], bias:-1.3227513168068106, loss:0.5608013161998043\n",
      "epoch:3024, weight:[1.63826708 1.15513468], bias:-1.3229410279858274, loss:0.5607887527501275\n",
      "epoch:3025, weight:[1.63855064 1.15523066], bias:-1.3231307099670038, loss:0.5607761913895066\n",
      "epoch:3026, weight:[1.6388342  1.15532661], bias:-1.3233203627603498, loss:0.5607636321169835\n",
      "epoch:3027, weight:[1.63911775 1.15542252], bias:-1.32350998637587, loss:0.5607510749316001\n",
      "epoch:3028, weight:[1.63940129 1.15551839], bias:-1.3236995808235636, loss:0.5607385198323998\n",
      "epoch:3029, weight:[1.63968483 1.15561422], bias:-1.3238891461134257, loss:0.5607259668184255\n",
      "epoch:3030, weight:[1.63996837 1.15571002], bias:-1.3240786822554451, loss:0.5607134158887219\n",
      "epoch:3031, weight:[1.6402519  1.15580579], bias:-1.3242681892596064, loss:0.5607008670423342\n",
      "epoch:3032, weight:[1.64053542 1.15590151], bias:-1.3244576671358887, loss:0.5606883202783078\n",
      "epoch:3033, weight:[1.64081894 1.1559972 ], bias:-1.3246471158942663, loss:0.5606757755956893\n",
      "epoch:3034, weight:[1.64110246 1.15609286], bias:-1.3248365355447083, loss:0.5606632329935253\n",
      "epoch:3035, weight:[1.64138597 1.15618848], bias:-1.3250259260971784, loss:0.560650692470864\n",
      "epoch:3036, weight:[1.64166947 1.15628406], bias:-1.3252152875616359, loss:0.5606381540267537\n",
      "epoch:3037, weight:[1.64195297 1.15637961], bias:-1.3254046199480347, loss:0.5606256176602435\n",
      "epoch:3038, weight:[1.64223647 1.15647512], bias:-1.3255939232663236, loss:0.5606130833703834\n",
      "epoch:3039, weight:[1.64251996 1.15657059], bias:-1.3257831975264467, loss:0.5606005511562236\n",
      "epoch:3040, weight:[1.64280344 1.15666603], bias:-1.3259724427383426, loss:0.5605880210168156\n",
      "epoch:3041, weight:[1.64308692 1.15676143], bias:-1.3261616589119454, loss:0.5605754929512112\n",
      "epoch:3042, weight:[1.6433704 1.1568568], bias:-1.3263508460571836, loss:0.5605629669584627\n",
      "epoch:3043, weight:[1.64365387 1.15695213], bias:-1.3265400041839812, loss:0.5605504430376237\n",
      "epoch:3044, weight:[1.64393733 1.15704742], bias:-1.326729133302257, loss:0.560537921187748\n",
      "epoch:3045, weight:[1.64422079 1.15714268], bias:-1.3269182334219247, loss:0.5605254014078903\n",
      "epoch:3046, weight:[1.64450424 1.15723791], bias:-1.3271073045528932, loss:0.560512883697106\n",
      "epoch:3047, weight:[1.64478769 1.15733309], bias:-1.3272963467050662, loss:0.5605003680544507\n",
      "epoch:3048, weight:[1.64507114 1.15742824], bias:-1.3274853598883427, loss:0.5604878544789813\n",
      "epoch:3049, weight:[1.64535458 1.15752336], bias:-1.3276743441126164, loss:0.5604753429697552\n",
      "epoch:3050, weight:[1.64563801 1.15761844], bias:-1.3278632993877764, loss:0.5604628335258304\n",
      "epoch:3051, weight:[1.64592144 1.15771348], bias:-1.3280522257237064, loss:0.5604503261462657\n",
      "epoch:3052, weight:[1.64620486 1.15780849], bias:-1.3282411231302855, loss:0.5604378208301202\n",
      "epoch:3053, weight:[1.64648828 1.15790346], bias:-1.3284299916173878, loss:0.5604253175764543\n",
      "epoch:3054, weight:[1.6467717 1.1579984], bias:-1.3286188311948823, loss:0.5604128163843285\n",
      "epoch:3055, weight:[1.6470551 1.1580933], bias:-1.3288076418726331, loss:0.5604003172528045\n",
      "epoch:3056, weight:[1.64733851 1.15818816], bias:-1.3289964236604994, loss:0.5603878201809442\n",
      "epoch:3057, weight:[1.64762191 1.15828299], bias:-1.3291851765683356, loss:0.5603753251678105\n",
      "epoch:3058, weight:[1.6479053  1.15837778], bias:-1.3293739006059908, loss:0.560362832212467\n",
      "epoch:3059, weight:[1.64818869 1.15847254], bias:-1.3295625957833097, loss:0.5603503413139772\n",
      "epoch:3060, weight:[1.64847207 1.15856726], bias:-1.3297512621101317, loss:0.5603378524714068\n",
      "epoch:3061, weight:[1.64875545 1.15866194], bias:-1.3299398995962912, loss:0.5603253656838207\n",
      "epoch:3062, weight:[1.64903882 1.15875659], bias:-1.330128508251618, loss:0.5603128809502853\n",
      "epoch:3063, weight:[1.64932219 1.15885121], bias:-1.3303170880859372, loss:0.5603003982698674\n",
      "epoch:3064, weight:[1.64960555 1.15894579], bias:-1.3305056391090684, loss:0.5602879176416345\n",
      "epoch:3065, weight:[1.64988891 1.15904033], bias:-1.3306941613308267, loss:0.5602754390646547\n",
      "epoch:3066, weight:[1.65017226 1.15913484], bias:-1.3308826547610224, loss:0.5602629625379971\n",
      "epoch:3067, weight:[1.65045561 1.15922931], bias:-1.3310711194094604, loss:0.5602504880607311\n",
      "epoch:3068, weight:[1.65073895 1.15932374], bias:-1.3312595552859414, loss:0.5602380156319265\n",
      "epoch:3069, weight:[1.65102229 1.15941814], bias:-1.3314479624002609, loss:0.5602255452506549\n",
      "epoch:3070, weight:[1.65130562 1.15951251], bias:-1.3316363407622094, loss:0.5602130769159875\n",
      "epoch:3071, weight:[1.65158895 1.15960684], bias:-1.331824690381573, loss:0.5602006106269966\n",
      "epoch:3072, weight:[1.65187227 1.15970113], bias:-1.3320130112681323, loss:0.5601881463827548\n",
      "epoch:3073, weight:[1.65215558 1.15979539], bias:-1.3322013034316638, loss:0.5601756841823359\n",
      "epoch:3074, weight:[1.6524389  1.15988961], bias:-1.3323895668819385, loss:0.5601632240248141\n",
      "epoch:3075, weight:[1.6527222 1.1599838], bias:-1.332577801628723, loss:0.5601507659092644\n",
      "epoch:3076, weight:[1.6530055  1.16007795], bias:-1.332766007681779, loss:0.5601383098347621\n",
      "epoch:3077, weight:[1.6532888  1.16017207], bias:-1.3329541850508633, loss:0.5601258558003835\n",
      "epoch:3078, weight:[1.65357209 1.16026615], bias:-1.3331423337457278, loss:0.5601134038052057\n",
      "epoch:3079, weight:[1.65385537 1.16036019], bias:-1.3333304537761195, loss:0.5601009538483058\n",
      "epoch:3080, weight:[1.65413865 1.1604542 ], bias:-1.333518545151781, loss:0.5600885059287627\n",
      "epoch:3081, weight:[1.65442193 1.16054817], bias:-1.3337066078824498, loss:0.5600760600456546\n",
      "epoch:3082, weight:[1.6547052  1.16064211], bias:-1.3338946419778586, loss:0.5600636161980616\n",
      "epoch:3083, weight:[1.65498846 1.16073602], bias:-1.3340826474477354, loss:0.5600511743850634\n",
      "epoch:3084, weight:[1.65527172 1.16082988], bias:-1.3342706243018037, loss:0.5600387346057413\n",
      "epoch:3085, weight:[1.65555498 1.16092372], bias:-1.3344585725497815, loss:0.5600262968591765\n",
      "epoch:3086, weight:[1.65583823 1.16101751], bias:-1.3346464922013825, loss:0.5600138611444515\n",
      "epoch:3087, weight:[1.65612147 1.16111128], bias:-1.3348343832663159, loss:0.5600014274606491\n",
      "epoch:3088, weight:[1.65640471 1.161205  ], bias:-1.3350222457542853, loss:0.5599889958068526\n",
      "epoch:3089, weight:[1.65668795 1.16129869], bias:-1.3352100796749904, loss:0.5599765661821464\n",
      "epoch:3090, weight:[1.65697117 1.16139235], bias:-1.3353978850381256, loss:0.5599641385856151\n",
      "epoch:3091, weight:[1.6572544  1.16148597], bias:-1.335585661853381, loss:0.5599517130163445\n",
      "epoch:3092, weight:[1.65753762 1.16157955], bias:-1.3357734101304415, loss:0.5599392894734206\n",
      "epoch:3093, weight:[1.65782083 1.1616731 ], bias:-1.3359611298789873, loss:0.55992686795593\n",
      "epoch:3094, weight:[1.65810404 1.16176662], bias:-1.3361488211086943, loss:0.5599144484629609\n",
      "epoch:3095, weight:[1.65838724 1.1618601 ], bias:-1.336336483829233, loss:0.5599020309936008\n",
      "epoch:3096, weight:[1.65867044 1.16195354], bias:-1.33652411805027, loss:0.5598896155469385\n",
      "epoch:3097, weight:[1.65895363 1.16204695], bias:-1.3367117237814665, loss:0.5598772021220635\n",
      "epoch:3098, weight:[1.65923682 1.16214033], bias:-1.3368993010324792, loss:0.559864790718066\n",
      "epoch:3099, weight:[1.65952    1.16223366], bias:-1.3370868498129602, loss:0.5598523813340368\n",
      "epoch:3100, weight:[1.65980318 1.16232697], bias:-1.3372743701325567, loss:0.5598399739690673\n",
      "epoch:3101, weight:[1.66008635 1.16242024], bias:-1.3374618620009113, loss:0.5598275686222492\n",
      "epoch:3102, weight:[1.66036951 1.16251347], bias:-1.3376493254276622, loss:0.5598151652926758\n",
      "epoch:3103, weight:[1.66065268 1.16260667], bias:-1.3378367604224424, loss:0.55980276397944\n",
      "epoch:3104, weight:[1.66093583 1.16269983], bias:-1.3380241669948802, loss:0.559790364681636\n",
      "epoch:3105, weight:[1.66121898 1.16279296], bias:-1.3382115451546, loss:0.5597779673983585\n",
      "epoch:3106, weight:[1.66150213 1.16288605], bias:-1.3383988949112204, loss:0.5597655721287027\n",
      "epoch:3107, weight:[1.66178527 1.16297911], bias:-1.3385862162743563, loss:0.5597531788717647\n",
      "epoch:3108, weight:[1.6620684  1.16307213], bias:-1.3387735092536173, loss:0.559740787626641\n",
      "epoch:3109, weight:[1.66235153 1.16316512], bias:-1.3389607738586087, loss:0.5597283983924292\n",
      "epoch:3110, weight:[1.66263466 1.16325807], bias:-1.339148010098931, loss:0.5597160111682267\n",
      "epoch:3111, weight:[1.66291778 1.16335099], bias:-1.3393352179841802, loss:0.5597036259531323\n",
      "epoch:3112, weight:[1.66320089 1.16344387], bias:-1.3395223975239474, loss:0.5596912427462455\n",
      "epoch:3113, weight:[1.663484   1.16353672], bias:-1.339709548727819, loss:0.5596788615466657\n",
      "epoch:3114, weight:[1.6637671  1.16362953], bias:-1.3398966716053773, loss:0.5596664823534936\n",
      "epoch:3115, weight:[1.6640502  1.16372231], bias:-1.3400837661661993, loss:0.5596541051658305\n",
      "epoch:3116, weight:[1.6643333  1.16381505], bias:-1.3402708324198578, loss:0.5596417299827782\n",
      "epoch:3117, weight:[1.66461638 1.16390776], bias:-1.340457870375921, loss:0.5596293568034386\n",
      "epoch:3118, weight:[1.66489947 1.16400043], bias:-1.3406448800439519, loss:0.5596169856269156\n",
      "epoch:3119, weight:[1.66518254 1.16409307], bias:-1.3408318614335097, loss:0.5596046164523126\n",
      "epoch:3120, weight:[1.66546562 1.16418567], bias:-1.3410188145541486, loss:0.5595922492787339\n",
      "epoch:3121, weight:[1.66574868 1.16427824], bias:-1.3412057394154182, loss:0.5595798841052844\n",
      "epoch:3122, weight:[1.66603175 1.16437078], bias:-1.3413926360268635, loss:0.5595675209310701\n",
      "epoch:3123, weight:[1.6663148  1.16446328], bias:-1.3415795043980248, loss:0.559555159755197\n",
      "epoch:3124, weight:[1.66659785 1.16455574], bias:-1.341766344538438, loss:0.5595428005767723\n",
      "epoch:3125, weight:[1.6668809  1.16464817], bias:-1.3419531564576344, loss:0.5595304433949035\n",
      "epoch:3126, weight:[1.66716394 1.16474056], bias:-1.3421399401651406, loss:0.5595180882086989\n",
      "epoch:3127, weight:[1.66744698 1.16483292], bias:-1.3423266956704787, loss:0.5595057350172673\n",
      "epoch:3128, weight:[1.66773001 1.16492525], bias:-1.3425134229831661, loss:0.5594933838197181\n",
      "epoch:3129, weight:[1.66801303 1.16501754], bias:-1.342700122112716, loss:0.5594810346151616\n",
      "epoch:3130, weight:[1.66829605 1.16510979], bias:-1.3428867930686363, loss:0.5594686874027087\n",
      "epoch:3131, weight:[1.66857906 1.16520201], bias:-1.3430734358604315, loss:0.5594563421814707\n",
      "epoch:3132, weight:[1.66886207 1.1652942 ], bias:-1.3432600504976004, loss:0.5594439989505595\n",
      "epoch:3133, weight:[1.66914508 1.16538635], bias:-1.3434466369896378, loss:0.5594316577090882\n",
      "epoch:3134, weight:[1.66942808 1.16547846], bias:-1.3436331953460339, loss:0.5594193184561698\n",
      "epoch:3135, weight:[1.66971107 1.16557055], bias:-1.3438197255762743, loss:0.5594069811909184\n",
      "epoch:3136, weight:[1.66999406 1.16566259], bias:-1.3440062276898401, loss:0.5593946459124486\n",
      "epoch:3137, weight:[1.67027704 1.1657546 ], bias:-1.3441927016962079, loss:0.5593823126198756\n",
      "epoch:3138, weight:[1.67056002 1.16584658], bias:-1.3443791476048497, loss:0.5593699813123153\n",
      "epoch:3139, weight:[1.67084299 1.16593852], bias:-1.344565565425233, loss:0.5593576519888844\n",
      "epoch:3140, weight:[1.67112596 1.16603043], bias:-1.344751955166821, loss:0.5593453246486998\n",
      "epoch:3141, weight:[1.67140892 1.16612231], bias:-1.344938316839072, loss:0.5593329992908793\n",
      "epoch:3142, weight:[1.67169187 1.16621415], bias:-1.34512465045144, loss:0.5593206759145416\n",
      "epoch:3143, weight:[1.67197483 1.16630595], bias:-1.3453109560133745, loss:0.5593083545188053\n",
      "epoch:3144, weight:[1.67225777 1.16639772], bias:-1.3454972335343205, loss:0.5592960351027906\n",
      "epoch:3145, weight:[1.67254071 1.16648946], bias:-1.3456834830237185, loss:0.5592837176656175\n",
      "epoch:3146, weight:[1.67282365 1.16658116], bias:-1.3458697044910044, loss:0.5592714022064068\n",
      "epoch:3147, weight:[1.67310658 1.16667282], bias:-1.3460558979456096, loss:0.5592590887242805\n",
      "epoch:3148, weight:[1.6733895  1.16676446], bias:-1.3462420633969614, loss:0.5592467772183605\n",
      "epoch:3149, weight:[1.67367242 1.16685605], bias:-1.3464282008544821, loss:0.5592344676877694\n",
      "epoch:3150, weight:[1.67395533 1.16694762], bias:-1.34661431032759, loss:0.5592221601316312\n",
      "epoch:3151, weight:[1.67423824 1.16703914], bias:-1.3468003918256986, loss:0.5592098545490695\n",
      "epoch:3152, weight:[1.67452115 1.16713064], bias:-1.3469864453582168, loss:0.5591975509392095\n",
      "epoch:3153, weight:[1.67480404 1.1672221 ], bias:-1.3471724709345494, loss:0.5591852493011761\n",
      "epoch:3154, weight:[1.67508694 1.16731352], bias:-1.3473584685640967, loss:0.5591729496340955\n",
      "epoch:3155, weight:[1.67536982 1.16740491], bias:-1.3475444382562545, loss:0.5591606519370941\n",
      "epoch:3156, weight:[1.67565271 1.16749627], bias:-1.3477303800204141, loss:0.5591483562092994\n",
      "epoch:3157, weight:[1.67593558 1.16758759], bias:-1.3479162938659623, loss:0.559136062449839\n",
      "epoch:3158, weight:[1.67621845 1.16767888], bias:-1.3481021798022816, loss:0.5591237706578416\n",
      "epoch:3159, weight:[1.67650132 1.16777013], bias:-1.3482880378387498, loss:0.5591114808324359\n",
      "epoch:3160, weight:[1.67678418 1.16786135], bias:-1.3484738679847408, loss:0.5590991929727521\n",
      "epoch:3161, weight:[1.67706703 1.16795254], bias:-1.3486596702496234, loss:0.5590869070779202\n",
      "epoch:3162, weight:[1.67734988 1.16804369], bias:-1.3488454446427625, loss:0.5590746231470712\n",
      "epoch:3163, weight:[1.67763273 1.16813481], bias:-1.3490311911735184, loss:0.5590623411793366\n",
      "epoch:3164, weight:[1.67791557 1.16822589], bias:-1.349216909851247, loss:0.559050061173849\n",
      "epoch:3165, weight:[1.6781984  1.16831693], bias:-1.3494026006852997, loss:0.5590377831297411\n",
      "epoch:3166, weight:[1.67848123 1.16840795], bias:-1.3495882636850236, loss:0.5590255070461458\n",
      "epoch:3167, weight:[1.67876405 1.16849893], bias:-1.3497738988597614, loss:0.5590132329221978\n",
      "epoch:3168, weight:[1.67904687 1.16858987], bias:-1.3499595062188512, loss:0.5590009607570315\n",
      "epoch:3169, weight:[1.67932968 1.16868078], bias:-1.350145085771627, loss:0.5589886905497823\n",
      "epoch:3170, weight:[1.67961249 1.16877166], bias:-1.3503306375274184, loss:0.558976422299586\n",
      "epoch:3171, weight:[1.67989529 1.1688625 ], bias:-1.3505161614955505, loss:0.5589641560055791\n",
      "epoch:3172, weight:[1.68017809 1.16895331], bias:-1.350701657685344, loss:0.5589518916668991\n",
      "epoch:3173, weight:[1.68046088 1.16904408], bias:-1.3508871261061148, loss:0.5589396292826835\n",
      "epoch:3174, weight:[1.68074367 1.16913482], bias:-1.3510725667671755, loss:0.5589273688520705\n",
      "epoch:3175, weight:[1.68102645 1.16922553], bias:-1.3512579796778335, loss:0.5589151103741993\n",
      "epoch:3176, weight:[1.68130922 1.1693162 ], bias:-1.351443364847392, loss:0.5589028538482099\n",
      "epoch:3177, weight:[1.68159199 1.16940684], bias:-1.35162872228515, loss:0.5588905992732419\n",
      "epoch:3178, weight:[1.68187475 1.16949744], bias:-1.3518140520004018, loss:0.5588783466484366\n",
      "epoch:3179, weight:[1.68215751 1.16958801], bias:-1.3519993540024378, loss:0.5588660959729351\n",
      "epoch:3180, weight:[1.68244027 1.16967855], bias:-1.3521846283005436, loss:0.5588538472458798\n",
      "epoch:3181, weight:[1.68272301 1.16976905], bias:-1.3523698749040007, loss:0.5588416004664132\n",
      "epoch:3182, weight:[1.68300576 1.16985952], bias:-1.3525550938220865, loss:0.5588293556336789\n",
      "epoch:3183, weight:[1.68328849 1.16994995], bias:-1.3527402850640735, loss:0.5588171127468202\n",
      "epoch:3184, weight:[1.68357123 1.17004035], bias:-1.3529254486392304, loss:0.5588048718049822\n",
      "epoch:3185, weight:[1.68385395 1.17013071], bias:-1.3531105845568212, loss:0.5587926328073097\n",
      "epoch:3186, weight:[1.68413667 1.17022105], bias:-1.353295692826106, loss:0.5587803957529487\n",
      "epoch:3187, weight:[1.68441939 1.17031134], bias:-1.3534807734563399, loss:0.5587681606410454\n",
      "epoch:3188, weight:[1.6847021  1.17040161], bias:-1.3536658264567742, loss:0.5587559274707468\n",
      "epoch:3189, weight:[1.6849848  1.17049184], bias:-1.353850851836656, loss:0.5587436962412003\n",
      "epoch:3190, weight:[1.6852675  1.17058203], bias:-1.3540358496052278, loss:0.5587314669515545\n",
      "epoch:3191, weight:[1.6855502  1.17067219], bias:-1.3542208197717278, loss:0.5587192396009578\n",
      "epoch:3192, weight:[1.68583289 1.17076232], bias:-1.35440576234539, loss:0.5587070141885598\n",
      "epoch:3193, weight:[1.68611557 1.17085241], bias:-1.354590677335444, loss:0.5586947907135106\n",
      "epoch:3194, weight:[1.68639825 1.17094247], bias:-1.354775564751115, loss:0.5586825691749605\n",
      "epoch:3195, weight:[1.68668092 1.1710325 ], bias:-1.3549604246016245, loss:0.558670349572061\n",
      "epoch:3196, weight:[1.68696359 1.17112249], bias:-1.355145256896189, loss:0.5586581319039635\n",
      "epoch:3197, weight:[1.68724625 1.17121245], bias:-1.3553300616440211, loss:0.5586459161698211\n",
      "epoch:3198, weight:[1.6875289  1.17130238], bias:-1.355514838854329, loss:0.5586337023687862\n",
      "epoch:3199, weight:[1.68781155 1.17139227], bias:-1.3556995885363168, loss:0.5586214905000129\n",
      "epoch:3200, weight:[1.6880942  1.17148212], bias:-1.355884310699184, loss:0.5586092805626552\n",
      "epoch:3201, weight:[1.68837684 1.17157195], bias:-1.3560690053521263, loss:0.5585970725558679\n",
      "epoch:3202, weight:[1.68865947 1.17166174], bias:-1.3562536725043346, loss:0.5585848664788066\n",
      "epoch:3203, weight:[1.6889421  1.17175149], bias:-1.356438312164996, loss:0.5585726623306272\n",
      "epoch:3204, weight:[1.68922473 1.17184121], bias:-1.3566229243432932, loss:0.5585604601104864\n",
      "epoch:3205, weight:[1.68950734 1.1719309 ], bias:-1.3568075090484046, loss:0.5585482598175416\n",
      "epoch:3206, weight:[1.68978996 1.17202056], bias:-1.3569920662895043, loss:0.5585360614509505\n",
      "epoch:3207, weight:[1.69007256 1.17211018], bias:-1.3571765960757622, loss:0.5585238650098717\n",
      "epoch:3208, weight:[1.69035517 1.17219977], bias:-1.357361098416344, loss:0.5585116704934641\n",
      "epoch:3209, weight:[1.69063776 1.17228932], bias:-1.3575455733204111, loss:0.5584994779008873\n",
      "epoch:3210, weight:[1.69092035 1.17237884], bias:-1.3577300207971208, loss:0.5584872872313016\n",
      "epoch:3211, weight:[1.69120294 1.17246833], bias:-1.357914440855626, loss:0.5584750984838681\n",
      "epoch:3212, weight:[1.69148552 1.17255778], bias:-1.3580988335050757, loss:0.5584629116577479\n",
      "epoch:3213, weight:[1.69176809 1.1726472 ], bias:-1.3582831987546142, loss:0.558450726752103\n",
      "epoch:3214, weight:[1.69205066 1.17273658], bias:-1.358467536613382, loss:0.5584385437660966\n",
      "epoch:3215, weight:[1.69233322 1.17282594], bias:-1.3586518470905151, loss:0.5584263626988913\n",
      "epoch:3216, weight:[1.69261578 1.17291525], bias:-1.3588361301951455, loss:0.5584141835496514\n",
      "epoch:3217, weight:[1.69289834 1.17300454], bias:-1.359020385936401, loss:0.558402006317541\n",
      "epoch:3218, weight:[1.69318088 1.17309379], bias:-1.359204614323405, loss:0.5583898310017253\n",
      "epoch:3219, weight:[1.69346342 1.17318301], bias:-1.3593888153652767, loss:0.5583776576013698\n",
      "epoch:3220, weight:[1.69374596 1.17327219], bias:-1.3595729890711314, loss:0.5583654861156409\n",
      "epoch:3221, weight:[1.69402849 1.17336134], bias:-1.35975713545008, loss:0.5583533165437052\n",
      "epoch:3222, weight:[1.69431102 1.17345046], bias:-1.359941254511229, loss:0.5583411488847301\n",
      "epoch:3223, weight:[1.69459354 1.17353954], bias:-1.3601253462636813, loss:0.5583289831378838\n",
      "epoch:3224, weight:[1.69487605 1.17362859], bias:-1.3603094107165352, loss:0.5583168193023347\n",
      "epoch:3225, weight:[1.69515856 1.17371761], bias:-1.3604934478788848, loss:0.558304657377252\n",
      "epoch:3226, weight:[1.69544106 1.17380659], bias:-1.3606774577598202, loss:0.5582924973618053\n",
      "epoch:3227, weight:[1.69572356 1.17389554], bias:-1.3608614403684272, loss:0.5582803392551655\n",
      "epoch:3228, weight:[1.69600605 1.17398446], bias:-1.3610453957137876, loss:0.558268183056503\n",
      "epoch:3229, weight:[1.69628854 1.17407334], bias:-1.3612293238049789, loss:0.5582560287649896\n",
      "epoch:3230, weight:[1.69657102 1.17416219], bias:-1.3614132246510744, loss:0.5582438763797973\n",
      "epoch:3231, weight:[1.6968535  1.17425101], bias:-1.3615970982611434, loss:0.5582317259000991\n",
      "epoch:3232, weight:[1.69713597 1.17433979], bias:-1.3617809446442508, loss:0.5582195773250677\n",
      "epoch:3233, weight:[1.69741843 1.17442854], bias:-1.3619647638094579, loss:0.5582074306538775\n",
      "epoch:3234, weight:[1.69770089 1.17451726], bias:-1.362148555765821, loss:0.5581952858857029\n",
      "epoch:3235, weight:[1.69798335 1.17460594], bias:-1.3623323205223932, loss:0.5581831430197188\n",
      "epoch:3236, weight:[1.69826579 1.17469459], bias:-1.3625160580882227, loss:0.5581710020551012\n",
      "epoch:3237, weight:[1.69854824 1.17478321], bias:-1.362699768472354, loss:0.5581588629910258\n",
      "epoch:3238, weight:[1.69883067 1.17487179], bias:-1.3628834516838275, loss:0.5581467258266698\n",
      "epoch:3239, weight:[1.69911311 1.17496034], bias:-1.3630671077316792, loss:0.5581345905612104\n",
      "epoch:3240, weight:[1.69939553 1.17504886], bias:-1.3632507366249411, loss:0.5581224571938258\n",
      "epoch:3241, weight:[1.69967795 1.17513734], bias:-1.363434338372641, loss:0.5581103257236947\n",
      "epoch:3242, weight:[1.69996037 1.17522579], bias:-1.3636179129838029, loss:0.5580981961499959\n",
      "epoch:3243, weight:[1.70024278 1.17531421], bias:-1.3638014604674462, loss:0.5580860684719092\n",
      "epoch:3244, weight:[1.70052518 1.17540259], bias:-1.3639849808325866, loss:0.558073942688615\n",
      "epoch:3245, weight:[1.70080758 1.17549094], bias:-1.3641684740882354, loss:0.5580618187992944\n",
      "epoch:3246, weight:[1.70108998 1.17557926], bias:-1.3643519402434001, loss:0.5580496968031287\n",
      "epoch:3247, weight:[1.70137236 1.17566755], bias:-1.364535379307084, loss:0.5580375766992997\n",
      "epoch:3248, weight:[1.70165475 1.1757558 ], bias:-1.364718791288286, loss:0.5580254584869905\n",
      "epoch:3249, weight:[1.70193712 1.17584401], bias:-1.3649021761960016, loss:0.5580133421653841\n",
      "epoch:3250, weight:[1.70221949 1.1759322 ], bias:-1.3650855340392214, loss:0.5580012277336643\n",
      "epoch:3251, weight:[1.70250186 1.17602035], bias:-1.3652688648269322, loss:0.5579891151910158\n",
      "epoch:3252, weight:[1.70278422 1.17610847], bias:-1.3654521685681171, loss:0.5579770045366232\n",
      "epoch:3253, weight:[1.70306657 1.17619656], bias:-1.3656354452717547, loss:0.557964895769672\n",
      "epoch:3254, weight:[1.70334892 1.17628461], bias:-1.3658186949468198, loss:0.557952788889349\n",
      "epoch:3255, weight:[1.70363127 1.17637263], bias:-1.3660019176022828, loss:0.5579406838948399\n",
      "epoch:3256, weight:[1.7039136  1.17646061], bias:-1.3661851132471103, loss:0.5579285807853327\n",
      "epoch:3257, weight:[1.70419594 1.17654857], bias:-1.366368281890265, loss:0.557916479560015\n",
      "epoch:3258, weight:[1.70447826 1.17663649], bias:-1.3665514235407048, loss:0.5579043802180753\n",
      "epoch:3259, weight:[1.70476058 1.17672438], bias:-1.3667345382073846, loss:0.5578922827587024\n",
      "epoch:3260, weight:[1.7050429  1.17681223], bias:-1.3669176258992544, loss:0.5578801871810862\n",
      "epoch:3261, weight:[1.70532521 1.17690005], bias:-1.3671006866252604, loss:0.5578680934844168\n",
      "epoch:3262, weight:[1.70560751 1.17698784], bias:-1.3672837203943449, loss:0.5578560016678846\n",
      "epoch:3263, weight:[1.70588981 1.1770756 ], bias:-1.367466727215446, loss:0.5578439117306814\n",
      "epoch:3264, weight:[1.70617211 1.17716332], bias:-1.3676497070974978, loss:0.5578318236719987\n",
      "epoch:3265, weight:[1.7064544  1.17725101], bias:-1.3678326600494306, loss:0.5578197374910293\n",
      "epoch:3266, weight:[1.70673668 1.17733867], bias:-1.3680155860801702, loss:0.5578076531869657\n",
      "epoch:3267, weight:[1.70701895 1.17742629], bias:-1.3681984851986386, loss:0.557795570759002\n",
      "epoch:3268, weight:[1.70730123 1.17751388], bias:-1.368381357413754, loss:0.5577834902063322\n",
      "epoch:3269, weight:[1.70758349 1.17760144], bias:-1.3685642027344302, loss:0.5577714115281508\n",
      "epoch:3270, weight:[1.70786575 1.17768896], bias:-1.3687470211695774, loss:0.5577593347236536\n",
      "epoch:3271, weight:[1.70814801 1.17777646], bias:-1.368929812728101, loss:0.5577472597920361\n",
      "epoch:3272, weight:[1.70843025 1.17786392], bias:-1.3691125774189035, loss:0.5577351867324948\n",
      "epoch:3273, weight:[1.7087125  1.17795134], bias:-1.3692953152508824, loss:0.5577231155442267\n",
      "epoch:3274, weight:[1.70899474 1.17803874], bias:-1.3694780262329318, loss:0.5577110462264295\n",
      "epoch:3275, weight:[1.70927697 1.1781261 ], bias:-1.3696607103739415, loss:0.5576989787783014\n",
      "epoch:3276, weight:[1.70955919 1.17821343], bias:-1.3698433676827977, loss:0.5576869131990411\n",
      "epoch:3277, weight:[1.70984141 1.17830072], bias:-1.3700259981683818, loss:0.5576748494878477\n",
      "epoch:3278, weight:[1.71012363 1.17838799], bias:-1.370208601839572, loss:0.5576627876439214\n",
      "epoch:3279, weight:[1.71040584 1.17847522], bias:-1.3703911787052423, loss:0.5576507276664623\n",
      "epoch:3280, weight:[1.71068804 1.17856242], bias:-1.3705737287742625, loss:0.5576386695546713\n",
      "epoch:3281, weight:[1.71097024 1.17864958], bias:-1.3707562520554986, loss:0.5576266133077505\n",
      "epoch:3282, weight:[1.71125244 1.17873671], bias:-1.3709387485578124, loss:0.5576145589249016\n",
      "epoch:3283, weight:[1.71153462 1.17882381], bias:-1.371121218290062, loss:0.5576025064053272\n",
      "epoch:3284, weight:[1.7118168  1.17891088], bias:-1.3713036612611016, loss:0.5575904557482306\n",
      "epoch:3285, weight:[1.71209898 1.17899791], bias:-1.371486077479781, loss:0.5575784069528162\n",
      "epoch:3286, weight:[1.71238115 1.17908491], bias:-1.3716684669549464, loss:0.5575663600182875\n",
      "epoch:3287, weight:[1.71266332 1.17917188], bias:-1.3718508296954397, loss:0.5575543149438502\n",
      "epoch:3288, weight:[1.71294548 1.17925882], bias:-1.3720331657100993, loss:0.5575422717287092\n",
      "epoch:3289, weight:[1.71322763 1.17934572], bias:-1.372215475007759, loss:0.5575302303720707\n",
      "epoch:3290, weight:[1.71350978 1.17943259], bias:-1.3723977575972497, loss:0.5575181908731418\n",
      "epoch:3291, weight:[1.71379192 1.17951943], bias:-1.372580013487397, loss:0.5575061532311292\n",
      "epoch:3292, weight:[1.71407406 1.17960624], bias:-1.3727622426870238, loss:0.5574941174452408\n",
      "epoch:3293, weight:[1.71435619 1.17969301], bias:-1.3729444452049482, loss:0.5574820835146848\n",
      "epoch:3294, weight:[1.71463831 1.17977975], bias:-1.3731266210499846, loss:0.5574700514386702\n",
      "epoch:3295, weight:[1.71492043 1.17986646], bias:-1.3733087702309437, loss:0.5574580212164063\n",
      "epoch:3296, weight:[1.71520255 1.17995314], bias:-1.3734908927566318, loss:0.5574459928471032\n",
      "epoch:3297, weight:[1.71548466 1.18003978], bias:-1.3736729886358516, loss:0.5574339663299713\n",
      "epoch:3298, weight:[1.71576676 1.18012639], bias:-1.373855057877402, loss:0.5574219416642221\n",
      "epoch:3299, weight:[1.71604886 1.18021297], bias:-1.3740371004900778, loss:0.5574099188490669\n",
      "epoch:3300, weight:[1.71633095 1.18029952], bias:-1.3742191164826696, loss:0.5573978978837179\n",
      "epoch:3301, weight:[1.71661303 1.18038603], bias:-1.3744011058639645, loss:0.5573858787673879\n",
      "epoch:3302, weight:[1.71689511 1.18047251], bias:-1.3745830686427454, loss:0.5573738614992905\n",
      "epoch:3303, weight:[1.71717719 1.18055896], bias:-1.3747650048277915, loss:0.5573618460786391\n",
      "epoch:3304, weight:[1.71745926 1.18064538], bias:-1.3749469144278779, loss:0.5573498325046486\n",
      "epoch:3305, weight:[1.71774132 1.18073176], bias:-1.3751287974517759, loss:0.5573378207765338\n",
      "epoch:3306, weight:[1.71802338 1.18081811], bias:-1.375310653908253, loss:0.5573258108935103\n",
      "epoch:3307, weight:[1.71830543 1.18090443], bias:-1.3754924838060725, loss:0.557313802854794\n",
      "epoch:3308, weight:[1.71858748 1.18099072], bias:-1.375674287153994, loss:0.5573017966596019\n",
      "epoch:3309, weight:[1.71886952 1.18107697], bias:-1.3758560639607733, loss:0.5572897923071509\n",
      "epoch:3310, weight:[1.71915155 1.18116319], bias:-1.3760378142351621, loss:0.557277789796659\n",
      "epoch:3311, weight:[1.71943358 1.18124938], bias:-1.3762195379859083, loss:0.5572657891273444\n",
      "epoch:3312, weight:[1.71971561 1.18133554], bias:-1.3764012352217558, loss:0.5572537902984259\n",
      "epoch:3313, weight:[1.71999763 1.18142167], bias:-1.376582905951445, loss:0.5572417933091229\n",
      "epoch:3314, weight:[1.72027964 1.18150776], bias:-1.3767645501837118, loss:0.5572297981586556\n",
      "epoch:3315, weight:[1.72056165 1.18159382], bias:-1.3769461679272887, loss:0.5572178048462443\n",
      "epoch:3316, weight:[1.72084365 1.18167985], bias:-1.3771277591909044, loss:0.5572058133711102\n",
      "epoch:3317, weight:[1.72112564 1.18176584], bias:-1.3773093239832832, loss:0.5571938237324748\n",
      "epoch:3318, weight:[1.72140763 1.18185181], bias:-1.3774908623131459, loss:0.5571818359295605\n",
      "epoch:3319, weight:[1.72168962 1.18193774], bias:-1.3776723741892094, loss:0.5571698499615898\n",
      "epoch:3320, weight:[1.7219716  1.18202364], bias:-1.3778538596201868, loss:0.5571578658277859\n",
      "epoch:3321, weight:[1.72225357 1.18210951], bias:-1.3780353186147871, loss:0.5571458835273727\n",
      "epoch:3322, weight:[1.72253554 1.18219534], bias:-1.3782167511817158, loss:0.5571339030595746\n",
      "epoch:3323, weight:[1.7228175  1.18228115], bias:-1.3783981573296742, loss:0.5571219244236166\n",
      "epoch:3324, weight:[1.72309945 1.18236692], bias:-1.37857953706736, loss:0.557109947618724\n",
      "epoch:3325, weight:[1.7233814  1.18245265], bias:-1.3787608904034667, loss:0.5570979726441229\n",
      "epoch:3326, weight:[1.72366335 1.18253836], bias:-1.3789422173466845, loss:0.5570859994990396\n",
      "epoch:3327, weight:[1.72394529 1.18262404], bias:-1.3791235179056993, loss:0.5570740281827012\n",
      "epoch:3328, weight:[1.72422722 1.18270968], bias:-1.3793047920891932, loss:0.5570620586943359\n",
      "epoch:3329, weight:[1.72450915 1.18279529], bias:-1.3794860399058448, loss:0.5570500910331713\n",
      "epoch:3330, weight:[1.72479107 1.18288087], bias:-1.3796672613643286, loss:0.5570381251984364\n",
      "epoch:3331, weight:[1.72507298 1.18296641], bias:-1.379848456473315, loss:0.5570261611893603\n",
      "epoch:3332, weight:[1.72535489 1.18305193], bias:-1.3800296252414712, loss:0.5570141990051728\n",
      "epoch:3333, weight:[1.7256368  1.18313741], bias:-1.3802107676774602, loss:0.5570022386451045\n",
      "epoch:3334, weight:[1.7259187  1.18322286], bias:-1.3803918837899412, loss:0.5569902801083859\n",
      "epoch:3335, weight:[1.72620059 1.18330828], bias:-1.3805729735875696, loss:0.5569783233942488\n",
      "epoch:3336, weight:[1.72648248 1.18339366], bias:-1.380754037078997, loss:0.5569663685019252\n",
      "epoch:3337, weight:[1.72676436 1.18347902], bias:-1.3809350742728712, loss:0.5569544154306472\n",
      "epoch:3338, weight:[1.72704624 1.18356434], bias:-1.3811160851778361, loss:0.5569424641796478\n",
      "epoch:3339, weight:[1.72732811 1.18364963], bias:-1.381297069802532, loss:0.5569305147481614\n",
      "epoch:3340, weight:[1.72760997 1.18373489], bias:-1.381478028155595, loss:0.5569185671354214\n",
      "epoch:3341, weight:[1.72789183 1.18382011], bias:-1.381658960245658, loss:0.5569066213406627\n",
      "epoch:3342, weight:[1.72817368 1.18390531], bias:-1.3818398660813493, loss:0.5568946773631205\n",
      "epoch:3343, weight:[1.72845553 1.18399047], bias:-1.3820207456712943, loss:0.5568827352020306\n",
      "epoch:3344, weight:[1.72873737 1.1840756 ], bias:-1.3822015990241139, loss:0.5568707948566295\n",
      "epoch:3345, weight:[1.72901921 1.1841607 ], bias:-1.3823824261484257, loss:0.5568588563261535\n",
      "epoch:3346, weight:[1.72930104 1.18424577], bias:-1.3825632270528432, loss:0.5568469196098403\n",
      "epoch:3347, weight:[1.72958286 1.1843308 ], bias:-1.382744001745976, loss:0.5568349847069279\n",
      "epoch:3348, weight:[1.72986468 1.18441581], bias:-1.3829247502364304, loss:0.5568230516166545\n",
      "epoch:3349, weight:[1.73014649 1.18450078], bias:-1.3831054725328085, loss:0.556811120338259\n",
      "epoch:3350, weight:[1.7304283  1.18458572], bias:-1.3832861686437086, loss:0.5567991908709813\n",
      "epoch:3351, weight:[1.7307101  1.18467062], bias:-1.3834668385777256, loss:0.556787263214061\n",
      "epoch:3352, weight:[1.7309919 1.1847555], bias:-1.3836474823434504, loss:0.556775337366739\n",
      "epoch:3353, weight:[1.73127369 1.18484034], bias:-1.38382809994947, loss:0.5567634133282565\n",
      "epoch:3354, weight:[1.73155547 1.18492516], bias:-1.384008691404368, loss:0.5567514910978546\n",
      "epoch:3355, weight:[1.73183725 1.18500994], bias:-1.384189256716724, loss:0.556739570674776\n",
      "epoch:3356, weight:[1.73211902 1.18509469], bias:-1.3843697958951136, loss:0.556727652058263\n",
      "epoch:3357, weight:[1.73240079 1.1851794 ], bias:-1.384550308948109, loss:0.5567157352475594\n",
      "epoch:3358, weight:[1.73268255 1.18526409], bias:-1.3847307958842787, loss:0.5567038202419083\n",
      "epoch:3359, weight:[1.73296431 1.18534874], bias:-1.384911256712187, loss:0.5566919070405545\n",
      "epoch:3360, weight:[1.73324606 1.18543336], bias:-1.385091691440395, loss:0.5566799956427426\n",
      "epoch:3361, weight:[1.7335278  1.18551795], bias:-1.3852721000774597, loss:0.556668086047718\n",
      "epoch:3362, weight:[1.73380954 1.18560251], bias:-1.3854524826319345, loss:0.5566561782547269\n",
      "epoch:3363, weight:[1.73409127 1.18568704], bias:-1.3856328391123691, loss:0.5566442722630153\n",
      "epoch:3364, weight:[1.734373   1.18577154], bias:-1.385813169527309, loss:0.5566323680718303\n",
      "epoch:3365, weight:[1.73465472 1.185856  ], bias:-1.3859934738852968, loss:0.5566204656804193\n",
      "epoch:3366, weight:[1.73493643 1.18594043], bias:-1.3861737521948705, loss:0.5566085650880302\n",
      "epoch:3367, weight:[1.73521814 1.18602483], bias:-1.386354004464565, loss:0.5565966662939124\n",
      "epoch:3368, weight:[1.73549985 1.1861092 ], bias:-1.3865342307029112, loss:0.5565847692973139\n",
      "epoch:3369, weight:[1.73578154 1.18619354], bias:-1.3867144309184363, loss:0.5565728740974847\n",
      "epoch:3370, weight:[1.73606324 1.18627784], bias:-1.3868946051196638, loss:0.5565609806936751\n",
      "epoch:3371, weight:[1.73634492 1.18636212], bias:-1.3870747533151135, loss:0.5565490890851353\n",
      "epoch:3372, weight:[1.7366266  1.18644636], bias:-1.3872548755133014, loss:0.5565371992711171\n",
      "epoch:3373, weight:[1.73690828 1.18653057], bias:-1.3874349717227399, loss:0.5565253112508717\n",
      "epoch:3374, weight:[1.73718995 1.18661475], bias:-1.3876150419519375, loss:0.5565134250236515\n",
      "epoch:3375, weight:[1.73747161 1.1866989 ], bias:-1.3877950862093993, loss:0.556501540588709\n",
      "epoch:3376, weight:[1.73775327 1.18678302], bias:-1.3879751045036264, loss:0.556489657945298\n",
      "epoch:3377, weight:[1.73803492 1.1868671 ], bias:-1.3881550968431164, loss:0.5564777770926719\n",
      "epoch:3378, weight:[1.73831656 1.18695116], bias:-1.3883350632363631, loss:0.5564658980300851\n",
      "epoch:3379, weight:[1.7385982  1.18703518], bias:-1.3885150036918565, loss:0.5564540207567924\n",
      "epoch:3380, weight:[1.73887984 1.18711917], bias:-1.3886949182180832, loss:0.5564421452720492\n",
      "epoch:3381, weight:[1.73916146 1.18720313], bias:-1.388874806823526, loss:0.5564302715751115\n",
      "epoch:3382, weight:[1.73944309 1.18728706], bias:-1.3890546695166635, loss:0.5564183996652355\n",
      "epoch:3383, weight:[1.7397247  1.18737095], bias:-1.3892345063059715, loss:0.5564065295416782\n",
      "epoch:3384, weight:[1.74000631 1.18745482], bias:-1.3894143171999214, loss:0.5563946612036974\n",
      "epoch:3385, weight:[1.74028792 1.18753865], bias:-1.3895941022069813, loss:0.5563827946505504\n",
      "epoch:3386, weight:[1.74056952 1.18762246], bias:-1.3897738613356154, loss:0.5563709298814964\n",
      "epoch:3387, weight:[1.74085111 1.18770623], bias:-1.3899535945942845, loss:0.5563590668957938\n",
      "epoch:3388, weight:[1.7411327  1.18778997], bias:-1.3901333019914455, loss:0.5563472056927024\n",
      "epoch:3389, weight:[1.74141428 1.18787368], bias:-1.3903129835355514, loss:0.5563353462714824\n",
      "epoch:3390, weight:[1.74169586 1.18795735], bias:-1.3904926392350523, loss:0.5563234886313941\n",
      "epoch:3391, weight:[1.74197743 1.188041  ], bias:-1.3906722690983937, loss:0.5563116327716987\n",
      "epoch:3392, weight:[1.74225899 1.18812461], bias:-1.390851873134018, loss:0.5562997786916579\n",
      "epoch:3393, weight:[1.74254055 1.1882082 ], bias:-1.3910314513503639, loss:0.5562879263905336\n",
      "epoch:3394, weight:[1.7428221  1.18829175], bias:-1.3912110037558663, loss:0.5562760758675889\n",
      "epoch:3395, weight:[1.74310365 1.18837527], bias:-1.3913905303589564, loss:0.5562642271220862\n",
      "epoch:3396, weight:[1.74338519 1.18845876], bias:-1.391570031168062, loss:0.5562523801532896\n",
      "epoch:3397, weight:[1.74366673 1.18854222], bias:-1.3917495061916072, loss:0.5562405349604634\n",
      "epoch:3398, weight:[1.74394826 1.18862564], bias:-1.391928955438012, loss:0.5562286915428721\n",
      "epoch:3399, weight:[1.74422978 1.18870904], bias:-1.3921083789156936, loss:0.5562168498997812\n",
      "epoch:3400, weight:[1.7445113  1.18879241], bias:-1.3922877766330646, loss:0.5562050100304559\n",
      "epoch:3401, weight:[1.74479281 1.18887574], bias:-1.3924671485985347, loss:0.5561931719341627\n",
      "epoch:3402, weight:[1.74507431 1.18895904], bias:-1.3926464948205095, loss:0.5561813356101685\n",
      "epoch:3403, weight:[1.74535581 1.18904231], bias:-1.3928258153073911, loss:0.5561695010577405\n",
      "epoch:3404, weight:[1.74563731 1.18912555], bias:-1.3930051100675782, loss:0.5561576682761465\n",
      "epoch:3405, weight:[1.7459188  1.18920876], bias:-1.3931843791094656, loss:0.5561458372646547\n",
      "epoch:3406, weight:[1.74620028 1.18929194], bias:-1.3933636224414443, loss:0.5561340080225339\n",
      "epoch:3407, weight:[1.74648176 1.18937509], bias:-1.3935428400719023, loss:0.5561221805490535\n",
      "epoch:3408, weight:[1.74676323 1.1894582 ], bias:-1.3937220320092234, loss:0.5561103548434833\n",
      "epoch:3409, weight:[1.74704469 1.18954129], bias:-1.393901198261788, loss:0.5560985309050935\n",
      "epoch:3410, weight:[1.74732615 1.18962434], bias:-1.3940803388379728, loss:0.5560867087331552\n",
      "epoch:3411, weight:[1.7476076  1.18970736], bias:-1.394259453746151, loss:0.5560748883269393\n",
      "epoch:3412, weight:[1.74788905 1.18979036], bias:-1.3944385429946922, loss:0.5560630696857185\n",
      "epoch:3413, weight:[1.74817049 1.18987332], bias:-1.3946176065919622, loss:0.5560512528087644\n",
      "epoch:3414, weight:[1.74845193 1.18995625], bias:-1.3947966445463233, loss:0.5560394376953501\n",
      "epoch:3415, weight:[1.74873336 1.19003914], bias:-1.3949756568661345, loss:0.5560276243447494\n",
      "epoch:3416, weight:[1.74901478 1.19012201], bias:-1.3951546435597504, loss:0.5560158127562356\n",
      "epoch:3417, weight:[1.7492962  1.19020485], bias:-1.3953336046355227, loss:0.5560040029290833\n",
      "epoch:3418, weight:[1.74957761 1.19028765], bias:-1.3955125401017994, loss:0.5559921948625676\n",
      "epoch:3419, weight:[1.74985902 1.19037043], bias:-1.3956914499669248, loss:0.5559803885559638\n",
      "epoch:3420, weight:[1.75014042 1.19045317], bias:-1.3958703342392396, loss:0.5559685840085474\n",
      "epoch:3421, weight:[1.75042181 1.19053589], bias:-1.3960491929270809, loss:0.5559567812195957\n",
      "epoch:3422, weight:[1.7507032  1.19061857], bias:-1.396228026038782, loss:0.555944980188385\n",
      "epoch:3423, weight:[1.75098458 1.19070122], bias:-1.3964068335826731, loss:0.555933180914193\n",
      "epoch:3424, weight:[1.75126596 1.19078384], bias:-1.3965856155670806, loss:0.5559213833962975\n",
      "epoch:3425, weight:[1.75154733 1.19086643], bias:-1.396764372000327, loss:0.5559095876339771\n",
      "epoch:3426, weight:[1.7518287  1.19094899], bias:-1.396943102890732, loss:0.5558977936265106\n",
      "epoch:3427, weight:[1.75211006 1.19103151], bias:-1.3971218082466108, loss:0.5558860013731778\n",
      "epoch:3428, weight:[1.75239141 1.19111401], bias:-1.3973004880762754, loss:0.5558742108732582\n",
      "epoch:3429, weight:[1.75267276 1.19119648], bias:-1.3974791423880344, loss:0.5558624221260323\n",
      "epoch:3430, weight:[1.7529541  1.19127891], bias:-1.3976577711901927, loss:0.5558506351307814\n",
      "epoch:3431, weight:[1.75323543 1.19136132], bias:-1.3978363744910518, loss:0.5558388498867868\n",
      "epoch:3432, weight:[1.75351676 1.19144369], bias:-1.3980149522989094, loss:0.5558270663933306\n",
      "epoch:3433, weight:[1.75379809 1.19152603], bias:-1.3981935046220595, loss:0.5558152846496949\n",
      "epoch:3434, weight:[1.75407941 1.19160834], bias:-1.3983720314687929, loss:0.5558035046551629\n",
      "epoch:3435, weight:[1.75436072 1.19169062], bias:-1.3985505328473966, loss:0.5557917264090183\n",
      "epoch:3436, weight:[1.75464202 1.19177288], bias:-1.3987290087661544, loss:0.5557799499105447\n",
      "epoch:3437, weight:[1.75492332 1.1918551 ], bias:-1.3989074592333461, loss:0.5557681751590265\n",
      "epoch:3438, weight:[1.75520462 1.19193728], bias:-1.3990858842572482, loss:0.5557564021537493\n",
      "epoch:3439, weight:[1.75548591 1.19201944], bias:-1.3992642838461335, loss:0.5557446308939977\n",
      "epoch:3440, weight:[1.75576719 1.19210157], bias:-1.3994426580082715, loss:0.5557328613790585\n",
      "epoch:3441, weight:[1.75604847 1.19218367], bias:-1.399621006751928, loss:0.5557210936082175\n",
      "epoch:3442, weight:[1.75632974 1.19226573], bias:-1.3997993300853648, loss:0.5557093275807622\n",
      "epoch:3443, weight:[1.756611   1.19234777], bias:-1.3999776280168412, loss:0.5556975632959795\n",
      "epoch:3444, weight:[1.75689226 1.19242977], bias:-1.400155900554612, loss:0.555685800753158\n",
      "epoch:3445, weight:[1.75717351 1.19251175], bias:-1.400334147706929, loss:0.5556740399515854\n",
      "epoch:3446, weight:[1.75745476 1.19259369], bias:-1.4005123694820405, loss:0.5556622808905514\n",
      "epoch:3447, weight:[1.757736  1.1926756], bias:-1.400690565888191, loss:0.5556505235693447\n",
      "epoch:3448, weight:[1.75801723 1.19275749], bias:-1.4008687369336215, loss:0.5556387679872556\n",
      "epoch:3449, weight:[1.75829846 1.19283934], bias:-1.4010468826265694, loss:0.5556270141435748\n",
      "epoch:3450, weight:[1.75857969 1.19292116], bias:-1.4012250029752689, loss:0.5556152620375929\n",
      "epoch:3451, weight:[1.7588609  1.19300295], bias:-1.4014030979879504, loss:0.5556035116686012\n",
      "epoch:3452, weight:[1.75914211 1.19308471], bias:-1.401581167672841, loss:0.5555917630358923\n",
      "epoch:3453, weight:[1.75942332 1.19316644], bias:-1.4017592120381641, loss:0.5555800161387577\n",
      "epoch:3454, weight:[1.75970452 1.19324814], bias:-1.4019372310921396, loss:0.5555682709764906\n",
      "epoch:3455, weight:[1.75998571 1.19332981], bias:-1.402115224842984, loss:0.5555565275483847\n",
      "epoch:3456, weight:[1.7602669  1.19341145], bias:-1.4022931932989102, loss:0.5555447858537335\n",
      "epoch:3457, weight:[1.76054808 1.19349306], bias:-1.402471136468128, loss:0.5555330458918316\n",
      "epoch:3458, weight:[1.76082926 1.19357463], bias:-1.4026490543588428, loss:0.5555213076619738\n",
      "epoch:3459, weight:[1.76111043 1.19365618], bias:-1.4028269469792571, loss:0.5555095711634555\n",
      "epoch:3460, weight:[1.76139159 1.1937377 ], bias:-1.4030048143375702, loss:0.5554978363955723\n",
      "epoch:3461, weight:[1.76167275 1.19381918], bias:-1.4031826564419771, loss:0.5554861033576208\n",
      "epoch:3462, weight:[1.7619539  1.19390064], bias:-1.4033604733006702, loss:0.5554743720488978\n",
      "epoch:3463, weight:[1.76223505 1.19398206], bias:-1.4035382649218375, loss:0.5554626424687007\n",
      "epoch:3464, weight:[1.76251619 1.19406346], bias:-1.4037160313136643, loss:0.555450914616327\n",
      "epoch:3465, weight:[1.76279732 1.19414482], bias:-1.4038937724843317, loss:0.5554391884910751\n",
      "epoch:3466, weight:[1.76307845 1.19422616], bias:-1.404071488442018, loss:0.5554274640922438\n",
      "epoch:3467, weight:[1.76335957 1.19430746], bias:-1.4042491791948977, loss:0.5554157414191324\n",
      "epoch:3468, weight:[1.76364069 1.19438873], bias:-1.4044268447511414, loss:0.5554040204710406\n",
      "epoch:3469, weight:[1.7639218  1.19446997], bias:-1.4046044851189172, loss:0.5553923012472688\n",
      "epoch:3470, weight:[1.7642029  1.19455119], bias:-1.404782100306389, loss:0.5553805837471177\n",
      "epoch:3471, weight:[1.764484   1.19463237], bias:-1.4049596903217172, loss:0.5553688679698882\n",
      "epoch:3472, weight:[1.76476509 1.19471352], bias:-1.405137255173059, loss:0.5553571539148822\n",
      "epoch:3473, weight:[1.76504618 1.19479464], bias:-1.405314794868568, loss:0.5553454415814019\n",
      "epoch:3474, weight:[1.76532726 1.19487573], bias:-1.4054923094163947, loss:0.55533373096875\n",
      "epoch:3475, weight:[1.76560833 1.1949568 ], bias:-1.4056697988246856, loss:0.5553220220762297\n",
      "epoch:3476, weight:[1.7658894  1.19503783], bias:-1.405847263101584, loss:0.5553103149031444\n",
      "epoch:3477, weight:[1.76617046 1.19511883], bias:-1.4060247022552295, loss:0.5552986094487985\n",
      "epoch:3478, weight:[1.76645152 1.1951998 ], bias:-1.4062021162937586, loss:0.5552869057124962\n",
      "epoch:3479, weight:[1.76673257 1.19528074], bias:-1.406379505225304, loss:0.555275203693543\n",
      "epoch:3480, weight:[1.76701361 1.19536165], bias:-1.4065568690579957, loss:0.5552635033912443\n",
      "epoch:3481, weight:[1.76729465 1.19544253], bias:-1.4067342077999592, loss:0.5552518048049062\n",
      "epoch:3482, weight:[1.76757568 1.19552338], bias:-1.406911521459317, loss:0.5552401079338349\n",
      "epoch:3483, weight:[1.76785671 1.1956042 ], bias:-1.4070888100441885, loss:0.555228412777338\n",
      "epoch:3484, weight:[1.76813773 1.19568499], bias:-1.407266073562689, loss:0.5552167193347226\n",
      "epoch:3485, weight:[1.76841874 1.19576575], bias:-1.4074433120229308, loss:0.5552050276052968\n",
      "epoch:3486, weight:[1.76869975 1.19584647], bias:-1.4076205254330227, loss:0.5551933375883691\n",
      "epoch:3487, weight:[1.76898075 1.19592717], bias:-1.4077977138010702, loss:0.555181649283248\n",
      "epoch:3488, weight:[1.76926175 1.19600784], bias:-1.407974877135175, loss:0.5551699626892435\n",
      "epoch:3489, weight:[1.76954274 1.19608848], bias:-1.4081520154434355, loss:0.5551582778056652\n",
      "epoch:3490, weight:[1.76982372 1.19616909], bias:-1.4083291287339468, loss:0.5551465946318236\n",
      "epoch:3491, weight:[1.7701047  1.19624967], bias:-1.4085062170148004, loss:0.5551349131670293\n",
      "epoch:3492, weight:[1.77038567 1.19633022], bias:-1.4086832802940845, loss:0.555123233410594\n",
      "epoch:3493, weight:[1.77066664 1.19641073], bias:-1.4088603185798838, loss:0.5551115553618293\n",
      "epoch:3494, weight:[1.7709476  1.19649122], bias:-1.4090373318802798, loss:0.5550998790200474\n",
      "epoch:3495, weight:[1.77122855 1.19657168], bias:-1.4092143202033502, loss:0.5550882043845612\n",
      "epoch:3496, weight:[1.7715095  1.19665211], bias:-1.4093912835571696, loss:0.5550765314546838\n",
      "epoch:3497, weight:[1.77179044 1.19673251], bias:-1.409568221949809, loss:0.5550648602297289\n",
      "epoch:3498, weight:[1.77207138 1.19681288], bias:-1.409745135389336, loss:0.5550531907090109\n",
      "epoch:3499, weight:[1.77235231 1.19689322], bias:-1.4099220238838148, loss:0.5550415228918443\n",
      "epoch:3500, weight:[1.77263323 1.19697352], bias:-1.4100988874413063, loss:0.5550298567775444\n",
      "epoch:3501, weight:[1.77291415 1.1970538 ], bias:-1.410275726069868, loss:0.5550181923654264\n",
      "epoch:3502, weight:[1.77319506 1.19713405], bias:-1.4104525397775538, loss:0.5550065296548068\n",
      "epoch:3503, weight:[1.77347597 1.19721427], bias:-1.4106293285724143, loss:0.554994868645002\n",
      "epoch:3504, weight:[1.77375687 1.19729446], bias:-1.4108060924624968, loss:0.5549832093353292\n",
      "epoch:3505, weight:[1.77403776 1.19737462], bias:-1.410982831455845, loss:0.5549715517251056\n",
      "epoch:3506, weight:[1.77431865 1.19745475], bias:-1.4111595455604993, loss:0.5549598958136494\n",
      "epoch:3507, weight:[1.77459953 1.19753484], bias:-1.4113362347844967, loss:0.554948241600279\n",
      "epoch:3508, weight:[1.7748804  1.19761491], bias:-1.411512899135871, loss:0.5549365890843133\n",
      "epoch:3509, weight:[1.77516127 1.19769495], bias:-1.4116895386226522, loss:0.5549249382650716\n",
      "epoch:3510, weight:[1.77544214 1.19777496], bias:-1.4118661532528674, loss:0.5549132891418739\n",
      "epoch:3511, weight:[1.77572299 1.19785494], bias:-1.41204274303454, loss:0.5549016417140407\n",
      "epoch:3512, weight:[1.77600385 1.19793489], bias:-1.4122193079756897, loss:0.5548899959808923\n",
      "epoch:3513, weight:[1.77628469 1.19801481], bias:-1.4123958480843337, loss:0.5548783519417506\n",
      "epoch:3514, weight:[1.77656553 1.1980947 ], bias:-1.412572363368485, loss:0.5548667095959368\n",
      "epoch:3515, weight:[1.77684636 1.19817456], bias:-1.4127488538361537, loss:0.5548550689427735\n",
      "epoch:3516, weight:[1.77712719 1.19825439], bias:-1.4129253194953462, loss:0.5548434299815829\n",
      "epoch:3517, weight:[1.77740801 1.19833419], bias:-1.4131017603540657, loss:0.5548317927116888\n",
      "epoch:3518, weight:[1.77768883 1.19841397], bias:-1.4132781764203122, loss:0.5548201571324144\n",
      "epoch:3519, weight:[1.77796964 1.19849371], bias:-1.413454567702082, loss:0.5548085232430839\n",
      "epoch:3520, weight:[1.77825044 1.19857342], bias:-1.413630934207368, loss:0.5547968910430219\n",
      "epoch:3521, weight:[1.77853123 1.1986531 ], bias:-1.4138072759441602, loss:0.5547852605315531\n",
      "epoch:3522, weight:[1.77881203 1.19873275], bias:-1.413983592920445, loss:0.5547736317080035\n",
      "epoch:3523, weight:[1.77909281 1.19881238], bias:-1.414159885144205, loss:0.5547620045716989\n",
      "epoch:3524, weight:[1.77937359 1.19889197], bias:-1.4143361526234202, loss:0.5547503791219653\n",
      "epoch:3525, weight:[1.77965436 1.19897153], bias:-1.4145123953660665, loss:0.5547387553581301\n",
      "epoch:3526, weight:[1.77993513 1.19905107], bias:-1.4146886133801173, loss:0.5547271332795206\n",
      "epoch:3527, weight:[1.78021589 1.19913057], bias:-1.4148648066735419, loss:0.5547155128854642\n",
      "epoch:3528, weight:[1.78049664 1.19921004], bias:-1.4150409752543063, loss:0.5547038941752895\n",
      "epoch:3529, weight:[1.78077739 1.19928949], bias:-1.4152171191303735, loss:0.5546922771483255\n",
      "epoch:3530, weight:[1.78105813 1.1993689 ], bias:-1.4153932383097032, loss:0.5546806618039007\n",
      "epoch:3531, weight:[1.78133887 1.19944829], bias:-1.4155693328002514, loss:0.5546690481413455\n",
      "epoch:3532, weight:[1.7816196  1.19952765], bias:-1.4157454026099712, loss:0.5546574361599896\n",
      "epoch:3533, weight:[1.78190032 1.19960697], bias:-1.4159214477468116, loss:0.5546458258591638\n",
      "epoch:3534, weight:[1.78218104 1.19968627], bias:-1.416097468218719, loss:0.5546342172381992\n",
      "epoch:3535, weight:[1.78246175 1.19976554], bias:-1.4162734640336365, loss:0.5546226102964269\n",
      "epoch:3536, weight:[1.78274246 1.19984477], bias:-1.4164494351995032, loss:0.5546110050331793\n",
      "epoch:3537, weight:[1.78302316 1.19992398], bias:-1.4166253817242553, loss:0.5545994014477887\n",
      "epoch:3538, weight:[1.78330385 1.20000316], bias:-1.4168013036158258, loss:0.5545877995395881\n",
      "epoch:3539, weight:[1.78358454 1.20008231], bias:-1.416977200882144, loss:0.5545761993079108\n",
      "epoch:3540, weight:[1.78386522 1.20016143], bias:-1.417153073531136, loss:0.5545646007520906\n",
      "epoch:3541, weight:[1.78414589 1.20024052], bias:-1.4173289215707248, loss:0.5545530038714618\n",
      "epoch:3542, weight:[1.78442656 1.20031958], bias:-1.4175047450088298, loss:0.5545414086653593\n",
      "epoch:3543, weight:[1.78470722 1.20039861], bias:-1.4176805438533675, loss:0.554529815133118\n",
      "epoch:3544, weight:[1.78498788 1.20047761], bias:-1.4178563181122503, loss:0.5545182232740739\n",
      "epoch:3545, weight:[1.78526853 1.20055659], bias:-1.4180320677933882, loss:0.5545066330875628\n",
      "epoch:3546, weight:[1.78554918 1.20063553], bias:-1.4182077929046872, loss:0.5544950445729214\n",
      "epoch:3547, weight:[1.78582981 1.20071444], bias:-1.4183834934540502, loss:0.5544834577294868\n",
      "epoch:3548, weight:[1.78611045 1.20079333], bias:-1.418559169449377, loss:0.5544718725565965\n",
      "epoch:3549, weight:[1.78639107 1.20087218], bias:-1.418734820898564, loss:0.5544602890535884\n",
      "epoch:3550, weight:[1.78667169 1.20095101], bias:-1.4189104478095038, loss:0.5544487072198008\n",
      "epoch:3551, weight:[1.78695231 1.2010298 ], bias:-1.4190860501900864, loss:0.5544371270545726\n",
      "epoch:3552, weight:[1.78723291 1.20110857], bias:-1.4192616280481982, loss:0.5544255485572435\n",
      "epoch:3553, weight:[1.78751352 1.20118731], bias:-1.4194371813917221, loss:0.5544139717271528\n",
      "epoch:3554, weight:[1.78779411 1.20126602], bias:-1.4196127102285383, loss:0.5544023965636408\n",
      "epoch:3555, weight:[1.7880747  1.20134469], bias:-1.419788214566523, loss:0.5543908230660484\n",
      "epoch:3556, weight:[1.78835528 1.20142334], bias:-1.4199636944135494, loss:0.5543792512337166\n",
      "epoch:3557, weight:[1.78863586 1.20150196], bias:-1.4201391497774876, loss:0.5543676810659869\n",
      "epoch:3558, weight:[1.78891643 1.20158055], bias:-1.420314580666204, loss:0.5543561125622015\n",
      "epoch:3559, weight:[1.789197   1.20165912], bias:-1.4204899870875622, loss:0.5543445457217029\n",
      "epoch:3560, weight:[1.78947756 1.20173765], bias:-1.4206653690494222, loss:0.554332980543834\n",
      "epoch:3561, weight:[1.78975811 1.20181615], bias:-1.4208407265596408, loss:0.554321417027938\n",
      "epoch:3562, weight:[1.79003865 1.20189463], bias:-1.4210160596260712, loss:0.5543098551733591\n",
      "epoch:3563, weight:[1.79031919 1.20197307], bias:-1.421191368256564, loss:0.5542982949794415\n",
      "epoch:3564, weight:[1.79059973 1.20205149], bias:-1.4213666524589659, loss:0.55428673644553\n",
      "epoch:3565, weight:[1.79088026 1.20212987], bias:-1.4215419122411206, loss:0.5542751795709696\n",
      "epoch:3566, weight:[1.79116078 1.20220823], bias:-1.4217171476108685, loss:0.5542636243551059\n",
      "epoch:3567, weight:[1.79144129 1.20228656], bias:-1.4218923585760468, loss:0.5542520707972854\n",
      "epoch:3568, weight:[1.7917218  1.20236486], bias:-1.422067545144489, loss:0.5542405188968546\n",
      "epoch:3569, weight:[1.79200231 1.20244313], bias:-1.4222427073240262, loss:0.5542289686531601\n",
      "epoch:3570, weight:[1.7922828  1.20252137], bias:-1.4224178451224854, loss:0.5542174200655497\n",
      "epoch:3571, weight:[1.79256329 1.20259958], bias:-1.4225929585476906, loss:0.5542058731333713\n",
      "epoch:3572, weight:[1.79284378 1.20267776], bias:-1.4227680476074627, loss:0.5541943278559733\n",
      "epoch:3573, weight:[1.79312426 1.20275591], bias:-1.4229431123096192, loss:0.5541827842327042\n",
      "epoch:3574, weight:[1.79340473 1.20283404], bias:-1.4231181526619743, loss:0.5541712422629135\n",
      "epoch:3575, weight:[1.7936852  1.20291213], bias:-1.423293168672339, loss:0.554159701945951\n",
      "epoch:3576, weight:[1.79396566 1.2029902 ], bias:-1.423468160348521, loss:0.5541481632811665\n",
      "epoch:3577, weight:[1.79424611 1.20306824], bias:-1.423643127698325, loss:0.5541366262679109\n",
      "epoch:3578, weight:[1.79452656 1.20314624], bias:-1.423818070729552, loss:0.554125090905535\n",
      "epoch:3579, weight:[1.794807   1.20322422], bias:-1.42399298945, loss:0.5541135571933905\n",
      "epoch:3580, weight:[1.79508744 1.20330217], bias:-1.424167883867464, loss:0.5541020251308292\n",
      "epoch:3581, weight:[1.79536786 1.20338009], bias:-1.4243427539897355, loss:0.5540904947172035\n",
      "epoch:3582, weight:[1.79564829 1.20345798], bias:-1.4245175998246025, loss:0.5540789659518663\n",
      "epoch:3583, weight:[1.7959287  1.20353585], bias:-1.42469242137985, loss:0.554067438834171\n",
      "epoch:3584, weight:[1.79620912 1.20361368], bias:-1.4248672186632598, loss:0.5540559133634708\n",
      "epoch:3585, weight:[1.79648952 1.20369149], bias:-1.4250419916826107, loss:0.5540443895391204\n",
      "epoch:3586, weight:[1.79676992 1.20376926], bias:-1.425216740445678, loss:0.554032867360474\n",
      "epoch:3587, weight:[1.79705031 1.20384701], bias:-1.4253914649602333, loss:0.554021346826887\n",
      "epoch:3588, weight:[1.7973307  1.20392473], bias:-1.425566165234046, loss:0.5540098279377147\n",
      "epoch:3589, weight:[1.79761108 1.20400242], bias:-1.425740841274881, loss:0.5539983106923129\n",
      "epoch:3590, weight:[1.79789145 1.20408008], bias:-1.4259154930905016, loss:0.5539867950900383\n",
      "epoch:3591, weight:[1.79817182 1.20415771], bias:-1.4260901206886663, loss:0.5539752811302473\n",
      "epoch:3592, weight:[1.79845218 1.20423531], bias:-1.4262647240771311, loss:0.5539637688122975\n",
      "epoch:3593, weight:[1.79873253 1.20431288], bias:-1.4264393032636489, loss:0.5539522581355464\n",
      "epoch:3594, weight:[1.79901288 1.20439043], bias:-1.4266138582559689, loss:0.5539407490993522\n",
      "epoch:3595, weight:[1.79929322 1.20446794], bias:-1.4267883890618376, loss:0.5539292417030736\n",
      "epoch:3596, weight:[1.79957356 1.20454543], bias:-1.426962895688998, loss:0.5539177359460692\n",
      "epoch:3597, weight:[1.79985389 1.20462289], bias:-1.4271373781451897, loss:0.5539062318276989\n",
      "epoch:3598, weight:[1.80013421 1.20470032], bias:-1.4273118364381496, loss:0.5538947293473226\n",
      "epoch:3599, weight:[1.80041453 1.20477772], bias:-1.4274862705756113, loss:0.5538832285043005\n",
      "epoch:3600, weight:[1.80069484 1.20485509], bias:-1.4276606805653045, loss:0.5538717292979931\n",
      "epoch:3601, weight:[1.80097515 1.20493243], bias:-1.4278350664149564, loss:0.5538602317277619\n",
      "epoch:3602, weight:[1.80125545 1.20500975], bias:-1.4280094281322908, loss:0.5538487357929687\n",
      "epoch:3603, weight:[1.80153574 1.20508703], bias:-1.4281837657250285, loss:0.5538372414929752\n",
      "epoch:3604, weight:[1.80181603 1.20516429], bias:-1.4283580792008865, loss:0.5538257488271441\n",
      "epoch:3605, weight:[1.80209631 1.20524152], bias:-1.4285323685675793, loss:0.5538142577948384\n",
      "epoch:3606, weight:[1.80237658 1.20531872], bias:-1.4287066338328176, loss:0.5538027683954216\n",
      "epoch:3607, weight:[1.80265685 1.20539589], bias:-1.4288808750043092, loss:0.5537912806282571\n",
      "epoch:3608, weight:[1.80293711 1.20547303], bias:-1.429055092089759, loss:0.5537797944927098\n",
      "epoch:3609, weight:[1.80321737 1.20555014], bias:-1.429229285096868, loss:0.5537683099881439\n",
      "epoch:3610, weight:[1.80349762 1.20562723], bias:-1.4294034540333345, loss:0.553756827113925\n",
      "epoch:3611, weight:[1.80377786 1.20570428], bias:-1.4295775989068535, loss:0.553745345869418\n",
      "epoch:3612, weight:[1.8040581  1.20578131], bias:-1.429751719725117, loss:0.5537338662539896\n",
      "epoch:3613, weight:[1.80433833 1.20585831], bias:-1.4299258164958137, loss:0.5537223882670058\n",
      "epoch:3614, weight:[1.80461855 1.20593528], bias:-1.4300998892266288, loss:0.5537109119078338\n",
      "epoch:3615, weight:[1.80489877 1.20601222], bias:-1.4302739379252447, loss:0.5536994371758406\n",
      "epoch:3616, weight:[1.80517898 1.20608913], bias:-1.4304479625993405, loss:0.5536879640703941\n",
      "epoch:3617, weight:[1.80545919 1.20616602], bias:-1.4306219632565922, loss:0.5536764925908625\n",
      "epoch:3618, weight:[1.80573939 1.20624287], bias:-1.4307959399046724, loss:0.5536650227366143\n",
      "epoch:3619, weight:[1.80601958 1.2063197 ], bias:-1.4309698925512506, loss:0.5536535545070186\n",
      "epoch:3620, weight:[1.80629977 1.2063965 ], bias:-1.4311438212039933, loss:0.5536420879014451\n",
      "epoch:3621, weight:[1.80657995 1.20647327], bias:-1.4313177258705638, loss:0.5536306229192632\n",
      "epoch:3622, weight:[1.80686012 1.20655001], bias:-1.431491606558622, loss:0.5536191595598436\n",
      "epoch:3623, weight:[1.80714029 1.20662672], bias:-1.431665463275825, loss:0.5536076978225574\n",
      "epoch:3624, weight:[1.80742045 1.20670341], bias:-1.4318392960298263, loss:0.5535962377067748\n",
      "epoch:3625, weight:[1.80770061 1.20678006], bias:-1.4320131048282765, loss:0.5535847792118684\n",
      "epoch:3626, weight:[1.80798076 1.20685669], bias:-1.432186889678823, loss:0.5535733223372097\n",
      "epoch:3627, weight:[1.8082609  1.20693329], bias:-1.4323606505891102, loss:0.5535618670821715\n",
      "epoch:3628, weight:[1.80854104 1.20700986], bias:-1.432534387566779, loss:0.5535504134461265\n",
      "epoch:3629, weight:[1.80882117 1.2070864 ], bias:-1.4327081006194675, loss:0.5535389614284484\n",
      "epoch:3630, weight:[1.80910129 1.20716292], bias:-1.4328817897548103, loss:0.5535275110285104\n",
      "epoch:3631, weight:[1.80938141 1.2072394 ], bias:-1.433055454980439, loss:0.5535160622456872\n",
      "epoch:3632, weight:[1.80966152 1.20731586], bias:-1.4332290963039822, loss:0.553504615079353\n",
      "epoch:3633, weight:[1.80994163 1.20739228], bias:-1.433402713733065, loss:0.5534931695288833\n",
      "epoch:3634, weight:[1.81022173 1.20746868], bias:-1.4335763072753096, loss:0.5534817255936533\n",
      "epoch:3635, weight:[1.81050182 1.20754506], bias:-1.4337498769383352, loss:0.5534702832730389\n",
      "epoch:3636, weight:[1.81078191 1.2076214 ], bias:-1.4339234227297577, loss:0.5534588425664168\n",
      "epoch:3637, weight:[1.81106199 1.20769771], bias:-1.4340969446571896, loss:0.5534474034731632\n",
      "epoch:3638, weight:[1.81134206 1.207774  ], bias:-1.4342704427282407, loss:0.5534359659926558\n",
      "epoch:3639, weight:[1.81162213 1.20785026], bias:-1.4344439169505172, loss:0.5534245301242717\n",
      "epoch:3640, weight:[1.81190219 1.20792649], bias:-1.4346173673316227, loss:0.5534130958673896\n",
      "epoch:3641, weight:[1.81218225 1.20800269], bias:-1.4347907938791573, loss:0.5534016632213874\n",
      "epoch:3642, weight:[1.8124623  1.20807886], bias:-1.4349641966007178, loss:0.5533902321856441\n",
      "epoch:3643, weight:[1.81274234 1.20815501], bias:-1.4351375755038984, loss:0.5533788027595393\n",
      "epoch:3644, weight:[1.81302237 1.20823112], bias:-1.43531093059629, loss:0.5533673749424525\n",
      "epoch:3645, weight:[1.8133024  1.20830721], bias:-1.4354842618854797, loss:0.5533559487337637\n",
      "epoch:3646, weight:[1.81358243 1.20838327], bias:-1.4356575693790528, loss:0.5533445241328541\n",
      "epoch:3647, weight:[1.81386245 1.2084593 ], bias:-1.43583085308459, loss:0.5533331011391038\n",
      "epoch:3648, weight:[1.81414246 1.20853531], bias:-1.4360041130096701, loss:0.5533216797518951\n",
      "epoch:3649, weight:[1.81442246 1.20861128], bias:-1.4361773491618681, loss:0.5533102599706091\n",
      "epoch:3650, weight:[1.81470246 1.20868723], bias:-1.436350561548756, loss:0.5532988417946287\n",
      "epoch:3651, weight:[1.81498245 1.20876315], bias:-1.4365237501779027, loss:0.5532874252233362\n",
      "epoch:3652, weight:[1.81526244 1.20883904], bias:-1.436696915056874, loss:0.553276010256115\n",
      "epoch:3653, weight:[1.81554242 1.2089149 ], bias:-1.4368700561932326, loss:0.5532645968923482\n",
      "epoch:3654, weight:[1.81582239 1.20899073], bias:-1.4370431735945381, loss:0.5532531851314202\n",
      "epoch:3655, weight:[1.81610236 1.20906654], bias:-1.437216267268347, loss:0.5532417749727151\n",
      "epoch:3656, weight:[1.81638232 1.20914232], bias:-1.4373893372222128, loss:0.5532303664156181\n",
      "epoch:3657, weight:[1.81666228 1.20921807], bias:-1.4375623834636857, loss:0.5532189594595137\n",
      "epoch:3658, weight:[1.81694222 1.20929379], bias:-1.4377354060003127, loss:0.5532075541037883\n",
      "epoch:3659, weight:[1.81722217 1.20936948], bias:-1.437908404839638, loss:0.5531961503478277\n",
      "epoch:3660, weight:[1.8175021  1.20944515], bias:-1.4380813799892025, loss:0.5531847481910179\n",
      "epoch:3661, weight:[1.81778203 1.20952078], bias:-1.438254331456544, loss:0.5531733476327463\n",
      "epoch:3662, weight:[1.81806195 1.20959639], bias:-1.4384272592491971, loss:0.5531619486724\n",
      "epoch:3663, weight:[1.81834187 1.20967197], bias:-1.4386001633746939, loss:0.5531505513093666\n",
      "epoch:3664, weight:[1.81862178 1.20974753], bias:-1.4387730438405626, loss:0.5531391555430349\n",
      "epoch:3665, weight:[1.81890168 1.20982305], bias:-1.4389459006543288, loss:0.5531277613727928\n",
      "epoch:3666, weight:[1.81918158 1.20989855], bias:-1.4391187338235147, loss:0.5531163687980294\n",
      "epoch:3667, weight:[1.81946147 1.20997402], bias:-1.43929154335564, loss:0.5531049778181344\n",
      "epoch:3668, weight:[1.81974136 1.21004946], bias:-1.4394643292582203, loss:0.5530935884324969\n",
      "epoch:3669, weight:[1.82002124 1.21012487], bias:-1.4396370915387693, loss:0.553082200640508\n",
      "epoch:3670, weight:[1.82030111 1.21020026], bias:-1.4398098302047966, loss:0.5530708144415576\n",
      "epoch:3671, weight:[1.82058098 1.21027561], bias:-1.4399825452638093, loss:0.5530594298350374\n",
      "epoch:3672, weight:[1.82086083 1.21035094], bias:-1.4401552367233112, loss:0.5530480468203381\n",
      "epoch:3673, weight:[1.82114069 1.21042624], bias:-1.4403279045908033, loss:0.5530366653968524\n",
      "epoch:3674, weight:[1.82142054 1.21050151], bias:-1.440500548873783, loss:0.5530252855639721\n",
      "epoch:3675, weight:[1.82170038 1.21057676], bias:-1.4406731695797452, loss:0.55301390732109\n",
      "epoch:3676, weight:[1.82198021 1.21065198], bias:-1.4408457667161814, loss:0.5530025306675991\n",
      "epoch:3677, weight:[1.82226004 1.21072717], bias:-1.4410183402905798, loss:0.5529911556028936\n",
      "epoch:3678, weight:[1.82253986 1.21080233], bias:-1.441190890310426, loss:0.5529797821263664\n",
      "epoch:3679, weight:[1.82281968 1.21087746], bias:-1.4413634167832023, loss:0.5529684102374125\n",
      "epoch:3680, weight:[1.82309948 1.21095257], bias:-1.4415359197163882, loss:0.5529570399354266\n",
      "epoch:3681, weight:[1.82337929 1.21102764], bias:-1.4417083991174597, loss:0.5529456712198038\n",
      "epoch:3682, weight:[1.82365908 1.21110269], bias:-1.44188085499389, loss:0.5529343040899396\n",
      "epoch:3683, weight:[1.82393887 1.21117772], bias:-1.442053287353149, loss:0.5529229385452302\n",
      "epoch:3684, weight:[1.82421866 1.21125271], bias:-1.442225696202704, loss:0.552911574585072\n",
      "epoch:3685, weight:[1.82449843 1.21132768], bias:-1.4423980815500188, loss:0.5529002122088615\n",
      "epoch:3686, weight:[1.8247782  1.21140261], bias:-1.4425704434025544, loss:0.5528888514159968\n",
      "epoch:3687, weight:[1.82505797 1.21147752], bias:-1.4427427817677685, loss:0.5528774922058745\n",
      "epoch:3688, weight:[1.82533773 1.21155241], bias:-1.442915096653116, loss:0.5528661345778931\n",
      "epoch:3689, weight:[1.82561748 1.21162726], bias:-1.4430873880660484, loss:0.5528547785314512\n",
      "epoch:3690, weight:[1.82589722 1.21170209], bias:-1.4432596560140147, loss:0.5528434240659473\n",
      "epoch:3691, weight:[1.82617696 1.21177689], bias:-1.4434319005044605, loss:0.5528320711807813\n",
      "epoch:3692, weight:[1.8264567  1.21185166], bias:-1.443604121544828, loss:0.552820719875352\n",
      "epoch:3693, weight:[1.82673642 1.2119264 ], bias:-1.4437763191425572, loss:0.5528093701490605\n",
      "epoch:3694, weight:[1.82701614 1.21200112], bias:-1.4439484933050846, loss:0.5527980220013065\n",
      "epoch:3695, weight:[1.82729585 1.21207581], bias:-1.4441206440398433, loss:0.5527866754314911\n",
      "epoch:3696, weight:[1.82757556 1.21215047], bias:-1.444292771354264, loss:0.5527753304390159\n",
      "epoch:3697, weight:[1.82785526 1.2122251 ], bias:-1.4444648752557738, loss:0.5527639870232822\n",
      "epoch:3698, weight:[1.82813496 1.21229971], bias:-1.4446369557517975, loss:0.5527526451836926\n",
      "epoch:3699, weight:[1.82841464 1.21237429], bias:-1.4448090128497562, loss:0.5527413049196493\n",
      "epoch:3700, weight:[1.82869433 1.21244884], bias:-1.4449810465570678, loss:0.5527299662305555\n",
      "epoch:3701, weight:[1.828974   1.21252336], bias:-1.4451530568811481, loss:0.5527186291158142\n",
      "epoch:3702, weight:[1.82925367 1.21259785], bias:-1.445325043829409, loss:0.5527072935748294\n",
      "epoch:3703, weight:[1.82953333 1.21267232], bias:-1.4454970074092597, loss:0.5526959596070052\n",
      "epoch:3704, weight:[1.82981299 1.21274676], bias:-1.4456689476281064, loss:0.5526846272117462\n",
      "epoch:3705, weight:[1.83009264 1.21282117], bias:-1.445840864493352, loss:0.5526732963884572\n",
      "epoch:3706, weight:[1.83037228 1.21289556], bias:-1.446012758012397, loss:0.5526619671365439\n",
      "epoch:3707, weight:[1.83065192 1.21296991], bias:-1.446184628192638, loss:0.5526506394554115\n",
      "epoch:3708, weight:[1.83093155 1.21304424], bias:-1.4463564750414695, loss:0.5526393133444667\n",
      "epoch:3709, weight:[1.83121117 1.21311854], bias:-1.4465282985662824, loss:0.5526279888031159\n",
      "epoch:3710, weight:[1.83149079 1.21319282], bias:-1.4467000987744647, loss:0.552616665830766\n",
      "epoch:3711, weight:[1.8317704  1.21326706], bias:-1.4468718756734014, loss:0.5526053444268245\n",
      "epoch:3712, weight:[1.83205001 1.21334128], bias:-1.4470436292704743, loss:0.552594024590699\n",
      "epoch:3713, weight:[1.8323296  1.21341547], bias:-1.4472153595730626, loss:0.5525827063217981\n",
      "epoch:3714, weight:[1.8326092  1.21348964], bias:-1.4473870665885422, loss:0.5525713896195297\n",
      "epoch:3715, weight:[1.83288878 1.21356377], bias:-1.447558750324286, loss:0.5525600744833034\n",
      "epoch:3716, weight:[1.83316836 1.21363788], bias:-1.4477304107876638, loss:0.5525487609125281\n",
      "epoch:3717, weight:[1.83344793 1.21371196], bias:-1.447902047986043, loss:0.5525374489066142\n",
      "epoch:3718, weight:[1.8337275  1.21378602], bias:-1.448073661926787, loss:0.5525261384649713\n",
      "epoch:3719, weight:[1.83400706 1.21386005], bias:-1.4482452526172571, loss:0.5525148295870103\n",
      "epoch:3720, weight:[1.83428661 1.21393404], bias:-1.448416820064811, loss:0.552503522272142\n",
      "epoch:3721, weight:[1.83456616 1.21400802], bias:-1.4485883642768038, loss:0.552492216519778\n",
      "epoch:3722, weight:[1.8348457  1.21408196], bias:-1.4487598852605872, loss:0.5524809123293296\n",
      "epoch:3723, weight:[1.83512524 1.21415588], bias:-1.4489313830235102, loss:0.5524696097002098\n",
      "epoch:3724, weight:[1.83540476 1.21422977], bias:-1.449102857572919, loss:0.5524583086318304\n",
      "epoch:3725, weight:[1.83568429 1.21430363], bias:-1.4492743089161562, loss:0.5524470091236047\n",
      "epoch:3726, weight:[1.8359638  1.21437746], bias:-1.449445737060562, loss:0.5524357111749459\n",
      "epoch:3727, weight:[1.83624331 1.21445127], bias:-1.4496171420134731, loss:0.5524244147852682\n",
      "epoch:3728, weight:[1.83652281 1.21452505], bias:-1.4497885237822237, loss:0.5524131199539853\n",
      "epoch:3729, weight:[1.83680231 1.2145988 ], bias:-1.4499598823741446, loss:0.552401826680512\n",
      "epoch:3730, weight:[1.8370818  1.21467253], bias:-1.450131217796564, loss:0.5523905349642632\n",
      "epoch:3731, weight:[1.83736128 1.21474623], bias:-1.4503025300568066, loss:0.552379244804654\n",
      "epoch:3732, weight:[1.83764076 1.2148199 ], bias:-1.4504738191621949, loss:0.5523679562011005\n",
      "epoch:3733, weight:[1.83792023 1.21489354], bias:-1.4506450851200476, loss:0.5523566691530187\n",
      "epoch:3734, weight:[1.83819969 1.21496716], bias:-1.450816327937681, loss:0.5523453836598254\n",
      "epoch:3735, weight:[1.83847915 1.21504074], bias:-1.450987547622408, loss:0.5523340997209368\n",
      "epoch:3736, weight:[1.8387586  1.21511431], bias:-1.4511587441815386, loss:0.5523228173357712\n",
      "epoch:3737, weight:[1.83903804 1.21518784], bias:-1.4513299176223802, loss:0.5523115365037456\n",
      "epoch:3738, weight:[1.83931748 1.21526135], bias:-1.4515010679522367, loss:0.5523002572242784\n",
      "epoch:3739, weight:[1.83959691 1.21533483], bias:-1.4516721951784095, loss:0.552288979496788\n",
      "epoch:3740, weight:[1.83987633 1.21540828], bias:-1.4518432993081969, loss:0.5522777033206933\n",
      "epoch:3741, weight:[1.84015575 1.2154817 ], bias:-1.4520143803488939, loss:0.5522664286954136\n",
      "epoch:3742, weight:[1.84043517 1.2155551 ], bias:-1.452185438307793, loss:0.5522551556203688\n",
      "epoch:3743, weight:[1.84071457 1.21562847], bias:-1.4523564731921834, loss:0.5522438840949785\n",
      "epoch:3744, weight:[1.84099397 1.21570182], bias:-1.4525274850093515, loss:0.5522326141186636\n",
      "epoch:3745, weight:[1.84127336 1.21577513], bias:-1.4526984737665807, loss:0.552221345690845\n",
      "epoch:3746, weight:[1.84155275 1.21584842], bias:-1.4528694394711514, loss:0.5522100788109436\n",
      "epoch:3747, weight:[1.84183213 1.21592169], bias:-1.4530403821303413, loss:0.5521988134783814\n",
      "epoch:3748, weight:[1.8421115  1.21599492], bias:-1.4532113017514248, loss:0.5521875496925798\n",
      "epoch:3749, weight:[1.84239087 1.21606813], bias:-1.4533821983416733, loss:0.5521762874529621\n",
      "epoch:3750, weight:[1.84267023 1.21614131], bias:-1.4535530719083556, loss:0.5521650267589503\n",
      "epoch:3751, weight:[1.84294958 1.21621446], bias:-1.4537239224587373, loss:0.5521537676099683\n",
      "epoch:3752, weight:[1.84322893 1.21628759], bias:-1.4538947500000812, loss:0.5521425100054392\n",
      "epoch:3753, weight:[1.84350827 1.21636069], bias:-1.4540655545396468, loss:0.5521312539447872\n",
      "epoch:3754, weight:[1.8437876  1.21643376], bias:-1.454236336084691, loss:0.5521199994274364\n",
      "epoch:3755, weight:[1.84406693 1.21650681], bias:-1.4544070946424679, loss:0.5521087464528119\n",
      "epoch:3756, weight:[1.84434625 1.21657983], bias:-1.4545778302202281, loss:0.5520974950203386\n",
      "epoch:3757, weight:[1.84462557 1.21665282], bias:-1.45474854282522, loss:0.5520862451294422\n",
      "epoch:3758, weight:[1.84490488 1.21672578], bias:-1.4549192324646882, loss:0.5520749967795486\n",
      "epoch:3759, weight:[1.84518418 1.21679872], bias:-1.4550898991458752, loss:0.5520637499700838\n",
      "epoch:3760, weight:[1.84546347 1.21687163], bias:-1.4552605428760197, loss:0.5520525047004751\n",
      "epoch:3761, weight:[1.84574276 1.21694451], bias:-1.4554311636623583, loss:0.5520412609701488\n",
      "epoch:3762, weight:[1.84602205 1.21701737], bias:-1.455601761512124, loss:0.5520300187785332\n",
      "epoch:3763, weight:[1.84630132 1.2170902 ], bias:-1.4557723364325472, loss:0.5520187781250553\n",
      "epoch:3764, weight:[1.84658059 1.217163  ], bias:-1.4559428884308556, loss:0.5520075390091441\n",
      "epoch:3765, weight:[1.84685985 1.21723577], bias:-1.4561134175142734, loss:0.5519963014302277\n",
      "epoch:3766, weight:[1.84713911 1.21730852], bias:-1.4562839236900222, loss:0.5519850653877354\n",
      "epoch:3767, weight:[1.84741836 1.21738124], bias:-1.456454406965321, loss:0.5519738308810964\n",
      "epoch:3768, weight:[1.8476976  1.21745394], bias:-1.456624867347385, loss:0.5519625979097406\n",
      "epoch:3769, weight:[1.84797684 1.21752661], bias:-1.456795304843427, loss:0.5519513664730981\n",
      "epoch:3770, weight:[1.84825607 1.21759925], bias:-1.4569657194606571, loss:0.5519401365705994\n",
      "epoch:3771, weight:[1.8485353  1.21767186], bias:-1.4571361112062822, loss:0.5519289082016756\n",
      "epoch:3772, weight:[1.84881451 1.21774445], bias:-1.4573064800875062, loss:0.5519176813657577\n",
      "epoch:3773, weight:[1.84909373 1.21781701], bias:-1.4574768261115303, loss:0.5519064560622776\n",
      "epoch:3774, weight:[1.84937293 1.21788954], bias:-1.4576471492855525, loss:0.5518952322906676\n",
      "epoch:3775, weight:[1.84965213 1.21796205], bias:-1.4578174496167684, loss:0.5518840100503597\n",
      "epoch:3776, weight:[1.84993132 1.21803453], bias:-1.45798772711237, loss:0.551872789340787\n",
      "epoch:3777, weight:[1.8502105  1.21810698], bias:-1.458157981779547, loss:0.5518615701613826\n",
      "epoch:3778, weight:[1.85048968 1.21817941], bias:-1.4583282136254856, loss:0.5518503525115802\n",
      "epoch:3779, weight:[1.85076885 1.2182518 ], bias:-1.4584984226573696, loss:0.5518391363908136\n",
      "epoch:3780, weight:[1.85104802 1.21832418], bias:-1.45866860888238, loss:0.5518279217985176\n",
      "epoch:3781, weight:[1.85132718 1.21839652], bias:-1.458838772307694, loss:0.5518167087341266\n",
      "epoch:3782, weight:[1.85160633 1.21846884], bias:-1.459008912940487, loss:0.5518054971970756\n",
      "epoch:3783, weight:[1.85188548 1.21854113], bias:-1.4591790307879309, loss:0.5517942871868005\n",
      "epoch:3784, weight:[1.85216462 1.2186134 ], bias:-1.4593491258571945, loss:0.5517830787027367\n",
      "epoch:3785, weight:[1.85244375 1.21868564], bias:-1.459519198155444, loss:0.5517718717443209\n",
      "epoch:3786, weight:[1.85272288 1.21875785], bias:-1.459689247689843, loss:0.5517606663109895\n",
      "epoch:3787, weight:[1.853002   1.21883003], bias:-1.4598592744675518, loss:0.5517494624021796\n",
      "epoch:3788, weight:[1.85328111 1.21890219], bias:-1.4600292784957278, loss:0.5517382600173287\n",
      "epoch:3789, weight:[1.85356022 1.21897432], bias:-1.4601992597815256, loss:0.5517270591558744\n",
      "epoch:3790, weight:[1.85383932 1.21904643], bias:-1.460369218332097, loss:0.5517158598172549\n",
      "epoch:3791, weight:[1.85411841 1.21911851], bias:-1.460539154154591, loss:0.5517046620009087\n",
      "epoch:3792, weight:[1.8543975  1.21919056], bias:-1.460709067256153, loss:0.5516934657062748\n",
      "epoch:3793, weight:[1.85467658 1.21926258], bias:-1.4608789576439263, loss:0.5516822709327925\n",
      "epoch:3794, weight:[1.85495565 1.21933458], bias:-1.461048825325051, loss:0.5516710776799012\n",
      "epoch:3795, weight:[1.85523472 1.21940655], bias:-1.4612186703066647, loss:0.5516598859470414\n",
      "epoch:3796, weight:[1.85551378 1.2194785 ], bias:-1.4613884925959015, loss:0.551648695733653\n",
      "epoch:3797, weight:[1.85579284 1.21955041], bias:-1.4615582921998929, loss:0.5516375070391774\n",
      "epoch:3798, weight:[1.85607188 1.21962231], bias:-1.4617280691257675, loss:0.551626319863055\n",
      "epoch:3799, weight:[1.85635092 1.21969417], bias:-1.461897823380651, loss:0.551615134204728\n",
      "epoch:3800, weight:[1.85662996 1.21976601], bias:-1.4620675549716664, loss:0.5516039500636379\n",
      "epoch:3801, weight:[1.85690899 1.21983782], bias:-1.4622372639059336, loss:0.5515927674392271\n",
      "epoch:3802, weight:[1.85718801 1.21990961], bias:-1.4624069501905697, loss:0.5515815863309386\n",
      "epoch:3803, weight:[1.85746702 1.21998137], bias:-1.462576613832689, loss:0.5515704067382151\n",
      "epoch:3804, weight:[1.85774603 1.2200531 ], bias:-1.4627462548394028, loss:0.5515592286605\n",
      "epoch:3805, weight:[1.85802504 1.2201248 ], bias:-1.4629158732178196, loss:0.5515480520972371\n",
      "epoch:3806, weight:[1.85830403 1.22019648], bias:-1.463085468975045, loss:0.5515368770478707\n",
      "epoch:3807, weight:[1.85858302 1.22026814], bias:-1.4632550421181818, loss:0.5515257035118453\n",
      "epoch:3808, weight:[1.858862   1.22033976], bias:-1.46342459265433, loss:0.5515145314886054\n",
      "epoch:3809, weight:[1.85914098 1.22041136], bias:-1.4635941205905862, loss:0.551503360977597\n",
      "epoch:3810, weight:[1.85941995 1.22048294], bias:-1.4637636259340452, loss:0.5514921919782653\n",
      "epoch:3811, weight:[1.85969891 1.22055448], bias:-1.4639331086917977, loss:0.5514810244900562\n",
      "epoch:3812, weight:[1.85997787 1.220626  ], bias:-1.4641025688709324, loss:0.5514698585124164\n",
      "epoch:3813, weight:[1.86025682 1.2206975 ], bias:-1.4642720064785348, loss:0.5514586940447926\n",
      "epoch:3814, weight:[1.86053576 1.22076896], bias:-1.4644414215216879, loss:0.5514475310866318\n",
      "epoch:3815, weight:[1.8608147  1.22084041], bias:-1.4646108140074712, loss:0.5514363696373816\n",
      "epoch:3816, weight:[1.86109363 1.22091182], bias:-1.4647801839429617, loss:0.5514252096964899\n",
      "epoch:3817, weight:[1.86137255 1.22098321], bias:-1.4649495313352339, loss:0.5514140512634047\n",
      "epoch:3818, weight:[1.86165147 1.22105457], bias:-1.4651188561913588, loss:0.551402894337575\n",
      "epoch:3819, weight:[1.86193038 1.22112591], bias:-1.465288158518405, loss:0.5513917389184494\n",
      "epoch:3820, weight:[1.86220928 1.22119721], bias:-1.465457438323438, loss:0.5513805850054777\n",
      "epoch:3821, weight:[1.86248818 1.2212685 ], bias:-1.4656266956135207, loss:0.5513694325981091\n",
      "epoch:3822, weight:[1.86276707 1.22133975], bias:-1.4657959303957129, loss:0.551358281695794\n",
      "epoch:3823, weight:[1.86304595 1.22141098], bias:-1.4659651426770717, loss:0.5513471322979828\n",
      "epoch:3824, weight:[1.86332483 1.22148219], bias:-1.4661343324646514, loss:0.5513359844041262\n",
      "epoch:3825, weight:[1.8636037  1.22155336], bias:-1.4663034997655033, loss:0.5513248380136758\n",
      "epoch:3826, weight:[1.86388256 1.22162452], bias:-1.4664726445866758, loss:0.5513136931260826\n",
      "epoch:3827, weight:[1.86416142 1.22169564], bias:-1.4666417669352148, loss:0.5513025497407988\n",
      "epoch:3828, weight:[1.86444027 1.22176674], bias:-1.466810866818163, loss:0.5512914078572767\n",
      "epoch:3829, weight:[1.86471911 1.22183781], bias:-1.4669799442425606, loss:0.5512802674749692\n",
      "epoch:3830, weight:[1.86499795 1.22190886], bias:-1.4671489992154447, loss:0.5512691285933289\n",
      "epoch:3831, weight:[1.86527678 1.22197988], bias:-1.46731803174385, loss:0.5512579912118093\n",
      "epoch:3832, weight:[1.86555561 1.22205087], bias:-1.4674870418348074, loss:0.5512468553298642\n",
      "epoch:3833, weight:[1.86583443 1.22212184], bias:-1.467656029495346, loss:0.5512357209469476\n",
      "epoch:3834, weight:[1.86611324 1.22219278], bias:-1.4678249947324917, loss:0.5512245880625144\n",
      "epoch:3835, weight:[1.86639204 1.22226369], bias:-1.4679939375532676, loss:0.551213456676019\n",
      "epoch:3836, weight:[1.86667084 1.22233458], bias:-1.4681628579646935, loss:0.5512023267869167\n",
      "epoch:3837, weight:[1.86694963 1.22240544], bias:-1.4683317559737872, loss:0.5511911983946634\n",
      "epoch:3838, weight:[1.86722842 1.22247628], bias:-1.468500631587563, loss:0.5511800714987148\n",
      "epoch:3839, weight:[1.86750719 1.22254709], bias:-1.468669484813033, loss:0.5511689460985271\n",
      "epoch:3840, weight:[1.86778597 1.22261787], bias:-1.4688383156572058, loss:0.551157822193557\n",
      "epoch:3841, weight:[1.86806473 1.22268863], bias:-1.4690071241270877, loss:0.5511466997832616\n",
      "epoch:3842, weight:[1.86834349 1.22275936], bias:-1.469175910229682, loss:0.5511355788670985\n",
      "epoch:3843, weight:[1.86862224 1.22283007], bias:-1.469344673971989, loss:0.551124459444525\n",
      "epoch:3844, weight:[1.86890099 1.22290075], bias:-1.4695134153610065, loss:0.5511133415149998\n",
      "epoch:3845, weight:[1.86917973 1.2229714 ], bias:-1.4696821344037294, loss:0.5511022250779809\n",
      "epoch:3846, weight:[1.86945846 1.22304203], bias:-1.4698508311071496, loss:0.5510911101329273\n",
      "epoch:3847, weight:[1.86973718 1.22311263], bias:-1.4700195054782565, loss:0.5510799966792981\n",
      "epoch:3848, weight:[1.8700159 1.2231832], bias:-1.4701881575240363, loss:0.5510688847165531\n",
      "epoch:3849, weight:[1.87029461 1.22325375], bias:-1.470356787251473, loss:0.5510577742441521\n",
      "epoch:3850, weight:[1.87057332 1.22332427], bias:-1.4705253946675467, loss:0.5510466652615554\n",
      "epoch:3851, weight:[1.87085202 1.22339477], bias:-1.4706939797792362, loss:0.5510355577682237\n",
      "epoch:3852, weight:[1.87113071 1.22346524], bias:-1.4708625425935162, loss:0.551024451763618\n",
      "epoch:3853, weight:[1.8714094  1.22353569], bias:-1.4710310831173594, loss:0.5510133472471995\n",
      "epoch:3854, weight:[1.87168807 1.2236061 ], bias:-1.471199601357735, loss:0.55100224421843\n",
      "epoch:3855, weight:[1.87196675 1.2236765 ], bias:-1.4713680973216103, loss:0.5509911426767717\n",
      "epoch:3856, weight:[1.87224541 1.22374686], bias:-1.4715365710159491, loss:0.5509800426216869\n",
      "epoch:3857, weight:[1.87252407 1.2238172 ], bias:-1.4717050224477126, loss:0.5509689440526385\n",
      "epoch:3858, weight:[1.87280272 1.22388752], bias:-1.4718734516238592, loss:0.5509578469690898\n",
      "epoch:3859, weight:[1.87308137 1.22395781], bias:-1.4720418585513444, loss:0.5509467513705039\n",
      "epoch:3860, weight:[1.87336001 1.22402807], bias:-1.4722102432371211, loss:0.550935657256345\n",
      "epoch:3861, weight:[1.87363864 1.22409831], bias:-1.4723786056881394, loss:0.5509245646260772\n",
      "epoch:3862, weight:[1.87391727 1.22416852], bias:-1.4725469459113465, loss:0.5509134734791653\n",
      "epoch:3863, weight:[1.87419589 1.2242387 ], bias:-1.472715263913687, loss:0.5509023838150738\n",
      "epoch:3864, weight:[1.8744745  1.22430886], bias:-1.4728835597021024, loss:0.5508912956332686\n",
      "epoch:3865, weight:[1.87475311 1.22437899], bias:-1.4730518332835316, loss:0.5508802089332149\n",
      "epoch:3866, weight:[1.8750317 1.2244491], bias:-1.4732200846649108, loss:0.5508691237143789\n",
      "epoch:3867, weight:[1.8753103  1.22451918], bias:-1.4733883138531734, loss:0.550858039976227\n",
      "epoch:3868, weight:[1.87558888 1.22458924], bias:-1.4735565208552497, loss:0.5508469577182258\n",
      "epoch:3869, weight:[1.87586746 1.22465927], bias:-1.4737247056780676, loss:0.5508358769398425\n",
      "epoch:3870, weight:[1.87614603 1.22472927], bias:-1.4738928683285522, loss:0.5508247976405444\n",
      "epoch:3871, weight:[1.8764246  1.22479925], bias:-1.4740610088136255, loss:0.5508137198197993\n",
      "epoch:3872, weight:[1.87670316 1.2248692 ], bias:-1.474229127140207, loss:0.5508026434770756\n",
      "epoch:3873, weight:[1.87698171 1.22493913], bias:-1.4743972233152134, loss:0.5507915686118415\n",
      "epoch:3874, weight:[1.87726026 1.22500903], bias:-1.4745652973455587, loss:0.5507804952235661\n",
      "epoch:3875, weight:[1.8775388 1.2250789], bias:-1.4747333492381538, loss:0.5507694233117184\n",
      "epoch:3876, weight:[1.87781733 1.22514875], bias:-1.4749013789999073, loss:0.5507583528757682\n",
      "epoch:3877, weight:[1.87809586 1.22521857], bias:-1.4750693866377245, loss:0.5507472839151851\n",
      "epoch:3878, weight:[1.87837438 1.22528837], bias:-1.4752373721585084, loss:0.5507362164294395\n",
      "epoch:3879, weight:[1.87865289 1.22535814], bias:-1.475405335569159, loss:0.5507251504180021\n",
      "epoch:3880, weight:[1.87893139 1.22542789], bias:-1.4755732768765737, loss:0.5507140858803437\n",
      "epoch:3881, weight:[1.87920989 1.22549761], bias:-1.4757411960876468, loss:0.5507030228159359\n",
      "epoch:3882, weight:[1.87948839 1.2255673 ], bias:-1.4759090932092702, loss:0.55069196122425\n",
      "epoch:3883, weight:[1.87976687 1.22563697], bias:-1.476076968248333, loss:0.5506809011047584\n",
      "epoch:3884, weight:[1.88004535 1.22570661], bias:-1.4762448212117212, loss:0.5506698424569332\n",
      "epoch:3885, weight:[1.88032382 1.22577623], bias:-1.4764126521063183, loss:0.5506587852802474\n",
      "epoch:3886, weight:[1.88060229 1.22584582], bias:-1.4765804609390054, loss:0.5506477295741736\n",
      "epoch:3887, weight:[1.88088075 1.22591539], bias:-1.4767482477166602, loss:0.5506366753381857\n",
      "epoch:3888, weight:[1.8811592  1.22598493], bias:-1.476916012446158, loss:0.5506256225717574\n",
      "epoch:3889, weight:[1.88143765 1.22605444], bias:-1.4770837551343712, loss:0.5506145712743625\n",
      "epoch:3890, weight:[1.88171609 1.22612393], bias:-1.4772514757881694, loss:0.5506035214454758\n",
      "epoch:3891, weight:[1.88199452 1.22619339], bias:-1.4774191744144198, loss:0.550592473084572\n",
      "epoch:3892, weight:[1.88227295 1.22626283], bias:-1.4775868510199865, loss:0.5505814261911266\n",
      "epoch:3893, weight:[1.88255136 1.22633224], bias:-1.4777545056117312, loss:0.5505703807646145\n",
      "epoch:3894, weight:[1.88282978 1.22640163], bias:-1.4779221381965122, loss:0.5505593368045119\n",
      "epoch:3895, weight:[1.88310818 1.22647099], bias:-1.4780897487811857, loss:0.5505482943102952\n",
      "epoch:3896, weight:[1.88338658 1.22654033], bias:-1.4782573373726051, loss:0.5505372532814407\n",
      "epoch:3897, weight:[1.88366497 1.22660963], bias:-1.4784249039776207, loss:0.5505262137174253\n",
      "epoch:3898, weight:[1.88394336 1.22667892], bias:-1.4785924486030804, loss:0.5505151756177263\n",
      "epoch:3899, weight:[1.88422174 1.22674818], bias:-1.4787599712558293, loss:0.5505041389818216\n",
      "epoch:3900, weight:[1.88450011 1.22681741], bias:-1.4789274719427095, loss:0.5504931038091887\n",
      "epoch:3901, weight:[1.88477848 1.22688662], bias:-1.4790949506705606, loss:0.5504820700993064\n",
      "epoch:3902, weight:[1.88505684 1.2269558 ], bias:-1.4792624074462195, loss:0.5504710378516529\n",
      "epoch:3903, weight:[1.88533519 1.22702495], bias:-1.4794298422765204, loss:0.5504600070657074\n",
      "epoch:3904, weight:[1.88561353 1.22709409], bias:-1.4795972551682945, loss:0.550448977740949\n",
      "epoch:3905, weight:[1.88589187 1.22716319], bias:-1.4797646461283704, loss:0.5504379498768578\n",
      "epoch:3906, weight:[1.8861702  1.22723227], bias:-1.4799320151635742, loss:0.5504269234729136\n",
      "epoch:3907, weight:[1.88644853 1.22730132], bias:-1.4800993622807288, loss:0.5504158985285965\n",
      "epoch:3908, weight:[1.88672685 1.22737035], bias:-1.4802666874866548, loss:0.5504048750433879\n",
      "epoch:3909, weight:[1.88700516 1.22743936], bias:-1.4804339907881698, loss:0.5503938530167682\n",
      "epoch:3910, weight:[1.88728346 1.22750833], bias:-1.480601272192089, loss:0.550382832448219\n",
      "epoch:3911, weight:[1.88756176 1.22757729], bias:-1.4807685317052244, loss:0.5503718133372225\n",
      "epoch:3912, weight:[1.88784005 1.22764621], bias:-1.4809357693343859, loss:0.5503607956832599\n",
      "epoch:3913, weight:[1.88811834 1.22771512], bias:-1.4811029850863802, loss:0.5503497794858144\n",
      "epoch:3914, weight:[1.88839662 1.22778399], bias:-1.4812701789680114, loss:0.5503387647443684\n",
      "epoch:3915, weight:[1.88867489 1.22785284], bias:-1.4814373509860808, loss:0.5503277514584053\n",
      "epoch:3916, weight:[1.88895315 1.22792167], bias:-1.4816045011473873, loss:0.5503167396274082\n",
      "epoch:3917, weight:[1.88923141 1.22799047], bias:-1.4817716294587266, loss:0.5503057292508614\n",
      "epoch:3918, weight:[1.88950966 1.22805924], bias:-1.4819387359268923, loss:0.5502947203282486\n",
      "epoch:3919, weight:[1.88978791 1.22812799], bias:-1.4821058205586746, loss:0.5502837128590545\n",
      "epoch:3920, weight:[1.89006615 1.22819672], bias:-1.4822728833608616, loss:0.5502727068427637\n",
      "epoch:3921, weight:[1.89034438 1.22826541], bias:-1.4824399243402384, loss:0.5502617022788617\n",
      "epoch:3922, weight:[1.8906226  1.22833409], bias:-1.4826069435035873, loss:0.5502506991668338\n",
      "epoch:3923, weight:[1.89090082 1.22840274], bias:-1.482773940857688, loss:0.550239697506166\n",
      "epoch:3924, weight:[1.89117903 1.22847136], bias:-1.482940916409318, loss:0.5502286972963443\n",
      "epoch:3925, weight:[1.89145723 1.22853996], bias:-1.483107870165251, loss:0.5502176985368553\n",
      "epoch:3926, weight:[1.89173543 1.22860853], bias:-1.4832748021322586, loss:0.550206701227186\n",
      "epoch:3927, weight:[1.89201362 1.22867707], bias:-1.4834417123171102, loss:0.5501957053668235\n",
      "epoch:3928, weight:[1.89229181 1.2287456 ], bias:-1.4836086007265716, loss:0.5501847109552553\n",
      "epoch:3929, weight:[1.89256998 1.22881409], bias:-1.4837754673674066, loss:0.5501737179919696\n",
      "epoch:3930, weight:[1.89284815 1.22888256], bias:-1.4839423122463757, loss:0.5501627264764541\n",
      "epoch:3931, weight:[1.89312632 1.22895101], bias:-1.4841091353702374, loss:0.5501517364081977\n",
      "epoch:3932, weight:[1.89340447 1.22901943], bias:-1.4842759367457468, loss:0.5501407477866894\n",
      "epoch:3933, weight:[1.89368262 1.22908782], bias:-1.4844427163796567, loss:0.5501297606114183\n",
      "epoch:3934, weight:[1.89396077 1.2291562 ], bias:-1.4846094742787173, loss:0.5501187748818738\n",
      "epoch:3935, weight:[1.89423891 1.22922454], bias:-1.4847762104496758, loss:0.5501077905975462\n",
      "epoch:3936, weight:[1.89451703 1.22929286], bias:-1.484942924899277, loss:0.5500968077579255\n",
      "epoch:3937, weight:[1.89479516 1.22936115], bias:-1.4851096176342626, loss:0.5500858263625021\n",
      "epoch:3938, weight:[1.89507327 1.22942942], bias:-1.4852762886613722, loss:0.5500748464107676\n",
      "epoch:3939, weight:[1.89535138 1.22949767], bias:-1.4854429379873422, loss:0.5500638679022126\n",
      "epoch:3940, weight:[1.89562949 1.22956589], bias:-1.4856095656189066, loss:0.5500528908363289\n",
      "epoch:3941, weight:[1.89590758 1.22963408], bias:-1.4857761715627964, loss:0.5500419152126086\n",
      "epoch:3942, weight:[1.89618567 1.22970225], bias:-1.4859427558257405, loss:0.5500309410305437\n",
      "epoch:3943, weight:[1.89646376 1.22977039], bias:-1.4861093184144647, loss:0.5500199682896272\n",
      "epoch:3944, weight:[1.89674183 1.22983851], bias:-1.4862758593356922, loss:0.5500089969893516\n",
      "epoch:3945, weight:[1.8970199  1.22990661], bias:-1.4864423785961434, loss:0.5499980271292103\n",
      "epoch:3946, weight:[1.89729796 1.22997467], bias:-1.4866088762025362, loss:0.5499870587086972\n",
      "epoch:3947, weight:[1.89757602 1.23004272], bias:-1.4867753521615859, loss:0.5499760917273059\n",
      "epoch:3948, weight:[1.89785407 1.23011074], bias:-1.4869418064800048, loss:0.5499651261845308\n",
      "epoch:3949, weight:[1.89813211 1.23017873], bias:-1.4871082391645027, loss:0.5499541620798666\n",
      "epoch:3950, weight:[1.89841014 1.2302467 ], bias:-1.487274650221787, loss:0.549943199412808\n",
      "epoch:3951, weight:[1.89868817 1.23031464], bias:-1.487441039658562, loss:0.5499322381828505\n",
      "epoch:3952, weight:[1.89896619 1.23038256], bias:-1.4876074074815295, loss:0.5499212783894898\n",
      "epoch:3953, weight:[1.89924421 1.23045045], bias:-1.487773753697389, loss:0.5499103200322216\n",
      "epoch:3954, weight:[1.89952222 1.23051832], bias:-1.4879400783128365, loss:0.5498993631105423\n",
      "epoch:3955, weight:[1.89980022 1.23058616], bias:-1.488106381334566, loss:0.5498884076239483\n",
      "epoch:3956, weight:[1.90007821 1.23065398], bias:-1.4882726627692688, loss:0.549877453571937\n",
      "epoch:3957, weight:[1.9003562  1.23072177], bias:-1.4884389226236332, loss:0.5498665009540052\n",
      "epoch:3958, weight:[1.90063418 1.23078954], bias:-1.4886051609043451, loss:0.5498555497696507\n",
      "epoch:3959, weight:[1.90091216 1.23085729], bias:-1.4887713776180878, loss:0.5498446000183717\n",
      "epoch:3960, weight:[1.90119012 1.230925  ], bias:-1.4889375727715417, loss:0.5498336516996658\n",
      "epoch:3961, weight:[1.90146808 1.2309927 ], bias:-1.4891037463713848, loss:0.5498227048130324\n",
      "epoch:3962, weight:[1.90174604 1.23106037], bias:-1.489269898424292, loss:0.5498117593579698\n",
      "epoch:3963, weight:[1.90202398 1.23112801], bias:-1.4894360289369362, loss:0.5498008153339774\n",
      "epoch:3964, weight:[1.90230192 1.23119563], bias:-1.4896021379159872, loss:0.5497898727405551\n",
      "epoch:3965, weight:[1.90257986 1.23126322], bias:-1.4897682253681122, loss:0.5497789315772024\n",
      "epoch:3966, weight:[1.90285778 1.23133079], bias:-1.4899342912999756, loss:0.5497679918434198\n",
      "epoch:3967, weight:[1.9031357  1.23139833], bias:-1.4901003357182396, loss:0.5497570535387077\n",
      "epoch:3968, weight:[1.90341362 1.23146585], bias:-1.4902663586295635, loss:0.5497461166625672\n",
      "epoch:3969, weight:[1.90369152 1.23153335], bias:-1.490432360040604, loss:0.5497351812144994\n",
      "epoch:3970, weight:[1.90396942 1.23160082], bias:-1.490598339958015, loss:0.5497242471940059\n",
      "epoch:3971, weight:[1.90424732 1.23166826], bias:-1.490764298388448, loss:0.5497133146005887\n",
      "epoch:3972, weight:[1.9045252  1.23173568], bias:-1.4909302353385514, loss:0.5497023834337498\n",
      "epoch:3973, weight:[1.90480308 1.23180308], bias:-1.4910961508149716, loss:0.5496914536929917\n",
      "epoch:3974, weight:[1.90508095 1.23187045], bias:-1.491262044824352, loss:0.5496805253778176\n",
      "epoch:3975, weight:[1.90535882 1.23193779], bias:-1.4914279173733336, loss:0.5496695984877304\n",
      "epoch:3976, weight:[1.90563668 1.23200511], bias:-1.4915937684685543, loss:0.5496586730222337\n",
      "epoch:3977, weight:[1.90591453 1.23207241], bias:-1.4917595981166496, loss:0.5496477489808315\n",
      "epoch:3978, weight:[1.90619237 1.23213968], bias:-1.4919254063242524, loss:0.5496368263630278\n",
      "epoch:3979, weight:[1.90647021 1.23220693], bias:-1.4920911930979932, loss:0.5496259051683271\n",
      "epoch:3980, weight:[1.90674804 1.23227415], bias:-1.4922569584444996, loss:0.5496149853962343\n",
      "epoch:3981, weight:[1.90702587 1.23234134], bias:-1.4924227023703964, loss:0.5496040670462548\n",
      "epoch:3982, weight:[1.90730368 1.23240852], bias:-1.492588424882306, loss:0.5495931501178934\n",
      "epoch:3983, weight:[1.90758149 1.23247566], bias:-1.4927541259868482, loss:0.5495822346106567\n",
      "epoch:3984, weight:[1.9078593  1.23254279], bias:-1.49291980569064, loss:0.5495713205240501\n",
      "epoch:3985, weight:[1.9081371  1.23260988], bias:-1.4930854640002964, loss:0.5495604078575805\n",
      "epoch:3986, weight:[1.90841489 1.23267696], bias:-1.4932511009224287, loss:0.5495494966107546\n",
      "epoch:3987, weight:[1.90869267 1.232744  ], bias:-1.4934167164636465, loss:0.5495385867830795\n",
      "epoch:3988, weight:[1.90897045 1.23281103], bias:-1.4935823106305561, loss:0.5495276783740629\n",
      "epoch:3989, weight:[1.90924822 1.23287803], bias:-1.4937478834297617, loss:0.5495167713832119\n",
      "epoch:3990, weight:[1.90952598 1.232945  ], bias:-1.4939134348678647, loss:0.5495058658100349\n",
      "epoch:3991, weight:[1.90980373 1.23301195], bias:-1.4940789649514639, loss:0.5494949616540405\n",
      "epoch:3992, weight:[1.91008148 1.23307888], bias:-1.4942444736871552, loss:0.5494840589147372\n",
      "epoch:3993, weight:[1.91035923 1.23314578], bias:-1.4944099610815325, loss:0.549473157591634\n",
      "epoch:3994, weight:[1.91063696 1.23321265], bias:-1.4945754271411864, loss:0.5494622576842404\n",
      "epoch:3995, weight:[1.91091469 1.2332795 ], bias:-1.4947408718727053, loss:0.5494513591920659\n",
      "epoch:3996, weight:[1.91119241 1.23334633], bias:-1.494906295282675, loss:0.5494404621146206\n",
      "epoch:3997, weight:[1.91147013 1.23341313], bias:-1.4950716973776785, loss:0.549429566451415\n",
      "epoch:3998, weight:[1.91174784 1.23347991], bias:-1.4952370781642963, loss:0.5494186722019596\n",
      "epoch:3999, weight:[1.91202554 1.23354666], bias:-1.4954024376491062, loss:0.5494077793657651\n",
      "epoch:4000, weight:[1.91230323 1.23361339], bias:-1.4955677758386834, loss:0.5493968879423434\n",
      "epoch:4001, weight:[1.91258092 1.2336801 ], bias:-1.4957330927396006, loss:0.5493859979312057\n",
      "epoch:4002, weight:[1.9128586  1.23374678], bias:-1.495898388358428, loss:0.5493751093318638\n",
      "epoch:4003, weight:[1.91313627 1.23381343], bias:-1.496063662701733, loss:0.5493642221438303\n",
      "epoch:4004, weight:[1.91341394 1.23388006], bias:-1.4962289157760804, loss:0.5493533363666178\n",
      "epoch:4005, weight:[1.9136916  1.23394667], bias:-1.4963941475880325, loss:0.5493424519997385\n",
      "epoch:4006, weight:[1.91396925 1.23401325], bias:-1.4965593581441488, loss:0.5493315690427065\n",
      "epoch:4007, weight:[1.9142469  1.23407981], bias:-1.4967245474509863, loss:0.5493206874950348\n",
      "epoch:4008, weight:[1.91452454 1.23414634], bias:-1.4968897155150995, loss:0.5493098073562375\n",
      "epoch:4009, weight:[1.91480217 1.23421285], bias:-1.4970548623430404, loss:0.5492989286258285\n",
      "epoch:4010, weight:[1.9150798  1.23427933], bias:-1.4972199879413581, loss:0.5492880513033225\n",
      "epoch:4011, weight:[1.91535742 1.23434579], bias:-1.4973850923165992, loss:0.5492771753882343\n",
      "epoch:4012, weight:[1.91563503 1.23441222], bias:-1.497550175475308, loss:0.5492663008800788\n",
      "epoch:4013, weight:[1.91591264 1.23447863], bias:-1.497715237424026, loss:0.5492554277783716\n",
      "epoch:4014, weight:[1.91619023 1.23454502], bias:-1.4978802781692917, loss:0.5492445560826287\n",
      "epoch:4015, weight:[1.91646783 1.23461138], bias:-1.4980452977176417, loss:0.5492336857923656\n",
      "epoch:4016, weight:[1.91674541 1.23467772], bias:-1.4982102960756096, loss:0.549222816907099\n",
      "epoch:4017, weight:[1.91702299 1.23474403], bias:-1.4983752732497266, loss:0.5492119494263457\n",
      "epoch:4018, weight:[1.91730056 1.23481032], bias:-1.4985402292465213, loss:0.5492010833496226\n",
      "epoch:4019, weight:[1.91757812 1.23487658], bias:-1.4987051640725195, loss:0.5491902186764471\n",
      "epoch:4020, weight:[1.91785568 1.23494282], bias:-1.4988700777342447, loss:0.5491793554063367\n",
      "epoch:4021, weight:[1.91813323 1.23500904], bias:-1.4990349702382175, loss:0.5491684935388096\n",
      "epoch:4022, weight:[1.91841077 1.23507523], bias:-1.4991998415909564, loss:0.5491576330733839\n",
      "epoch:4023, weight:[1.91868831 1.23514139], bias:-1.499364691798977, loss:0.5491467740095781\n",
      "epoch:4024, weight:[1.91896584 1.23520754], bias:-1.499529520868792, loss:0.5491359163469114\n",
      "epoch:4025, weight:[1.91924336 1.23527365], bias:-1.4996943288069122, loss:0.5491250600849029\n",
      "epoch:4026, weight:[1.91952088 1.23533975], bias:-1.4998591156198455, loss:0.5491142052230721\n",
      "epoch:4027, weight:[1.91979839 1.23540582], bias:-1.5000238813140971, loss:0.5491033517609387\n",
      "epoch:4028, weight:[1.92007589 1.23547186], bias:-1.5001886258961699, loss:0.5490924996980233\n",
      "epoch:4029, weight:[1.92035339 1.23553788], bias:-1.500353349372564, loss:0.549081649033846\n",
      "epoch:4030, weight:[1.92063087 1.23560388], bias:-1.5005180517497771, loss:0.5490707997679279\n",
      "epoch:4031, weight:[1.92090836 1.23566985], bias:-1.5006827330343042, loss:0.5490599518997898\n",
      "epoch:4032, weight:[1.92118583 1.2357358 ], bias:-1.5008473932326376, loss:0.5490491054289532\n",
      "epoch:4033, weight:[1.9214633  1.23580172], bias:-1.5010120323512675, loss:0.54903826035494\n",
      "epoch:4034, weight:[1.92174076 1.23586762], bias:-1.501176650396681, loss:0.5490274166772721\n",
      "epoch:4035, weight:[1.92201821 1.2359335 ], bias:-1.5013412473753631, loss:0.5490165743954719\n",
      "epoch:4036, weight:[1.92229566 1.23599935], bias:-1.5015058232937961, loss:0.5490057335090619\n",
      "epoch:4037, weight:[1.9225731  1.23606517], bias:-1.5016703781584595, loss:0.5489948940175655\n",
      "epoch:4038, weight:[1.92285053 1.23613098], bias:-1.5018349119758303, loss:0.5489840559205056\n",
      "epoch:4039, weight:[1.92312796 1.23619676], bias:-1.5019994247523831, loss:0.5489732192174059\n",
      "epoch:4040, weight:[1.92340538 1.23626251], bias:-1.5021639164945901, loss:0.5489623839077905\n",
      "epoch:4041, weight:[1.92368279 1.23632824], bias:-1.5023283872089206, loss:0.5489515499911833\n",
      "epoch:4042, weight:[1.9239602  1.23639395], bias:-1.5024928369018413, loss:0.5489407174671092\n",
      "epoch:4043, weight:[1.92423759 1.23645963], bias:-1.5026572655798167, loss:0.5489298863350928\n",
      "epoch:4044, weight:[1.92451499 1.23652529], bias:-1.5028216732493085, loss:0.5489190565946592\n",
      "epoch:4045, weight:[1.92479237 1.23659092], bias:-1.502986059916776, loss:0.5489082282453341\n",
      "epoch:4046, weight:[1.92506975 1.23665653], bias:-1.5031504255886756, loss:0.5488974012866431\n",
      "epoch:4047, weight:[1.92534712 1.23672211], bias:-1.5033147702714618, loss:0.5488865757181123\n",
      "epoch:4048, weight:[1.92562448 1.23678767], bias:-1.5034790939715859, loss:0.5488757515392683\n",
      "epoch:4049, weight:[1.92590184 1.23685321], bias:-1.503643396695497, loss:0.5488649287496374\n",
      "epoch:4050, weight:[1.92617919 1.23691873], bias:-1.5038076784496415, loss:0.5488541073487472\n",
      "epoch:4051, weight:[1.92645653 1.23698421], bias:-1.5039719392404636, loss:0.5488432873361243\n",
      "epoch:4052, weight:[1.92673387 1.23704968], bias:-1.5041361790744043, loss:0.5488324687112969\n",
      "epoch:4053, weight:[1.9270112  1.23711512], bias:-1.5043003979579028, loss:0.5488216514737928\n",
      "epoch:4054, weight:[1.92728852 1.23718054], bias:-1.5044645958973952, loss:0.5488108356231401\n",
      "epoch:4055, weight:[1.92756584 1.23724593], bias:-1.5046287728993153, loss:0.5488000211588674\n",
      "epoch:4056, weight:[1.92784315 1.2373113 ], bias:-1.504792928970094, loss:0.5487892080805035\n",
      "epoch:4057, weight:[1.92812045 1.23737664], bias:-1.5049570641161605, loss:0.5487783963875776\n",
      "epoch:4058, weight:[1.92839774 1.23744196], bias:-1.5051211783439407, loss:0.5487675860796194\n",
      "epoch:4059, weight:[1.92867503 1.23750726], bias:-1.5052852716598581, loss:0.5487567771561582\n",
      "epoch:4060, weight:[1.92895231 1.23757253], bias:-1.505449344070334, loss:0.5487459696167246\n",
      "epoch:4061, weight:[1.92922959 1.23763778], bias:-1.505613395581787, loss:0.5487351634608489\n",
      "epoch:4062, weight:[1.92950685 1.23770301], bias:-1.5057774262006327, loss:0.5487243586880614\n",
      "epoch:4063, weight:[1.92978411 1.23776821], bias:-1.505941435933285, loss:0.5487135552978936\n",
      "epoch:4064, weight:[1.93006137 1.23783339], bias:-1.5061054247861547, loss:0.5487027532898763\n",
      "epoch:4065, weight:[1.93033861 1.23789854], bias:-1.5062693927656503, loss:0.5486919526635416\n",
      "epoch:4066, weight:[1.93061585 1.23796367], bias:-1.5064333398781775, loss:0.5486811534184209\n",
      "epoch:4067, weight:[1.93089308 1.23802877], bias:-1.50659726613014, loss:0.548670355554047\n",
      "epoch:4068, weight:[1.93117031 1.23809386], bias:-1.506761171527938, loss:0.548659559069952\n",
      "epoch:4069, weight:[1.93144753 1.23815891], bias:-1.5069250560779706, loss:0.5486487639656686\n",
      "epoch:4070, weight:[1.93172474 1.23822395], bias:-1.507088919786633, loss:0.5486379702407305\n",
      "epoch:4071, weight:[1.93200194 1.23828896], bias:-1.507252762660319, loss:0.5486271778946706\n",
      "epoch:4072, weight:[1.93227914 1.23835394], bias:-1.507416584705419, loss:0.5486163869270231\n",
      "epoch:4073, weight:[1.93255633 1.2384189 ], bias:-1.5075803859283214, loss:0.5486055973373216\n",
      "epoch:4074, weight:[1.93283352 1.23848384], bias:-1.5077441663354119, loss:0.5485948091251007\n",
      "epoch:4075, weight:[1.93311069 1.23854876], bias:-1.5079079259330737, loss:0.548584022289895\n",
      "epoch:4076, weight:[1.93338786 1.23861365], bias:-1.5080716647276875, loss:0.5485732368312395\n",
      "epoch:4077, weight:[1.93366503 1.23867851], bias:-1.5082353827256314, loss:0.5485624527486692\n",
      "epoch:4078, weight:[1.93394218 1.23874336], bias:-1.5083990799332812, loss:0.5485516700417201\n",
      "epoch:4079, weight:[1.93421933 1.23880818], bias:-1.5085627563570099, loss:0.5485408887099275\n",
      "epoch:4080, weight:[1.93449647 1.23887297], bias:-1.5087264120031882, loss:0.5485301087528277\n",
      "epoch:4081, weight:[1.93477361 1.23893774], bias:-1.5088900468781845, loss:0.5485193301699577\n",
      "epoch:4082, weight:[1.93505074 1.23900249], bias:-1.509053660988364, loss:0.5485085529608539\n",
      "epoch:4083, weight:[1.93532786 1.23906722], bias:-1.5092172543400901, loss:0.548497777125053\n",
      "epoch:4084, weight:[1.93560497 1.23913192], bias:-1.5093808269397233, loss:0.5484870026620926\n",
      "epoch:4085, weight:[1.93588208 1.23919659], bias:-1.5095443787936218, loss:0.5484762295715108\n",
      "epoch:4086, weight:[1.93615918 1.23926125], bias:-1.5097079099081412, loss:0.5484654578528448\n",
      "epoch:4087, weight:[1.93643627 1.23932587], bias:-1.5098714202896346, loss:0.5484546875056335\n",
      "epoch:4088, weight:[1.93671336 1.23939048], bias:-1.5100349099444526, loss:0.5484439185294152\n",
      "epoch:4089, weight:[1.93699044 1.23945506], bias:-1.510198378878943, loss:0.5484331509237287\n",
      "epoch:4090, weight:[1.93726751 1.23951962], bias:-1.5103618270994519, loss:0.5484223846881133\n",
      "epoch:4091, weight:[1.93754457 1.23958415], bias:-1.5105252546123222, loss:0.5484116198221083\n",
      "epoch:4092, weight:[1.93782163 1.23964866], bias:-1.5106886614238946, loss:0.5484008563252536\n",
      "epoch:4093, weight:[1.93809868 1.23971315], bias:-1.510852047540507, loss:0.5483900941970892\n",
      "epoch:4094, weight:[1.93837573 1.23977761], bias:-1.5110154129684952, loss:0.5483793334371554\n",
      "epoch:4095, weight:[1.93865276 1.23984205], bias:-1.5111787577141922, loss:0.5483685740449928\n",
      "epoch:4096, weight:[1.9389298  1.23990647], bias:-1.5113420817839287, loss:0.5483578160201424\n",
      "epoch:4097, weight:[1.93920682 1.23997086], bias:-1.511505385184033, loss:0.5483470593621456\n",
      "epoch:4098, weight:[1.93948384 1.24003523], bias:-1.5116686679208304, loss:0.5483363040705438\n",
      "epoch:4099, weight:[1.93976084 1.24009958], bias:-1.5118319300006444, loss:0.5483255501448789\n",
      "epoch:4100, weight:[1.94003785 1.2401639 ], bias:-1.5119951714297957, loss:0.5483147975846928\n",
      "epoch:4101, weight:[1.94031484 1.2402282 ], bias:-1.5121583922146022, loss:0.5483040463895281\n",
      "epoch:4102, weight:[1.94059183 1.24029247], bias:-1.51232159236138, loss:0.5482932965589279\n",
      "epoch:4103, weight:[1.94086881 1.24035672], bias:-1.512484771876442, loss:0.5482825480924345\n",
      "epoch:4104, weight:[1.94114579 1.24042095], bias:-1.5126479307660992, loss:0.5482718009895917\n",
      "epoch:4105, weight:[1.94142275 1.24048515], bias:-1.5128110690366596, loss:0.548261055249943\n",
      "epoch:4106, weight:[1.94169971 1.24054933], bias:-1.512974186694429, loss:0.5482503108730324\n",
      "epoch:4107, weight:[1.94197667 1.24061349], bias:-1.513137283745711, loss:0.548239567858404\n",
      "epoch:4108, weight:[1.94225361 1.24067762], bias:-1.5133003601968062, loss:0.5482288262056024\n",
      "epoch:4109, weight:[1.94253055 1.24074173], bias:-1.513463416054013, loss:0.5482180859141722\n",
      "epoch:4110, weight:[1.94280749 1.24080582], bias:-1.5136264513236273, loss:0.5482073469836586\n",
      "epoch:4111, weight:[1.94308441 1.24086988], bias:-1.5137894660119424, loss:0.548196609413607\n",
      "epoch:4112, weight:[1.94336133 1.24093392], bias:-1.5139524601252494, loss:0.548185873203563\n",
      "epoch:4113, weight:[1.94363824 1.24099794], bias:-1.5141154336698366, loss:0.548175138353073\n",
      "epoch:4114, weight:[1.94391515 1.24106193], bias:-1.5142783866519902, loss:0.5481644048616826\n",
      "epoch:4115, weight:[1.94419204 1.2411259 ], bias:-1.5144413190779935, loss:0.5481536727289386\n",
      "epoch:4116, weight:[1.94446893 1.24118984], bias:-1.5146042309541277, loss:0.548142941954388\n",
      "epoch:4117, weight:[1.94474582 1.24125376], bias:-1.5147671222866712, loss:0.548132212537578\n",
      "epoch:4118, weight:[1.94502269 1.24131766], bias:-1.5149299930819002, loss:0.5481214844780559\n",
      "epoch:4119, weight:[1.94529956 1.24138154], bias:-1.5150928433460884, loss:0.5481107577753693\n",
      "epoch:4120, weight:[1.94557643 1.24144539], bias:-1.515255673085507, loss:0.5481000324290665\n",
      "epoch:4121, weight:[1.94585328 1.24150922], bias:-1.5154184823064245, loss:0.5480893084386956\n",
      "epoch:4122, weight:[1.94613013 1.24157302], bias:-1.5155812710151075, loss:0.5480785858038053\n",
      "epoch:4123, weight:[1.94640697 1.2416368 ], bias:-1.5157440392178196, loss:0.5480678645239444\n",
      "epoch:4124, weight:[1.9466838  1.24170056], bias:-1.5159067869208223, loss:0.5480571445986623\n",
      "epoch:4125, weight:[1.94696063 1.24176429], bias:-1.5160695141303742, loss:0.5480464260275083\n",
      "epoch:4126, weight:[1.94723745 1.24182801], bias:-1.516232220852732, loss:0.5480357088100323\n",
      "epoch:4127, weight:[1.94751426 1.24189169], bias:-1.5163949070941494, loss:0.5480249929457841\n",
      "epoch:4128, weight:[1.94779107 1.24195536], bias:-1.5165575728608782, loss:0.5480142784343144\n",
      "epoch:4129, weight:[1.94806787 1.242019  ], bias:-1.5167202181591675, loss:0.5480035652751737\n",
      "epoch:4130, weight:[1.94834466 1.24208262], bias:-1.5168828429952637, loss:0.5479928534679126\n",
      "epoch:4131, weight:[1.94862145 1.24214621], bias:-1.517045447375411, loss:0.5479821430120829\n",
      "epoch:4132, weight:[1.94889823 1.24220978], bias:-1.517208031305851, loss:0.547971433907236\n",
      "epoch:4133, weight:[1.949175   1.24227333], bias:-1.5173705947928229, loss:0.5479607261529233\n",
      "epoch:4134, weight:[1.94945176 1.24233686], bias:-1.5175331378425638, loss:0.5479500197486971\n",
      "epoch:4135, weight:[1.94972852 1.24240036], bias:-1.5176956604613079, loss:0.5479393146941098\n",
      "epoch:4136, weight:[1.95000527 1.24246384], bias:-1.5178581626552872, loss:0.5479286109887144\n",
      "epoch:4137, weight:[1.95028201 1.24252729], bias:-1.518020644430731, loss:0.5479179086320634\n",
      "epoch:4138, weight:[1.95055875 1.24259072], bias:-1.5181831057938664, loss:0.5479072076237101\n",
      "epoch:4139, weight:[1.95083547 1.24265413], bias:-1.5183455467509182, loss:0.5478965079632082\n",
      "epoch:4140, weight:[1.9511122  1.24271752], bias:-1.518507967308108, loss:0.5478858096501115\n",
      "epoch:4141, weight:[1.95138891 1.24278088], bias:-1.5186703674716562, loss:0.5478751126839739\n",
      "epoch:4142, weight:[1.95166562 1.24284422], bias:-1.5188327472477796, loss:0.54786441706435\n",
      "epoch:4143, weight:[1.95194232 1.24290753], bias:-1.5189951066426932, loss:0.5478537227907946\n",
      "epoch:4144, weight:[1.95221901 1.24297082], bias:-1.5191574456626094, loss:0.5478430298628623\n",
      "epoch:4145, weight:[1.9524957  1.24303409], bias:-1.519319764313738, loss:0.5478323382801086\n",
      "epoch:4146, weight:[1.95277238 1.24309734], bias:-1.5194820626022867, loss:0.5478216480420891\n",
      "epoch:4147, weight:[1.95304905 1.24316056], bias:-1.5196443405344604, loss:0.5478109591483594\n",
      "epoch:4148, weight:[1.95332572 1.24322376], bias:-1.519806598116462, loss:0.5478002715984759\n",
      "epoch:4149, weight:[1.95360237 1.24328694], bias:-1.5199688353544913, loss:0.5477895853919947\n",
      "epoch:4150, weight:[1.95387903 1.24335009], bias:-1.5201310522547467, loss:0.5477789005284728\n",
      "epoch:4151, weight:[1.95415567 1.24341322], bias:-1.520293248823423, loss:0.5477682170074667\n",
      "epoch:4152, weight:[1.95443231 1.24347633], bias:-1.5204554250667135, loss:0.5477575348285342\n",
      "epoch:4153, weight:[1.95470894 1.24353941], bias:-1.5206175809908085, loss:0.5477468539912325\n",
      "epoch:4154, weight:[1.95498556 1.24360247], bias:-1.5207797166018961, loss:0.5477361744951197\n",
      "epoch:4155, weight:[1.95526218 1.24366551], bias:-1.520941831906162, loss:0.5477254963397534\n",
      "epoch:4156, weight:[1.95553878 1.24372853], bias:-1.5211039269097895, loss:0.5477148195246925\n",
      "epoch:4157, weight:[1.95581539 1.24379152], bias:-1.5212660016189592, loss:0.5477041440494956\n",
      "epoch:4158, weight:[1.95609198 1.24385449], bias:-1.5214280560398497, loss:0.5476934699137216\n",
      "epoch:4159, weight:[1.95636857 1.24391743], bias:-1.5215900901786368, loss:0.5476827971169296\n",
      "epoch:4160, weight:[1.95664515 1.24398036], bias:-1.5217521040414943, loss:0.5476721256586793\n",
      "epoch:4161, weight:[1.95692172 1.24404326], bias:-1.521914097634593, loss:0.5476614555385303\n",
      "epoch:4162, weight:[1.95719829 1.24410613], bias:-1.5220760709641021, loss:0.5476507867560432\n",
      "epoch:4163, weight:[1.95747485 1.24416899], bias:-1.5222380240361875, loss:0.5476401193107777\n",
      "epoch:4164, weight:[1.9577514  1.24423182], bias:-1.5223999568570132, loss:0.5476294532022951\n",
      "epoch:4165, weight:[1.95802795 1.24429462], bias:-1.5225618694327407, loss:0.5476187884301558\n",
      "epoch:4166, weight:[1.95830448 1.24435741], bias:-1.522723761769529, loss:0.5476081249939214\n",
      "epoch:4167, weight:[1.95858102 1.24442017], bias:-1.5228856338735348, loss:0.5475974628931534\n",
      "epoch:4168, weight:[1.95885754 1.24448291], bias:-1.5230474857509122, loss:0.5475868021274132\n",
      "epoch:4169, weight:[1.95913406 1.24454562], bias:-1.5232093174078132, loss:0.5475761426962632\n",
      "epoch:4170, weight:[1.95941057 1.24460832], bias:-1.523371128850387, loss:0.5475654845992657\n",
      "epoch:4171, weight:[1.95968707 1.24467098], bias:-1.523532920084781, loss:0.5475548278359833\n",
      "epoch:4172, weight:[1.95996356 1.24473363], bias:-1.5236946911171394, loss:0.5475441724059791\n",
      "epoch:4173, weight:[1.96024005 1.24479626], bias:-1.5238564419536047, loss:0.5475335183088158\n",
      "epoch:4174, weight:[1.96051653 1.24485886], bias:-1.5240181726003166, loss:0.5475228655440575\n",
      "epoch:4175, weight:[1.96079301 1.24492143], bias:-1.5241798830634123, loss:0.5475122141112674\n",
      "epoch:4176, weight:[1.96106948 1.24498399], bias:-1.5243415733490273, loss:0.5475015640100102\n",
      "epoch:4177, weight:[1.96134594 1.24504652], bias:-1.5245032434632937, loss:0.5474909152398494\n",
      "epoch:4178, weight:[1.96162239 1.24510903], bias:-1.524664893412342, loss:0.5474802678003501\n",
      "epoch:4179, weight:[1.96189884 1.24517152], bias:-1.5248265232022997, loss:0.5474696216910772\n",
      "epoch:4180, weight:[1.96217527 1.24523398], bias:-1.5249881328392925, loss:0.5474589769115954\n",
      "epoch:4181, weight:[1.96245171 1.24529642], bias:-1.5251497223294432, loss:0.5474483334614706\n",
      "epoch:4182, weight:[1.96272813 1.24535884], bias:-1.5253112916788727, loss:0.5474376913402685\n",
      "epoch:4183, weight:[1.96300455 1.24542123], bias:-1.5254728408936988, loss:0.5474270505475549\n",
      "epoch:4184, weight:[1.96328096 1.24548361], bias:-1.5256343699800377, loss:0.5474164110828961\n",
      "epoch:4185, weight:[1.96355736 1.24554596], bias:-1.5257958789440027, loss:0.5474057729458586\n",
      "epoch:4186, weight:[1.96383376 1.24560828], bias:-1.5259573677917049, loss:0.5473951361360093\n",
      "epoch:4187, weight:[1.96411015 1.24567059], bias:-1.5261188365292528, loss:0.5473845006529154\n",
      "epoch:4188, weight:[1.96438653 1.24573287], bias:-1.5262802851627528, loss:0.5473738664961441\n",
      "epoch:4189, weight:[1.9646629  1.24579512], bias:-1.5264417136983086, loss:0.547363233665263\n",
      "epoch:4190, weight:[1.96493927 1.24585736], bias:-1.526603122142022, loss:0.5473526021598402\n",
      "epoch:4191, weight:[1.96521563 1.24591957], bias:-1.5267645104999918, loss:0.5473419719794437\n",
      "epoch:4192, weight:[1.96549199 1.24598176], bias:-1.5269258787783149, loss:0.5473313431236421\n",
      "epoch:4193, weight:[1.96576833 1.24604393], bias:-1.5270872269830855, loss:0.5473207155920043\n",
      "epoch:4194, weight:[1.96604467 1.24610607], bias:-1.5272485551203958, loss:0.5473100893840993\n",
      "epoch:4195, weight:[1.966321  1.2461682], bias:-1.5274098631963353, loss:0.5472994644994962\n",
      "epoch:4196, weight:[1.96659733 1.24623029], bias:-1.5275711512169912, loss:0.5472888409377649\n",
      "epoch:4197, weight:[1.96687365 1.24629237], bias:-1.527732419188448, loss:0.5472782186984749\n",
      "epoch:4198, weight:[1.96714996 1.24635442], bias:-1.5278936671167886, loss:0.5472675977811966\n",
      "epoch:4199, weight:[1.96742626 1.24641645], bias:-1.5280548950080928, loss:0.5472569781855005\n",
      "epoch:4200, weight:[1.96770256 1.24647846], bias:-1.5282161028684385, loss:0.5472463599109567\n",
      "epoch:4201, weight:[1.96797885 1.24654045], bias:-1.5283772907039008, loss:0.5472357429571368\n",
      "epoch:4202, weight:[1.96825513 1.24660241], bias:-1.5285384585205528, loss:0.5472251273236118\n",
      "epoch:4203, weight:[1.96853141 1.24666435], bias:-1.5286996063244649, loss:0.5472145130099535\n",
      "epoch:4204, weight:[1.96880768 1.24672627], bias:-1.5288607341217055, loss:0.547203900015733\n",
      "epoch:4205, weight:[1.96908394 1.24678816], bias:-1.5290218419183403, loss:0.5471932883405229\n",
      "epoch:4206, weight:[1.96936019 1.24685004], bias:-1.529182929720433, loss:0.5471826779838955\n",
      "epoch:4207, weight:[1.96963644 1.24691189], bias:-1.5293439975340444, loss:0.5471720689454233\n",
      "epoch:4208, weight:[1.96991268 1.24697371], bias:-1.5295050453652335, loss:0.547161461224679\n",
      "epoch:4209, weight:[1.97018891 1.24703552], bias:-1.5296660732200564, loss:0.5471508548212362\n",
      "epoch:4210, weight:[1.97046513 1.2470973 ], bias:-1.5298270811045673, loss:0.5471402497346679\n",
      "epoch:4211, weight:[1.97074135 1.24715906], bias:-1.5299880690248178, loss:0.5471296459645479\n",
      "epoch:4212, weight:[1.97101756 1.24722079], bias:-1.5301490369868571, loss:0.5471190435104504\n",
      "epoch:4213, weight:[1.97129377 1.24728251], bias:-1.530309984996732, loss:0.5471084423719493\n",
      "epoch:4214, weight:[1.97156996 1.2473442 ], bias:-1.5304709130604874, loss:0.5470978425486194\n",
      "epoch:4215, weight:[1.97184615 1.24740587], bias:-1.5306318211841652, loss:0.5470872440400355\n",
      "epoch:4216, weight:[1.97212234 1.24746751], bias:-1.5307927093738054, loss:0.5470766468457722\n",
      "epoch:4217, weight:[1.97239851 1.24752914], bias:-1.5309535776354455, loss:0.5470660509654052\n",
      "epoch:4218, weight:[1.97267468 1.24759074], bias:-1.5311144259751204, loss:0.5470554563985102\n",
      "epoch:4219, weight:[1.97295084 1.24765232], bias:-1.531275254398863, loss:0.5470448631446628\n",
      "epoch:4220, weight:[1.973227   1.24771387], bias:-1.531436062912704, loss:0.5470342712034393\n",
      "epoch:4221, weight:[1.97350314 1.24777541], bias:-1.531596851522671, loss:0.547023680574416\n",
      "epoch:4222, weight:[1.97377928 1.24783692], bias:-1.53175762023479, loss:0.5470130912571696\n",
      "epoch:4223, weight:[1.97405541 1.24789841], bias:-1.5319183690550844, loss:0.5470025032512772\n",
      "epoch:4224, weight:[1.97433154 1.24795988], bias:-1.532079097989575, loss:0.5469919165563158\n",
      "epoch:4225, weight:[1.97460766 1.24802132], bias:-1.5322398070442806, loss:0.5469813311718631\n",
      "epoch:4226, weight:[1.97488377 1.24808274], bias:-1.5324004962252176, loss:0.5469707470974967\n",
      "epoch:4227, weight:[1.97515987 1.24814414], bias:-1.5325611655383997, loss:0.5469601643327947\n",
      "epoch:4228, weight:[1.97543597 1.24820552], bias:-1.5327218149898387, loss:0.5469495828773354\n",
      "epoch:4229, weight:[1.97571206 1.24826687], bias:-1.532882444585544, loss:0.5469390027306972\n",
      "epoch:4230, weight:[1.97598814 1.2483282 ], bias:-1.5330430543315223, loss:0.5469284238924591\n",
      "epoch:4231, weight:[1.97626422 1.24838951], bias:-1.5332036442337784, loss:0.5469178463622003\n",
      "epoch:4232, weight:[1.97654029 1.2484508 ], bias:-1.5333642142983146, loss:0.5469072701395\n",
      "epoch:4233, weight:[1.97681635 1.24851206], bias:-1.5335247645311305, loss:0.5468966952239379\n",
      "epoch:4234, weight:[1.9770924 1.2485733], bias:-1.533685294938224, loss:0.5468861216150939\n",
      "epoch:4235, weight:[1.97736845 1.24863452], bias:-1.5338458055255901, loss:0.5468755493125481\n",
      "epoch:4236, weight:[1.97764449 1.24869572], bias:-1.534006296299222, loss:0.5468649783158811\n",
      "epoch:4237, weight:[1.97792052 1.2487569 ], bias:-1.53416676726511, loss:0.5468544086246733\n",
      "epoch:4238, weight:[1.97819654 1.24881805], bias:-1.5343272184292425, loss:0.5468438402385059\n",
      "epoch:4239, weight:[1.97847256 1.24887918], bias:-1.5344876497976052, loss:0.5468332731569604\n",
      "epoch:4240, weight:[1.97874857 1.24894029], bias:-1.534648061376182, loss:0.5468227073796178\n",
      "epoch:4241, weight:[1.97902458 1.24900137], bias:-1.5348084531709538, loss:0.5468121429060603\n",
      "epoch:4242, weight:[1.97930057 1.24906244], bias:-1.5349688251878997, loss:0.5468015797358695\n",
      "epoch:4243, weight:[1.97957656 1.24912348], bias:-1.5351291774329963, loss:0.546791017868628\n",
      "epoch:4244, weight:[1.97985254 1.2491845 ], bias:-1.5352895099122177, loss:0.5467804573039184\n",
      "epoch:4245, weight:[1.98012852 1.24924549], bias:-1.5354498226315358, loss:0.5467698980413235\n",
      "epoch:4246, weight:[1.98040449 1.24930647], bias:-1.5356101155969204, loss:0.5467593400804264\n",
      "epoch:4247, weight:[1.98068045 1.24936742], bias:-1.5357703888143386, loss:0.5467487834208102\n",
      "epoch:4248, weight:[1.9809564  1.24942835], bias:-1.5359306422897554, loss:0.546738228062059\n",
      "epoch:4249, weight:[1.98123235 1.24948926], bias:-1.5360908760291336, loss:0.5467276740037563\n",
      "epoch:4250, weight:[1.98150828 1.24955014], bias:-1.5362510900384334, loss:0.5467171212454863\n",
      "epoch:4251, weight:[1.98178422 1.249611  ], bias:-1.5364112843236126, loss:0.5467065697868339\n",
      "epoch:4252, weight:[1.98206014 1.24967185], bias:-1.536571458890627, loss:0.5466960196273832\n",
      "epoch:4253, weight:[1.98233606 1.24973266], bias:-1.5367316137454299, loss:0.5466854707667194\n",
      "epoch:4254, weight:[1.98261197 1.24979346], bias:-1.5368917488939724, loss:0.5466749232044276\n",
      "epoch:4255, weight:[1.98288787 1.24985423], bias:-1.5370518643422033, loss:0.5466643769400934\n",
      "epoch:4256, weight:[1.98316377 1.24991499], bias:-1.5372119600960688, loss:0.5466538319733026\n",
      "epoch:4257, weight:[1.98343966 1.24997572], bias:-1.537372036161513, loss:0.5466432883036411\n",
      "epoch:4258, weight:[1.98371554 1.25003642], bias:-1.537532092544478, loss:0.5466327459306952\n",
      "epoch:4259, weight:[1.98399141 1.25009711], bias:-1.5376921292509027, loss:0.5466222048540517\n",
      "epoch:4260, weight:[1.98426728 1.25015777], bias:-1.5378521462867247, loss:0.5466116650732967\n",
      "epoch:4261, weight:[1.98454314 1.25021841], bias:-1.5380121436578786, loss:0.5466011265880178\n",
      "epoch:4262, weight:[1.98481899 1.25027903], bias:-1.538172121370297, loss:0.5465905893978019\n",
      "epoch:4263, weight:[1.98509484 1.25033963], bias:-1.53833207942991, loss:0.5465800535022375\n",
      "epoch:4264, weight:[1.98537067 1.2504002 ], bias:-1.5384920178426458, loss:0.5465695189009115\n",
      "epoch:4265, weight:[1.98564651 1.25046076], bias:-1.5386519366144298, loss:0.5465589855934123\n",
      "epoch:4266, weight:[1.98592233 1.25052129], bias:-1.5388118357511853, loss:0.5465484535793285\n",
      "epoch:4267, weight:[1.98619815 1.2505818 ], bias:-1.5389717152588331, loss:0.5465379228582482\n",
      "epoch:4268, weight:[1.98647396 1.25064228], bias:-1.5391315751432924, loss:0.5465273934297605\n",
      "epoch:4269, weight:[1.98674976 1.25070275], bias:-1.539291415410479, loss:0.546516865293455\n",
      "epoch:4270, weight:[1.98702555 1.25076319], bias:-1.5394512360663075, loss:0.5465063384489206\n",
      "epoch:4271, weight:[1.98730134 1.25082361], bias:-1.5396110371166893, loss:0.5464958128957472\n",
      "epoch:4272, weight:[1.98757712 1.25088401], bias:-1.539770818567534, loss:0.5464852886335246\n",
      "epoch:4273, weight:[1.98785289 1.25094438], bias:-1.539930580424749, loss:0.5464747656618429\n",
      "epoch:4274, weight:[1.98812866 1.25100474], bias:-1.5400903226942388, loss:0.5464642439802928\n",
      "epoch:4275, weight:[1.98840442 1.25106507], bias:-1.5402500453819064, loss:0.5464537235884649\n",
      "epoch:4276, weight:[1.98868017 1.25112538], bias:-1.5404097484936519, loss:0.5464432044859502\n",
      "epoch:4277, weight:[1.98895591 1.25118567], bias:-1.5405694320353733, loss:0.5464326866723397\n",
      "epoch:4278, weight:[1.98923165 1.25124593], bias:-1.5407290960129665, loss:0.546422170147225\n",
      "epoch:4279, weight:[1.98950738 1.25130618], bias:-1.5408887404323248, loss:0.5464116549101979\n",
      "epoch:4280, weight:[1.9897831 1.2513664], bias:-1.5410483652993392, loss:0.5464011409608506\n",
      "epoch:4281, weight:[1.99005882 1.2514266 ], bias:-1.5412079706198987, loss:0.5463906282987752\n",
      "epoch:4282, weight:[1.99033453 1.25148678], bias:-1.5413675563998899, loss:0.546380116923564\n",
      "epoch:4283, weight:[1.99061023 1.25154693], bias:-1.541527122645197, loss:0.54636960683481\n",
      "epoch:4284, weight:[1.99088592 1.25160707], bias:-1.541686669361702, loss:0.5463590980321059\n",
      "epoch:4285, weight:[1.99116161 1.25166718], bias:-1.5418461965552845, loss:0.5463485905150457\n",
      "epoch:4286, weight:[1.99143729 1.25172727], bias:-1.542005704231822, loss:0.5463380842832223\n",
      "epoch:4287, weight:[1.99171296 1.25178734], bias:-1.5421651923971895, loss:0.5463275793362298\n",
      "epoch:4288, weight:[1.99198863 1.25184739], bias:-1.54232466105726, loss:0.5463170756736622\n",
      "epoch:4289, weight:[1.99226428 1.25190741], bias:-1.542484110217904, loss:0.5463065732951133\n",
      "epoch:4290, weight:[1.99253993 1.25196741], bias:-1.54264353988499, loss:0.5462960722001786\n",
      "epoch:4291, weight:[1.99281558 1.25202739], bias:-1.5428029500643838, loss:0.5462855723884527\n",
      "epoch:4292, weight:[1.99309121 1.25208735], bias:-1.542962340761949, loss:0.5462750738595301\n",
      "epoch:4293, weight:[1.99336684 1.25214729], bias:-1.5431217119835472, loss:0.5462645766130065\n",
      "epoch:4294, weight:[1.99364246 1.25220721], bias:-1.5432810637350376, loss:0.5462540806484778\n",
      "epoch:4295, weight:[1.99391808 1.2522671 ], bias:-1.5434403960222771, loss:0.5462435859655393\n",
      "epoch:4296, weight:[1.99419369 1.25232697], bias:-1.5435997088511202, loss:0.5462330925637876\n",
      "epoch:4297, weight:[1.99446929 1.25238682], bias:-1.5437590022274195, loss:0.5462226004428188\n",
      "epoch:4298, weight:[1.99474488 1.25244665], bias:-1.5439182761570247, loss:0.5462121096022294\n",
      "epoch:4299, weight:[1.99502046 1.25250645], bias:-1.544077530645784, loss:0.5462016200416168\n",
      "epoch:4300, weight:[1.99529604 1.25256624], bias:-1.5442367656995426, loss:0.5461911317605774\n",
      "epoch:4301, weight:[1.99557161 1.252626  ], bias:-1.5443959813241441, loss:0.5461806447587091\n",
      "epoch:4302, weight:[1.99584718 1.25268574], bias:-1.5445551775254294, loss:0.5461701590356093\n",
      "epoch:4303, weight:[1.99612273 1.25274546], bias:-1.544714354309237, loss:0.546159674590876\n",
      "epoch:4304, weight:[1.99639828 1.25280516], bias:-1.5448735116814036, loss:0.5461491914241073\n",
      "epoch:4305, weight:[1.99667382 1.25286483], bias:-1.5450326496477633, loss:0.5461387095349016\n",
      "epoch:4306, weight:[1.99694936 1.25292449], bias:-1.545191768214148, loss:0.5461282289228574\n",
      "epoch:4307, weight:[1.99722488 1.25298412], bias:-1.5453508673863876, loss:0.5461177495875739\n",
      "epoch:4308, weight:[1.9975004  1.25304373], bias:-1.5455099471703093, loss:0.5461072715286502\n",
      "epoch:4309, weight:[1.99777592 1.25310332], bias:-1.5456690075717383, loss:0.5460967947456855\n",
      "epoch:4310, weight:[1.99805142 1.25316288], bias:-1.5458280485964975, loss:0.5460863192382797\n",
      "epoch:4311, weight:[1.99832692 1.25322243], bias:-1.5459870702504075, loss:0.5460758450060325\n",
      "epoch:4312, weight:[1.99860241 1.25328195], bias:-1.5461460725392868, loss:0.5460653720485441\n",
      "epoch:4313, weight:[1.9988779  1.25334145], bias:-1.5463050554689515, loss:0.546054900365415\n",
      "epoch:4314, weight:[1.99915337 1.25340093], bias:-1.5464640190452152, loss:0.546044429956246\n",
      "epoch:4315, weight:[1.99942884 1.25346039], bias:-1.54662296327389, loss:0.5460339608206378\n",
      "epoch:4316, weight:[1.9997043  1.25351983], bias:-1.5467818881607847, loss:0.5460234929581917\n",
      "epoch:4317, weight:[1.99997976 1.25357924], bias:-1.5469407937117068, loss:0.546013026368509\n",
      "epoch:4318, weight:[2.00025521 1.25363864], bias:-1.547099679932461, loss:0.5460025610511913\n",
      "epoch:4319, weight:[2.00053065 1.25369801], bias:-1.5472585468288498, loss:0.5459920970058408\n",
      "epoch:4320, weight:[2.00080608 1.25375736], bias:-1.5474173944066736, loss:0.5459816342320596\n",
      "epoch:4321, weight:[2.0010815  1.25381669], bias:-1.5475762226717307, loss:0.5459711727294501\n",
      "epoch:4322, weight:[2.00135692 1.25387599], bias:-1.5477350316298166, loss:0.5459607124976148\n",
      "epoch:4323, weight:[2.00163233 1.25393528], bias:-1.5478938212867253, loss:0.5459502535361569\n",
      "epoch:4324, weight:[2.00190774 1.25399454], bias:-1.548052591648248, loss:0.5459397958446794\n",
      "epoch:4325, weight:[2.00218313 1.25405378], bias:-1.5482113427201736, loss:0.5459293394227857\n",
      "epoch:4326, weight:[2.00245852 1.254113  ], bias:-1.5483700745082891, loss:0.5459188842700796\n",
      "epoch:4327, weight:[2.0027339 1.2541722], bias:-1.5485287870183793, loss:0.5459084303861651\n",
      "epoch:4328, weight:[2.00300928 1.25423138], bias:-1.5486874802562265, loss:0.5458979777706462\n",
      "epoch:4329, weight:[2.00328465 1.25429054], bias:-1.5488461542276108, loss:0.5458875264231272\n",
      "epoch:4330, weight:[2.00356001 1.25434967], bias:-1.5490048089383102, loss:0.5458770763432131\n",
      "epoch:4331, weight:[2.00383536 1.25440878], bias:-1.5491634443941, loss:0.5458666275305085\n",
      "epoch:4332, weight:[2.0041107  1.25446787], bias:-1.549322060600754, loss:0.545856179984619\n",
      "epoch:4333, weight:[2.00438604 1.25452694], bias:-1.5494806575640434, loss:0.5458457337051497\n",
      "epoch:4334, weight:[2.00466137 1.25458599], bias:-1.549639235289737, loss:0.5458352886917062\n",
      "epoch:4335, weight:[2.0049367  1.25464502], bias:-1.5497977937836016, loss:0.5458248449438945\n",
      "epoch:4336, weight:[2.00521201 1.25470402], bias:-1.5499563330514015, loss:0.545814402461321\n",
      "epoch:4337, weight:[2.00548732 1.25476301], bias:-1.550114853098899, loss:0.5458039612435917\n",
      "epoch:4338, weight:[2.00576262 1.25482197], bias:-1.5502733539318545, loss:0.5457935212903136\n",
      "epoch:4339, weight:[2.00603792 1.25488091], bias:-1.5504318355560254, loss:0.5457830826010933\n",
      "epoch:4340, weight:[2.0063132  1.25493983], bias:-1.5505902979771673, loss:0.5457726451755381\n",
      "epoch:4341, weight:[2.00658848 1.25499873], bias:-1.5507487412010337, loss:0.5457622090132557\n",
      "epoch:4342, weight:[2.00686376 1.2550576 ], bias:-1.5509071652333755, loss:0.5457517741138531\n",
      "epoch:4343, weight:[2.00713902 1.25511646], bias:-1.5510655700799416, loss:0.5457413404769387\n",
      "epoch:4344, weight:[2.00741428 1.25517529], bias:-1.5512239557464789, loss:0.5457309081021204\n",
      "epoch:4345, weight:[2.00768953 1.2552341 ], bias:-1.5513823222387315, loss:0.5457204769890067\n",
      "epoch:4346, weight:[2.00796477 1.25529289], bias:-1.5515406695624419, loss:0.5457100471372062\n",
      "epoch:4347, weight:[2.00824001 1.25535166], bias:-1.5516989977233497, loss:0.5456996185463275\n",
      "epoch:4348, weight:[2.00851524 1.25541041], bias:-1.551857306727193, loss:0.5456891912159801\n",
      "epoch:4349, weight:[2.00879046 1.25546914], bias:-1.5520155965797073, loss:0.5456787651457735\n",
      "epoch:4350, weight:[2.00906567 1.25552784], bias:-1.5521738672866259, loss:0.5456683403353167\n",
      "epoch:4351, weight:[2.00934088 1.25558652], bias:-1.5523321188536798, loss:0.54565791678422\n",
      "epoch:4352, weight:[2.00961608 1.25564519], bias:-1.552490351286598, loss:0.5456474944920932\n",
      "epoch:4353, weight:[2.00989127 1.25570383], bias:-1.552648564591107, loss:0.545637073458547\n",
      "epoch:4354, weight:[2.01016646 1.25576245], bias:-1.5528067587729313, loss:0.5456266536831917\n",
      "epoch:4355, weight:[2.01044163 1.25582104], bias:-1.552964933837793, loss:0.5456162351656382\n",
      "epoch:4356, weight:[2.0107168  1.25587962], bias:-1.5531230897914126, loss:0.5456058179054978\n",
      "epoch:4357, weight:[2.01099197 1.25593818], bias:-1.5532812266395073, loss:0.5455954019023815\n",
      "epoch:4358, weight:[2.01126712 1.25599671], bias:-1.553439344387793, loss:0.5455849871559009\n",
      "epoch:4359, weight:[2.01154227 1.25605522], bias:-1.553597443041983, loss:0.545574573665668\n",
      "epoch:4360, weight:[2.01181741 1.25611372], bias:-1.5537555226077886, loss:0.5455641614312946\n",
      "epoch:4361, weight:[2.01209255 1.25617219], bias:-1.5539135830909185, loss:0.5455537504523931\n",
      "epoch:4362, weight:[2.01236767 1.25623063], bias:-1.5540716244970798, loss:0.5455433407285764\n",
      "epoch:4363, weight:[2.01264279 1.25628906], bias:-1.5542296468319767, loss:0.5455329322594563\n",
      "epoch:4364, weight:[2.0129179  1.25634747], bias:-1.5543876501013119, loss:0.5455225250446468\n",
      "epoch:4365, weight:[2.01319301 1.25640585], bias:-1.5545456343107853, loss:0.545512119083761\n",
      "epoch:4366, weight:[2.0134681  1.25646422], bias:-1.5547035994660947, loss:0.5455017143764118\n",
      "epoch:4367, weight:[2.01374319 1.25652256], bias:-1.5548615455729362, loss:0.5454913109222136\n",
      "epoch:4368, weight:[2.01401828 1.25658088], bias:-1.555019472637003, loss:0.5454809087207799\n",
      "epoch:4369, weight:[2.01429335 1.25663918], bias:-1.5551773806639866, loss:0.5454705077717251\n",
      "epoch:4370, weight:[2.01456842 1.25669746], bias:-1.555335269659576, loss:0.5454601080746639\n",
      "epoch:4371, weight:[2.01484348 1.25675572], bias:-1.555493139629458, loss:0.5454497096292109\n",
      "epoch:4372, weight:[2.01511853 1.25681396], bias:-1.5556509905793177, loss:0.545439312434981\n",
      "epoch:4373, weight:[2.01539358 1.25687217], bias:-1.5558088225148374, loss:0.5454289164915891\n",
      "epoch:4374, weight:[2.01566862 1.25693037], bias:-1.5559666354416974, loss:0.545418521798651\n",
      "epoch:4375, weight:[2.01594365 1.25698854], bias:-1.556124429365576, loss:0.5454081283557822\n",
      "epoch:4376, weight:[2.01621867 1.25704669], bias:-1.5562822042921491, loss:0.5453977361625988\n",
      "epoch:4377, weight:[2.01649369 1.25710482], bias:-1.5564399602270904, loss:0.5453873452187167\n",
      "epoch:4378, weight:[2.0167687  1.25716293], bias:-1.5565976971760713, loss:0.5453769555237525\n",
      "epoch:4379, weight:[2.0170437  1.25722102], bias:-1.5567554151447613, loss:0.5453665670773227\n",
      "epoch:4380, weight:[2.01731869 1.25727909], bias:-1.5569131141388277, loss:0.5453561798790442\n",
      "epoch:4381, weight:[2.01759368 1.25733713], bias:-1.5570707941639352, loss:0.5453457939285341\n",
      "epoch:4382, weight:[2.01786866 1.25739516], bias:-1.557228455225747, loss:0.5453354092254096\n",
      "epoch:4383, weight:[2.01814363 1.25745316], bias:-1.5573860973299232, loss:0.5453250257692887\n",
      "epoch:4384, weight:[2.01841859 1.25751115], bias:-1.5575437204821225, loss:0.545314643559789\n",
      "epoch:4385, weight:[2.01869355 1.25756911], bias:-1.5577013246880014, loss:0.5453042625965283\n",
      "epoch:4386, weight:[2.0189685  1.25762705], bias:-1.5578589099532134, loss:0.5452938828791253\n",
      "epoch:4387, weight:[2.01924345 1.25768497], bias:-1.5580164762834108, loss:0.5452835044071983\n",
      "epoch:4388, weight:[2.01951838 1.25774287], bias:-1.558174023684243, loss:0.5452731271803661\n",
      "epoch:4389, weight:[2.01979331 1.25780074], bias:-1.5583315521613577, loss:0.5452627511982479\n",
      "epoch:4390, weight:[2.02006823 1.2578586 ], bias:-1.5584890617204001, loss:0.5452523764604628\n",
      "epoch:4391, weight:[2.02034314 1.25791644], bias:-1.5586465523670134, loss:0.5452420029666303\n",
      "epoch:4392, weight:[2.02061805 1.25797425], bias:-1.5588040241068386, loss:0.5452316307163702\n",
      "epoch:4393, weight:[2.02089295 1.25803204], bias:-1.5589614769455142, loss:0.5452212597093022\n",
      "epoch:4394, weight:[2.02116784 1.25808982], bias:-1.5591189108886772, loss:0.545210889945047\n",
      "epoch:4395, weight:[2.02144272 1.25814757], bias:-1.5592763259419617, loss:0.5452005214232245\n",
      "epoch:4396, weight:[2.0217176 1.2582053], bias:-1.5594337221110002, loss:0.5451901541434556\n",
      "epoch:4397, weight:[2.02199247 1.25826301], bias:-1.5595910994014226, loss:0.5451797881053613\n",
      "epoch:4398, weight:[2.02226733 1.2583207 ], bias:-1.559748457818857, loss:0.5451694233085628\n",
      "epoch:4399, weight:[2.02254218 1.25837836], bias:-1.559905797368929, loss:0.5451590597526812\n",
      "epoch:4400, weight:[2.02281703 1.25843601], bias:-1.5600631180572622, loss:0.5451486974373384\n",
      "epoch:4401, weight:[2.02309187 1.25849364], bias:-1.560220419889478, loss:0.5451383363621561\n",
      "epoch:4402, weight:[2.0233667  1.25855124], bias:-1.5603777028711956, loss:0.5451279765267564\n",
      "epoch:4403, weight:[2.02364153 1.25860882], bias:-1.560534967008032, loss:0.5451176179307615\n",
      "epoch:4404, weight:[2.02391635 1.25866639], bias:-1.5606922123056022, loss:0.5451072605737944\n",
      "epoch:4405, weight:[2.02419116 1.25872393], bias:-1.5608494387695189, loss:0.5450969044554775\n",
      "epoch:4406, weight:[2.02446596 1.25878145], bias:-1.5610066464053927, loss:0.5450865495754338\n",
      "epoch:4407, weight:[2.02474076 1.25883895], bias:-1.5611638352188317, loss:0.5450761959332868\n",
      "epoch:4408, weight:[2.02501554 1.25889643], bias:-1.5613210052154425, loss:0.5450658435286598\n",
      "epoch:4409, weight:[2.02529032 1.25895389], bias:-1.5614781564008289, loss:0.5450554923611769\n",
      "epoch:4410, weight:[2.0255651  1.25901133], bias:-1.5616352887805929, loss:0.5450451424304616\n",
      "epoch:4411, weight:[2.02583986 1.25906874], bias:-1.5617924023603342, loss:0.5450347937361383\n",
      "epoch:4412, weight:[2.02611462 1.25912614], bias:-1.5619494971456507, loss:0.5450244462778314\n",
      "epoch:4413, weight:[2.02638937 1.25918351], bias:-1.5621065731421375, loss:0.5450141000551659\n",
      "epoch:4414, weight:[2.02666412 1.25924087], bias:-1.5622636303553878, loss:0.545003755067766\n",
      "epoch:4415, weight:[2.02693885 1.2592982 ], bias:-1.562420668790993, loss:0.5449934113152574\n",
      "epoch:4416, weight:[2.02721358 1.25935551], bias:-1.5625776884545417, loss:0.5449830687972653\n",
      "epoch:4417, weight:[2.0274883 1.2594128], bias:-1.562734689351621, loss:0.5449727275134154\n",
      "epoch:4418, weight:[2.02776302 1.25947007], bias:-1.5628916714878154, loss:0.5449623874633335\n",
      "epoch:4419, weight:[2.02803773 1.25952732], bias:-1.5630486348687074, loss:0.5449520486466454\n",
      "epoch:4420, weight:[2.02831242 1.25958455], bias:-1.5632055794998774, loss:0.5449417110629775\n",
      "epoch:4421, weight:[2.02858712 1.25964176], bias:-1.5633625053869036, loss:0.5449313747119565\n",
      "epoch:4422, weight:[2.0288618  1.25969895], bias:-1.563519412535362, loss:0.5449210395932091\n",
      "epoch:4423, weight:[2.02913648 1.25975612], bias:-1.5636763009508265, loss:0.5449107057063626\n",
      "epoch:4424, weight:[2.02941115 1.25981326], bias:-1.5638331706388688, loss:0.5449003730510436\n",
      "epoch:4425, weight:[2.02968581 1.25987039], bias:-1.5639900216050586, loss:0.5448900416268798\n",
      "epoch:4426, weight:[2.02996047 1.25992749], bias:-1.5641468538549632, loss:0.5448797114334991\n",
      "epoch:4427, weight:[2.03023511 1.25998457], bias:-1.564303667394148, loss:0.5448693824705295\n",
      "epoch:4428, weight:[2.03050975 1.26004164], bias:-1.564460462228176, loss:0.5448590547375984\n",
      "epoch:4429, weight:[2.03078439 1.26009868], bias:-1.5646172383626082, loss:0.5448487282343351\n",
      "epoch:4430, weight:[2.03105901 1.2601557 ], bias:-1.5647739958030038, loss:0.5448384029603678\n",
      "epoch:4431, weight:[2.03133363 1.2602127 ], bias:-1.5649307345549193, loss:0.5448280789153251\n",
      "epoch:4432, weight:[2.03160824 1.26026968], bias:-1.5650874546239093, loss:0.5448177560988365\n",
      "epoch:4433, weight:[2.03188284 1.26032664], bias:-1.5652441560155261, loss:0.5448074345105307\n",
      "epoch:4434, weight:[2.03215744 1.26038358], bias:-1.5654008387353204, loss:0.5447971141500382\n",
      "epoch:4435, weight:[2.03243203 1.2604405 ], bias:-1.56555750278884, loss:0.544786795016988\n",
      "epoch:4436, weight:[2.03270661 1.2604974 ], bias:-1.565714148181631, loss:0.5447764771110103\n",
      "epoch:4437, weight:[2.03298118 1.26055427], bias:-1.5658707749192375, loss:0.5447661604317354\n",
      "epoch:4438, weight:[2.03325575 1.26061113], bias:-1.5660273830072011, loss:0.5447558449787935\n",
      "epoch:4439, weight:[2.03353031 1.26066796], bias:-1.5661839724510616, loss:0.5447455307518154\n",
      "epoch:4440, weight:[2.03380486 1.26072478], bias:-1.5663405432563562, loss:0.5447352177504322\n",
      "epoch:4441, weight:[2.0340794  1.26078157], bias:-1.5664970954286204, loss:0.5447249059742748\n",
      "epoch:4442, weight:[2.03435394 1.26083835], bias:-1.5666536289733874, loss:0.5447145954229746\n",
      "epoch:4443, weight:[2.03462847 1.2608951 ], bias:-1.5668101438961883, loss:0.5447042860961633\n",
      "epoch:4444, weight:[2.03490299 1.26095183], bias:-1.5669666402025522, loss:0.5446939779934726\n",
      "epoch:4445, weight:[2.03517751 1.26100854], bias:-1.5671231178980058, loss:0.5446836711145346\n",
      "epoch:4446, weight:[2.03545201 1.26106523], bias:-1.5672795769880739, loss:0.5446733654589816\n",
      "epoch:4447, weight:[2.03572651 1.26112191], bias:-1.5674360174782789, loss:0.5446630610264459\n",
      "epoch:4448, weight:[2.036001   1.26117856], bias:-1.5675924393741414, loss:0.5446527578165606\n",
      "epoch:4449, weight:[2.03627549 1.26123518], bias:-1.5677488426811799, loss:0.5446424558289584\n",
      "epoch:4450, weight:[2.03654997 1.26129179], bias:-1.5679052274049103, loss:0.5446321550632726\n",
      "epoch:4451, weight:[2.03682444 1.26134838], bias:-1.568061593550847, loss:0.5446218555191363\n",
      "epoch:4452, weight:[2.0370989  1.26140495], bias:-1.5682179411245019, loss:0.5446115571961837\n",
      "epoch:4453, weight:[2.03737335 1.2614615 ], bias:-1.5683742701313845, loss:0.5446012600940481\n",
      "epoch:4454, weight:[2.0376478  1.26151802], bias:-1.568530580577003, loss:0.544590964212364\n",
      "epoch:4455, weight:[2.03792224 1.26157453], bias:-1.5686868724668626, loss:0.5445806695507656\n",
      "epoch:4456, weight:[2.03819667 1.26163102], bias:-1.568843145806467, loss:0.544570376108887\n",
      "epoch:4457, weight:[2.0384711  1.26168748], bias:-1.5689994006013177, loss:0.5445600838863637\n",
      "epoch:4458, weight:[2.03874552 1.26174393], bias:-1.5691556368569137, loss:0.5445497928828301\n",
      "epoch:4459, weight:[2.03901993 1.26180035], bias:-1.5693118545787523, loss:0.5445395030979218\n",
      "epoch:4460, weight:[2.03929433 1.26185675], bias:-1.5694680537723285, loss:0.544529214531274\n",
      "epoch:4461, weight:[2.03956873 1.26191314], bias:-1.569624234443135, loss:0.5445189271825225\n",
      "epoch:4462, weight:[2.03984311 1.2619695 ], bias:-1.569780396596663, loss:0.5445086410513035\n",
      "epoch:4463, weight:[2.04011749 1.26202584], bias:-1.569936540238401, loss:0.5444983561372523\n",
      "epoch:4464, weight:[2.04039187 1.26208216], bias:-1.5700926653738354, loss:0.5444880724400061\n",
      "epoch:4465, weight:[2.04066623 1.26213847], bias:-1.5702487720084508, loss:0.5444777899592009\n",
      "epoch:4466, weight:[2.04094059 1.26219475], bias:-1.5704048601477296, loss:0.5444675086944737\n",
      "epoch:4467, weight:[2.04121494 1.26225101], bias:-1.5705609297971521, loss:0.5444572286454614\n",
      "epoch:4468, weight:[2.04148929 1.26230725], bias:-1.5707169809621964, loss:0.5444469498118013\n",
      "epoch:4469, weight:[2.04176362 1.26236347], bias:-1.5708730136483384, loss:0.5444366721931314\n",
      "epoch:4470, weight:[2.04203795 1.26241967], bias:-1.5710290278610521, loss:0.5444263957890884\n",
      "epoch:4471, weight:[2.04231227 1.26247585], bias:-1.5711850236058094, loss:0.5444161205993109\n",
      "epoch:4472, weight:[2.04258658 1.26253201], bias:-1.57134100088808, loss:0.5444058466234366\n",
      "epoch:4473, weight:[2.04286089 1.26258814], bias:-1.5714969597133313, loss:0.5443955738611043\n",
      "epoch:4474, weight:[2.04313519 1.26264426], bias:-1.5716529000870292, loss:0.5443853023119524\n",
      "epoch:4475, weight:[2.04340948 1.26270036], bias:-1.571808822014637, loss:0.5443750319756194\n",
      "epoch:4476, weight:[2.04368376 1.26275644], bias:-1.5719647255016156, loss:0.5443647628517448\n",
      "epoch:4477, weight:[2.04395804 1.26281249], bias:-1.5721206105534247, loss:0.5443544949399677\n",
      "epoch:4478, weight:[2.04423231 1.26286853], bias:-1.5722764771755213, loss:0.5443442282399273\n",
      "epoch:4479, weight:[2.04450657 1.26292455], bias:-1.5724323253733605, loss:0.5443339627512637\n",
      "epoch:4480, weight:[2.04478083 1.26298054], bias:-1.572588155152395, loss:0.5443236984736165\n",
      "epoch:4481, weight:[2.04505507 1.26303652], bias:-1.5727439665180758, loss:0.5443134354066259\n",
      "epoch:4482, weight:[2.04532931 1.26309247], bias:-1.5728997594758516, loss:0.5443031735499324\n",
      "epoch:4483, weight:[2.04560354 1.26314841], bias:-1.573055534031169, loss:0.5442929129031764\n",
      "epoch:4484, weight:[2.04587777 1.26320432], bias:-1.5732112901894726, loss:0.5442826534659989\n",
      "epoch:4485, weight:[2.04615198 1.26326022], bias:-1.5733670279562049, loss:0.5442723952380407\n",
      "epoch:4486, weight:[2.04642619 1.26331609], bias:-1.573522747336806, loss:0.5442621382189432\n",
      "epoch:4487, weight:[2.04670039 1.26337195], bias:-1.5736784483367146, loss:0.5442518824083475\n",
      "epoch:4488, weight:[2.04697459 1.26342778], bias:-1.5738341309613666, loss:0.544241627805896\n",
      "epoch:4489, weight:[2.04724877 1.26348359], bias:-1.5739897952161963, loss:0.54423137441123\n",
      "epoch:4490, weight:[2.04752295 1.26353939], bias:-1.5741454411066356, loss:0.5442211222239918\n",
      "epoch:4491, weight:[2.04779713 1.26359516], bias:-1.5743010686381143, loss:0.5442108712438237\n",
      "epoch:4492, weight:[2.04807129 1.26365091], bias:-1.5744566778160605, loss:0.5442006214703684\n",
      "epoch:4493, weight:[2.04834545 1.26370665], bias:-1.5746122686458996, loss:0.5441903729032685\n",
      "epoch:4494, weight:[2.0486196  1.26376236], bias:-1.5747678411330557, loss:0.5441801255421673\n",
      "epoch:4495, weight:[2.04889374 1.26381805], bias:-1.5749233952829502, loss:0.5441698793867077\n",
      "epoch:4496, weight:[2.04916787 1.26387372], bias:-1.5750789311010027, loss:0.5441596344365331\n",
      "epoch:4497, weight:[2.049442   1.26392938], bias:-1.5752344485926304, loss:0.5441493906912874\n",
      "epoch:4498, weight:[2.04971612 1.26398501], bias:-1.575389947763249, loss:0.5441391481506146\n",
      "epoch:4499, weight:[2.04999023 1.26404062], bias:-1.5755454286182713, loss:0.5441289068141583\n",
      "epoch:4500, weight:[2.05026434 1.26409621], bias:-1.575700891163109, loss:0.5441186666815633\n",
      "epoch:4501, weight:[2.05053843 1.26415178], bias:-1.575856335403171, loss:0.5441084277524738\n",
      "epoch:4502, weight:[2.05081252 1.26420733], bias:-1.5760117613438642, loss:0.5440981900265347\n",
      "epoch:4503, weight:[2.0510866  1.26426286], bias:-1.5761671689905938, loss:0.544087953503391\n",
      "epoch:4504, weight:[2.05136068 1.26431837], bias:-1.5763225583487626, loss:0.5440777181826877\n",
      "epoch:4505, weight:[2.05163475 1.26437387], bias:-1.5764779294237714, loss:0.5440674840640706\n",
      "epoch:4506, weight:[2.05190881 1.26442934], bias:-1.576633282221019, loss:0.5440572511471848\n",
      "epoch:4507, weight:[2.05218286 1.26448479], bias:-1.576788616745902, loss:0.5440470194316767\n",
      "epoch:4508, weight:[2.0524569  1.26454022], bias:-1.576943933003815, loss:0.5440367889171921\n",
      "epoch:4509, weight:[2.05273094 1.26459563], bias:-1.5770992310001506, loss:0.5440265596033769\n",
      "epoch:4510, weight:[2.05300497 1.26465102], bias:-1.5772545107402993, loss:0.5440163314898782\n",
      "epoch:4511, weight:[2.05327899 1.26470639], bias:-1.5774097722296494, loss:0.5440061045763424\n",
      "epoch:4512, weight:[2.05355301 1.26476174], bias:-1.5775650154735874, loss:0.5439958788624165\n",
      "epoch:4513, weight:[2.05382701 1.26481707], bias:-1.5777202404774973, loss:0.5439856543477476\n",
      "epoch:4514, weight:[2.05410101 1.26487238], bias:-1.5778754472467615, loss:0.543975431031983\n",
      "epoch:4515, weight:[2.054375   1.26492767], bias:-1.5780306357867602, loss:0.5439652089147703\n",
      "epoch:4516, weight:[2.05464899 1.26498294], bias:-1.5781858061028713, loss:0.5439549879957575\n",
      "epoch:4517, weight:[2.05492297 1.26503819], bias:-1.5783409582004708, loss:0.5439447682745924\n",
      "epoch:4518, weight:[2.05519694 1.26509342], bias:-1.5784960920849327, loss:0.5439345497509233\n",
      "epoch:4519, weight:[2.0554709  1.26514863], bias:-1.578651207761629, loss:0.5439243324243983\n",
      "epoch:4520, weight:[2.05574485 1.26520382], bias:-1.5788063052359294, loss:0.5439141162946666\n",
      "epoch:4521, weight:[2.0560188  1.26525899], bias:-1.5789613845132018, loss:0.5439039013613768\n",
      "epoch:4522, weight:[2.05629274 1.26531414], bias:-1.5791164455988118, loss:0.5438936876241779\n",
      "epoch:4523, weight:[2.05656667 1.26536927], bias:-1.579271488498123, loss:0.5438834750827194\n",
      "epoch:4524, weight:[2.0568406  1.26542438], bias:-1.579426513216497, loss:0.5438732637366507\n",
      "epoch:4525, weight:[2.05711451 1.26547947], bias:-1.5795815197592935, loss:0.5438630535856214\n",
      "epoch:4526, weight:[2.05738842 1.26553454], bias:-1.57973650813187, loss:0.5438528446292816\n",
      "epoch:4527, weight:[2.05766233 1.26558959], bias:-1.5798914783395817, loss:0.5438426368672816\n",
      "epoch:4528, weight:[2.05793622 1.26564462], bias:-1.5800464303877821, loss:0.5438324302992714\n",
      "epoch:4529, weight:[2.05821011 1.26569963], bias:-1.5802013642818227, loss:0.543822224924902\n",
      "epoch:4530, weight:[2.05848399 1.26575462], bias:-1.5803562800270525, loss:0.5438120207438236\n",
      "epoch:4531, weight:[2.05875786 1.26580959], bias:-1.580511177628819, loss:0.5438018177556879\n",
      "epoch:4532, weight:[2.05903172 1.26586454], bias:-1.5806660570924673, loss:0.5437916159601456\n",
      "epoch:4533, weight:[2.05930558 1.26591947], bias:-1.5808209184233404, loss:0.5437814153568484\n",
      "epoch:4534, weight:[2.05957943 1.26597439], bias:-1.5809757616267794, loss:0.5437712159454479\n",
      "epoch:4535, weight:[2.05985327 1.26602928], bias:-1.5811305867081236, loss:0.5437610177255959\n",
      "epoch:4536, weight:[2.06012711 1.26608415], bias:-1.5812853936727096, loss:0.5437508206969445\n",
      "epoch:4537, weight:[2.06040093 1.266139  ], bias:-1.5814401825258726, loss:0.5437406248591463\n",
      "epoch:4538, weight:[2.06067475 1.26619383], bias:-1.5815949532729454, loss:0.5437304302118531\n",
      "epoch:4539, weight:[2.06094856 1.26624864], bias:-1.5817497059192591, loss:0.5437202367547181\n",
      "epoch:4540, weight:[2.06122237 1.26630343], bias:-1.5819044404701423, loss:0.5437100444873942\n",
      "epoch:4541, weight:[2.06149617 1.26635821], bias:-1.582059156930922, loss:0.5436998534095344\n",
      "epoch:4542, weight:[2.06176995 1.26641296], bias:-1.5822138553069225, loss:0.5436896635207922\n",
      "epoch:4543, weight:[2.06204374 1.26646769], bias:-1.582368535603467, loss:0.543679474820821\n",
      "epoch:4544, weight:[2.06231751 1.2665224 ], bias:-1.5825231978258756, loss:0.5436692873092747\n",
      "epoch:4545, weight:[2.06259128 1.2665771 ], bias:-1.5826778419794674, loss:0.5436591009858073\n",
      "epoch:4546, weight:[2.06286504 1.26663177], bias:-1.582832468069559, loss:0.5436489158500728\n",
      "epoch:4547, weight:[2.06313879 1.26668642], bias:-1.5829870761014646, loss:0.5436387319017256\n",
      "epoch:4548, weight:[2.06341253 1.26674106], bias:-1.583141666080497, loss:0.5436285491404206\n",
      "epoch:4549, weight:[2.06368627 1.26679567], bias:-1.5832962380119664, loss:0.5436183675658124\n",
      "epoch:4550, weight:[2.06396    1.26685026], bias:-1.5834507919011815, loss:0.5436081871775561\n",
      "epoch:4551, weight:[2.06423372 1.26690484], bias:-1.5836053277534488, loss:0.5435980079753069\n",
      "epoch:4552, weight:[2.06450743 1.26695939], bias:-1.5837598455740725, loss:0.5435878299587201\n",
      "epoch:4553, weight:[2.06478114 1.26701393], bias:-1.583914345368355, loss:0.543577653127452\n",
      "epoch:4554, weight:[2.06505484 1.26706844], bias:-1.5840688271415968, loss:0.5435674774811576\n",
      "epoch:4555, weight:[2.06532853 1.26712294], bias:-1.5842232908990959, loss:0.5435573030194936\n",
      "epoch:4556, weight:[2.06560221 1.26717741], bias:-1.5843777366461487, loss:0.543547129742116\n",
      "epoch:4557, weight:[2.06587589 1.26723187], bias:-1.5845321643880494, loss:0.5435369576486815\n",
      "epoch:4558, weight:[2.06614956 1.2672863 ], bias:-1.5846865741300904, loss:0.5435267867388467\n",
      "epoch:4559, weight:[2.06642322 1.26734072], bias:-1.5848409658775617, loss:0.5435166170122685\n",
      "epoch:4560, weight:[2.06669687 1.26739512], bias:-1.5849953396357517, loss:0.5435064484686041\n",
      "epoch:4561, weight:[2.06697052 1.26744949], bias:-1.5851496954099462, loss:0.5434962811075107\n",
      "epoch:4562, weight:[2.06724416 1.26750385], bias:-1.5853040332054296, loss:0.5434861149286461\n",
      "epoch:4563, weight:[2.06751779 1.26755819], bias:-1.585458353027484, loss:0.5434759499316679\n",
      "epoch:4564, weight:[2.06779141 1.26761251], bias:-1.5856126548813891, loss:0.543465786116234\n",
      "epoch:4565, weight:[2.06806503 1.2676668 ], bias:-1.5857669387724236, loss:0.5434556234820026\n",
      "epoch:4566, weight:[2.06833864 1.26772108], bias:-1.585921204705863, loss:0.5434454620286322\n",
      "epoch:4567, weight:[2.06861224 1.26777534], bias:-1.5860754526869816, loss:0.5434353017557813\n",
      "epoch:4568, weight:[2.06888583 1.26782958], bias:-1.5862296827210514, loss:0.5434251426631086\n",
      "epoch:4569, weight:[2.06915942 1.2678838 ], bias:-1.5863838948133422, loss:0.5434149847502732\n",
      "epoch:4570, weight:[2.069433 1.267938], bias:-1.586538088969122, loss:0.5434048280169343\n",
      "epoch:4571, weight:[2.06970657 1.26799218], bias:-1.586692265193657, loss:0.5433946724627513\n",
      "epoch:4572, weight:[2.06998013 1.26804634], bias:-1.586846423492211, loss:0.543384518087384\n",
      "epoch:4573, weight:[2.07025368 1.26810049], bias:-1.587000563870046, loss:0.5433743648904922\n",
      "epoch:4574, weight:[2.07052723 1.26815461], bias:-1.5871546863324217, loss:0.5433642128717358\n",
      "epoch:4575, weight:[2.07080077 1.26820871], bias:-1.5873087908845962, loss:0.5433540620307747\n",
      "epoch:4576, weight:[2.0710743  1.26826279], bias:-1.5874628775318254, loss:0.54334391236727\n",
      "epoch:4577, weight:[2.07134783 1.26831686], bias:-1.5876169462793632, loss:0.543333763880882\n",
      "epoch:4578, weight:[2.07162135 1.2683709 ], bias:-1.5877709971324614, loss:0.5433236165712715\n",
      "epoch:4579, weight:[2.07189486 1.26842492], bias:-1.5879250300963699, loss:0.5433134704380999\n",
      "epoch:4580, weight:[2.07216836 1.26847893], bias:-1.5880790451763367, loss:0.5433033254810281\n",
      "epoch:4581, weight:[2.07244186 1.26853291], bias:-1.5882330423776074, loss:0.5432931816997179\n",
      "epoch:4582, weight:[2.07271534 1.26858688], bias:-1.5883870217054261, loss:0.5432830390938307\n",
      "epoch:4583, weight:[2.07298882 1.26864083], bias:-1.5885409831650346, loss:0.5432728976630288\n",
      "epoch:4584, weight:[2.07326229 1.26869475], bias:-1.5886949267616726, loss:0.5432627574069736\n",
      "epoch:4585, weight:[2.07353576 1.26874866], bias:-1.5888488525005782, loss:0.5432526183253281\n",
      "epoch:4586, weight:[2.07380922 1.26880255], bias:-1.589002760386987, loss:0.5432424804177546\n",
      "epoch:4587, weight:[2.07408267 1.26885642], bias:-1.589156650426133, loss:0.5432323436839156\n",
      "epoch:4588, weight:[2.07435611 1.26891026], bias:-1.589310522623248, loss:0.5432222081234741\n",
      "epoch:4589, weight:[2.07462954 1.26896409], bias:-1.589464376983562, loss:0.5432120737360933\n",
      "epoch:4590, weight:[2.07490297 1.2690179 ], bias:-1.5896182135123025, loss:0.5432019405214366\n",
      "epoch:4591, weight:[2.07517639 1.26907169], bias:-1.5897720322146958, loss:0.5431918084791671\n",
      "epoch:4592, weight:[2.0754498  1.26912546], bias:-1.5899258330959654, loss:0.5431816776089492\n",
      "epoch:4593, weight:[2.0757232  1.26917922], bias:-1.5900796161613333, loss:0.5431715479104462\n",
      "epoch:4594, weight:[2.0759966  1.26923295], bias:-1.5902333814160194, loss:0.5431614193833226\n",
      "epoch:4595, weight:[2.07626999 1.26928666], bias:-1.5903871288652416, loss:0.5431512920272428\n",
      "epoch:4596, weight:[2.07654337 1.26934035], bias:-1.5905408585142156, loss:0.5431411658418711\n",
      "epoch:4597, weight:[2.07681674 1.26939403], bias:-1.5906945703681552, loss:0.5431310408268724\n",
      "epoch:4598, weight:[2.07709011 1.26944768], bias:-1.5908482644322726, loss:0.5431209169819115\n",
      "epoch:4599, weight:[2.07736347 1.26950132], bias:-1.5910019407117775, loss:0.5431107943066537\n",
      "epoch:4600, weight:[2.07763682 1.26955493], bias:-1.591155599211878, loss:0.5431006728007642\n",
      "epoch:4601, weight:[2.07791016 1.26960853], bias:-1.59130923993778, loss:0.5430905524639088\n",
      "epoch:4602, weight:[2.0781835  1.26966211], bias:-1.5914628628946872, loss:0.5430804332957533\n",
      "epoch:4603, weight:[2.07845683 1.26971566], bias:-1.5916164680878018, loss:0.543070315295963\n",
      "epoch:4604, weight:[2.07873015 1.2697692 ], bias:-1.5917700555223238, loss:0.5430601984642048\n",
      "epoch:4605, weight:[2.07900346 1.26982272], bias:-1.591923625203451, loss:0.5430500828001448\n",
      "epoch:4606, weight:[2.07927676 1.26987622], bias:-1.5920771771363795, loss:0.5430399683034496\n",
      "epoch:4607, weight:[2.07955006 1.2699297 ], bias:-1.5922307113263034, loss:0.543029854973786\n",
      "epoch:4608, weight:[2.07982335 1.26998316], bias:-1.5923842277784146, loss:0.543019742810821\n",
      "epoch:4609, weight:[2.08009664 1.2700366 ], bias:-1.5925377264979033, loss:0.5430096318142213\n",
      "epoch:4610, weight:[2.08036991 1.27009003], bias:-1.5926912074899573, loss:0.5429995219836552\n",
      "epoch:4611, weight:[2.08064318 1.27014343], bias:-1.5928446707597628, loss:0.5429894133187895\n",
      "epoch:4612, weight:[2.08091644 1.27019681], bias:-1.592998116312504, loss:0.5429793058192921\n",
      "epoch:4613, weight:[2.08118969 1.27025018], bias:-1.593151544153363, loss:0.5429691994848311\n",
      "epoch:4614, weight:[2.08146293 1.27030352], bias:-1.59330495428752, loss:0.5429590943150747\n",
      "epoch:4615, weight:[2.08173617 1.27035685], bias:-1.593458346720153, loss:0.5429489903096916\n",
      "epoch:4616, weight:[2.0820094  1.27041015], bias:-1.5936117214564385, loss:0.5429388874683496\n",
      "epoch:4617, weight:[2.08228262 1.27046344], bias:-1.5937650785015505, loss:0.542928785790718\n",
      "epoch:4618, weight:[2.08255584 1.27051671], bias:-1.5939184178606614, loss:0.5429186852764659\n",
      "epoch:4619, weight:[2.08282904 1.27056996], bias:-1.5940717395389412, loss:0.542908585925262\n",
      "epoch:4620, weight:[2.08310224 1.27062319], bias:-1.5942250435415586, loss:0.542898487736776\n",
      "epoch:4621, weight:[2.08337543 1.2706764 ], bias:-1.5943783298736798, loss:0.5428883907106775\n",
      "epoch:4622, weight:[2.08364862 1.27072959], bias:-1.594531598540469, loss:0.542878294846636\n",
      "epoch:4623, weight:[2.08392179 1.27078276], bias:-1.594684849547089, loss:0.5428682001443217\n",
      "epoch:4624, weight:[2.08419496 1.27083592], bias:-1.5948380828986997, loss:0.5428581066034048\n",
      "epoch:4625, weight:[2.08446812 1.27088905], bias:-1.5949912986004597, loss:0.5428480142235556\n",
      "epoch:4626, weight:[2.08474128 1.27094216], bias:-1.5951444966575257, loss:0.5428379230044446\n",
      "epoch:4627, weight:[2.08501442 1.27099526], bias:-1.5952976770750522, loss:0.5428278329457425\n",
      "epoch:4628, weight:[2.08528756 1.27104834], bias:-1.5954508398581917, loss:0.5428177440471207\n",
      "epoch:4629, weight:[2.08556069 1.27110139], bias:-1.5956039850120947, loss:0.54280765630825\n",
      "epoch:4630, weight:[2.08583381 1.27115443], bias:-1.5957571125419099, loss:0.5427975697288019\n",
      "epoch:4631, weight:[2.08610693 1.27120745], bias:-1.5959102224527841, loss:0.5427874843084477\n",
      "epoch:4632, weight:[2.08638003 1.27126045], bias:-1.596063314749862, loss:0.5427774000468595\n",
      "epoch:4633, weight:[2.08665313 1.27131343], bias:-1.5962163894382861, loss:0.5427673169437089\n",
      "epoch:4634, weight:[2.08692623 1.27136639], bias:-1.5963694465231975, loss:0.5427572349986686\n",
      "epoch:4635, weight:[2.08719931 1.27141933], bias:-1.5965224860097347, loss:0.5427471542114104\n",
      "epoch:4636, weight:[2.08747239 1.27147226], bias:-1.5966755079030348, loss:0.5427370745816069\n",
      "epoch:4637, weight:[2.08774546 1.27152516], bias:-1.5968285122082326, loss:0.5427269961089315\n",
      "epoch:4638, weight:[2.08801852 1.27157805], bias:-1.5969814989304612, loss:0.5427169187930563\n",
      "epoch:4639, weight:[2.08829157 1.27163091], bias:-1.5971344680748516, loss:0.542706842633655\n",
      "epoch:4640, weight:[2.08856462 1.27168376], bias:-1.5972874196465328, loss:0.5426967676304006\n",
      "epoch:4641, weight:[2.08883766 1.27173659], bias:-1.5974403536506316, loss:0.542686693782967\n",
      "epoch:4642, weight:[2.08911069 1.2717894 ], bias:-1.5975932700922735, loss:0.5426766210910273\n",
      "epoch:4643, weight:[2.08938371 1.27184219], bias:-1.5977461689765815, loss:0.5426665495542561\n",
      "epoch:4644, weight:[2.08965673 1.27189496], bias:-1.597899050308677, loss:0.5426564791723272\n",
      "epoch:4645, weight:[2.08992974 1.27194771], bias:-1.598051914093679, loss:0.542646409944915\n",
      "epoch:4646, weight:[2.09020274 1.27200044], bias:-1.5982047603367053, loss:0.5426363418716941\n",
      "epoch:4647, weight:[2.09047573 1.27205315], bias:-1.598357589042871, loss:0.5426262749523386\n",
      "epoch:4648, weight:[2.09074872 1.27210585], bias:-1.5985104002172894, loss:0.5426162091865244\n",
      "epoch:4649, weight:[2.0910217  1.27215852], bias:-1.5986631938650722, loss:0.542606144573926\n",
      "epoch:4650, weight:[2.09129467 1.27221118], bias:-1.5988159699913287, loss:0.5425960811142188\n",
      "epoch:4651, weight:[2.09156763 1.27226382], bias:-1.5989687286011667, loss:0.5425860188070781\n",
      "epoch:4652, weight:[2.09184058 1.27231644], bias:-1.5991214696996918, loss:0.5425759576521799\n",
      "epoch:4653, weight:[2.09211353 1.27236904], bias:-1.5992741932920078, loss:0.5425658976491997\n",
      "epoch:4654, weight:[2.09238647 1.27242162], bias:-1.5994268993832164, loss:0.5425558387978142\n",
      "epoch:4655, weight:[2.0926594  1.27247418], bias:-1.5995795879784172, loss:0.542545781097699\n",
      "epoch:4656, weight:[2.09293233 1.27252672], bias:-1.599732259082708, loss:0.5425357245485309\n",
      "epoch:4657, weight:[2.09320524 1.27257925], bias:-1.5998849127011854, loss:0.5425256691499866\n",
      "epoch:4658, weight:[2.09347815 1.27263175], bias:-1.6000375488389427, loss:0.5425156149017428\n",
      "epoch:4659, weight:[2.09375105 1.27268424], bias:-1.6001901675010723, loss:0.5425055618034766\n",
      "epoch:4660, weight:[2.09402395 1.2727367 ], bias:-1.6003427686926643, loss:0.5424955098548652\n",
      "epoch:4661, weight:[2.09429683 1.27278915], bias:-1.6004953524188068, loss:0.5424854590555864\n",
      "epoch:4662, weight:[2.09456971 1.27284158], bias:-1.600647918684586, loss:0.5424754094053171\n",
      "epoch:4663, weight:[2.09484258 1.27289399], bias:-1.6008004674950862, loss:0.5424653609037355\n",
      "epoch:4664, weight:[2.09511544 1.27294638], bias:-1.6009529988553899, loss:0.5424553135505198\n",
      "epoch:4665, weight:[2.0953883  1.27299875], bias:-1.6011055127705773, loss:0.5424452673453479\n",
      "epoch:4666, weight:[2.09566115 1.27305111], bias:-1.6012580092457271, loss:0.5424352222878986\n",
      "epoch:4667, weight:[2.09593399 1.27310344], bias:-1.601410488285916, loss:0.5424251783778499\n",
      "epoch:4668, weight:[2.09620682 1.27315576], bias:-1.6015629498962183, loss:0.5424151356148811\n",
      "epoch:4669, weight:[2.09647964 1.27320806], bias:-1.6017153940817068, loss:0.5424050939986708\n",
      "epoch:4670, weight:[2.09675246 1.27326033], bias:-1.6018678208474526, loss:0.5423950535288985\n",
      "epoch:4671, weight:[2.09702527 1.27331259], bias:-1.6020202301985242, loss:0.5423850142052432\n",
      "epoch:4672, weight:[2.09729807 1.27336483], bias:-1.6021726221399886, loss:0.5423749760273849\n",
      "epoch:4673, weight:[2.09757087 1.27341705], bias:-1.6023249966769109, loss:0.542364938995003\n",
      "epoch:4674, weight:[2.09784365 1.27346926], bias:-1.602477353814354, loss:0.5423549031077776\n",
      "epoch:4675, weight:[2.09811643 1.27352144], bias:-1.6026296935573792, loss:0.5423448683653885\n",
      "epoch:4676, weight:[2.0983892  1.27357361], bias:-1.6027820159110455, loss:0.5423348347675165\n",
      "epoch:4677, weight:[2.09866197 1.27362575], bias:-1.6029343208804103, loss:0.5423248023138417\n",
      "epoch:4678, weight:[2.09893472 1.27367788], bias:-1.603086608470529, loss:0.5423147710040452\n",
      "epoch:4679, weight:[2.09920747 1.27372999], bias:-1.603238878686455, loss:0.5423047408378076\n",
      "epoch:4680, weight:[2.09948021 1.27378208], bias:-1.60339113153324, loss:0.5422947118148099\n",
      "epoch:4681, weight:[2.09975294 1.27383415], bias:-1.6035433670159334, loss:0.5422846839347337\n",
      "epoch:4682, weight:[2.10002567 1.2738862 ], bias:-1.6036955851395829, loss:0.5422746571972603\n",
      "epoch:4683, weight:[2.10029839 1.27393824], bias:-1.6038477859092342, loss:0.5422646316020713\n",
      "epoch:4684, weight:[2.1005711  1.27399025], bias:-1.6039999693299312, loss:0.5422546071488488\n",
      "epoch:4685, weight:[2.1008438  1.27404225], bias:-1.6041521354067159, loss:0.5422445838372743\n",
      "epoch:4686, weight:[2.10111649 1.27409423], bias:-1.6043042841446282, loss:0.5422345616670303\n",
      "epoch:4687, weight:[2.10138918 1.27414618], bias:-1.6044564155487062, loss:0.5422245406377995\n",
      "epoch:4688, weight:[2.10166186 1.27419813], bias:-1.6046085296239863, loss:0.5422145207492641\n",
      "epoch:4689, weight:[2.10193453 1.27425005], bias:-1.6047606263755025, loss:0.5422045020011069\n",
      "epoch:4690, weight:[2.10220719 1.27430195], bias:-1.6049127058082873, loss:0.5421944843930115\n",
      "epoch:4691, weight:[2.10247985 1.27435383], bias:-1.6050647679273709, loss:0.5421844679246604\n",
      "epoch:4692, weight:[2.1027525 1.2744057], bias:-1.605216812737782, loss:0.5421744525957368\n",
      "epoch:4693, weight:[2.10302514 1.27445755], bias:-1.6053688402445472, loss:0.542164438405925\n",
      "epoch:4694, weight:[2.10329777 1.27450937], bias:-1.6055208504526912, loss:0.5421544253549082\n",
      "epoch:4695, weight:[2.1035704  1.27456118], bias:-1.605672843367237, loss:0.5421444134423706\n",
      "epoch:4696, weight:[2.10384301 1.27461297], bias:-1.605824818993205, loss:0.5421344026679962\n",
      "epoch:4697, weight:[2.10411562 1.27466475], bias:-1.6059767773356146, loss:0.5421243930314693\n",
      "epoch:4698, weight:[2.10438823 1.2747165 ], bias:-1.6061287183994828, loss:0.5421143845324743\n",
      "epoch:4699, weight:[2.10466082 1.27476823], bias:-1.6062806421898246, loss:0.5421043771706959\n",
      "epoch:4700, weight:[2.10493341 1.27481995], bias:-1.6064325487116533, loss:0.5420943709458191\n",
      "epoch:4701, weight:[2.10520599 1.27487165], bias:-1.6065844379699803, loss:0.5420843658575287\n",
      "epoch:4702, weight:[2.10547856 1.27492333], bias:-1.606736309969815, loss:0.5420743619055105\n",
      "epoch:4703, weight:[2.10575112 1.27497499], bias:-1.606888164716165, loss:0.5420643590894495\n",
      "epoch:4704, weight:[2.10602368 1.27502663], bias:-1.6070400022140359, loss:0.5420543574090313\n",
      "epoch:4705, weight:[2.10629623 1.27507825], bias:-1.6071918224684314, loss:0.5420443568639416\n",
      "epoch:4706, weight:[2.10656877 1.27512985], bias:-1.6073436254843534, loss:0.5420343574538669\n",
      "epoch:4707, weight:[2.1068413  1.27518144], bias:-1.6074954112668018, loss:0.5420243591784929\n",
      "epoch:4708, weight:[2.10711383 1.27523301], bias:-1.6076471798207748, loss:0.542014362037506\n",
      "epoch:4709, weight:[2.10738634 1.27528456], bias:-1.6077989311512684, loss:0.542004366030593\n",
      "epoch:4710, weight:[2.10765885 1.27533609], bias:-1.607950665263277, loss:0.5419943711574404\n",
      "epoch:4711, weight:[2.10793136 1.2753876 ], bias:-1.6081023821617926, loss:0.5419843774177355\n",
      "epoch:4712, weight:[2.10820385 1.27543909], bias:-1.608254081851806, loss:0.5419743848111649\n",
      "epoch:4713, weight:[2.10847634 1.27549057], bias:-1.6084057643383058, loss:0.5419643933374163\n",
      "epoch:4714, weight:[2.10874882 1.27554202], bias:-1.6085574296262783, loss:0.541954402996177\n",
      "epoch:4715, weight:[2.10902129 1.27559346], bias:-1.6087090777207087, loss:0.5419444137871346\n",
      "epoch:4716, weight:[2.10929375 1.27564488], bias:-1.6088607086265796, loss:0.5419344257099773\n",
      "epoch:4717, weight:[2.10956621 1.27569628], bias:-1.609012322348872, loss:0.5419244387643927\n",
      "epoch:4718, weight:[2.10983865 1.27574766], bias:-1.609163918892565, loss:0.5419144529500692\n",
      "epoch:4719, weight:[2.1101111  1.27579902], bias:-1.609315498262636, loss:0.5419044682666954\n",
      "epoch:4720, weight:[2.11038353 1.27585037], bias:-1.6094670604640602, loss:0.5418944847139596\n",
      "epoch:4721, weight:[2.11065595 1.2759017 ], bias:-1.609618605501811, loss:0.5418845022915509\n",
      "epoch:4722, weight:[2.11092837 1.275953  ], bias:-1.6097701333808598, loss:0.541874520999158\n",
      "epoch:4723, weight:[2.11120078 1.27600429], bias:-1.6099216441061766, loss:0.5418645408364701\n",
      "epoch:4724, weight:[2.11147318 1.27605557], bias:-1.6100731376827289, loss:0.5418545618031764\n",
      "epoch:4725, weight:[2.11174558 1.27610682], bias:-1.6102246141154826, loss:0.5418445838989668\n",
      "epoch:4726, weight:[2.11201796 1.27615805], bias:-1.610376073409402, loss:0.5418346071235308\n",
      "epoch:4727, weight:[2.11229034 1.27620927], bias:-1.6105275155694487, loss:0.5418246314765583\n",
      "epoch:4728, weight:[2.11256271 1.27626047], bias:-1.6106789406005835, loss:0.5418146569577394\n",
      "epoch:4729, weight:[2.11283508 1.27631164], bias:-1.6108303485077644, loss:0.5418046835667643\n",
      "epoch:4730, weight:[2.11310743 1.27636281], bias:-1.610981739295948, loss:0.5417947113033235\n",
      "epoch:4731, weight:[2.11337978 1.27641395], bias:-1.6111331129700888, loss:0.5417847401671076\n",
      "epoch:4732, weight:[2.11365212 1.27646507], bias:-1.6112844695351396, loss:0.5417747701578071\n",
      "epoch:4733, weight:[2.11392445 1.27651618], bias:-1.6114358089960512, loss:0.5417648012751136\n",
      "epoch:4734, weight:[2.11419678 1.27656726], bias:-1.6115871313577725, loss:0.5417548335187179\n",
      "epoch:4735, weight:[2.11446909 1.27661833], bias:-1.6117384366252507, loss:0.5417448668883112\n",
      "epoch:4736, weight:[2.1147414  1.27666938], bias:-1.611889724803431, loss:0.5417349013835856\n",
      "epoch:4737, weight:[2.11501371 1.27672041], bias:-1.6120409958972566, loss:0.5417249370042323\n",
      "epoch:4738, weight:[2.115286   1.27677143], bias:-1.612192249911669, loss:0.5417149737499434\n",
      "epoch:4739, weight:[2.11555829 1.27682242], bias:-1.6123434868516078, loss:0.5417050116204111\n",
      "epoch:4740, weight:[2.11583056 1.2768734 ], bias:-1.6124947067220108, loss:0.5416950506153273\n",
      "epoch:4741, weight:[2.11610283 1.27692436], bias:-1.6126459095278136, loss:0.5416850907343851\n",
      "epoch:4742, weight:[2.1163751 1.2769753], bias:-1.6127970952739503, loss:0.5416751319772763\n",
      "epoch:4743, weight:[2.11664735 1.27702622], bias:-1.6129482639653532, loss:0.5416651743436943\n",
      "epoch:4744, weight:[2.1169196  1.27707712], bias:-1.6130994156069522, loss:0.5416552178333321\n",
      "epoch:4745, weight:[2.11719184 1.27712801], bias:-1.6132505502036758, loss:0.5416452624458827\n",
      "epoch:4746, weight:[2.11746407 1.27717888], bias:-1.6134016677604504, loss:0.5416353081810396\n",
      "epoch:4747, weight:[2.1177363  1.27722973], bias:-1.6135527682822006, loss:0.5416253550384961\n",
      "epoch:4748, weight:[2.11800851 1.27728056], bias:-1.6137038517738493, loss:0.5416154030179461\n",
      "epoch:4749, weight:[2.11828072 1.27733137], bias:-1.6138549182403175, loss:0.5416054521190834\n",
      "epoch:4750, weight:[2.11855292 1.27738216], bias:-1.614005967686524, loss:0.5415955023416024\n",
      "epoch:4751, weight:[2.11882512 1.27743294], bias:-1.6141570001173857, loss:0.5415855536851969\n",
      "epoch:4752, weight:[2.1190973  1.27748369], bias:-1.6143080155378184, loss:0.5415756061495616\n",
      "epoch:4753, weight:[2.11936948 1.27753443], bias:-1.6144590139527353, loss:0.5415656597343911\n",
      "epoch:4754, weight:[2.11964165 1.27758515], bias:-1.6146099953670479, loss:0.5415557144393803\n",
      "epoch:4755, weight:[2.11991381 1.27763586], bias:-1.614760959785666, loss:0.5415457702642242\n",
      "epoch:4756, weight:[2.12018597 1.27768654], bias:-1.6149119072134976, loss:0.5415358272086179\n",
      "epoch:4757, weight:[2.12045811 1.27773721], bias:-1.6150628376554486, loss:0.5415258852722568\n",
      "epoch:4758, weight:[2.12073025 1.27778786], bias:-1.6152137511164228, loss:0.5415159444548361\n",
      "epoch:4759, weight:[2.12100238 1.27783849], bias:-1.6153646476013228, loss:0.541506004756052\n",
      "epoch:4760, weight:[2.12127451 1.2778891 ], bias:-1.615515527115049, loss:0.5414960661756\n",
      "epoch:4761, weight:[2.12154662 1.27793969], bias:-1.6156663896624999, loss:0.5414861287131765\n",
      "epoch:4762, weight:[2.12181873 1.27799027], bias:-1.6158172352485722, loss:0.5414761923684777\n",
      "epoch:4763, weight:[2.12209083 1.27804082], bias:-1.6159680638781608, loss:0.5414662571411996\n",
      "epoch:4764, weight:[2.12236292 1.27809136], bias:-1.6161188755561586, loss:0.5414563230310394\n",
      "epoch:4765, weight:[2.12263501 1.27814188], bias:-1.6162696702874568, loss:0.5414463900376935\n",
      "epoch:4766, weight:[2.12290709 1.27819239], bias:-1.6164204480769446, loss:0.5414364581608591\n",
      "epoch:4767, weight:[2.12317916 1.27824287], bias:-1.6165712089295097, loss:0.5414265274002331\n",
      "epoch:4768, weight:[2.12345122 1.27829334], bias:-1.6167219528500374, loss:0.5414165977555128\n",
      "epoch:4769, weight:[2.12372327 1.27834378], bias:-1.6168726798434117, loss:0.5414066692263961\n",
      "epoch:4770, weight:[2.12399532 1.27839421], bias:-1.617023389914514, loss:0.5413967418125802\n",
      "epoch:4771, weight:[2.12426735 1.27844463], bias:-1.617174083068225, loss:0.5413868155137637\n",
      "epoch:4772, weight:[2.12453939 1.27849502], bias:-1.6173247593094224, loss:0.5413768903296438\n",
      "epoch:4773, weight:[2.12481141 1.2785454 ], bias:-1.6174754186429827, loss:0.5413669662599189\n",
      "epoch:4774, weight:[2.12508342 1.27859575], bias:-1.6176260610737805, loss:0.5413570433042878\n",
      "epoch:4775, weight:[2.12535543 1.27864609], bias:-1.6177766866066883, loss:0.5413471214624488\n",
      "epoch:4776, weight:[2.12562743 1.27869641], bias:-1.6179272952465769, loss:0.5413372007341004\n",
      "epoch:4777, weight:[2.12589942 1.27874672], bias:-1.6180778869983155, loss:0.541327281118942\n",
      "epoch:4778, weight:[2.12617141 1.278797  ], bias:-1.6182284618667708, loss:0.5413173626166724\n",
      "epoch:4779, weight:[2.12644338 1.27884727], bias:-1.6183790198568084, loss:0.5413074452269909\n",
      "epoch:4780, weight:[2.12671535 1.27889752], bias:-1.618529560973292, loss:0.5412975289495974\n",
      "epoch:4781, weight:[2.12698731 1.27894775], bias:-1.6186800852210825, loss:0.5412876137841909\n",
      "epoch:4782, weight:[2.12725926 1.27899796], bias:-1.6188305926050401, loss:0.5412776997304714\n",
      "epoch:4783, weight:[2.12753121 1.27904816], bias:-1.6189810831300229, loss:0.541267786788139\n",
      "epoch:4784, weight:[2.12780315 1.27909834], bias:-1.6191315568008866, loss:0.5412578749568938\n",
      "epoch:4785, weight:[2.12807508 1.2791485 ], bias:-1.6192820136224857, loss:0.5412479642364363\n",
      "epoch:4786, weight:[2.128347   1.27919864], bias:-1.6194324535996725, loss:0.5412380546264667\n",
      "epoch:4787, weight:[2.12861891 1.27924876], bias:-1.6195828767372975, loss:0.541228146126686\n",
      "epoch:4788, weight:[2.12889082 1.27929886], bias:-1.6197332830402096, loss:0.5412182387367948\n",
      "epoch:4789, weight:[2.12916272 1.27934895], bias:-1.6198836725132555, loss:0.5412083324564944\n",
      "epoch:4790, weight:[2.12943461 1.27939902], bias:-1.6200340451612805, loss:0.5411984272854858\n",
      "epoch:4791, weight:[2.12970649 1.27944907], bias:-1.6201844009891275, loss:0.5411885232234703\n",
      "epoch:4792, weight:[2.12997837 1.2794991 ], bias:-1.6203347400016384, loss:0.5411786202701502\n",
      "epoch:4793, weight:[2.13025023 1.27954912], bias:-1.6204850622036524, loss:0.5411687184252264\n",
      "epoch:4794, weight:[2.13052209 1.27959912], bias:-1.6206353676000074, loss:0.5411588176884011\n",
      "epoch:4795, weight:[2.13079394 1.2796491 ], bias:-1.6207856561955392, loss:0.5411489180593763\n",
      "epoch:4796, weight:[2.13106579 1.27969906], bias:-1.620935927995082, loss:0.5411390195378547\n",
      "epoch:4797, weight:[2.13133762 1.279749  ], bias:-1.6210861830034677, loss:0.5411291221235384\n",
      "epoch:4798, weight:[2.13160945 1.27979893], bias:-1.6212364212255272, loss:0.5411192258161299\n",
      "epoch:4799, weight:[2.13188127 1.27984883], bias:-1.621386642666089, loss:0.5411093306153322\n",
      "epoch:4800, weight:[2.13215309 1.27989872], bias:-1.6215368473299798, loss:0.5410994365208484\n",
      "epoch:4801, weight:[2.13242489 1.2799486 ], bias:-1.6216870352220247, loss:0.5410895435323813\n",
      "epoch:4802, weight:[2.13269669 1.27999845], bias:-1.6218372063470468, loss:0.5410796516496345\n",
      "epoch:4803, weight:[2.13296848 1.28004829], bias:-1.6219873607098672, loss:0.5410697608723113\n",
      "epoch:4804, weight:[2.13324026 1.2800981 ], bias:-1.6221374983153054, loss:0.5410598712001153\n",
      "epoch:4805, weight:[2.13351203 1.2801479 ], bias:-1.6222876191681792, loss:0.5410499826327507\n",
      "epoch:4806, weight:[2.1337838  1.28019769], bias:-1.6224377232733045, loss:0.5410400951699212\n",
      "epoch:4807, weight:[2.13405556 1.28024745], bias:-1.6225878106354952, loss:0.5410302088113312\n",
      "epoch:4808, weight:[2.13432731 1.2802972 ], bias:-1.6227378812595634, loss:0.5410203235566851\n",
      "epoch:4809, weight:[2.13459905 1.28034693], bias:-1.6228879351503198, loss:0.541010439405687\n",
      "epoch:4810, weight:[2.13487079 1.28039664], bias:-1.6230379723125727, loss:0.5410005563580419\n",
      "epoch:4811, weight:[2.13514251 1.28044633], bias:-1.623187992751129, loss:0.5409906744134547\n",
      "epoch:4812, weight:[2.13541423 1.280496  ], bias:-1.6233379964707935, loss:0.5409807935716306\n",
      "epoch:4813, weight:[2.13568594 1.28054566], bias:-1.6234879834763694, loss:0.5409709138322746\n",
      "epoch:4814, weight:[2.13595765 1.2805953 ], bias:-1.623637953772658, loss:0.5409610351950919\n",
      "epoch:4815, weight:[2.13622934 1.28064492], bias:-1.6237879073644588, loss:0.5409511576597885\n",
      "epoch:4816, weight:[2.13650103 1.28069453], bias:-1.6239378442565695, loss:0.54094128122607\n",
      "epoch:4817, weight:[2.13677271 1.28074411], bias:-1.6240877644537859, loss:0.5409314058936422\n",
      "epoch:4818, weight:[2.13704439 1.28079368], bias:-1.624237667960902, loss:0.5409215316622112\n",
      "epoch:4819, weight:[2.13731605 1.28084323], bias:-1.6243875547827102, loss:0.5409116585314836\n",
      "epoch:4820, weight:[2.13758771 1.28089277], bias:-1.6245374249240008, loss:0.5409017865011653\n",
      "epoch:4821, weight:[2.13785936 1.28094228], bias:-1.6246872783895625, loss:0.5408919155709632\n",
      "epoch:4822, weight:[2.138131   1.28099178], bias:-1.624837115184182, loss:0.540882045740584\n",
      "epoch:4823, weight:[2.13840263 1.28104126], bias:-1.6249869353126445, loss:0.5408721770097347\n",
      "epoch:4824, weight:[2.13867426 1.28109072], bias:-1.625136738779733, loss:0.5408623093781224\n",
      "epoch:4825, weight:[2.13894587 1.28114016], bias:-1.6252865255902291, loss:0.5408524428454543\n",
      "epoch:4826, weight:[2.13921748 1.28118959], bias:-1.6254362957489121, loss:0.5408425774114382\n",
      "epoch:4827, weight:[2.13948909 1.281239  ], bias:-1.62558604926056, loss:0.5408327130757811\n",
      "epoch:4828, weight:[2.13976068 1.28128839], bias:-1.6257357861299486, loss:0.5408228498381914\n",
      "epoch:4829, weight:[2.14003227 1.28133776], bias:-1.6258855063618523, loss:0.5408129876983766\n",
      "epoch:4830, weight:[2.14030385 1.28138712], bias:-1.6260352099610433, loss:0.5408031266560454\n",
      "epoch:4831, weight:[2.14057542 1.28143646], bias:-1.6261848969322923, loss:0.5407932667109056\n",
      "epoch:4832, weight:[2.14084698 1.28148578], bias:-1.626334567280368, loss:0.5407834078626661\n",
      "epoch:4833, weight:[2.14111854 1.28153508], bias:-1.6264842210100372, loss:0.540773550111035\n",
      "epoch:4834, weight:[2.14139008 1.28158436], bias:-1.6266338581260653, loss:0.5407636934557215\n",
      "epoch:4835, weight:[2.14166162 1.28163363], bias:-1.6267834786332156, loss:0.5407538378964346\n",
      "epoch:4836, weight:[2.14193316 1.28168288], bias:-1.6269330825362498, loss:0.5407439834328834\n",
      "epoch:4837, weight:[2.14220468 1.28173211], bias:-1.6270826698399274, loss:0.5407341300647773\n",
      "epoch:4838, weight:[2.1424762  1.28178133], bias:-1.6272322405490067, loss:0.5407242777918256\n",
      "epoch:4839, weight:[2.1427477  1.28183052], bias:-1.6273817946682436, loss:0.5407144266137381\n",
      "epoch:4840, weight:[2.1430192 1.2818797], bias:-1.6275313322023928, loss:0.540704576530225\n",
      "epoch:4841, weight:[2.1432907  1.28192886], bias:-1.6276808531562066, loss:0.5406947275409956\n",
      "epoch:4842, weight:[2.14356218 1.28197801], bias:-1.627830357534436, loss:0.5406848796457605\n",
      "epoch:4843, weight:[2.14383366 1.28202713], bias:-1.6279798453418297, loss:0.54067503284423\n",
      "epoch:4844, weight:[2.14410513 1.28207624], bias:-1.6281293165831352, loss:0.5406651871361148\n",
      "epoch:4845, weight:[2.14437659 1.28212533], bias:-1.628278771263098, loss:0.540655342521125\n",
      "epoch:4846, weight:[2.14464804 1.2821744 ], bias:-1.6284282093864615, loss:0.5406454989989721\n",
      "epoch:4847, weight:[2.14491949 1.28222346], bias:-1.6285776309579676, loss:0.5406356565693667\n",
      "epoch:4848, weight:[2.14519093 1.2822725 ], bias:-1.6287270359823565, loss:0.5406258152320205\n",
      "epoch:4849, weight:[2.14546236 1.28232152], bias:-1.6288764244643663, loss:0.540615974986644\n",
      "epoch:4850, weight:[2.14573378 1.28237052], bias:-1.6290257964087336, loss:0.5406061358329497\n",
      "epoch:4851, weight:[2.1460052  1.28241951], bias:-1.6291751518201931, loss:0.5405962977706484\n",
      "epoch:4852, weight:[2.1462766  1.28246847], bias:-1.6293244907034776, loss:0.5405864607994527\n",
      "epoch:4853, weight:[2.146548   1.28251742], bias:-1.6294738130633184, loss:0.5405766249190742\n",
      "epoch:4854, weight:[2.14681939 1.28256636], bias:-1.6296231189044448, loss:0.5405667901292251\n",
      "epoch:4855, weight:[2.14709077 1.28261527], bias:-1.629772408231584, loss:0.5405569564296181\n",
      "epoch:4856, weight:[2.14736215 1.28266417], bias:-1.6299216810494623, loss:0.5405471238199655\n",
      "epoch:4857, weight:[2.14763352 1.28271305], bias:-1.6300709373628035, loss:0.5405372922999798\n",
      "epoch:4858, weight:[2.14790488 1.28276191], bias:-1.6302201771763298, loss:0.5405274618693743\n",
      "epoch:4859, weight:[2.14817623 1.28281076], bias:-1.6303694004947615, loss:0.5405176325278618\n",
      "epoch:4860, weight:[2.14844757 1.28285959], bias:-1.6305186073228175, loss:0.5405078042751553\n",
      "epoch:4861, weight:[2.14871891 1.2829084 ], bias:-1.6306677976652144, loss:0.5404979771109686\n",
      "epoch:4862, weight:[2.14899024 1.28295719], bias:-1.6308169715266676, loss:0.5404881510350149\n",
      "epoch:4863, weight:[2.14926156 1.28300596], bias:-1.6309661289118902, loss:0.5404783260470081\n",
      "epoch:4864, weight:[2.14953287 1.28305472], bias:-1.6311152698255937, loss:0.5404685021466618\n",
      "epoch:4865, weight:[2.14980418 1.28310346], bias:-1.631264394272488, loss:0.5404586793336903\n",
      "epoch:4866, weight:[2.15007547 1.28315218], bias:-1.631413502257281, loss:0.5404488576078076\n",
      "epoch:4867, weight:[2.15034676 1.28320089], bias:-1.6315625937846792, loss:0.5404390369687284\n",
      "epoch:4868, weight:[2.15061804 1.28324958], bias:-1.6317116688593867, loss:0.5404292174161669\n",
      "epoch:4869, weight:[2.15088932 1.28329825], bias:-1.6318607274861063, loss:0.5404193989498377\n",
      "epoch:4870, weight:[2.15116058 1.2833469 ], bias:-1.632009769669539, loss:0.540409581569456\n",
      "epoch:4871, weight:[2.15143184 1.28339554], bias:-1.6321587954143837, loss:0.5403997652747368\n",
      "epoch:4872, weight:[2.15170309 1.28344416], bias:-1.6323078047253379, loss:0.5403899500653949\n",
      "epoch:4873, weight:[2.15197433 1.28349276], bias:-1.6324567976070972, loss:0.5403801359411461\n",
      "epoch:4874, weight:[2.15224556 1.28354134], bias:-1.6326057740643554, loss:0.5403703229017057\n",
      "epoch:4875, weight:[2.15251679 1.28358991], bias:-1.6327547341018045, loss:0.5403605109467895\n",
      "epoch:4876, weight:[2.15278801 1.28363845], bias:-1.6329036777241348, loss:0.5403507000761132\n",
      "epoch:4877, weight:[2.15305922 1.28368699], bias:-1.6330526049360348, loss:0.5403408902893929\n",
      "epoch:4878, weight:[2.15333042 1.2837355 ], bias:-1.6332015157421913, loss:0.5403310815863449\n",
      "epoch:4879, weight:[2.15360162 1.283784  ], bias:-1.6333504101472893, loss:0.5403212739666852\n",
      "epoch:4880, weight:[2.1538728  1.28383248], bias:-1.633499288156012, loss:0.5403114674301306\n",
      "epoch:4881, weight:[2.15414398 1.28388094], bias:-1.6336481497730408, loss:0.5403016619763977\n",
      "epoch:4882, weight:[2.15441515 1.28392938], bias:-1.6337969950030555, loss:0.5402918576052036\n",
      "epoch:4883, weight:[2.15468632 1.28397781], bias:-1.633945823850734, loss:0.5402820543162647\n",
      "epoch:4884, weight:[2.15495747 1.28402622], bias:-1.6340946363207525, loss:0.5402722521092987\n",
      "epoch:4885, weight:[2.15522862 1.28407461], bias:-1.6342434324177852, loss:0.5402624509840228\n",
      "epoch:4886, weight:[2.15549976 1.28412299], bias:-1.634392212146505, loss:0.5402526509401543\n",
      "epoch:4887, weight:[2.15577089 1.28417134], bias:-1.6345409755115827, loss:0.540242851977411\n",
      "epoch:4888, weight:[2.15604202 1.28421968], bias:-1.6346897225176873, loss:0.5402330540955106\n",
      "epoch:4889, weight:[2.15631313 1.28426801], bias:-1.6348384531694864, loss:0.5402232572941713\n",
      "epoch:4890, weight:[2.15658424 1.28431631], bias:-1.6349871674716454, loss:0.5402134615731112\n",
      "epoch:4891, weight:[2.15685534 1.2843646 ], bias:-1.6351358654288284, loss:0.5402036669320486\n",
      "epoch:4892, weight:[2.15712643 1.28441287], bias:-1.6352845470456971, loss:0.5401938733707017\n",
      "epoch:4893, weight:[2.15739752 1.28446113], bias:-1.6354332123269124, loss:0.5401840808887894\n",
      "epoch:4894, weight:[2.1576686  1.28450936], bias:-1.6355818612771325, loss:0.5401742894860306\n",
      "epoch:4895, weight:[2.15793966 1.28455758], bias:-1.6357304939010142, loss:0.540164499162144\n",
      "epoch:4896, weight:[2.15821073 1.28460579], bias:-1.6358791102032129, loss:0.5401547099168488\n",
      "epoch:4897, weight:[2.15848178 1.28465397], bias:-1.6360277101883818, loss:0.5401449217498645\n",
      "epoch:4898, weight:[2.15875282 1.28470214], bias:-1.6361762938611724, loss:0.5401351346609101\n",
      "epoch:4899, weight:[2.15902386 1.28475029], bias:-1.6363248612262347, loss:0.5401253486497055\n",
      "epoch:4900, weight:[2.15929489 1.28479842], bias:-1.6364734122882165, loss:0.5401155637159705\n",
      "epoch:4901, weight:[2.15956591 1.28484654], bias:-1.6366219470517644, loss:0.5401057798594251\n",
      "epoch:4902, weight:[2.15983693 1.28489464], bias:-1.636770465521523, loss:0.540095997079789\n",
      "epoch:4903, weight:[2.16010793 1.28494272], bias:-1.636918967702135, loss:0.5400862153767828\n",
      "epoch:4904, weight:[2.16037893 1.28499079], bias:-1.6370674535982415, loss:0.540076434750127\n",
      "epoch:4905, weight:[2.16064992 1.28503883], bias:-1.6372159232144818, loss:0.5400666551995418\n",
      "epoch:4906, weight:[2.1609209  1.28508686], bias:-1.6373643765554937, loss:0.5400568767247482\n",
      "epoch:4907, weight:[2.16119188 1.28513488], bias:-1.637512813625913, loss:0.5400470993254672\n",
      "epoch:4908, weight:[2.16146284 1.28518287], bias:-1.6376612344303736, loss:0.5400373230014196\n",
      "epoch:4909, weight:[2.1617338  1.28523085], bias:-1.6378096389735082, loss:0.5400275477523269\n",
      "epoch:4910, weight:[2.16200475 1.28527881], bias:-1.6379580272599472, loss:0.54001777357791\n",
      "epoch:4911, weight:[2.1622757  1.28532676], bias:-1.6381063992943194, loss:0.540008000477891\n",
      "epoch:4912, weight:[2.16254663 1.28537468], bias:-1.6382547550812523, loss:0.5399982284519912\n",
      "epoch:4913, weight:[2.16281756 1.28542259], bias:-1.638403094625371, loss:0.5399884574999326\n",
      "epoch:4914, weight:[2.16308848 1.28547049], bias:-1.6385514179312992, loss:0.5399786876214375\n",
      "epoch:4915, weight:[2.16335939 1.28551836], bias:-1.638699725003659, loss:0.5399689188162277\n",
      "epoch:4916, weight:[2.16363029 1.28556622], bias:-1.6388480158470704, loss:0.5399591510840257\n",
      "epoch:4917, weight:[2.16390119 1.28561406], bias:-1.638996290466152, loss:0.5399493844245538\n",
      "epoch:4918, weight:[2.16417207 1.28566189], bias:-1.6391445488655203, loss:0.5399396188375352\n",
      "epoch:4919, weight:[2.16444295 1.28570969], bias:-1.6392927910497905, loss:0.539929854322692\n",
      "epoch:4920, weight:[2.16471383 1.28575749], bias:-1.639441017023576, loss:0.5399200908797478\n",
      "epoch:4921, weight:[2.16498469 1.28580526], bias:-1.639589226791488, loss:0.5399103285084252\n",
      "epoch:4922, weight:[2.16525555 1.28585301], bias:-1.6397374203581363, loss:0.539900567208448\n",
      "epoch:4923, weight:[2.16552639 1.28590075], bias:-1.639885597728129, loss:0.5398908069795397\n",
      "epoch:4924, weight:[2.16579723 1.28594848], bias:-1.6400337589060725, loss:0.5398810478214233\n",
      "epoch:4925, weight:[2.16606807 1.28599618], bias:-1.6401819038965715, loss:0.5398712897338233\n",
      "epoch:4926, weight:[2.16633889 1.28604387], bias:-1.6403300327042285, loss:0.539861532716463\n",
      "epoch:4927, weight:[2.16660971 1.28609154], bias:-1.6404781453336448, loss:0.5398517767690667\n",
      "epoch:4928, weight:[2.16688052 1.28613919], bias:-1.64062624178942, loss:0.539842021891359\n",
      "epoch:4929, weight:[2.16715132 1.28618683], bias:-1.6407743220761515, loss:0.539832268083064\n",
      "epoch:4930, weight:[2.16742211 1.28623445], bias:-1.6409223861984352, loss:0.5398225153439064\n",
      "epoch:4931, weight:[2.16769289 1.28628205], bias:-1.6410704341608655, loss:0.5398127636736105\n",
      "epoch:4932, weight:[2.16796367 1.28632964], bias:-1.6412184659680347, loss:0.5398030130719018\n",
      "epoch:4933, weight:[2.16823444 1.28637721], bias:-1.6413664816245337, loss:0.5397932635385051\n",
      "epoch:4934, weight:[2.1685052  1.28642476], bias:-1.6415144811349516, loss:0.5397835150731456\n",
      "epoch:4935, weight:[2.16877596 1.28647229], bias:-1.6416624645038755, loss:0.5397737676755486\n",
      "epoch:4936, weight:[2.1690467  1.28651981], bias:-1.641810431735891, loss:0.5397640213454398\n",
      "epoch:4937, weight:[2.16931744 1.28656731], bias:-1.6419583828355822, loss:0.5397542760825446\n",
      "epoch:4938, weight:[2.16958817 1.2866148 ], bias:-1.642106317807531, loss:0.539744531886589\n",
      "epoch:4939, weight:[2.16985889 1.28666226], bias:-1.642254236656318, loss:0.539734788757299\n",
      "epoch:4940, weight:[2.1701296  1.28670971], bias:-1.6424021393865218, loss:0.5397250466944007\n",
      "epoch:4941, weight:[2.17040031 1.28675715], bias:-1.6425500260027193, loss:0.5397153056976205\n",
      "epoch:4942, weight:[2.17067101 1.28680456], bias:-1.6426978965094858, loss:0.5397055657666847\n",
      "epoch:4943, weight:[2.1709417  1.28685196], bias:-1.6428457509113952, loss:0.5396958269013201\n",
      "epoch:4944, weight:[2.17121238 1.28689934], bias:-1.642993589213019, loss:0.5396860891012534\n",
      "epoch:4945, weight:[2.17148305 1.28694671], bias:-1.6431414114189271, loss:0.5396763523662114\n",
      "epoch:4946, weight:[2.17175372 1.28699406], bias:-1.6432892175336884, loss:0.5396666166959215\n",
      "epoch:4947, weight:[2.17202438 1.28704139], bias:-1.6434370075618692, loss:0.5396568820901106\n",
      "epoch:4948, weight:[2.17229503 1.2870887 ], bias:-1.6435847815080347, loss:0.5396471485485062\n",
      "epoch:4949, weight:[2.17256567 1.287136  ], bias:-1.643732539376748, loss:0.539637416070836\n",
      "epoch:4950, weight:[2.1728363  1.28718328], bias:-1.6438802811725706, loss:0.5396276846568276\n",
      "epoch:4951, weight:[2.17310693 1.28723055], bias:-1.6440280069000623, loss:0.5396179543062091\n",
      "epoch:4952, weight:[2.17337755 1.28727779], bias:-1.6441757165637816, loss:0.539608225018708\n",
      "epoch:4953, weight:[2.17364816 1.28732502], bias:-1.6443234101682844, loss:0.5395984967940528\n",
      "epoch:4954, weight:[2.17391876 1.28737224], bias:-1.6444710877181257, loss:0.5395887696319722\n",
      "epoch:4955, weight:[2.17418936 1.28741943], bias:-1.6446187492178583, loss:0.5395790435321939\n",
      "epoch:4956, weight:[2.17445995 1.28746661], bias:-1.6447663946720337, loss:0.5395693184944472\n",
      "epoch:4957, weight:[2.17473052 1.28751378], bias:-1.6449140240852014, loss:0.5395595945184608\n",
      "epoch:4958, weight:[2.1750011  1.28756092], bias:-1.6450616374619091, loss:0.5395498716039632\n",
      "epoch:4959, weight:[2.17527166 1.28760805], bias:-1.6452092348067031, loss:0.5395401497506842\n",
      "epoch:4960, weight:[2.17554221 1.28765516], bias:-1.6453568161241279, loss:0.5395304289583525\n",
      "epoch:4961, weight:[2.17581276 1.28770226], bias:-1.645504381418726, loss:0.5395207092266978\n",
      "epoch:4962, weight:[2.1760833  1.28774934], bias:-1.6456519306950386, loss:0.5395109905554497\n",
      "epoch:4963, weight:[2.17635383 1.2877964 ], bias:-1.645799463957605, loss:0.5395012729443377\n",
      "epoch:4964, weight:[2.17662436 1.28784344], bias:-1.6459469812109628, loss:0.5394915563930919\n",
      "epoch:4965, weight:[2.17689487 1.28789047], bias:-1.6460944824596482, loss:0.5394818409014422\n",
      "epoch:4966, weight:[2.17716538 1.28793748], bias:-1.646241967708195, loss:0.5394721264691189\n",
      "epoch:4967, weight:[2.17743588 1.28798448], bias:-1.646389436961136, loss:0.5394624130958525\n",
      "epoch:4968, weight:[2.17770637 1.28803146], bias:-1.646536890223002, loss:0.5394527007813731\n",
      "epoch:4969, weight:[2.17797685 1.28807842], bias:-1.646684327498322, loss:0.5394429895254116\n",
      "epoch:4970, weight:[2.17824733 1.28812536], bias:-1.6468317487916235, loss:0.5394332793276988\n",
      "epoch:4971, weight:[2.1785178  1.28817229], bias:-1.6469791541074323, loss:0.5394235701879657\n",
      "epoch:4972, weight:[2.17878826 1.2882192 ], bias:-1.6471265434502724, loss:0.5394138621059434\n",
      "epoch:4973, weight:[2.17905871 1.28826609], bias:-1.6472739168246662, loss:0.539404155081363\n",
      "epoch:4974, weight:[2.17932915 1.28831297], bias:-1.6474212742351342, loss:0.5393944491139561\n",
      "epoch:4975, weight:[2.17959959 1.28835983], bias:-1.6475686156861953, loss:0.5393847442034541\n",
      "epoch:4976, weight:[2.17987002 1.28840668], bias:-1.647715941182367, loss:0.539375040349589\n",
      "epoch:4977, weight:[2.18014044 1.2884535 ], bias:-1.6478632507281645, loss:0.5393653375520926\n",
      "epoch:4978, weight:[2.18041085 1.28850031], bias:-1.648010544328102, loss:0.5393556358106969\n",
      "epoch:4979, weight:[2.18068126 1.28854711], bias:-1.6481578219866915, loss:0.5393459351251337\n",
      "epoch:4980, weight:[2.18095165 1.28859389], bias:-1.6483050837084434, loss:0.5393362354951362\n",
      "epoch:4981, weight:[2.18122204 1.28864065], bias:-1.6484523294978668, loss:0.5393265369204362\n",
      "epoch:4982, weight:[2.18149242 1.28868739], bias:-1.6485995593594687, loss:0.5393168394007665\n",
      "epoch:4983, weight:[2.18176279 1.28873412], bias:-1.6487467732977543, loss:0.5393071429358599\n",
      "epoch:4984, weight:[2.18203316 1.28878083], bias:-1.6488939713172275, loss:0.5392974475254495\n",
      "epoch:4985, weight:[2.18230352 1.28882752], bias:-1.64904115342239, loss:0.5392877531692682\n",
      "epoch:4986, weight:[2.18257386 1.2888742 ], bias:-1.6491883196177428, loss:0.5392780598670494\n",
      "epoch:4987, weight:[2.18284421 1.28892086], bias:-1.649335469907784, loss:0.5392683676185265\n",
      "epoch:4988, weight:[2.18311454 1.2889675 ], bias:-1.6494826042970108, loss:0.5392586764234327\n",
      "epoch:4989, weight:[2.18338486 1.28901413], bias:-1.6496297227899184, loss:0.5392489862815025\n",
      "epoch:4990, weight:[2.18365518 1.28906074], bias:-1.6497768253910006, loss:0.5392392971924688\n",
      "epoch:4991, weight:[2.18392549 1.28910733], bias:-1.649923912104749, loss:0.5392296091560665\n",
      "epoch:4992, weight:[2.18419579 1.28915391], bias:-1.6500709829356541, loss:0.5392199221720291\n",
      "epoch:4993, weight:[2.18446608 1.28920047], bias:-1.6502180378882043, loss:0.5392102362400911\n",
      "epoch:4994, weight:[2.18473637 1.28924702], bias:-1.6503650769668865, loss:0.5392005513599872\n",
      "epoch:4995, weight:[2.18500665 1.28929354], bias:-1.650512100176186, loss:0.5391908675314518\n",
      "epoch:4996, weight:[2.18527692 1.28934005], bias:-1.6506591075205863, loss:0.5391811847542197\n",
      "epoch:4997, weight:[2.18554718 1.28938655], bias:-1.6508060990045692, loss:0.539171503028026\n",
      "epoch:4998, weight:[2.18581743 1.28943303], bias:-1.6509530746326149, loss:0.5391618223526052\n",
      "epoch:4999, weight:[2.18608768 1.28947949], bias:-1.6511000344092017, loss:0.5391521427276933\n"
     ]
    }
   ],
   "source": [
    "my_model = myNN(learning_rate=0.01, epoch=5000, loss_threshold=0.4631)\n",
    "my_model.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02563631",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class myNN:\n",
    "    def __init__(self, learning_rate, epoch, loss_threshold):\n",
    "        \"\"\"\n",
    "        Initialize the neural network model with learning rate, epochs, and loss threshold.\n",
    "        \"\"\"\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epoch = epoch\n",
    "        self.loss_threshold = loss_threshold\n",
    "        self.loss = None  # Initialize loss attribute\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        \"\"\"\n",
    "        Train the neural network using gradient descent.\n",
    "        \n",
    "        Parameters:\n",
    "            X (numpy.ndarray): Input features of shape (m, n).\n",
    "            Y (numpy.ndarray): Target labels of shape (m,).\n",
    "        \"\"\"\n",
    "        # Initialize parameters\n",
    "        self.m, self.n = X.shape\n",
    "        self.weights = np.ones(self.n)\n",
    "        self.bias = 0\n",
    "\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "        # Gradient descent loop\n",
    "        for i in range(self.epoch):\n",
    "            self.update_weights()\n",
    "\n",
    "            # Print progress\n",
    "            print(f'Epoch: {i}, Weights: {self.weights}, Bias: {self.bias}, Loss: {self.loss}')\n",
    "\n",
    "            # Early stopping condition\n",
    "            if self.loss <= self.loss_threshold:\n",
    "                print(\"Loss threshold reached. Stopping early.\")\n",
    "                break\n",
    "\n",
    "    def update_weights(self):\n",
    "        \"\"\"\n",
    "        Perform one step of gradient descent: compute gradients, update weights and bias.\n",
    "        \"\"\"\n",
    "        # Calculate predictions\n",
    "        weighted_sum = np.dot(self.X, self.weights) + self.bias\n",
    "        y_predicted = 1 / (1 + np.exp(-weighted_sum))\n",
    "\n",
    "        # Clip predictions to avoid log(0) errors\n",
    "        epsilon = 1e-15\n",
    "        y_predicted_clipped = np.clip(y_predicted, epsilon, 1 - epsilon)\n",
    "\n",
    "        # Compute log loss\n",
    "        self.loss = -np.mean(\n",
    "            self.Y * np.log(y_predicted_clipped) + (1 - self.Y) * np.log(1 - y_predicted_clipped)\n",
    "        )\n",
    "\n",
    "        # Compute gradients\n",
    "        dw = np.dot(self.X.T, (y_predicted - self.Y)) / self.m\n",
    "        db = np.mean(y_predicted - self.Y)\n",
    "\n",
    "        # Update weights and bias\n",
    "        self.weights -= self.learning_rate * dw\n",
    "        self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict probabilities using the trained model.\n",
    "        \n",
    "        Parameters:\n",
    "            X (numpy.ndarray): Input features of shape (m, n).\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray: Predicted probabilities of shape (m,).\n",
    "        \"\"\"\n",
    "        weighted_sum = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = 1 / (1 + np.exp(-weighted_sum))\n",
    "        return y_predicted\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
